{"id":34557,"repository_id":7500354,"mainLanguage":"TypeScript","file_name":"build-zo-pr.yml","file_content":"name: Build ZO PR\nrun-name: Build ZO for ${{ github.event.number }} - ${{ github.event.pull_request.title }}\n\npermissions:\n  contents: read\n\non:\n  pull_request:\n    paths-ignore:\n      - 'apps/frontend/**'\n      - 'apps/frontend-e2e/**'\n      - 'apps/gi-frontend/**'\n      - 'apps/gi-frontend-e2e/**'\n      - 'apps/sr-frontend/**'\n      - 'apps/sr-frontend-e2e/**'\n      - 'apps/somnia/**'\n      - 'apps/somnia-e2e/**'\n      - 'libs/gi/**'\n      - 'libs/sr/**'\n    types: [opened, reopened, synchronize, labeled]\n\njobs:\n  call-build:\n    uses: ./.github/workflows/build-frontend.yml\n    with:\n      frontend_name: 'zzz-frontend'\n      deployment_name: ${{ github.event.number }}\n      repo_var_name: 'PR_REPO'\n      repo_deploy_secret_name: 'PR_REPO_SSH_KEY'\n      show_dev_components: ${{ contains(github.event.pull_request.labels.*.name, 'showDevComponents') }}\n","repository_owner":"frzyc","repository_name":"genshin-optimizer","tokens_count":244,"workflow":"name: Build ZO PR\nrun-name: Build ZO for ${{ github.event.number }} - ${{ \n  github.event.pull_request.title }}\n\npermissions:\n  contents: read\n\non:\n  pull_request:\n    paths-ignore:\n    - apps/frontend/**\n    - apps/frontend-e2e/**\n    - apps/gi-frontend/**\n    - apps/gi-frontend-e2e/**\n    - apps/sr-frontend/**\n    - apps/sr-frontend-e2e/**\n    - apps/somnia/**\n    - apps/somnia-e2e/**\n    - libs/gi/**\n    - libs/sr/**\n    types: [opened, reopened, synchronize, labeled]\n\njobs:\n  call-build:\n    uses: ./.github/workflows/build-frontend.yml\n    with:\n      frontend_name: zzz-frontend\n      deployment_name: ${{ github.event.number }}\n      repo_var_name: PR_REPO\n      repo_deploy_secret_name: PR_REPO_SSH_KEY\n      show_dev_components: ${{ contains(github.event.pull_request.labels.*.name,\n        'showDevComponents') }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Build ZO PR` for a GitHub repository whose primary programming language is TypeScript. The name for workflow runs is set to `Build ZO for ${{ github.event.number }} - ${{ github.event.pull_request.title }}`. This workflow will be triggered by an event: a pull request is created, a previously closed pull request is reopened, a pull request's head branch is updated or a label is added to a pull request. When all the path names of pull_request event match patterns in the paths-ignore filter(apps/frontend/**, apps/frontend-e2e/**, apps/gi-frontend/**, apps/gi-frontend-e2e/**, apps/sr-frontend/**, apps/sr-frontend-e2e/**, apps/somnia/**, apps/somnia-e2e/**, libs/gi/** or libs/sr/**), the workflow will not run. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `call-build`. ","prompt_level2":"Generate a GitHub Workflow named `Build ZO PR` for a GitHub repository whose primary programming language is TypeScript. The name for workflow runs is set to `Build ZO for ${{ github.event.number }} - ${{ github.event.pull_request.title }}`. This workflow will be triggered by an event: a pull request is created, a previously closed pull request is reopened, a pull request's head branch is updated or a label is added to a pull request. When all the path names of pull_request event match patterns in the paths-ignore filter(apps/frontend/**, apps/frontend-e2e/**, apps/gi-frontend/**, apps/gi-frontend-e2e/**, apps/sr-frontend/**, apps/sr-frontend-e2e/**, apps/somnia/**, apps/somnia-e2e/**, libs/gi/** or libs/sr/**), the workflow will not run. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `call-build`. ","prompt_level3":"Generate a GitHub Workflow named `Build ZO PR` for a GitHub repository whose primary programming language is TypeScript. The name for workflow runs is set to `Build ZO for ${{ github.event.number }} - ${{ github.event.pull_request.title }}`. This workflow will be triggered by an event: a pull request is created, a previously closed pull request is reopened, a pull request's head branch is updated or a label is added to a pull request. When all the path names of pull_request event match patterns in the paths-ignore filter(apps/frontend/**, apps/frontend-e2e/**, apps/gi-frontend/**, apps/gi-frontend-e2e/**, apps/sr-frontend/**, apps/sr-frontend-e2e/**, apps/somnia/**, apps/somnia-e2e/**, libs/gi/** or libs/sr/**), the workflow will not run. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `call-build`. This job will call a reusable workflow located at `./.github/workflows/build-frontend.yml`. The job will pass 5 inputs to the called workflow: the input `frontend_name` is `zzz-frontend`, the input `deployment_name` is `${{ github.event.number }}`, the input `repo_var_name` is `PR_REPO`, the input `repo_deploy_secret_name` is `PR_REPO_SSH_KEY` and the input `show_dev_components` is `${{ contains(github.event.pull_request.labels.*.name, 'showDevComponents') }}`. ","nb_triggers":1,"triggers":["pull_request"],"nb_jobs":1,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["./.github/workflows/build-frontend.yml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":60597,"repository_id":16566865,"mainLanguage":"PHP","file_name":"schema-dump.yml","file_content":"name: MySQL Schema Dump (Laravel)\non: [ push, pull_request ]\njobs:\n    schema-dump:\n        strategy:\n            matrix:\n                operating-system:\n                    - ubuntu-22.04\n                php-version:\n                    - '8.4'\n        name: php ${{ matrix.php-version }} on ${{ matrix.operating-system }}\n        runs-on: ${{ matrix.operating-system }}\n        services:\n            mysql:\n                image: mysql:8.0\n                env:\n                    MYSQL_ALLOW_EMPTY_PASSWORD: yes\n                    MYSQL_DATABASE: unit3d\n                ports:\n                    - 3306:3306\n                options: --health-cmd=\"mysqladmin ping\" --health-interval=10s --health-timeout=5s --health-retries=3\n            redis:\n                image: redis:7.2.1\n                ports:\n                    - 6379:6379\n                options: >-\n                    --health-cmd \"redis-cli ping\"\n                    --health-interval 10s\n                    --health-timeout 5s\n                    --health-retries 5\n        steps:\n            -   name: Checkout\n                uses: actions/checkout@v4\n                with:\n                    fetch-depth: 0\n            -   name: Setup PHP 8.4\n                uses: shivammathur/setup-php@v2\n                with:\n                    php-version: ${{ matrix.php-version }}\n                    extensions: curl, dom, gd, libxml, mbstring, zip, mysql, xml, intl, bcmath, redis-phpredis/phpredis@6.0.1\n                    ini-values: error_reporting=E_ALL\n                    coverage: none\n                    tools: composer:v2\n                env:\n                    REDIS_CONFIGURE_OPTS: --enable-redis\n            -   name: Install Composer Dependencies\n                env:\n                    COMPOSER_AUTH: ${{ secrets.COMPOSER_AUTH }}\n                run: composer install --no-ansi --no-interaction --no-scripts --no-progress --prefer-dist\n            -   name: Prepare The Laravel Environment\n                run: cp .env.example .env\n            -   name: Generate Application Key\n                run: php artisan key:generate\n            -   name: Clear Application Cache\n                run: php artisan optimize:clear\n            -   name: Run Migrations\n                run: php artisan migrate --force --schema-path=database/schema/mysql-schema-new.sql\n                env:\n                    DB_CONNECTION: mysql\n                    DB_HOST: 127.0.0.1\n                    DB_PORT: ${{ job.services.mysql.ports['3306'] }}\n                    DB_DATABASE: unit3d\n                    DB_USERNAME: root\n                    DB_PASSWORD: null\n            -   name: Run Schema Dump\n                run: php artisan schema:dump --path=database/schema/mysql-schema-new.sql\n                env:\n                    DB_CONNECTION: mysql\n                    DB_HOST: 127.0.0.1\n                    DB_PORT: ${{ job.services.mysql.ports['3306'] }}\n                    DB_DATABASE: unit3d\n                    DB_USERNAME: root\n                    DB_PASSWORD: null\n            -   name: Check if schema has changed\n                id: diff\n                run: |\n                    if [ -f database/schema/mysql-schema.sql ] && diff -q database/schema/mysql-schema.sql database/schema/mysql-schema-new.sql > /dev/null; then\n                      echo \"No changes detected in schema\"\n                      echo \"has_changes=false\" >> $GITHUB_OUTPUT\n                    else\n                      echo \"Changes detected in schema\"\n                      echo \"has_changes=true\" >> $GITHUB_OUTPUT\n                    fi\n            -   name: Update Schema\n                if: steps.diff.outputs.has_changes == 'true'\n                run: |\n                  cp database/schema/mysql-schema-new.sql database/schema/mysql-schema.sql\n                  rm database/schema/mysql-schema-new.sql\n            -   name: Commit Schema Changes\n                if: steps.diff.outputs.has_changes == 'true'\n                uses: stefanzweifel/git-auto-commit-action@v5\n                with:\n                    commit_message: \"automation: update schema dump\"\n                    commit_user_name: unit3d-bot\n                    commit_user_email: unit3d_gh_bot@protonmail.com\n                    commit_author: unit3d-bot <unit3d_gh_bot@protonmail.com>\n","repository_owner":"hdinnovations","repository_name":"unit3d-community-edition","tokens_count":916,"workflow":"name: MySQL Schema Dump (Laravel)\non: [push, pull_request]\njobs:\n  schema-dump:\n    strategy:\n      matrix:\n        operating-system:\n        - ubuntu-22.04\n        php-version:\n        - '8.4'\n    name: php ${{ matrix.php-version }} on ${{ matrix.operating-system }}\n    runs-on: ${{ matrix.operating-system }}\n    services:\n      mysql:\n        image: mysql:8.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_DATABASE: unit3d\n        ports:\n        - 3306:3306\n        options: --health-cmd=\"mysqladmin ping\" --health-interval=10s \n          --health-timeout=5s --health-retries=3\n      redis:\n        image: redis:7.2.1\n        ports:\n        - 6379:6379\n        options: >-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v4\n      with:\n        fetch-depth: 0\n    - name: Setup PHP 8.4\n      uses: shivammathur/setup-php@v2\n      with:\n        php-version: ${{ matrix.php-version }}\n        extensions: curl, dom, gd, libxml, mbstring, zip, mysql, xml, intl, \n          bcmath, redis-phpredis/phpredis@6.0.1\n        ini-values: error_reporting=E_ALL\n        coverage: none\n        tools: composer:v2\n      env:\n        REDIS_CONFIGURE_OPTS: --enable-redis\n    - name: Install Composer Dependencies\n      env:\n        COMPOSER_AUTH: ${{ secrets.COMPOSER_AUTH }}\n      run: composer install --no-ansi --no-interaction --no-scripts \n        --no-progress --prefer-dist\n    - name: Prepare The Laravel Environment\n      run: cp .env.example .env\n    - name: Generate Application Key\n      run: php artisan key:generate\n    - name: Clear Application Cache\n      run: php artisan optimize:clear\n    - name: Run Migrations\n      run: php artisan migrate --force \n        --schema-path=database/schema/mysql-schema-new.sql\n      env:\n        DB_CONNECTION: mysql\n        DB_HOST: 127.0.0.1\n        DB_PORT: ${{ job.services.mysql.ports['3306'] }}\n        DB_DATABASE: unit3d\n        DB_USERNAME: root\n        DB_PASSWORD:\n    - name: Run Schema Dump\n      run: php artisan schema:dump --path=database/schema/mysql-schema-new.sql\n      env:\n        DB_CONNECTION: mysql\n        DB_HOST: 127.0.0.1\n        DB_PORT: ${{ job.services.mysql.ports['3306'] }}\n        DB_DATABASE: unit3d\n        DB_USERNAME: root\n        DB_PASSWORD:\n    - name: Check if schema has changed\n      id: diff\n      run: |\n        if [ -f database/schema/mysql-schema.sql ] && diff -q database/schema/mysql-schema.sql database/schema/mysql-schema-new.sql > /dev/null; then\n          echo \"No changes detected in schema\"\n          echo \"has_changes=false\" >> $GITHUB_OUTPUT\n        else\n          echo \"Changes detected in schema\"\n          echo \"has_changes=true\" >> $GITHUB_OUTPUT\n        fi\n    - name: Update Schema\n      if: steps.diff.outputs.has_changes == 'true'\n      run: |\n        cp database/schema/mysql-schema-new.sql database/schema/mysql-schema.sql\n        rm database/schema/mysql-schema-new.sql\n    - name: Commit Schema Changes\n      if: steps.diff.outputs.has_changes == 'true'\n      uses: stefanzweifel/git-auto-commit-action@v5\n      with:\n        commit_message: 'automation: update schema dump'\n        commit_user_name: unit3d-bot\n        commit_user_email: unit3d_gh_bot@protonmail.com\n        commit_author: unit3d-bot <unit3d_gh_bot@protonmail.com>\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `MySQL Schema Dump (Laravel)` for a GitHub repository whose primary programming language is PHP. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow has one job. The 1st job is named `php ${{ matrix.php-version }} on ${{ matrix.operating-system }}` and its job id is `schema-dump`. ","prompt_level2":"Generate a GitHub Workflow named `MySQL Schema Dump (Laravel)` for a GitHub repository whose primary programming language is PHP. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow has one job. The 1st job is named `php ${{ matrix.php-version }} on ${{ matrix.operating-system }}` and its job id is `schema-dump`. The job `schema-dump` has 11 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Setup PHP 8.4`. The 3rd step is named `Install Composer Dependencies`. The 4th step is named `Prepare The Laravel Environment`. The 5th step is named `Generate Application Key`. The 6th step is named `Clear Application Cache`. The 7th step is named `Run Migrations`. The 8th step is named `Run Schema Dump`. The 9th step is named `Check if schema has changed` and its id is `diff`. The 10th step is named `Update Schema`. The 11th step is named `Commit Schema Changes`. ","prompt_level3":"Generate a GitHub Workflow named `MySQL Schema Dump (Laravel)` for a GitHub repository whose primary programming language is PHP. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow has one job. The 1st job is named `php ${{ matrix.php-version }} on ${{ matrix.operating-system }}` and its job id is `schema-dump`. This job will run on ${{ matrix.operating-system }} runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `operating-system` has one value: ubuntu-22.04. The variable `php-version` has one value: 8.4. The job defines a service called mysql which will be created using the Docker image `mysql:8.0`. The service container sets 2 environment variables to use: `MYSQL_ALLOW_EMPTY_PASSWORD` is set to `True` and `MYSQL_DATABASE` is set to `unit3d`. For communication, the port 3306 on the Docker host is mapped to port 3306 on the service container. It configures additional Docker container resource options: --health-cmd=\"mysqladmin ping\" --health-interval=10s --health-timeout=5s --health-retries=3. The job defines a service called redis which will be created using the Docker image `redis:7.2.1`. For communication, the port 6379 on the Docker host is mapped to port 6379 on the service container. It configures additional Docker container resource options: --health-cmd \"redis-cli ping\" --health-interval 10s --health-timeout 5s --health-retries 5. The job `schema-dump` has 11 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `fetch-depth` is set to `0`. The 2nd step is named `Setup PHP 8.4`. The step sets an environment variable to use: `REDIS_CONFIGURE_OPTS` is set to `--enable-redis`. This step runs action `shivammathur/setup-php` tagged as v2. The step defines 5 input parameters for the action: `php-version` is set to `${{ matrix.php-version }}`, `extensions` is set to `curl, dom, gd, libxml, mbstring, zip, mysql, xml, intl, bcmath, redis-phpredis/phpredis@6.0.1`, `ini-values` is set to `error_reporting=E_ALL`, `coverage` is set to `none` and `tools` is set to `composer:v2`. The 3rd step is named `Install Composer Dependencies`. The step sets an environment variable to use: `COMPOSER_AUTH` is set to `${{ secrets.COMPOSER_AUTH }}`. This step runs a script: `composer install --no-ansi --no-interaction --no-scripts --no-progress --prefer-dist`. The 4th step is named `Prepare The Laravel Environment`. This step runs a script: `cp .env.example .env`. The 5th step is named `Generate Application Key`. This step runs a script: `php artisan key:generate`. The 6th step is named `Clear Application Cache`. This step runs a script: `php artisan optimize:clear`. The 7th step is named `Run Migrations`. The step sets 6 environment variables to use: `DB_CONNECTION` is set to `mysql`, `DB_HOST` is set to `127.0.0.1`, `DB_PORT` is set to `${{ job.services.mysql.ports['3306'] }}`, `DB_DATABASE` is set to `unit3d`, `DB_USERNAME` is set to `root` and `DB_PASSWORD` is set to `None`. This step runs a script: `php artisan migrate --force --schema-path=database/schema/mysql-schema-new.sql`. The 8th step is named `Run Schema Dump`. The step sets 6 environment variables to use: `DB_CONNECTION` is set to `mysql`, `DB_HOST` is set to `127.0.0.1`, `DB_PORT` is set to `${{ job.services.mysql.ports['3306'] }}`, `DB_DATABASE` is set to `unit3d`, `DB_USERNAME` is set to `root` and `DB_PASSWORD` is set to `None`. This step runs a script: `php artisan schema:dump --path=database/schema/mysql-schema-new.sql`. The 9th step is named `Check if schema has changed` and its id is `diff`. This step runs a script: `if [ -f database/schema/mysql-schema.sql ] && diff -q database/schema/mysql-schema.sql database/schema/mysql-schema-new.sql > /dev/null; then\n  echo \"No changes detected in schema\"\n  echo \"has_changes=false\" >> $GITHUB_OUTPUT\nelse\n  echo \"Changes detected in schema\"\n  echo \"has_changes=true\" >> $GITHUB_OUTPUT\nfi\n`. The 10th step is named `Update Schema`. This step will run only if the condition(steps.diff.outputs.has_changes == 'true') is met. This step runs a script: `cp database/schema/mysql-schema-new.sql database/schema/mysql-schema.sql\nrm database/schema/mysql-schema-new.sql\n`. The 11th step is named `Commit Schema Changes`. This step will run only if the condition(steps.diff.outputs.has_changes == 'true') is met. This step runs action `stefanzweifel/git-auto-commit-action` tagged as v5. The step defines 4 input parameters for the action: `commit_message` is set to `automation: update schema dump`, `commit_user_name` is set to `unit3d-bot`, `commit_user_email` is set to `unit3d_gh_bot@protonmail.com` and `commit_author` is set to `unit3d-bot <unit3d_gh_bot@protonmail.com>`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":1,"nb_actions":3,"actions":["actions/checkout","shivammathur/setup-php","stefanzweifel/git-auto-commit-action"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v2","name":"shivammathur/setup-php"},{"version":"v5","name":"stefanzweifel/git-auto-commit-action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":11,"cyclomatic_complexity":1}
{"id":43394,"repository_id":94616208,"mainLanguage":"Go","file_name":"deploy-docsite.yml","file_content":"name: Docsite and Storybook CI/CD\n\nrun-name: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' && 'Build and Deploy' || 'Test Build' }} Docsite and Storybook\n\nenv:\n    NODE_VERSION: 22\n\non:\n    push:\n        branches:\n            - main\n    workflow_dispatch:\n    # Also run any time a PR is opened targeting the docs or storybook resources\n    pull_request:\n        branches:\n            - main\n        types:\n            - opened\n            - synchronize\n            - reopened\n            - ready_for_review\n        paths:\n            - \"docs/**\"\n            - \"storybook/**\"\n            - \"**/*.story.*\"\n            - \"**/*.stories.*\"\n            - \".github/workflows/deploy-docsite.yml\"\n            - \"Taskfile.yml\"\n\njobs:\n    build:\n        name: Build Docsite\n        runs-on: ubuntu-latest\n        if: github.event.pull_request.draft == false\n        steps:\n            - uses: actions/checkout@v4\n              with:\n                  fetch-depth: 0\n            - uses: actions/setup-node@v4\n              with:\n                  node-version: ${{env.NODE_VERSION}}\n            - name: Install Task\n              uses: arduino/setup-task@v2\n              with:\n                  version: 3.x\n                  repo-token: ${{ secrets.GITHUB_TOKEN }}\n            - name: Install yarn\n              run: |\n                  corepack enable\n                  yarn install\n            - name: Build docsite\n              run: task docsite:build:public\n            - name: Upload Build Artifact\n              # Only upload the build artifact when pushed to the main branch\n              if: github.event_name == 'push' && github.ref == 'refs/heads/main'\n              uses: actions/upload-pages-artifact@v3\n              with:\n                  path: docs/build\n    deploy:\n        name: Deploy to GitHub Pages\n        # Only deploy when pushed to the main branch\n        if: github.event_name == 'push' && github.ref == 'refs/heads/main'\n        needs: build\n        # Grant GITHUB_TOKEN the permissions required to make a Pages deployment\n        permissions:\n            pages: write # to deploy to Pages\n            id-token: write # to verify the deployment originates from an appropriate source\n\n        # Deploy to the github-pages environment\n        environment:\n            name: github-pages\n            url: ${{ steps.deployment.outputs.page_url }}\n\n        runs-on: ubuntu-latest\n        steps:\n            - name: Deploy to GitHub Pages\n              id: deployment\n              uses: actions/deploy-pages@v4\n","repository_owner":"wavetermdev","repository_name":"waveterm","tokens_count":553,"workflow":"name: Docsite and Storybook CI/CD\n\nrun-name: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' && \n  'Build and Deploy' || 'Test Build' }} Docsite and Storybook\n\nenv:\n  NODE_VERSION: 22\n\non:\n  push:\n    branches:\n    - main\n  workflow_dispatch:\n    # Also run any time a PR is opened targeting the docs or storybook resources\n  pull_request:\n    branches:\n    - main\n    types:\n    - opened\n    - synchronize\n    - reopened\n    - ready_for_review\n    paths:\n    - docs/**\n    - storybook/**\n    - '**/*.story.*'\n    - '**/*.stories.*'\n    - .github/workflows/deploy-docsite.yml\n    - Taskfile.yml\n\njobs:\n  build:\n    name: Build Docsite\n    runs-on: ubuntu-latest\n    if: github.event.pull_request.draft == false\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      with:\n        fetch-depth: 0\n    - name: Setup Node ${{env.NODE_VERSION}}\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{env.NODE_VERSION}}\n    - name: Install Task\n      uses: arduino/setup-task@v2\n      with:\n        version: 3.x\n        repo-token: ${{ secrets.GITHUB_TOKEN }}\n    - name: Install yarn\n      run: |\n        corepack enable\n        yarn install\n    - name: Build docsite\n      run: task docsite:build:public\n    - name: Upload Build Artifact\n              # Only upload the build artifact when pushed to the main branch\n      if: github.event_name == 'push' && github.ref == 'refs/heads/main'\n      uses: actions/upload-pages-artifact@v3\n      with:\n        path: docs/build\n  deploy:\n    name: Deploy to GitHub Pages\n        # Only deploy when pushed to the main branch\n    if: github.event_name == 'push' && github.ref == 'refs/heads/main'\n    needs: build\n        # Grant GITHUB_TOKEN the permissions required to make a Pages deployment\n    permissions:\n      pages: write       # to deploy to Pages\n      id-token: write       # to verify the deployment originates from an appropriate source\n\n        # Deploy to the github-pages environment\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n\n    runs-on: ubuntu-latest\n    steps:\n    - name: Deploy to GitHub Pages\n      id: deployment\n      uses: actions/deploy-pages@v4\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Docsite and Storybook CI/CD` for a GitHub repository whose primary programming language is Go. The name for workflow runs is set to `${{ github.event_name == 'push' && github.ref == 'refs/heads/main' && 'Build and Deploy' || 'Test Build' }} Docsite and Storybook`. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main. 2) someone manually triggers the workflow. 3) a pull request is created, a pull request's head branch is updated, a previously closed pull request is reopened or a draft pull request is marked as ready for review. The workflow would run whenever there is a pull_request event targeting: a branch named main. Only if at least one path of pull_request event matches a pattern in the paths filter(docs/**, storybook/**, **/*.story.*, **/*.stories.*, .github/workflows/deploy-docsite.yml or Taskfile.yml), the workflow runs. The workflow sets an environment variable to use: `NODE_VERSION` is set to `22`. The workflow has 2 jobs. The 1st job is named `Build Docsite` and its job id is `build`. The 2nd job is named `Deploy to GitHub Pages` and its job id is `deploy`. ","prompt_level2":"Generate a GitHub Workflow named `Docsite and Storybook CI/CD` for a GitHub repository whose primary programming language is Go. The name for workflow runs is set to `${{ github.event_name == 'push' && github.ref == 'refs/heads/main' && 'Build and Deploy' || 'Test Build' }} Docsite and Storybook`. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main. 2) someone manually triggers the workflow. 3) a pull request is created, a pull request's head branch is updated, a previously closed pull request is reopened or a draft pull request is marked as ready for review. The workflow would run whenever there is a pull_request event targeting: a branch named main. Only if at least one path of pull_request event matches a pattern in the paths filter(docs/**, storybook/**, **/*.story.*, **/*.stories.*, .github/workflows/deploy-docsite.yml or Taskfile.yml), the workflow runs. The workflow sets an environment variable to use: `NODE_VERSION` is set to `22`. The workflow has 2 jobs. The 1st job is named `Build Docsite` and its job id is `build`. The job `build` has 6 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Setup Node ${{env.NODE_VERSION}}`. The 3rd step is named `Install Task`. The 4th step is named `Install yarn`. The 5th step is named `Build docsite`. The 6th step is named `Upload Build Artifact`. The 2nd job is named `Deploy to GitHub Pages` and its job id is `deploy`. The job `deploy` has one step. The 1st step is named `Deploy to GitHub Pages` and its id is `deployment`. ","prompt_level3":"Generate a GitHub Workflow named `Docsite and Storybook CI/CD` for a GitHub repository whose primary programming language is Go. The name for workflow runs is set to `${{ github.event_name == 'push' && github.ref == 'refs/heads/main' && 'Build and Deploy' || 'Test Build' }} Docsite and Storybook`. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main. 2) someone manually triggers the workflow. 3) a pull request is created, a pull request's head branch is updated, a previously closed pull request is reopened or a draft pull request is marked as ready for review. The workflow would run whenever there is a pull_request event targeting: a branch named main. Only if at least one path of pull_request event matches a pattern in the paths filter(docs/**, storybook/**, **/*.story.*, **/*.stories.*, .github/workflows/deploy-docsite.yml or Taskfile.yml), the workflow runs. The workflow sets an environment variable to use: `NODE_VERSION` is set to `22`. The workflow has 2 jobs. The 1st job is named `Build Docsite` and its job id is `build`. This job will run only if the condition(github.event.pull_request.draft == false) is met. This job will run on ubuntu-latest runner. The job `build` has 6 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `fetch-depth` is set to `0`. The 2nd step is named `Setup Node ${{env.NODE_VERSION}}`. This step runs action `actions/setup-node` tagged as v4. The step defines an input parameter for the action: `node-version` is set to `${{env.NODE_VERSION}}`. The 3rd step is named `Install Task`. This step runs action `arduino/setup-task` tagged as v2. The step defines 2 input parameters for the action: `version` is set to `3.x` and `repo-token` is set to `${{ secrets.GITHUB_TOKEN }}`. The 4th step is named `Install yarn`. This step runs a script: `corepack enable\nyarn install\n`. The 5th step is named `Build docsite`. This step runs a script: `task docsite:build:public`. The 6th step is named `Upload Build Artifact`. This step will run only if the condition(github.event_name == 'push' && github.ref == 'refs/heads/main') is met. This step runs action `actions/upload-pages-artifact` tagged as v3. The step defines an input parameter for the action: `path` is set to `docs/build`. The 2nd job is named `Deploy to GitHub Pages` and its job id is `deploy`. Before this job runs, `build` must complete successfully. This job will run only if the condition(github.event_name == 'push' && github.ref == 'refs/heads/main') is met. This job will run on ubuntu-latest runner. The job `deploy` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `pages` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting only applies to the job `deploy`. This job references github-pages environment whose url is ${{ steps.deployment.outputs.page_url }}. The job `deploy` has one step. The 1st step is named `Deploy to GitHub Pages` and its id is `deployment`. This step runs action `actions/deploy-pages` tagged as v4. ","nb_triggers":3,"triggers":["pull_request","push","workflow_dispatch"],"nb_jobs":2,"nb_actions":5,"actions":["actions/checkout","actions/deploy-pages","actions/setup-node","actions/upload-pages-artifact","arduino/setup-task"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/setup-node"},{"version":"v2","name":"arduino/setup-task"},{"version":"v3","name":"actions/upload-pages-artifact"},{"version":"v4","name":"actions/deploy-pages"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":7,"cyclomatic_complexity":1}
{"id":59047,"repository_id":94532470,"mainLanguage":"Python","file_name":"bootstrap_region.yml","file_content":"name: Region Bootstrap\n\n# bootstraps new regions\n#\n# PURPOSE\n# Ensures new regions are deployable in future releases\n#\n# JOB 1 PROCESS\n#\n# 1. Installs CDK\n# 2. Bootstraps region\n#\n# JOB 2 PROCESS\n# 1. Sets up Go\n# 2. Installs the balance script\n# 3. Runs balance script to copy layers between aws regions\n\non:\n  workflow_dispatch:\n    inputs:\n      environment:\n        type: choice\n        options:\n          - beta\n          - prod\n        description: Deployment environment\n      region:\n        type: string\n        required: true\n        description: AWS region to bootstrap (i.e. eu-west-1)\n\nrun-name: Region Bootstrap ${{ inputs.region }}\n\npermissions:\n  contents: read\n\njobs:\n  cdk:\n    name: Install CDK\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      id-token: write\n    environment: layer-${{ inputs.environment }}\n    steps:\n      - id: credentials\n        name: AWS Credentials\n        uses: aws-actions/configure-aws-credentials@f24d7193d98baebaeacc7e2227925dd47cc267f5 # v4.2.0\n        with:\n          aws-region: ${{ inputs.region }}\n          role-to-assume: ${{ secrets.REGION_IAM_ROLE }}\n          mask-aws-account-id: true\n      - id: workdir\n        name: Create Workdir\n        run: |\n          mkdir -p build/project\n      - id: cdk-install\n        name: Install CDK\n        working-directory: build\n        run: |\n          npm i aws-cdk\n      - id: cdk-project\n        name: CDK Project\n        working-directory: build/project\n        run: |\n          npx cdk init app --language=typescript\n          AWS_REGION=\"${{ inputs.region }}\" npx cdk bootstrap\n\n  copy_layers:\n    name: Copy Layers\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      id-token: write\n    strategy:\n      matrix:\n        layer:\n          - AWSLambdaPowertoolsPythonV3-python39-arm64\n          - AWSLambdaPowertoolsPythonV3-python310-arm64\n          - AWSLambdaPowertoolsPythonV3-python311-arm64\n          - AWSLambdaPowertoolsPythonV3-python312-arm64\n          - AWSLambdaPowertoolsPythonV3-python313-arm64\n          - AWSLambdaPowertoolsPythonV3-python39-x86_64\n          - AWSLambdaPowertoolsPythonV3-python310-x86_64\n          - AWSLambdaPowertoolsPythonV3-python311-x86_64\n          - AWSLambdaPowertoolsPythonV3-python312-x86_64\n          - AWSLambdaPowertoolsPythonV3-python313-x86_64\n    environment: layer-${{ inputs.environment }}\n    steps:\n      - id: credentials\n        name: AWS Credentials\n        uses: aws-actions/configure-aws-credentials@f24d7193d98baebaeacc7e2227925dd47cc267f5 # v4.2.0\n        with:\n          aws-region: us-east-1\n          role-to-assume: ${{ secrets.REGION_IAM_ROLE }}\n          mask-aws-account-id: true\n      - id: go-setup\n        name: Setup Go\n        uses: actions/setup-go@d35c59abb061a4a6fb18e82ac0862c26744d6ab5 # v5.5.0\n      - id: go-env\n        name: Go Env\n        run: go env\n      - id: go-install-pkg\n        name: Install\n        run: go install github.com/aws-powertools/actions/layer-balancer/cmd/balance@latest\n      - id: run-balance\n        name: Run Balance\n        run: balance -read-region us-east-1 -write-region ${{ inputs.region }} -write-role ${{ secrets.BALANCE_ROLE_ARN }} -layer-name ${{ matrix.layer }} -dry-run=false\n","repository_owner":"aws-powertools","repository_name":"powertools-lambda-python","tokens_count":943,"workflow":"name: Region Bootstrap\n\n# bootstraps new regions\n#\n# PURPOSE\n# Ensures new regions are deployable in future releases\n#\n# JOB 1 PROCESS\n#\n# 1. Installs CDK\n# 2. Bootstraps region\n#\n# JOB 2 PROCESS\n# 1. Sets up Go\n# 2. Installs the balance script\n# 3. Runs balance script to copy layers between aws regions\n\non:\n  workflow_dispatch:\n    inputs:\n      environment:\n        type: choice\n        options:\n        - beta\n        - prod\n        description: Deployment environment\n      region:\n        type: string\n        required: true\n        description: AWS region to bootstrap (i.e. eu-west-1)\n\nrun-name: Region Bootstrap ${{ inputs.region }}\n\npermissions:\n  contents: read\n\njobs:\n  cdk:\n    name: Install CDK\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      id-token: write\n    environment: layer-${{ inputs.environment }}\n    steps:\n    - id: credentials\n      name: AWS Credentials\n      uses: \n        aws-actions/configure-aws-credentials@f24d7193d98baebaeacc7e2227925dd47cc267f5       # v4.2.0\n      with:\n        aws-region: ${{ inputs.region }}\n        role-to-assume: ${{ secrets.REGION_IAM_ROLE }}\n        mask-aws-account-id: true\n    - id: workdir\n      name: Create Workdir\n      run: |\n        mkdir -p build/project\n    - id: cdk-install\n      name: Install CDK\n      working-directory: build\n      run: |\n        npm i aws-cdk\n    - id: cdk-project\n      name: CDK Project\n      working-directory: build/project\n      run: |\n        npx cdk init app --language=typescript\n        AWS_REGION=\"${{ inputs.region }}\" npx cdk bootstrap\n\n  copy_layers:\n    name: Copy Layers\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      id-token: write\n    strategy:\n      matrix:\n        layer:\n        - AWSLambdaPowertoolsPythonV3-python39-arm64\n        - AWSLambdaPowertoolsPythonV3-python310-arm64\n        - AWSLambdaPowertoolsPythonV3-python311-arm64\n        - AWSLambdaPowertoolsPythonV3-python312-arm64\n        - AWSLambdaPowertoolsPythonV3-python313-arm64\n        - AWSLambdaPowertoolsPythonV3-python39-x86_64\n        - AWSLambdaPowertoolsPythonV3-python310-x86_64\n        - AWSLambdaPowertoolsPythonV3-python311-x86_64\n        - AWSLambdaPowertoolsPythonV3-python312-x86_64\n        - AWSLambdaPowertoolsPythonV3-python313-x86_64\n    environment: layer-${{ inputs.environment }}\n    steps:\n    - id: credentials\n      name: AWS Credentials\n      uses: \n        aws-actions/configure-aws-credentials@f24d7193d98baebaeacc7e2227925dd47cc267f5       # v4.2.0\n      with:\n        aws-region: us-east-1\n        role-to-assume: ${{ secrets.REGION_IAM_ROLE }}\n        mask-aws-account-id: true\n    - id: go-setup\n      name: Setup Go\n      uses: actions/setup-go@d35c59abb061a4a6fb18e82ac0862c26744d6ab5   # v5.5.0\n    - id: go-env\n      name: Go Env\n      run: go env\n    - id: go-install-pkg\n      name: Install\n      run: go install \n        github.com/aws-powertools/actions/layer-balancer/cmd/balance@latest\n    - id: run-balance\n      name: Run Balance\n      run: balance -read-region us-east-1 -write-region ${{ inputs.region }} \n        -write-role ${{ secrets.BALANCE_ROLE_ARN }} -layer-name ${{ matrix.layer\n        }} -dry-run=false\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Region Bootstrap` for a GitHub repository whose primary programming language is Python. The name for workflow runs is set to `Region Bootstrap ${{ inputs.region }}`. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 2 inputs: environment-the data type is choice, it has options including beta and prod and this input represents deployment environment; region-the data type is string, it must be supplied and this input represents aws region to bootstrap (i.e. eu-west-1). The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 2 jobs. The 1st job is named `Install CDK` and its job id is `cdk`. The 2nd job is named `Copy Layers` and its job id is `copy_layers`. ","prompt_level2":"Generate a GitHub Workflow named `Region Bootstrap` for a GitHub repository whose primary programming language is Python. The name for workflow runs is set to `Region Bootstrap ${{ inputs.region }}`. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 2 inputs: environment-the data type is choice, it has options including beta and prod and this input represents deployment environment; region-the data type is string, it must be supplied and this input represents aws region to bootstrap (i.e. eu-west-1). The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 2 jobs. The 1st job is named `Install CDK` and its job id is `cdk`. The job `cdk` has 4 steps. The 1st step is named `AWS Credentials` and its id is `credentials`. The 2nd step is named `Create Workdir` and its id is `workdir`. The 3rd step is named `Install CDK` and its id is `cdk-install`. The 4th step is named `CDK Project` and its id is `cdk-project`. The 2nd job is named `Copy Layers` and its job id is `copy_layers`. The job `copy_layers` has 5 steps. The 1st step is named `AWS Credentials` and its id is `credentials`. The 2nd step is named `Setup Go` and its id is `go-setup`. The 3rd step is named `Go Env` and its id is `go-env`. The 4th step is named `Install` and its id is `go-install-pkg`. The 5th step is named `Run Balance` and its id is `run-balance`. ","prompt_level3":"Generate a GitHub Workflow named `Region Bootstrap` for a GitHub repository whose primary programming language is Python. The name for workflow runs is set to `Region Bootstrap ${{ inputs.region }}`. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 2 inputs: environment-the data type is choice, it has options including beta and prod and this input represents deployment environment; region-the data type is string, it must be supplied and this input represents aws region to bootstrap (i.e. eu-west-1). The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 2 jobs. The 1st job is named `Install CDK` and its job id is `cdk`. This job will run on ubuntu-latest runner. The job `cdk` modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting only applies to the job `cdk`. This job references layer-${{ inputs.environment }} environment. The job `cdk` has 4 steps. The 1st step is named `AWS Credentials` and its id is `credentials`. This step runs action `aws-actions/configure-aws-credentials` whose commit is f24d7193d98baebaeacc7e2227925dd47cc267f5. The step defines 3 input parameters for the action: `aws-region` is set to `${{ inputs.region }}`, `role-to-assume` is set to `${{ secrets.REGION_IAM_ROLE }}` and `mask-aws-account-id` is set to `True`. The 2nd step is named `Create Workdir` and its id is `workdir`. This step runs a script: `mkdir -p build/project\n`. The 3rd step is named `Install CDK` and its id is `cdk-install`. This step runs a script: `npm i aws-cdk\n`. The 4th step is named `CDK Project` and its id is `cdk-project`. This step runs a script: `npx cdk init app --language=typescript\nAWS_REGION=\"${{ inputs.region }}\" npx cdk bootstrap\n`. The 2nd job is named `Copy Layers` and its job id is `copy_layers`. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `layer` has 10 values: AWSLambdaPowertoolsPythonV3-python39-arm64, AWSLambdaPowertoolsPythonV3-python310-arm64, AWSLambdaPowertoolsPythonV3-python311-arm64, AWSLambdaPowertoolsPythonV3-python312-arm64, AWSLambdaPowertoolsPythonV3-python313-arm64, AWSLambdaPowertoolsPythonV3-python39-x86_64, AWSLambdaPowertoolsPythonV3-python310-x86_64, AWSLambdaPowertoolsPythonV3-python311-x86_64, AWSLambdaPowertoolsPythonV3-python312-x86_64 and AWSLambdaPowertoolsPythonV3-python313-x86_64. The job `copy_layers` modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting only applies to the job `copy_layers`. This job references layer-${{ inputs.environment }} environment. The job `copy_layers` has 5 steps. The 1st step is named `AWS Credentials` and its id is `credentials`. This step runs action `aws-actions/configure-aws-credentials` whose commit is f24d7193d98baebaeacc7e2227925dd47cc267f5. The step defines 3 input parameters for the action: `aws-region` is set to `us-east-1`, `role-to-assume` is set to `${{ secrets.REGION_IAM_ROLE }}` and `mask-aws-account-id` is set to `True`. The 2nd step is named `Setup Go` and its id is `go-setup`. This step runs action `actions/setup-go` whose commit is d35c59abb061a4a6fb18e82ac0862c26744d6ab5. The 3rd step is named `Go Env` and its id is `go-env`. This step runs a script: `go env`. The 4th step is named `Install` and its id is `go-install-pkg`. This step runs a script: `go install github.com/aws-powertools/actions/layer-balancer/cmd/balance@latest`. The 5th step is named `Run Balance` and its id is `run-balance`. This step runs a script: `balance -read-region us-east-1 -write-region ${{ inputs.region }} -write-role ${{ secrets.BALANCE_ROLE_ARN }} -layer-name ${{ matrix.layer }} -dry-run=false`. ","nb_triggers":1,"triggers":["workflow_dispatch"],"nb_jobs":2,"nb_actions":3,"actions":["actions/setup-go","aws-actions/configure-aws-credentials","aws-actions/configure-aws-credentials"],"actions_details":[{"version":"f24d7193d98baebaeacc7e2227925dd47cc267f5","name":"aws-actions/configure-aws-credentials"},{"version":"f24d7193d98baebaeacc7e2227925dd47cc267f5","name":"aws-actions/configure-aws-credentials"},{"version":"d35c59abb061a4a6fb18e82ac0862c26744d6ab5","name":"actions/setup-go"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":9,"cyclomatic_complexity":2}
{"id":41115,"repository_id":94523916,"mainLanguage":"JavaScript","file_name":"deploy-hl7-vpn-tunnel-cdk-production.yml","file_content":"name: Deploy HL7 VPN Tunnel - Production\n\non:\n  workflow_dispatch:\n    inputs:\n      partner_name:\n        description: \"The partner we're deploying the tunnel for, e.g. 'MyTestHIE'\"\n        required: true\n        type: string\n\njobs:\n  deploy:\n    uses: ./.github/workflows/_deploy-hl7-vpn-tunnel-cdk.yml\n    with:\n      deploy_env: production\n      partner_name: ${{ github.event.inputs.partner_name }}\n      secrets_cdk_stack: ${{ vars.SECRET_STACK_NAME_PRODUCTION }}\n      AWS_REGION: ${{ vars.API_REGION_PRODUCTION }}\n    secrets:\n      SERVICE_PAT: ${{ secrets.SERVICE_PAT }}\n      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}\n      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n      SENTRY_AUTH_TOKEN: ${{ secrets.SENTRY_AUTH_TOKEN }}\n      SENTRY_ORG: ${{ secrets.SENTRY_ORG }}\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n","repository_owner":"metriport","repository_name":"metriport","tokens_count":237,"workflow":"name: Deploy HL7 VPN Tunnel - Production\n\non:\n  workflow_dispatch:\n    inputs:\n      partner_name:\n        description: The partner we're deploying the tunnel for, e.g. \n          'MyTestHIE'\n        required: true\n        type: string\n\njobs:\n  deploy:\n    uses: ./.github/workflows/_deploy-hl7-vpn-tunnel-cdk.yml\n    with:\n      deploy_env: production\n      partner_name: ${{ github.event.inputs.partner_name }}\n      secrets_cdk_stack: ${{ vars.SECRET_STACK_NAME_PRODUCTION }}\n      AWS_REGION: ${{ vars.API_REGION_PRODUCTION }}\n    secrets:\n      SERVICE_PAT: ${{ secrets.SERVICE_PAT }}\n      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}\n      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n      SENTRY_AUTH_TOKEN: ${{ secrets.SENTRY_AUTH_TOKEN }}\n      SENTRY_ORG: ${{ secrets.SENTRY_ORG }}\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Deploy HL7 VPN Tunnel - Production` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives an input: partner_name-this input represents the partner we're deploying the tunnel for, e.g. 'mytesthie', it must be supplied and the data type is string. The workflow has one job. The job id of the 1st job is `deploy`. ","prompt_level2":"Generate a GitHub Workflow named `Deploy HL7 VPN Tunnel - Production` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives an input: partner_name-this input represents the partner we're deploying the tunnel for, e.g. 'mytesthie', it must be supplied and the data type is string. The workflow has one job. The job id of the 1st job is `deploy`. ","prompt_level3":"Generate a GitHub Workflow named `Deploy HL7 VPN Tunnel - Production` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives an input: partner_name-this input represents the partner we're deploying the tunnel for, e.g. 'mytesthie', it must be supplied and the data type is string. The workflow has one job. The job id of the 1st job is `deploy`. This job will call a reusable workflow located at `./.github/workflows/_deploy-hl7-vpn-tunnel-cdk.yml`. The job will pass 4 inputs to the called workflow: the input `deploy_env` is `production`, the input `partner_name` is `${{ github.event.inputs.partner_name }}`, the input `secrets_cdk_stack` is `${{ vars.SECRET_STACK_NAME_PRODUCTION }}` and the input `AWS_REGION` is `${{ vars.API_REGION_PRODUCTION }}`. The job will pass 7 secrets to the called workflow: the secret `SERVICE_PAT` is `${{ secrets.SERVICE_PAT }}`, the secret `AWS_ACCESS_KEY_ID` is `${{ secrets.AWS_ACCESS_KEY_ID }}`, the secret `AWS_SECRET_ACCESS_KEY` is `${{ secrets.AWS_SECRET_ACCESS_KEY }}`, the secret `SENTRY_AUTH_TOKEN` is `${{ secrets.SENTRY_AUTH_TOKEN }}`, the secret `SENTRY_ORG` is `${{ secrets.SENTRY_ORG }}`, the secret `DOCKERHUB_USERNAME` is `${{ secrets.DOCKERHUB_USERNAME }}` and the secret `DOCKERHUB_TOKEN` is `${{ secrets.DOCKERHUB_TOKEN }}`. ","nb_triggers":1,"triggers":["workflow_dispatch"],"nb_jobs":1,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["./.github/workflows/_deploy-hl7-vpn-tunnel-cdk.yml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":20020,"repository_id":95144345,"mainLanguage":"C++","file_name":"pipeline.yml","file_content":"name: Deployment\n'on':\n  workflow_dispatch:\n    inputs:\n      date:\n        description: Build date\n        required: true\n        type: string\n      prerelease:\n        description: This is a pre-release\n        required: true\n        type: string\n      tags:\n        description: Tag a release\n        required: true\n        type: string\njobs:\n  build:\n    name: Build\n    uses: ./.github/workflows/build.yml\n    secrets:\n      AWS_ACCESS_KEY_ID: '${{ secrets.CF_ACCESS_KEY_ID }}'\n      AWS_SECRET_ACCESS_KEY: '${{ secrets.CF_ACCESS_KEY_SECRET }}'\n      AZURE_CLIENT_ID: '${{ secrets.AZURE_CLIENT_ID }}'\n      AZURE_CRT: '${{ secrets.AZURE_CRT }}'\n      AZURE_SUBSCRIPTION_ID: '${{ secrets.AZURE_SUBSCRIPTION_ID }}'\n      AZURE_TENANT_ID: '${{ secrets.AZURE_TENANT_ID }}'\n      AZURE_VAULT_ID: '${{ secrets.AZURE_VAULT_ID }}'\n      CF_ENDPOINT: '${{ secrets.CF_ENDPOINT }}'\n      MACOS_CERTIFICATE: '${{ secrets.MACOS_CERTIFICATE }}'\n      MACOS_CERTIFICATE_NAME: '${{ secrets.MACOS_CERTIFICATE_NAME }}'\n      MACOS_CERTIFICATE_PWD: '${{ secrets.MACOS_CERTIFICATE_PWD }}'\n      MACOS_CI_KEYCHAIN_PWD: '${{ secrets.MACOS_CI_KEYCHAIN_PWD }}'\n      MACOS_NOTARIZATION_APPLE_ID: '${{ secrets.MACOS_NOTARIZATION_APPLE_ID }}'\n      MACOS_NOTARIZATION_PWD: '${{ secrets.MACOS_NOTARIZATION_PWD }}'\n      MACOS_NOTARIZATION_TEAM_ID: '${{ secrets.MACOS_NOTARIZATION_TEAM_ID }}'\n      MOZ_API_KEY: '${{ secrets.MOZ_API_KEY }}'\n      ONE_PEM: '${{ secrets.ONE_PEM }}'\n      SIGN_BASE64: '${{ secrets.SIGN_BASE64 }}'\n    with:\n      MOZ_BUILD_DATE: '${{ github.event.inputs.date }}'\n      PRE_RELEASE: '${{ github.event.inputs.prerelease }}'\n      TAG_VERSION: '${{ github.event.inputs.tags }}'\n      TRIGGER_EVENT: '${{ github.event_name }}'\n  stage:\n    name: Deploy to Staging\n    uses: ./.github/workflows/stage.yml\n    needs: build\n    secrets:\n      AWS_ACCESS_KEY_ID: '${{ secrets.CF_ACCESS_KEY_ID }}'\n      AWS_SECRET_ACCESS_KEY: '${{ secrets.CF_ACCESS_KEY_SECRET }}'\n      CF_ENDPOINT: '${{ secrets.CF_ENDPOINT }}'\n    with:\n      DISPLAY_VERSION: '${{ github.event.inputs.tags }}'\n      PRE_RELEASE: '${{ github.event.inputs.prerelease }}'\n  production:\n    name: Deploy to Production\n    uses: ./.github/workflows/production.yml\n    needs: stage\n    secrets:\n      AWS_ACCESS_KEY_ID: '${{ secrets.CF_ACCESS_KEY_ID }}'\n      AWS_SECRET_ACCESS_KEY: '${{ secrets.CF_ACCESS_KEY_SECRET }}'\n      CF_AUTH: '${{ secrets.BULK_REDIRECT_TOKEN }}'\n      CF_ENDPOINT: '${{ secrets.CF_ENDPOINT }}'\n      CF_ZONE_ID: '${{ secrets.CF_ZONE_ID }}'\n    with:\n      COMMIT_SHA: '${{ github.sha }}'\n      PRE_RELEASE: '${{ github.event.inputs.prerelease }}'\n      DISPLAY_VERSION: '${{ github.event.inputs.tags }}'\n","repository_owner":"BrowserWorks","repository_name":"Waterfox","tokens_count":719,"workflow":"name: Deployment\non:\n  workflow_dispatch:\n    inputs:\n      date:\n        description: Build date\n        required: true\n        type: string\n      prerelease:\n        description: This is a pre-release\n        required: true\n        type: string\n      tags:\n        description: Tag a release\n        required: true\n        type: string\njobs:\n  build:\n    name: Build\n    uses: ./.github/workflows/build.yml\n    secrets:\n      AWS_ACCESS_KEY_ID: ${{ secrets.CF_ACCESS_KEY_ID }}\n      AWS_SECRET_ACCESS_KEY: ${{ secrets.CF_ACCESS_KEY_SECRET }}\n      AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}\n      AZURE_CRT: ${{ secrets.AZURE_CRT }}\n      AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\n      AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}\n      AZURE_VAULT_ID: ${{ secrets.AZURE_VAULT_ID }}\n      CF_ENDPOINT: ${{ secrets.CF_ENDPOINT }}\n      MACOS_CERTIFICATE: ${{ secrets.MACOS_CERTIFICATE }}\n      MACOS_CERTIFICATE_NAME: ${{ secrets.MACOS_CERTIFICATE_NAME }}\n      MACOS_CERTIFICATE_PWD: ${{ secrets.MACOS_CERTIFICATE_PWD }}\n      MACOS_CI_KEYCHAIN_PWD: ${{ secrets.MACOS_CI_KEYCHAIN_PWD }}\n      MACOS_NOTARIZATION_APPLE_ID: ${{ secrets.MACOS_NOTARIZATION_APPLE_ID }}\n      MACOS_NOTARIZATION_PWD: ${{ secrets.MACOS_NOTARIZATION_PWD }}\n      MACOS_NOTARIZATION_TEAM_ID: ${{ secrets.MACOS_NOTARIZATION_TEAM_ID }}\n      MOZ_API_KEY: ${{ secrets.MOZ_API_KEY }}\n      ONE_PEM: ${{ secrets.ONE_PEM }}\n      SIGN_BASE64: ${{ secrets.SIGN_BASE64 }}\n    with:\n      MOZ_BUILD_DATE: ${{ github.event.inputs.date }}\n      PRE_RELEASE: ${{ github.event.inputs.prerelease }}\n      TAG_VERSION: ${{ github.event.inputs.tags }}\n      TRIGGER_EVENT: ${{ github.event_name }}\n  stage:\n    name: Deploy to Staging\n    uses: ./.github/workflows/stage.yml\n    needs: build\n    secrets:\n      AWS_ACCESS_KEY_ID: ${{ secrets.CF_ACCESS_KEY_ID }}\n      AWS_SECRET_ACCESS_KEY: ${{ secrets.CF_ACCESS_KEY_SECRET }}\n      CF_ENDPOINT: ${{ secrets.CF_ENDPOINT }}\n    with:\n      DISPLAY_VERSION: ${{ github.event.inputs.tags }}\n      PRE_RELEASE: ${{ github.event.inputs.prerelease }}\n  production:\n    name: Deploy to Production\n    uses: ./.github/workflows/production.yml\n    needs: stage\n    secrets:\n      AWS_ACCESS_KEY_ID: ${{ secrets.CF_ACCESS_KEY_ID }}\n      AWS_SECRET_ACCESS_KEY: ${{ secrets.CF_ACCESS_KEY_SECRET }}\n      CF_AUTH: ${{ secrets.BULK_REDIRECT_TOKEN }}\n      CF_ENDPOINT: ${{ secrets.CF_ENDPOINT }}\n      CF_ZONE_ID: ${{ secrets.CF_ZONE_ID }}\n    with:\n      COMMIT_SHA: ${{ github.sha }}\n      PRE_RELEASE: ${{ github.event.inputs.prerelease }}\n      DISPLAY_VERSION: ${{ github.event.inputs.tags }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Deployment` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 3 inputs: date-this input represents build date, it must be supplied and the data type is string; prerelease-this input represents this is a pre-release, it must be supplied and the data type is string; tags-this input represents tag a release, it must be supplied and the data type is string. The workflow has 3 jobs. The 1st job is named `Build` and its job id is `build`. The 2nd job is named `Deploy to Staging` and its job id is `stage`. The 3rd job is named `Deploy to Production` and its job id is `production`. ","prompt_level2":"Generate a GitHub Workflow named `Deployment` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 3 inputs: date-this input represents build date, it must be supplied and the data type is string; prerelease-this input represents this is a pre-release, it must be supplied and the data type is string; tags-this input represents tag a release, it must be supplied and the data type is string. The workflow has 3 jobs. The 1st job is named `Build` and its job id is `build`. The 2nd job is named `Deploy to Staging` and its job id is `stage`. The 3rd job is named `Deploy to Production` and its job id is `production`. ","prompt_level3":"Generate a GitHub Workflow named `Deployment` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 3 inputs: date-this input represents build date, it must be supplied and the data type is string; prerelease-this input represents this is a pre-release, it must be supplied and the data type is string; tags-this input represents tag a release, it must be supplied and the data type is string. The workflow has 3 jobs. The 1st job is named `Build` and its job id is `build`. This job will call a reusable workflow located at `./.github/workflows/build.yml`. The job will pass 4 inputs to the called workflow: the input `MOZ_BUILD_DATE` is `${{ github.event.inputs.date }}`, the input `PRE_RELEASE` is `${{ github.event.inputs.prerelease }}`, the input `TAG_VERSION` is `${{ github.event.inputs.tags }}` and the input `TRIGGER_EVENT` is `${{ github.event_name }}`. The job will pass 18 secrets to the called workflow: the secret `AWS_ACCESS_KEY_ID` is `${{ secrets.CF_ACCESS_KEY_ID }}`, the secret `AWS_SECRET_ACCESS_KEY` is `${{ secrets.CF_ACCESS_KEY_SECRET }}`, the secret `AZURE_CLIENT_ID` is `${{ secrets.AZURE_CLIENT_ID }}`, the secret `AZURE_CRT` is `${{ secrets.AZURE_CRT }}`, the secret `AZURE_SUBSCRIPTION_ID` is `${{ secrets.AZURE_SUBSCRIPTION_ID }}`, the secret `AZURE_TENANT_ID` is `${{ secrets.AZURE_TENANT_ID }}`, the secret `AZURE_VAULT_ID` is `${{ secrets.AZURE_VAULT_ID }}`, the secret `CF_ENDPOINT` is `${{ secrets.CF_ENDPOINT }}`, the secret `MACOS_CERTIFICATE` is `${{ secrets.MACOS_CERTIFICATE }}`, the secret `MACOS_CERTIFICATE_NAME` is `${{ secrets.MACOS_CERTIFICATE_NAME }}`, the secret `MACOS_CERTIFICATE_PWD` is `${{ secrets.MACOS_CERTIFICATE_PWD }}`, the secret `MACOS_CI_KEYCHAIN_PWD` is `${{ secrets.MACOS_CI_KEYCHAIN_PWD }}`, the secret `MACOS_NOTARIZATION_APPLE_ID` is `${{ secrets.MACOS_NOTARIZATION_APPLE_ID }}`, the secret `MACOS_NOTARIZATION_PWD` is `${{ secrets.MACOS_NOTARIZATION_PWD }}`, the secret `MACOS_NOTARIZATION_TEAM_ID` is `${{ secrets.MACOS_NOTARIZATION_TEAM_ID }}`, the secret `MOZ_API_KEY` is `${{ secrets.MOZ_API_KEY }}`, the secret `ONE_PEM` is `${{ secrets.ONE_PEM }}` and the secret `SIGN_BASE64` is `${{ secrets.SIGN_BASE64 }}`. The 2nd job is named `Deploy to Staging` and its job id is `stage`. Before this job runs, `build` must complete successfully. This job will call a reusable workflow located at `./.github/workflows/stage.yml`. The job will pass 2 inputs to the called workflow: the input `DISPLAY_VERSION` is `${{ github.event.inputs.tags }}` and the input `PRE_RELEASE` is `${{ github.event.inputs.prerelease }}`. The job will pass 3 secrets to the called workflow: the secret `AWS_ACCESS_KEY_ID` is `${{ secrets.CF_ACCESS_KEY_ID }}`, the secret `AWS_SECRET_ACCESS_KEY` is `${{ secrets.CF_ACCESS_KEY_SECRET }}` and the secret `CF_ENDPOINT` is `${{ secrets.CF_ENDPOINT }}`. The 3rd job is named `Deploy to Production` and its job id is `production`. Before this job runs, `stage` must complete successfully. This job will call a reusable workflow located at `./.github/workflows/production.yml`. The job will pass 3 inputs to the called workflow: the input `COMMIT_SHA` is `${{ github.sha }}`, the input `PRE_RELEASE` is `${{ github.event.inputs.prerelease }}` and the input `DISPLAY_VERSION` is `${{ github.event.inputs.tags }}`. The job will pass 5 secrets to the called workflow: the secret `AWS_ACCESS_KEY_ID` is `${{ secrets.CF_ACCESS_KEY_ID }}`, the secret `AWS_SECRET_ACCESS_KEY` is `${{ secrets.CF_ACCESS_KEY_SECRET }}`, the secret `CF_AUTH` is `${{ secrets.BULK_REDIRECT_TOKEN }}`, the secret `CF_ENDPOINT` is `${{ secrets.CF_ENDPOINT }}` and the secret `CF_ZONE_ID` is `${{ secrets.CF_ZONE_ID }}`. ","nb_triggers":1,"triggers":["workflow_dispatch"],"nb_jobs":3,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":3,"reusable_workflows":["./.github/workflows/build.yml","./.github/workflows/production.yml","./.github/workflows/stage.yml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":15028,"repository_id":95366169,"mainLanguage":"TypeScript","file_name":"build-many.yml","file_content":"name: Build Many Containers\n\non:\n  workflow_dispatch:\n    inputs:\n      servers:\n        required: true\n        type: string\n\n  workflow_call:\n    inputs:\n      servers:\n        required: true\n        type: string\n\njobs:\n  get-server-list:\n    name: Get Server List\n\n    runs-on: ubuntu-latest\n\n    outputs:\n      servers: ${{ steps.set-servers.outputs.servers }}\n\n    steps:\n      - name: Install Bun\n        uses: oven-sh/setup-bun@v2\n\n      - name: Set server list\n        id: set-servers\n        run: |\n          bun -e \"console.log(JSON.stringify(\\\"${{ inputs.servers }}\\\".split(',').map(s => s.trim()).filter(Boolean)))\" > server-list.json\n          echo \"server-list.json contents:\"\n          cat server-list.json\n          echo \"servers=$(cat server-list.json)\" >> $GITHUB_OUTPUT\n\n  build-all:\n    name: Build All Containers\n\n    needs: get-server-list\n\n    permissions:\n      contents: read\n      packages: write\n      attestations: write\n      id-token: write\n\n    strategy:\n      matrix:\n        server: ${{ fromJson(needs.get-server-list.outputs.servers) }}\n      fail-fast: false\n\n    uses: ./.github/workflows/build-single.yml\n    with:\n      server: ${{ matrix.server }}\n    secrets: inherit\n","repository_owner":"metorial","repository_name":"mcp-containers","tokens_count":290,"workflow":"name: Build Many Containers\n\non:\n  workflow_dispatch:\n    inputs:\n      servers:\n        required: true\n        type: string\n\n  workflow_call:\n    inputs:\n      servers:\n        required: true\n        type: string\n\njobs:\n  get-server-list:\n    name: Get Server List\n\n    runs-on: ubuntu-latest\n\n    outputs:\n      servers: ${{ steps.set-servers.outputs.servers }}\n\n    steps:\n    - name: Install Bun\n      uses: oven-sh/setup-bun@v2\n\n    - name: Set server list\n      id: set-servers\n      run: |\n        bun -e \"console.log(JSON.stringify(\\\"${{ inputs.servers }}\\\".split(',').map(s => s.trim()).filter(Boolean)))\" > server-list.json\n        echo \"server-list.json contents:\"\n        cat server-list.json\n        echo \"servers=$(cat server-list.json)\" >> $GITHUB_OUTPUT\n\n  build-all:\n    name: Build All Containers\n\n    needs: get-server-list\n\n    permissions:\n      contents: read\n      packages: write\n      attestations: write\n      id-token: write\n\n    strategy:\n      matrix:\n        server: ${{ fromJson(needs.get-server-list.outputs.servers) }}\n      fail-fast: false\n\n    uses: ./.github/workflows/build-single.yml\n    with:\n      server: ${{ matrix.server }}\n    secrets: inherit\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Build Many Containers` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives an input: servers-it must be supplied and the data type is string. 2) this workflow is called by another workflow. This workflow receives an input: servers-it must be supplied and the data type is string. The workflow has 2 jobs. The 1st job is named `Get Server List` and its job id is `get-server-list`. The 2nd job is named `Build All Containers` and its job id is `build-all`. ","prompt_level2":"Generate a GitHub Workflow named `Build Many Containers` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives an input: servers-it must be supplied and the data type is string. 2) this workflow is called by another workflow. This workflow receives an input: servers-it must be supplied and the data type is string. The workflow has 2 jobs. The 1st job is named `Get Server List` and its job id is `get-server-list`. The job `get-server-list` has 2 steps. The 1st step is named `Install Bun`. The 2nd step is named `Set server list` and its id is `set-servers`. The 2nd job is named `Build All Containers` and its job id is `build-all`. ","prompt_level3":"Generate a GitHub Workflow named `Build Many Containers` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives an input: servers-it must be supplied and the data type is string. 2) this workflow is called by another workflow. This workflow receives an input: servers-it must be supplied and the data type is string. The workflow has 2 jobs. The 1st job is named `Get Server List` and its job id is `get-server-list`. This job will run on ubuntu-latest runner. The job `get-server-list` has 2 steps. The 1st step is named `Install Bun`. This step runs action `oven-sh/setup-bun` tagged as v2. The 2nd step is named `Set server list` and its id is `set-servers`. This step runs a script: `bun -e \"console.log(JSON.stringify(\\\"${{ inputs.servers }}\\\".split(',').map(s => s.trim()).filter(Boolean)))\" > server-list.json\necho \"server-list.json contents:\"\ncat server-list.json\necho \"servers=$(cat server-list.json)\" >> $GITHUB_OUTPUT\n`. This job has an output: `servers` is defined as ${{ steps.set-servers.outputs.servers }}. The 2nd job is named `Build All Containers` and its job id is `build-all`. Before this job runs, `get-server-list` must complete successfully. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `server` has 54 values: $, {, {,  , f, r, o, m, J, s, o, n, (, n, e, e, d, s, ., g, e, t, -, s, e, r, v, e, r, -, l, i, s, t, ., o, u, t, p, u, t, s, ., s, e, r, v, e, r, s, ),  , } and }. The job `build-all` modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope, write access is granted to the GITHUB_TOKEN in the `packages` scope, write access is granted to the GITHUB_TOKEN in the `attestations` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting only applies to the job `build-all`. This job will call a reusable workflow located at `./.github/workflows/build-single.yml`. The job will pass an input to the called workflow: the input `server` is `${{ matrix.server }}`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. ","nb_triggers":2,"triggers":["workflow_call","workflow_dispatch"],"nb_jobs":2,"nb_actions":1,"actions":["oven-sh/setup-bun"],"actions_details":[{"version":"v2","name":"oven-sh/setup-bun"}],"nb_reusable_workflows":1,"reusable_workflows":["./.github/workflows/build-single.yml"],"nb_steps":2,"cyclomatic_complexity":1}
{"id":80,"repository_id":7822166,"mainLanguage":"JavaScript","file_name":"pre-commit-checks.yml","file_content":"name: 'Maintenance: precommit checks'\n\non: [push, pull_request]\n\njobs:\n  pre-commit:\n    runs-on: ubuntu-latest\n    name: Run pre-commit checks\n    steps:\n      - name: Checkout the repository\n        uses: actions/checkout@v4\n\n      # Enablement of https://pre-commit.ci is desirable as it also\n      # enable auto-fixes for formatting violations. Still we still want to run\n      # our own GitHub action, just in case the external service becomes\n      # unavailable.\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n      - name: Install pre-commit\n        run: |\n          python3 -m pip install --upgrade pip\n          python3 -m pip install --upgrade pre-commit\n      - name: Run pre-commit\n        run: |\n          pre-commit run --all-files\n","repository_owner":"schemastore","repository_name":"schemastore","tokens_count":191,"workflow":"name: 'Maintenance: precommit checks'\n\non: [push, pull_request]\n\njobs:\n  pre-commit:\n    runs-on: ubuntu-latest\n    name: Run pre-commit checks\n    steps:\n    - name: Checkout the repository\n      uses: actions/checkout@v4\n\n      # Enablement of https://pre-commit.ci is desirable as it also\n      # enable auto-fixes for formatting violations. Still we still want to run\n      # our own GitHub action, just in case the external service becomes\n      # unavailable.\n    - name: Setup Python 3.11\n      uses: actions/setup-python@v5\n      with:\n        python-version: '3.11'\n    - name: Install pre-commit\n      run: |\n        python3 -m pip install --upgrade pip\n        python3 -m pip install --upgrade pre-commit\n    - name: Run pre-commit\n      run: |\n        pre-commit run --all-files\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Maintenance: precommit checks` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow has one job. The 1st job is named `Run pre-commit checks` and its job id is `pre-commit`. ","prompt_level2":"Generate a GitHub Workflow named `Maintenance: precommit checks` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow has one job. The 1st job is named `Run pre-commit checks` and its job id is `pre-commit`. The job `pre-commit` has 4 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Setup Python 3.11`. The 3rd step is named `Install pre-commit`. The 4th step is named `Run pre-commit`. ","prompt_level3":"Generate a GitHub Workflow named `Maintenance: precommit checks` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow has one job. The 1st job is named `Run pre-commit checks` and its job id is `pre-commit`. This job will run on ubuntu-latest runner. The job `pre-commit` has 4 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Setup Python 3.11`. This step runs action `actions/setup-python` tagged as v5. The step defines an input parameter for the action: `python-version` is set to `3.11`. The 3rd step is named `Install pre-commit`. This step runs a script: `python3 -m pip install --upgrade pip\npython3 -m pip install --upgrade pre-commit\n`. The 4th step is named `Run pre-commit`. This step runs a script: `pre-commit run --all-files\n`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","actions/setup-python"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v5","name":"actions/setup-python"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":4,"cyclomatic_complexity":1}
{"id":22770,"repository_id":31953428,"mainLanguage":"C++","file_name":"android-build.yml","file_content":"#\n# Copyright (c) Contributors to the Open 3D Engine Project.\n# For complete copyright and license terms please see the LICENSE at the root of this distribution.\n#\n# SPDX-License-Identifier: Apache-2.0 OR MIT\n#\n#\n\nname: Android Build\n\n# These jobs are to be triggered by ar.yml\n\non:\n  workflow_dispatch:\n  workflow_call:\n    inputs:\n      compiler: \n        required: true\n        type: string\n      config: \n        required: true\n        type: string\n      image: \n        required: true\n        type: string\n      platform: \n        required: true\n        type: string\n      type: \n        required: true\n        type: string\n      last_artifact: \n        required: false\n        type: boolean\n\nrun-name: ${{ inputs.platform }} - ${{ inputs.type }}\n\n# Activate compiler cache\nenv: \n  O3DE_ENABLE_COMPILER_CACHE: true\n  O3DE_COMPILER_CACHE_PATH: 'C:\\ProgramData\\Chocolatey\\bin\\ccache.exe'\n  NDK_VERSION: 25.1.8937393\n\n# Note: All 3P Github Actions use the commit hash for security reasons \n# Avoid using the tag version, which is vulnerable to supply chain attacks\n\njobs:\n  Build:\n    strategy:\n      fail-fast: false\n\n    runs-on: ${{ inputs.image }}\n        \n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n        with:\n          show-progress: false\n\n      - name: Git LFS pull\n        # Minimal pull for profile builds, otherwise pull all\n        run: |\n          git lfs install\n          if (\"${{ inputs.type }}\" -eq \"profile\") { git lfs pull --include \"*.ico,*.bmp\" } else { git lfs pull }\n\n      - name: Setup 3p, user, and build folders\n        # Symlink the .o3de folder to the github workspace to avoid permission issues\n        run: |\n          \"3rdParty\", \"build\", \".o3de\" | % {New-Item \"${{ github.workspace }}\\$_\" -ItemType 'Directory' -Force}\n          \".o3de\" | % {New-Item -Path $env:USERPROFILE\\$_ -ItemType SymbolicLink -Target ${{ github.workspace }}\\$_ -Force}\n          \"AutomatedTesting\\Cache\", \"AutomatedTesting\\user\" | % {New-Item \"${{ github.workspace }}\\$_\" -ItemType 'Directory' -Force}\n\n      - name: Setup ccache\n        uses: Chocobo1/setup-ccache-action@f84f86840109403e0fe0ded8b0766c9633affa16 # v1.4.7\n        continue-on-error: true\n        if: always()\n        with:\n          windows_compile_environment: msvc\n          prepend_symlinks_to_path: false\n          store_cache: false\n          restore_cache: false\n          ccache_options: |\n            max_size=15G\n            cache_dir=${{ github.workspace }}\\.ccache\n      \n      - name: Get last run\n        # Get the last runid of the target branch of a PR or the current branch\n        uses: dawidd6/action-download-artifact@07ab29fd4a977ae4d2b275087cf67563dfdf0295 # v9\n        id: last-run-id\n        if: ${{ inputs.last_artifact }}\n        continue-on-error: true\n        with:\n          workflow_search: true\n          workflow_conclusion: \"\"\n          branch: ${{ github.event_name == 'pull_request' && github.event.pull_request.base.ref || github.ref_name }}\n          search_artifacts: true\n          name: O3DE-${{ inputs.platform }}-${{ inputs.config }}-build\n          dry_run: true\n\n      - name: Set artifact run ID\n        # Set the run ID of the artifact to be used for the download step\n        id: set-artifact-run-id\n        if: steps.last-run-id.outcome == 'success' && inputs.last_artifact == true\n        run: |\n          $runId = ${{ fromJSON(steps.last-run-id.outputs.artifacts)[0].workflow_run.id }}\n          echo \"artifact_run_id=$runId\" >> $env:GITHUB_OUTPUT\n          echo \"Using artifacts from previous run: $runId\"\n      \n      - name: Restore artifact cache\n        # Restore the artifact from the \"Get last run\" step or from the current run\n        uses: actions/download-artifact@95815c38cf2ff2164869cbab79da8d1f422bc89e # v4.2.1\n        id: restore-artifact-cache\n        continue-on-error: true\n        with:\n          name: O3DE-${{ inputs.platform }}-${{ inputs.config }}-build\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          run-id: ${{ steps.set-artifact-run-id.outputs.artifact_run_id || github.run_id }}\n\n      - name: Extract artifact\n        # Extract the tar file from the artifact\n        id: extract-artifact\n        if: ${{ steps.restore-artifact-cache.outcome == 'success' }}\n        continue-on-error: true\n        run: |        \n          if (Test-Path ${{ github.workspace }}\\cache.tar) {          \n            tar -xvpf ${{ github.workspace }}\\cache.tar\n            rm ${{ github.workspace }}\\cache.tar\n          }\n      \n      - name: Setup cmake\n        # Pin the version of cmake  \n        uses: lukka/get-cmake@56d043d188c3612951d8755da8f4b709ec951ad6 # v3.31.6\n        with:\n          cmakeVersion: \"~3.30.0\"\n\n      - name: Set MSBuild options\n        # Configuire VS environment variables through the developer command prompt for MSVC\n        uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n                \n      - name: Configure environment\n        # Install dependencies for gradle and clang builds from the NDK\n        continue-on-error: true\n        run: |\n          echo \"Installing dependencies\"\n          echo \"Getting python...\"\n          python\\get_python.bat\n\n          echo \"Installing NDK ${{ env.NDK_VERSION }}...\"\n          & \"$env:ANDROID_HOME\\cmdline-tools\\latest\\bin\\sdkmanager.bat\" --install 'ndk;${{ env.NDK_VERSION }}' --sdk_root=$env:ANDROID_HOME\n          echo \"LY_NDK_DIR=$env:ANDROID_HOME\\ndk\\${{ env.NDK_VERSION }}\" >> $env:GITHUB_ENV\n          echo \"JDK_HOME=$env:JAVA_HOME_17_X64\" >> $env:GITHUB_ENV\n          echo \"JAVA_HOME=$env:JAVA_HOME_17_X64\" >> $env:GITHUB_ENV\n          echo \"GRADLE_BUILD_HOME=$env:GRADLE_HOME\" >> $env:GITHUB_ENV\n          \n      - name: Build ${{ inputs.type }}\n        # Builds with presets in ../scripts/build/Platform/Android/build_config.json\n        env:\n          LY_3RDPARTY_PATH: ${{ github.workspace }}\\3rdParty\n          USE_CCACHE: 1\n          NDK_CCACHE: ${{ env.O3DE_COMPILER_CACHE_PATH }}\n          CMAKE_C_COMPILER_LAUNCHER: ${{ env.O3DE_COMPILER_CACHE_PATH }}\n          CMAKE_CXX_COMPILER_LAUNCHER: ${{ env.O3DE_COMPILER_CACHE_PATH }}\n\n        run: |\n          scripts\\o3de.bat register --this-engine # Resolves registration issue with gradle build\n          python\\python.cmd -u scripts\\build\\ci_build.py --platform ${{ inputs.platform }} --type ${{ inputs.type }} \n      \n      - name: Compress artifacts\n        # Compress with posix format to preserve permissions and timestamps at nanosecond precision\n        id: compress-artifacts\n        if: ${{ (steps.extract-artifact.outcome == 'success' || steps.extract-artifact.outcome == 'skipped') && !cancelled() && !contains(inputs.type, 'test') }}\n        continue-on-error: true\n        run: |\n          try {\n            tar --format=posix -cvpf ${{ github.workspace }}\\cache.tar `\n              python `\n              3rdParty\\packages `\n              AutomatedTesting\\Cache `\n              AutomatedTesting\\user `\n              .ccache\n          } catch {\n            echo \"Warning: Error during tar compression\"\n          }\n  \n      - name: Save artifacts\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        if: ${{ steps.compress-artifacts.conclusion == 'success' && !cancelled() && !contains(inputs.type, 'test') }}\n        continue-on-error: true\n        with:\n          name: O3DE-${{ inputs.platform }}-${{ inputs.config }}-build\n          compression-level: 1\n          overwrite: true\n          path: |\n            ${{ github.workspace }}\\cache.tar\n","repository_owner":"o3de","repository_name":"o3de","tokens_count":2090,"workflow":"#\n# Copyright (c) Contributors to the Open 3D Engine Project.\n# For complete copyright and license terms please see the LICENSE at the root of this distribution.\n#\n# SPDX-License-Identifier: Apache-2.0 OR MIT\n#\n#\n\nname: Android Build\n\n# These jobs are to be triggered by ar.yml\n\non:\n  workflow_dispatch:\n  workflow_call:\n    inputs:\n      compiler:\n        required: true\n        type: string\n      config:\n        required: true\n        type: string\n      image:\n        required: true\n        type: string\n      platform:\n        required: true\n        type: string\n      type:\n        required: true\n        type: string\n      last_artifact:\n        required: false\n        type: boolean\n\nrun-name: ${{ inputs.platform }} - ${{ inputs.type }}\n\n# Activate compiler cache\nenv:\n  O3DE_ENABLE_COMPILER_CACHE: true\n  O3DE_COMPILER_CACHE_PATH: C:\\ProgramData\\Chocolatey\\bin\\ccache.exe\n  NDK_VERSION: 25.1.8937393\n\n# Note: All 3P Github Actions use the commit hash for security reasons \n# Avoid using the tag version, which is vulnerable to supply chain attacks\n\njobs:\n  Build:\n    strategy:\n      fail-fast: false\n\n    runs-on: ${{ inputs.image }}\n\n    steps:\n    - name: Checkout repo\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683   # v4.2.2\n      with:\n        show-progress: false\n\n    - name: Git LFS pull\n        # Minimal pull for profile builds, otherwise pull all\n      run: |\n        git lfs install\n        if (\"${{ inputs.type }}\" -eq \"profile\") { git lfs pull --include \"*.ico,*.bmp\" } else { git lfs pull }\n\n    - name: Setup 3p, user, and build folders\n        # Symlink the .o3de folder to the github workspace to avoid permission issues\n      run: |\n        \"3rdParty\", \"build\", \".o3de\" | % {New-Item \"${{ github.workspace }}\\$_\" -ItemType 'Directory' -Force}\n        \".o3de\" | % {New-Item -Path $env:USERPROFILE\\$_ -ItemType SymbolicLink -Target ${{ github.workspace }}\\$_ -Force}\n        \"AutomatedTesting\\Cache\", \"AutomatedTesting\\user\" | % {New-Item \"${{ github.workspace }}\\$_\" -ItemType 'Directory' -Force}\n\n    - name: Setup ccache\n      uses: \n        Chocobo1/setup-ccache-action@f84f86840109403e0fe0ded8b0766c9633affa16       # v1.4.7\n      continue-on-error: true\n      if: always()\n      with:\n        windows_compile_environment: msvc\n        prepend_symlinks_to_path: false\n        store_cache: false\n        restore_cache: false\n        ccache_options: |\n          max_size=15G\n          cache_dir=${{ github.workspace }}\\.ccache\n\n    - name: Get last run\n        # Get the last runid of the target branch of a PR or the current branch\n      uses: \n        dawidd6/action-download-artifact@07ab29fd4a977ae4d2b275087cf67563dfdf0295       # v9\n      id: last-run-id\n      if: ${{ inputs.last_artifact }}\n      continue-on-error: true\n      with:\n        workflow_search: true\n        workflow_conclusion: ''\n        branch: ${{ github.event_name == 'pull_request' && \n          github.event.pull_request.base.ref || github.ref_name }}\n        search_artifacts: true\n        name: O3DE-${{ inputs.platform }}-${{ inputs.config }}-build\n        dry_run: true\n\n    - name: Set artifact run ID\n        # Set the run ID of the artifact to be used for the download step\n      id: set-artifact-run-id\n      if: steps.last-run-id.outcome == 'success' && inputs.last_artifact == true\n      run: |\n        $runId = ${{ fromJSON(steps.last-run-id.outputs.artifacts)[0].workflow_run.id }}\n        echo \"artifact_run_id=$runId\" >> $env:GITHUB_OUTPUT\n        echo \"Using artifacts from previous run: $runId\"\n\n    - name: Restore artifact cache\n        # Restore the artifact from the \"Get last run\" step or from the current run\n      uses: actions/download-artifact@95815c38cf2ff2164869cbab79da8d1f422bc89e   # v4.2.1\n      id: restore-artifact-cache\n      continue-on-error: true\n      with:\n        name: O3DE-${{ inputs.platform }}-${{ inputs.config }}-build\n        github-token: ${{ secrets.GITHUB_TOKEN }}\n        run-id: ${{ steps.set-artifact-run-id.outputs.artifact_run_id || \n          github.run_id }}\n\n    - name: Extract artifact\n        # Extract the tar file from the artifact\n      id: extract-artifact\n      if: ${{ steps.restore-artifact-cache.outcome == 'success' }}\n      continue-on-error: true\n      run: |\n        if (Test-Path ${{ github.workspace }}\\cache.tar) {          \n          tar -xvpf ${{ github.workspace }}\\cache.tar\n          rm ${{ github.workspace }}\\cache.tar\n        }\n\n    - name: Setup cmake\n        # Pin the version of cmake  \n      uses: lukka/get-cmake@56d043d188c3612951d8755da8f4b709ec951ad6   # v3.31.6\n      with:\n        cmakeVersion: ~3.30.0\n\n    - name: Set MSBuild options\n        # Configuire VS environment variables through the developer command prompt for MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756   # v1.13.0\n    - name: Configure environment\n        # Install dependencies for gradle and clang builds from the NDK\n      continue-on-error: true\n      run: |\n        echo \"Installing dependencies\"\n        echo \"Getting python...\"\n        python\\get_python.bat\n\n        echo \"Installing NDK ${{ env.NDK_VERSION }}...\"\n        & \"$env:ANDROID_HOME\\cmdline-tools\\latest\\bin\\sdkmanager.bat\" --install 'ndk;${{ env.NDK_VERSION }}' --sdk_root=$env:ANDROID_HOME\n        echo \"LY_NDK_DIR=$env:ANDROID_HOME\\ndk\\${{ env.NDK_VERSION }}\" >> $env:GITHUB_ENV\n        echo \"JDK_HOME=$env:JAVA_HOME_17_X64\" >> $env:GITHUB_ENV\n        echo \"JAVA_HOME=$env:JAVA_HOME_17_X64\" >> $env:GITHUB_ENV\n        echo \"GRADLE_BUILD_HOME=$env:GRADLE_HOME\" >> $env:GITHUB_ENV\n\n    - name: Build ${{ inputs.type }}\n        # Builds with presets in ../scripts/build/Platform/Android/build_config.json\n      env:\n        LY_3RDPARTY_PATH: ${{ github.workspace }}\\3rdParty\n        USE_CCACHE: 1\n        NDK_CCACHE: ${{ env.O3DE_COMPILER_CACHE_PATH }}\n        CMAKE_C_COMPILER_LAUNCHER: ${{ env.O3DE_COMPILER_CACHE_PATH }}\n        CMAKE_CXX_COMPILER_LAUNCHER: ${{ env.O3DE_COMPILER_CACHE_PATH }}\n\n      run: |\n        scripts\\o3de.bat register --this-engine # Resolves registration issue with gradle build\n        python\\python.cmd -u scripts\\build\\ci_build.py --platform ${{ inputs.platform }} --type ${{ inputs.type }} \n\n    - name: Compress artifacts\n        # Compress with posix format to preserve permissions and timestamps at nanosecond precision\n      id: compress-artifacts\n      if: ${{ (steps.extract-artifact.outcome == 'success' || \n        steps.extract-artifact.outcome == 'skipped') && !cancelled() && \n        !contains(inputs.type, 'test') }}\n      continue-on-error: true\n      run: |\n        try {\n          tar --format=posix -cvpf ${{ github.workspace }}\\cache.tar `\n            python `\n            3rdParty\\packages `\n            AutomatedTesting\\Cache `\n            AutomatedTesting\\user `\n            .ccache\n        } catch {\n          echo \"Warning: Error during tar compression\"\n        }\n\n    - name: Save artifacts\n      uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02   # v4.6.2\n      if: ${{ steps.compress-artifacts.conclusion == 'success' && !cancelled() \n        && !contains(inputs.type, 'test') }}\n      continue-on-error: true\n      with:\n        name: O3DE-${{ inputs.platform }}-${{ inputs.config }}-build\n        compression-level: 1\n        overwrite: true\n        path: |\n          ${{ github.workspace }}\\cache.tar\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Android Build` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `${{ inputs.platform }} - ${{ inputs.type }}`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) this workflow is called by another workflow. This workflow receives 6 inputs: compiler-it must be supplied and the data type is string; config-it must be supplied and the data type is string; image-it must be supplied and the data type is string; platform-it must be supplied and the data type is string; type-it must be supplied and the data type is string; last_artifact-it is optional and the data type is boolean. The workflow sets 3 environment variables to use: `O3DE_ENABLE_COMPILER_CACHE` is set to `True`, `O3DE_COMPILER_CACHE_PATH` is set to `C:\\ProgramData\\Chocolatey\\bin\\ccache.exe` and `NDK_VERSION` is set to `25.1.8937393`. The workflow has one job. The job id of the 1st job is `Build`. ","prompt_level2":"Generate a GitHub Workflow named `Android Build` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `${{ inputs.platform }} - ${{ inputs.type }}`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) this workflow is called by another workflow. This workflow receives 6 inputs: compiler-it must be supplied and the data type is string; config-it must be supplied and the data type is string; image-it must be supplied and the data type is string; platform-it must be supplied and the data type is string; type-it must be supplied and the data type is string; last_artifact-it is optional and the data type is boolean. The workflow sets 3 environment variables to use: `O3DE_ENABLE_COMPILER_CACHE` is set to `True`, `O3DE_COMPILER_CACHE_PATH` is set to `C:\\ProgramData\\Chocolatey\\bin\\ccache.exe` and `NDK_VERSION` is set to `25.1.8937393`. The workflow has one job. The job id of the 1st job is `Build`. The job `Build` has 14 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Git LFS pull`. The 3rd step is named `Setup 3p, user, and build folders`. The 4th step is named `Setup ccache`. The 5th step is named `Get last run` and its id is `last-run-id`. The 6th step is named `Set artifact run ID` and its id is `set-artifact-run-id`. The 7th step is named `Restore artifact cache` and its id is `restore-artifact-cache`. The 8th step is named `Extract artifact` and its id is `extract-artifact`. The 9th step is named `Setup cmake`. The 10th step is named `Set MSBuild options`. The 11th step is named `Configure environment`. The 12th step is named `Build ${{ inputs.type }}`. The 13th step is named `Compress artifacts` and its id is `compress-artifacts`. The 14th step is named `Save artifacts`. ","prompt_level3":"Generate a GitHub Workflow named `Android Build` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `${{ inputs.platform }} - ${{ inputs.type }}`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) this workflow is called by another workflow. This workflow receives 6 inputs: compiler-it must be supplied and the data type is string; config-it must be supplied and the data type is string; image-it must be supplied and the data type is string; platform-it must be supplied and the data type is string; type-it must be supplied and the data type is string; last_artifact-it is optional and the data type is boolean. The workflow sets 3 environment variables to use: `O3DE_ENABLE_COMPILER_CACHE` is set to `True`, `O3DE_COMPILER_CACHE_PATH` is set to `C:\\ProgramData\\Chocolatey\\bin\\ccache.exe` and `NDK_VERSION` is set to `25.1.8937393`. The workflow has one job. The job id of the 1st job is `Build`. This job will run on ${{ inputs.image }} runner. The job `Build` has 14 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is 11bd71901bbe5b1630ceea73d27597364c9af683. The step defines an input parameter for the action: `show-progress` is set to `False`. The 2nd step is named `Git LFS pull`. This step runs a script: `git lfs install\nif (\"${{ inputs.type }}\" -eq \"profile\") { git lfs pull --include \"*.ico,*.bmp\" } else { git lfs pull }\n`. The 3rd step is named `Setup 3p, user, and build folders`. This step runs a script: `\"3rdParty\", \"build\", \".o3de\" | % {New-Item \"${{ github.workspace }}\\$_\" -ItemType 'Directory' -Force}\n\".o3de\" | % {New-Item -Path $env:USERPROFILE\\$_ -ItemType SymbolicLink -Target ${{ github.workspace }}\\$_ -Force}\n\"AutomatedTesting\\Cache\", \"AutomatedTesting\\user\" | % {New-Item \"${{ github.workspace }}\\$_\" -ItemType 'Directory' -Force}\n`. The 4th step is named `Setup ccache`. This step will run only if the condition(always()) is met. This step runs action `Chocobo1/setup-ccache-action` whose commit is f84f86840109403e0fe0ded8b0766c9633affa16. The step defines 5 input parameters for the action: `windows_compile_environment` is set to `msvc`, `prepend_symlinks_to_path` is set to `False`, `store_cache` is set to `False`, `restore_cache` is set to `False` and `ccache_options` is set to `max_size=15G\ncache_dir=${{ github.workspace }}\\.ccache\n`. When this step fails, the job will move on to the next step. The 5th step is named `Get last run` and its id is `last-run-id`. This step will run only if the condition(${{ inputs.last_artifact }}) is met. This step runs action `dawidd6/action-download-artifact` whose commit is 07ab29fd4a977ae4d2b275087cf67563dfdf0295. The step defines 6 input parameters for the action: `workflow_search` is set to `True`, `workflow_conclusion` is set to ``, `branch` is set to `${{ github.event_name == 'pull_request' && github.event.pull_request.base.ref || github.ref_name }}`, `search_artifacts` is set to `True`, `name` is set to `O3DE-${{ inputs.platform }}-${{ inputs.config }}-build` and `dry_run` is set to `True`. When this step fails, the job will move on to the next step. The 6th step is named `Set artifact run ID` and its id is `set-artifact-run-id`. This step will run only if the condition(steps.last-run-id.outcome == 'success' && inputs.last_artifact == true) is met. This step runs a script: `$runId = ${{ fromJSON(steps.last-run-id.outputs.artifacts)[0].workflow_run.id }}\necho \"artifact_run_id=$runId\" >> $env:GITHUB_OUTPUT\necho \"Using artifacts from previous run: $runId\"\n`. The 7th step is named `Restore artifact cache` and its id is `restore-artifact-cache`. This step runs action `actions/download-artifact` whose commit is 95815c38cf2ff2164869cbab79da8d1f422bc89e. The step defines 3 input parameters for the action: `name` is set to `O3DE-${{ inputs.platform }}-${{ inputs.config }}-build`, `github-token` is set to `${{ secrets.GITHUB_TOKEN }}` and `run-id` is set to `${{ steps.set-artifact-run-id.outputs.artifact_run_id || github.run_id }}`. When this step fails, the job will move on to the next step. The 8th step is named `Extract artifact` and its id is `extract-artifact`. This step will run only if the condition(${{ steps.restore-artifact-cache.outcome == 'success' }}) is met. This step runs a script: `if (Test-Path ${{ github.workspace }}\\cache.tar) {          \n  tar -xvpf ${{ github.workspace }}\\cache.tar\n  rm ${{ github.workspace }}\\cache.tar\n}\n`. When this step fails, the job will move on to the next step. The 9th step is named `Setup cmake`. This step runs action `lukka/get-cmake` whose commit is 56d043d188c3612951d8755da8f4b709ec951ad6. The step defines an input parameter for the action: `cmakeVersion` is set to `~3.30.0`. The 10th step is named `Set MSBuild options`. This step runs action `ilammy/msvc-dev-cmd` whose commit is 0b201ec74fa43914dc39ae48a89fd1d8cb592756. The 11th step is named `Configure environment`. This step runs a script: `echo \"Installing dependencies\"\necho \"Getting python...\"\npython\\get_python.bat\n\necho \"Installing NDK ${{ env.NDK_VERSION }}...\"\n& \"$env:ANDROID_HOME\\cmdline-tools\\latest\\bin\\sdkmanager.bat\" --install 'ndk;${{ env.NDK_VERSION }}' --sdk_root=$env:ANDROID_HOME\necho \"LY_NDK_DIR=$env:ANDROID_HOME\\ndk\\${{ env.NDK_VERSION }}\" >> $env:GITHUB_ENV\necho \"JDK_HOME=$env:JAVA_HOME_17_X64\" >> $env:GITHUB_ENV\necho \"JAVA_HOME=$env:JAVA_HOME_17_X64\" >> $env:GITHUB_ENV\necho \"GRADLE_BUILD_HOME=$env:GRADLE_HOME\" >> $env:GITHUB_ENV\n`. When this step fails, the job will move on to the next step. The 12th step is named `Build ${{ inputs.type }}`. The step sets 5 environment variables to use: `LY_3RDPARTY_PATH` is set to `${{ github.workspace }}\\3rdParty`, `USE_CCACHE` is set to `1`, `NDK_CCACHE` is set to `${{ env.O3DE_COMPILER_CACHE_PATH }}`, `CMAKE_C_COMPILER_LAUNCHER` is set to `${{ env.O3DE_COMPILER_CACHE_PATH }}` and `CMAKE_CXX_COMPILER_LAUNCHER` is set to `${{ env.O3DE_COMPILER_CACHE_PATH }}`. This step runs a script: `scripts\\o3de.bat register --this-engine # Resolves registration issue with gradle build\npython\\python.cmd -u scripts\\build\\ci_build.py --platform ${{ inputs.platform }} --type ${{ inputs.type }} \n`. The 13th step is named `Compress artifacts` and its id is `compress-artifacts`. This step will run only if the condition(${{ (steps.extract-artifact.outcome == 'success' || steps.extract-artifact.outcome == 'skipped') && !cancelled() && !contains(inputs.type, 'test') }}) is met. This step runs a script: `try {\n  tar --format=posix -cvpf ${{ github.workspace }}\\cache.tar `\n    python `\n    3rdParty\\packages `\n    AutomatedTesting\\Cache `\n    AutomatedTesting\\user `\n    .ccache\n} catch {\n  echo \"Warning: Error during tar compression\"\n}\n`. When this step fails, the job will move on to the next step. The 14th step is named `Save artifacts`. This step will run only if the condition(${{ steps.compress-artifacts.conclusion == 'success' && !cancelled() && !contains(inputs.type, 'test') }}) is met. This step runs action `actions/upload-artifact` whose commit is ea165f8d65b6e75b540449e92b4886f43607fa02. The step defines 4 input parameters for the action: `name` is set to `O3DE-${{ inputs.platform }}-${{ inputs.config }}-build`, `compression-level` is set to `1`, `overwrite` is set to `True` and `path` is set to `${{ github.workspace }}\\cache.tar\n`. When this step fails, the job will move on to the next step. ","nb_triggers":2,"triggers":["workflow_call","workflow_dispatch"],"nb_jobs":1,"nb_actions":7,"actions":["Chocobo1/setup-ccache-action","actions/checkout","actions/download-artifact","actions/upload-artifact","dawidd6/action-download-artifact","ilammy/msvc-dev-cmd","lukka/get-cmake"],"actions_details":[{"version":"11bd71901bbe5b1630ceea73d27597364c9af683","name":"actions/checkout"},{"version":"f84f86840109403e0fe0ded8b0766c9633affa16","name":"Chocobo1/setup-ccache-action"},{"version":"07ab29fd4a977ae4d2b275087cf67563dfdf0295","name":"dawidd6/action-download-artifact"},{"version":"95815c38cf2ff2164869cbab79da8d1f422bc89e","name":"actions/download-artifact"},{"version":"56d043d188c3612951d8755da8f4b709ec951ad6","name":"lukka/get-cmake"},{"version":"0b201ec74fa43914dc39ae48a89fd1d8cb592756","name":"ilammy/msvc-dev-cmd"},{"version":"ea165f8d65b6e75b540449e92b4886f43607fa02","name":"actions/upload-artifact"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":14,"cyclomatic_complexity":1}
{"id":1554,"repository_id":5742509,"mainLanguage":"JavaScript","file_name":"release.yml","file_content":"name: Release\n\non:\n  release:\n    types: [published]\n\npermissions:\n  contents: read\n\njobs:\n  npm:\n    name: npm\n    runs-on: ubuntu-latest\n\n    environment:\n      name: npm\n      url: https://www.npmjs.com/package/consul\n\n    permissions:\n      id-token: write\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Node\n        uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          registry-url: https://registry.npmjs.org\n\n      - name: Setup pnpm\n        uses: pnpm/action-setup@v4\n        with:\n          version: 9\n\n      - name: Install\n        run: pnpm install\n\n      - name: Publish\n        run: pnpm publish --access public --no-git-checks\n        env:\n          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n","repository_owner":"silas","repository_name":"node-consul","tokens_count":208,"workflow":"name: Release\n\non:\n  release:\n    types: [published]\n\npermissions:\n  contents: read\n\njobs:\n  npm:\n    name: npm\n    runs-on: ubuntu-latest\n\n    environment:\n      name: npm\n      url: https://www.npmjs.com/package/consul\n\n    permissions:\n      id-token: write\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v4\n\n    - name: Setup Node\n      uses: actions/setup-node@v4\n      with:\n        node-version: 20\n        registry-url: https://registry.npmjs.org\n\n    - name: Setup pnpm\n      uses: pnpm/action-setup@v4\n      with:\n        version: 9\n\n    - name: Install\n      run: pnpm install\n\n    - name: Publish\n      run: pnpm publish --access public --no-git-checks\n      env:\n        NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Release` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by an event: a release, pre-release, or draft of a release is published. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `npm` and its job id is `npm`. ","prompt_level2":"Generate a GitHub Workflow named `Release` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by an event: a release, pre-release, or draft of a release is published. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `npm` and its job id is `npm`. The job `npm` has 5 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Setup Node`. The 3rd step is named `Setup pnpm`. The 4th step is named `Install`. The 5th step is named `Publish`. ","prompt_level3":"Generate a GitHub Workflow named `Release` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by an event: a release, pre-release, or draft of a release is published. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `npm` and its job id is `npm`. This job will run on ubuntu-latest runner. The job `npm` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting only applies to the job `npm`. This job references npm environment whose url is https://www.npmjs.com/package/consul. The job `npm` has 5 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Setup Node`. This step runs action `actions/setup-node` tagged as v4. The step defines 2 input parameters for the action: `node-version` is set to `20` and `registry-url` is set to `https://registry.npmjs.org`. The 3rd step is named `Setup pnpm`. This step runs action `pnpm/action-setup` tagged as v4. The step defines an input parameter for the action: `version` is set to `9`. The 4th step is named `Install`. This step runs a script: `pnpm install`. The 5th step is named `Publish`. The step sets an environment variable to use: `NODE_AUTH_TOKEN` is set to `${{ secrets.NPM_TOKEN }}`. This step runs a script: `pnpm publish --access public --no-git-checks`. ","nb_triggers":1,"triggers":["release"],"nb_jobs":1,"nb_actions":3,"actions":["actions/checkout","actions/setup-node","pnpm/action-setup"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/setup-node"},{"version":"v4","name":"pnpm/action-setup"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":5,"cyclomatic_complexity":1}
{"id":55467,"repository_id":3604723,"mainLanguage":"TypeScript","file_name":"ci.yml","file_content":"name: CI\n\non: [push, pull_request]\n\njobs:\n  python-lint:\n    runs-on: ubuntu-latest\n    container:\n      image: alpine:latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Package installation\n        run: |\n          apk add --no-cache git python3 py3-pip\n          python3 -m venv /venv\n          source /venv/bin/activate\n          pip install tox\n\n      - name: Run linting\n        run: |\n          source /venv/bin/activate\n          git config --global --add safe.directory \"$GITHUB_WORKSPACE\"\n          tox -e pep8 -v\n\n  validate-schema:\n    runs-on: ubuntu-latest\n    container:\n      image: alpine:latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Package installation\n        run: |\n          apk add --no-cache git python3 py3-pip\n          python3 -m venv /venv\n          source /venv/bin/activate\n          pip install tox jsonschema pyyaml\n\n      - name: Run schema validation\n        run: |\n          source /venv/bin/activate\n          git config --global --add safe.directory \"$GITHUB_WORKSPACE\"\n          tox -e validate -v\n","repository_owner":"getmanfred","repository_name":"mac","tokens_count":292,"workflow":"name: CI\n\non: [push, pull_request]\n\njobs:\n  python-lint:\n    runs-on: ubuntu-latest\n    container:\n      image: alpine:latest\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    - name: Package installation\n      run: |\n        apk add --no-cache git python3 py3-pip\n        python3 -m venv /venv\n        source /venv/bin/activate\n        pip install tox\n\n    - name: Run linting\n      run: |\n        source /venv/bin/activate\n        git config --global --add safe.directory \"$GITHUB_WORKSPACE\"\n        tox -e pep8 -v\n\n  validate-schema:\n    runs-on: ubuntu-latest\n    container:\n      image: alpine:latest\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    - name: Package installation\n      run: |\n        apk add --no-cache git python3 py3-pip\n        python3 -m venv /venv\n        source /venv/bin/activate\n        pip install tox jsonschema pyyaml\n\n    - name: Run schema validation\n      run: |\n        source /venv/bin/activate\n        git config --global --add safe.directory \"$GITHUB_WORKSPACE\"\n        tox -e validate -v\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `CI` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow has 2 jobs. The job id of the 1st job is `python-lint`. The job id of the 2nd job is `validate-schema`. ","prompt_level2":"Generate a GitHub Workflow named `CI` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow has 2 jobs. The job id of the 1st job is `python-lint`. The job `python-lint` has 3 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Package installation`. The 3rd step is named `Run linting`. The job id of the 2nd job is `validate-schema`. The job `validate-schema` has 3 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Package installation`. The 3rd step is named `Run schema validation`. ","prompt_level3":"Generate a GitHub Workflow named `CI` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow has 2 jobs. The job id of the 1st job is `python-lint`. This job will run on ubuntu-latest runner. The job creates a Docker container that uses `alpine:latest` image. The job `python-lint` has 3 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v3. The 2nd step is named `Package installation`. This step runs a script: `apk add --no-cache git python3 py3-pip\npython3 -m venv /venv\nsource /venv/bin/activate\npip install tox\n`. The 3rd step is named `Run linting`. This step runs a script: `source /venv/bin/activate\ngit config --global --add safe.directory \"$GITHUB_WORKSPACE\"\ntox -e pep8 -v\n`. The job id of the 2nd job is `validate-schema`. This job will run on ubuntu-latest runner. The job creates a Docker container that uses `alpine:latest` image. The job `validate-schema` has 3 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v3. The 2nd step is named `Package installation`. This step runs a script: `apk add --no-cache git python3 py3-pip\npython3 -m venv /venv\nsource /venv/bin/activate\npip install tox jsonschema pyyaml\n`. The 3rd step is named `Run schema validation`. This step runs a script: `source /venv/bin/activate\ngit config --global --add safe.directory \"$GITHUB_WORKSPACE\"\ntox -e validate -v\n`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":2,"nb_actions":2,"actions":["actions/checkout","actions/checkout"],"actions_details":[{"version":"v3","name":"actions/checkout"},{"version":"v3","name":"actions/checkout"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":6,"cyclomatic_complexity":2}
{"id":43323,"repository_id":4051192,"mainLanguage":"TypeScript","file_name":"ci-library.yml","file_content":"name:  CI - Library\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n\njobs:\n  typecheck:\n    name:  Typecheck\n    runs-on: ubuntu-latest\n    steps:\n      - name:  Checkout repo\n        uses: actions/checkout@v4\n\n      - name:  Setup node\n        uses: actions/setup-node@v4\n        with:\n          node-version-file: .nvmrc\n\n      - name:  Download deps\n        uses: bahmutov/npm-install@v1\n\n      - name:  Type check\n        run: npm run --workspace=remeda check\n\n  test-typing:\n    name: Tests/ Types [TypeScript ${{ matrix.typescript-version }}]\n    needs:\n      - typecheck\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        typescript-version:\n          - \"5.8\"\n          - \"5.7\"\n          - \"5.6\"\n          - \"5.5\"\n          - \"5.4\"\n          - \"5.3\"\n          - \"5.2\"\n          # This is the current lowest version of typescript we support. Do not\n          # change this without bumping a major version. We support up to 4\n          # versions back from the latest version of typescript at time of a\n          # major release.\n          - \"5.1\"\n\n    steps:\n      - name:  Checkout repo\n        uses: actions/checkout@v4\n\n      - name:  Setup node\n        uses: actions/setup-node@v4\n        with:\n          node-version-file: .nvmrc\n\n      - name:  Download deps\n        uses: bahmutov/npm-install@v1\n\n      # TODO: We are rebuilding everything several times, our builds aren't very\n      # expensive, but we can easily optimize by caching the 'dist' directory\n      # once.\n      - name:  Build\n        run: npm run --workspace=remeda build -- --dts-only\n\n      - name:  Install Typescript\n        run: npm install --workspace=remeda -D typescript@${{ matrix.typescript-version }}\n\n      - name:  Type tests\n        run: npm run  --workspace=remeda test:typing\n\n      - name:  Check Outputs\n        run: npm run  --workspace=remeda check:dist\n\n  test-runtime:\n    name: Tests/ Runtime [Node ${{ matrix.node }}]\n    needs:\n      - typecheck\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        node:\n          - 23\n          - 22\n          - 20\n          - 18\n    steps:\n      - name:  Checkout repo\n        uses: actions/checkout@v4\n\n      - name:  Setup node\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node }}\n\n      - name:  Download deps\n        uses: bahmutov/npm-install@v1\n\n      - name:  Run tests\n        run: npm run --workspace=remeda test:runtime\n\n  lint:\n    name:  Lint\n    needs:\n      - typecheck\n    runs-on: ubuntu-latest\n    steps:\n      - name:  Checkout repo\n        uses: actions/checkout@v4\n\n      - name:  Setup node\n        uses: actions/setup-node@v4\n        with:\n          node-version-file: .nvmrc\n\n      - name:  Download deps\n        uses: bahmutov/npm-install@v1\n\n      - name:  Lint\n        run: npm run  --workspace=remeda lint\n\n  formatting:\n    name:  Format\n    needs:\n      - typecheck\n    runs-on: ubuntu-latest\n    steps:\n      - name:  Checkout repo\n        uses: actions/checkout@v4\n\n      - name:  Setup node\n        uses: actions/setup-node@v4\n        with:\n          node-version-file: .nvmrc\n\n      - name:  Download deps\n        uses: bahmutov/npm-install@v1\n\n      - name:  Format\n        run: npm run --workspace=remeda format\n\n  publish:\n    needs:\n      - test-typing\n      - test-runtime\n      - formatting\n\n    if: github.repository == 'remeda/remeda' && github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n      - name:  Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name:  Setup node\n        uses: actions/setup-node@v4\n        with:\n          node-version-file: .nvmrc\n\n      - name:  Download deps\n        uses: bahmutov/npm-install@v1\n\n      - name:  Build\n        run: npm run --workspace=remeda build\n\n      - name:  Lint output\n        run: npm run --workspace=remeda lint:build\n\n      - name:  Release\n        run: npm run --workspace=remeda release\n        env:\n          GH_TOKEN: ${{secrets.GH_TOKEN}}\n          NPM_TOKEN: ${{secrets.NPM_TOKEN}}\n","repository_owner":"remeda","repository_name":"remeda","tokens_count":1204,"workflow":"name:  CI - Library\n\non:\n  push:\n    branches:\n    - main\n  pull_request:\n\njobs:\n  typecheck:\n    name:  Typecheck\n    runs-on: ubuntu-latest\n    steps:\n    - name:  Checkout repo\n      uses: actions/checkout@v4\n\n    - name:  Setup node\n      uses: actions/setup-node@v4\n      with:\n        node-version-file: .nvmrc\n\n    - name:  Download deps\n      uses: bahmutov/npm-install@v1\n\n    - name:  Type check\n      run: npm run --workspace=remeda check\n\n  test-typing:\n    name: Tests/ Types [TypeScript ${{ matrix.typescript-version }}]\n    needs:\n    - typecheck\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        typescript-version:\n        - '5.8'\n        - '5.7'\n        - '5.6'\n        - '5.5'\n        - '5.4'\n        - '5.3'\n        - '5.2'\n          # This is the current lowest version of typescript we support. Do not\n          # change this without bumping a major version. We support up to 4\n          # versions back from the latest version of typescript at time of a\n          # major release.\n        - '5.1'\n\n    steps:\n    - name:  Checkout repo\n      uses: actions/checkout@v4\n\n    - name:  Setup node\n      uses: actions/setup-node@v4\n      with:\n        node-version-file: .nvmrc\n\n    - name:  Download deps\n      uses: bahmutov/npm-install@v1\n\n      # TODO: We are rebuilding everything several times, our builds aren't very\n      # expensive, but we can easily optimize by caching the 'dist' directory\n      # once.\n    - name:  Build\n      run: npm run --workspace=remeda build -- --dts-only\n\n    - name:  Install Typescript\n      run: npm install --workspace=remeda -D typescript@${{ \n        matrix.typescript-version }}\n\n    - name:  Type tests\n      run: npm run  --workspace=remeda test:typing\n\n    - name:  Check Outputs\n      run: npm run  --workspace=remeda check:dist\n\n  test-runtime:\n    name: Tests/ Runtime [Node ${{ matrix.node }}]\n    needs:\n    - typecheck\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        node:\n        - 23\n        - 22\n        - 20\n        - 18\n    steps:\n    - name:  Checkout repo\n      uses: actions/checkout@v4\n\n    - name:  Setup node\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ matrix.node }}\n\n    - name:  Download deps\n      uses: bahmutov/npm-install@v1\n\n    - name:  Run tests\n      run: npm run --workspace=remeda test:runtime\n\n  lint:\n    name:  Lint\n    needs:\n    - typecheck\n    runs-on: ubuntu-latest\n    steps:\n    - name:  Checkout repo\n      uses: actions/checkout@v4\n\n    - name:  Setup node\n      uses: actions/setup-node@v4\n      with:\n        node-version-file: .nvmrc\n\n    - name:  Download deps\n      uses: bahmutov/npm-install@v1\n\n    - name:  Lint\n      run: npm run  --workspace=remeda lint\n\n  formatting:\n    name:  Format\n    needs:\n    - typecheck\n    runs-on: ubuntu-latest\n    steps:\n    - name:  Checkout repo\n      uses: actions/checkout@v4\n\n    - name:  Setup node\n      uses: actions/setup-node@v4\n      with:\n        node-version-file: .nvmrc\n\n    - name:  Download deps\n      uses: bahmutov/npm-install@v1\n\n    - name:  Format\n      run: npm run --workspace=remeda format\n\n  publish:\n    needs:\n    - test-typing\n    - test-runtime\n    - formatting\n\n    if: github.repository == 'remeda/remeda' && github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n    - name:  Checkout repo\n      uses: actions/checkout@v4\n      with:\n        fetch-depth: 0\n\n    - name:  Setup node\n      uses: actions/setup-node@v4\n      with:\n        node-version-file: .nvmrc\n\n    - name:  Download deps\n      uses: bahmutov/npm-install@v1\n\n    - name:  Build\n      run: npm run --workspace=remeda build\n\n    - name:  Lint output\n      run: npm run --workspace=remeda lint:build\n\n    - name:  Release\n      run: npm run --workspace=remeda release\n      env:\n        GH_TOKEN: ${{secrets.GH_TOKEN}}\n        NPM_TOKEN: ${{secrets.NPM_TOKEN}}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named ` CI - Library` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main. 2) there is activity relating to a pull request. The workflow has 6 jobs. The 1st job is named ` Typecheck` and its job id is `typecheck`. The 2nd job is named `Tests/ Types [TypeScript ${{ matrix.typescript-version }}]` and its job id is `test-typing`. The 3rd job is named `Tests/ Runtime [Node ${{ matrix.node }}]` and its job id is `test-runtime`. The 4th job is named ` Lint` and its job id is `lint`. The 5th job is named ` Format` and its job id is `formatting`. The job id of the 6th job is `publish`. ","prompt_level2":"Generate a GitHub Workflow named ` CI - Library` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main. 2) there is activity relating to a pull request. The workflow has 6 jobs. The 1st job is named ` Typecheck` and its job id is `typecheck`. The job `typecheck` has 4 steps. The 1st step is named `Checkout repository`. The 2nd step is named ` Setup node`. The 3rd step is named ` Download deps`. The 4th step is named ` Type check`. The 2nd job is named `Tests/ Types [TypeScript ${{ matrix.typescript-version }}]` and its job id is `test-typing`. The job `test-typing` has 7 steps. The 1st step is named `Checkout repository`. The 2nd step is named ` Setup node`. The 3rd step is named ` Download deps`. The 4th step is named ` Build`. The 5th step is named ` Install Typescript`. The 6th step is named ` Type tests`. The 7th step is named ` Check Outputs`. The 3rd job is named `Tests/ Runtime [Node ${{ matrix.node }}]` and its job id is `test-runtime`. The job `test-runtime` has 4 steps. The 1st step is named `Checkout repository`. The 2nd step is named ` Setup node`. The 3rd step is named ` Download deps`. The 4th step is named ` Run tests`. The 4th job is named ` Lint` and its job id is `lint`. The job `lint` has 4 steps. The 1st step is named `Checkout repository`. The 2nd step is named ` Setup node`. The 3rd step is named ` Download deps`. The 4th step is named ` Lint`. The 5th job is named ` Format` and its job id is `formatting`. The job `formatting` has 4 steps. The 1st step is named `Checkout repository`. The 2nd step is named ` Setup node`. The 3rd step is named ` Download deps`. The 4th step is named ` Format`. The job id of the 6th job is `publish`. The job `publish` has 6 steps. The 1st step is named `Checkout repository`. The 2nd step is named ` Setup node`. The 3rd step is named ` Download deps`. The 4th step is named ` Build`. The 5th step is named ` Lint output`. The 6th step is named ` Release`. ","prompt_level3":"Generate a GitHub Workflow named ` CI - Library` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main. 2) there is activity relating to a pull request. The workflow has 6 jobs. The 1st job is named ` Typecheck` and its job id is `typecheck`. This job will run on ubuntu-latest runner. The job `typecheck` has 4 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named ` Setup node`. This step runs action `actions/setup-node` tagged as v4. The step defines an input parameter for the action: `node-version-file` is set to `.nvmrc`. The 3rd step is named ` Download deps`. This step runs action `bahmutov/npm-install` tagged as v1. The 4th step is named ` Type check`. This step runs a script: `npm run --workspace=remeda check`. The 2nd job is named `Tests/ Types [TypeScript ${{ matrix.typescript-version }}]` and its job id is `test-typing`. Before this job runs, `typecheck` must complete successfully. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `typescript-version` has 8 values: 5.8, 5.7, 5.6, 5.5, 5.4, 5.3, 5.2 and 5.1. The job `test-typing` has 7 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named ` Setup node`. This step runs action `actions/setup-node` tagged as v4. The step defines an input parameter for the action: `node-version-file` is set to `.nvmrc`. The 3rd step is named ` Download deps`. This step runs action `bahmutov/npm-install` tagged as v1. The 4th step is named ` Build`. This step runs a script: `npm run --workspace=remeda build -- --dts-only`. The 5th step is named ` Install Typescript`. This step runs a script: `npm install --workspace=remeda -D typescript@${{ matrix.typescript-version }}`. The 6th step is named ` Type tests`. This step runs a script: `npm run  --workspace=remeda test:typing`. The 7th step is named ` Check Outputs`. This step runs a script: `npm run  --workspace=remeda check:dist`. The 3rd job is named `Tests/ Runtime [Node ${{ matrix.node }}]` and its job id is `test-runtime`. Before this job runs, `typecheck` must complete successfully. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `node` has 4 values: 23, 22, 20 and 18. The job `test-runtime` has 4 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named ` Setup node`. This step runs action `actions/setup-node` tagged as v4. The step defines an input parameter for the action: `node-version` is set to `${{ matrix.node }}`. The 3rd step is named ` Download deps`. This step runs action `bahmutov/npm-install` tagged as v1. The 4th step is named ` Run tests`. This step runs a script: `npm run --workspace=remeda test:runtime`. The 4th job is named ` Lint` and its job id is `lint`. Before this job runs, `typecheck` must complete successfully. This job will run on ubuntu-latest runner. The job `lint` has 4 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named ` Setup node`. This step runs action `actions/setup-node` tagged as v4. The step defines an input parameter for the action: `node-version-file` is set to `.nvmrc`. The 3rd step is named ` Download deps`. This step runs action `bahmutov/npm-install` tagged as v1. The 4th step is named ` Lint`. This step runs a script: `npm run  --workspace=remeda lint`. The 5th job is named ` Format` and its job id is `formatting`. Before this job runs, `typecheck` must complete successfully. This job will run on ubuntu-latest runner. The job `formatting` has 4 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named ` Setup node`. This step runs action `actions/setup-node` tagged as v4. The step defines an input parameter for the action: `node-version-file` is set to `.nvmrc`. The 3rd step is named ` Download deps`. This step runs action `bahmutov/npm-install` tagged as v1. The 4th step is named ` Format`. This step runs a script: `npm run --workspace=remeda format`. The job id of the 6th job is `publish`. Before this job runs, `test-typing`, `test-runtime` and `formatting` must complete successfully. This job will run only if the condition(github.repository == 'remeda/remeda' && github.ref == 'refs/heads/main') is met. This job will run on ubuntu-latest runner. The job `publish` has 6 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `fetch-depth` is set to `0`. The 2nd step is named ` Setup node`. This step runs action `actions/setup-node` tagged as v4. The step defines an input parameter for the action: `node-version-file` is set to `.nvmrc`. The 3rd step is named ` Download deps`. This step runs action `bahmutov/npm-install` tagged as v1. The 4th step is named ` Build`. This step runs a script: `npm run --workspace=remeda build`. The 5th step is named ` Lint output`. This step runs a script: `npm run --workspace=remeda lint:build`. The 6th step is named ` Release`. The step sets 2 environment variables to use: `GH_TOKEN` is set to `${{secrets.GH_TOKEN}}` and `NPM_TOKEN` is set to `${{secrets.NPM_TOKEN}}`. This step runs a script: `npm run --workspace=remeda release`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":6,"nb_actions":18,"actions":["actions/checkout","actions/checkout","actions/checkout","actions/checkout","actions/checkout","actions/checkout","actions/setup-node","actions/setup-node","actions/setup-node","actions/setup-node","actions/setup-node","actions/setup-node","bahmutov/npm-install","bahmutov/npm-install","bahmutov/npm-install","bahmutov/npm-install","bahmutov/npm-install","bahmutov/npm-install"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/setup-node"},{"version":"v1","name":"bahmutov/npm-install"},{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/setup-node"},{"version":"v1","name":"bahmutov/npm-install"},{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/setup-node"},{"version":"v1","name":"bahmutov/npm-install"},{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/setup-node"},{"version":"v1","name":"bahmutov/npm-install"},{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/setup-node"},{"version":"v1","name":"bahmutov/npm-install"},{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/setup-node"},{"version":"v1","name":"bahmutov/npm-install"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":29,"cyclomatic_complexity":4}
{"id":242,"repository_id":91567220,"mainLanguage":"Python","file_name":"platform-backend-ci.yml","file_content":"name: AutoGPT Platform - Backend CI\n\non:\n  push:\n    branches: [master, dev, ci-test*]\n    paths:\n      - \".github/workflows/platform-backend-ci.yml\"\n      - \"autogpt_platform/backend/**\"\n      - \"autogpt_platform/autogpt_libs/**\"\n  pull_request:\n    branches: [master, dev, release-*]\n    paths:\n      - \".github/workflows/platform-backend-ci.yml\"\n      - \"autogpt_platform/backend/**\"\n      - \"autogpt_platform/autogpt_libs/**\"\n  merge_group:\n\nconcurrency:\n  group: ${{ format('backend-ci-{0}', github.head_ref && format('{0}-{1}', github.event_name, github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ startsWith(github.event_name, 'pull_request') }}\n\ndefaults:\n  run:\n    shell: bash\n    working-directory: autogpt_platform/backend\n\njobs:\n  test:\n    permissions:\n      contents: read\n    timeout-minutes: 30\n    strategy:\n      fail-fast: false\n      matrix:\n        python-version: [\"3.10\"]\n    runs-on: ubuntu-latest\n\n    services:\n      redis:\n        image: bitnami/redis:6.2\n        env:\n          REDIS_PASSWORD: testpassword\n        ports:\n          - 6379:6379\n      rabbitmq:\n        image: rabbitmq:3.12-management\n        ports:\n          - 5672:5672\n          - 15672:15672\n        env:\n          RABBITMQ_DEFAULT_USER: ${{ env.RABBITMQ_DEFAULT_USER }}\n          RABBITMQ_DEFAULT_PASS: ${{ env.RABBITMQ_DEFAULT_PASS }}\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n          submodules: true\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n\n      - name: Setup Supabase\n        uses: supabase/setup-cli@v1\n        with:\n          version: latest\n\n      - id: get_date\n        name: Get date\n        run: echo \"date=$(date +'%Y-%m-%d')\" >> $GITHUB_OUTPUT\n\n      - name: Set up Python dependency cache\n        uses: actions/cache@v4\n        with:\n          path: ~/.cache/pypoetry\n          key: poetry-${{ runner.os }}-${{ hashFiles('autogpt_platform/backend/poetry.lock') }}\n\n      - name: Install Poetry (Unix)\n        run: |\n          curl -sSL https://install.python-poetry.org | python3 -\n\n          if [ \"${{ runner.os }}\" = \"macOS\" ]; then\n            PATH=\"$HOME/.local/bin:$PATH\"\n            echo \"$HOME/.local/bin\" >> $GITHUB_PATH\n          fi\n\n      - name: Check poetry.lock\n        run: |\n          poetry lock\n\n          if ! git diff --quiet poetry.lock; then\n            echo \"Error: poetry.lock not up to date.\"\n            echo\n            git diff poetry.lock\n            exit 1\n          fi\n\n      - name: Install Python dependencies\n        run: poetry install\n\n      - name: Generate Prisma Client\n        run: poetry run prisma generate\n\n      - id: supabase\n        name: Start Supabase\n        working-directory: .\n        run: |\n          supabase init\n          supabase start --exclude postgres-meta,realtime,storage-api,imgproxy,inbucket,studio,edge-runtime,logflare,vector,supavisor\n          supabase status -o env | sed 's/=\"/=/; s/\"$//' >> $GITHUB_OUTPUT\n        # outputs:\n        # DB_URL, API_URL, GRAPHQL_URL, ANON_KEY, SERVICE_ROLE_KEY, JWT_SECRET\n\n      - name: Run Database Migrations\n        run: poetry run prisma migrate dev --name updates\n        env:\n          DATABASE_URL: ${{ steps.supabase.outputs.DB_URL }}\n\n      - id: lint\n        name: Run Linter\n        run: poetry run lint\n\n      - name: Run pytest with coverage\n        run: |\n          if [[ \"${{ runner.debug }}\" == \"1\" ]]; then\n            poetry run pytest -s -vv -o log_cli=true -o log_cli_level=DEBUG test\n          else\n            poetry run pytest -s -vv test\n          fi\n        if: success() || (failure() && steps.lint.outcome == 'failure')\n        env:\n          LOG_LEVEL: ${{ runner.debug && 'DEBUG' || 'INFO' }}\n          DATABASE_URL: ${{ steps.supabase.outputs.DB_URL }}\n          SUPABASE_URL: ${{ steps.supabase.outputs.API_URL }}\n          SUPABASE_SERVICE_ROLE_KEY: ${{ steps.supabase.outputs.SERVICE_ROLE_KEY }}\n          SUPABASE_JWT_SECRET: ${{ steps.supabase.outputs.JWT_SECRET }}\n          REDIS_HOST: 'localhost'\n          REDIS_PORT: '6379'\n          REDIS_PASSWORD: 'testpassword'\n\n    env:\n      CI: true\n      PLAIN_OUTPUT: True\n      RUN_ENV: local\n      PORT: 8080\n      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n      # We know these are here, don't report this as a security vulnerability\n      # This is used as the default credential for the entire system's RabbitMQ instance\n      # If you want to replace this, you can do so by making our entire system generate\n      # new credentials for each local user and update the environment variables in\n      # the backend service, docker composes, and examples\n      RABBITMQ_DEFAULT_USER: 'rabbitmq_user_default'\n      RABBITMQ_DEFAULT_PASS: 'k0VMxyIJF9S35f3x2uaw5IWAl6Y536O7'\n\n      # - name: Upload coverage reports to Codecov\n      #   uses: codecov/codecov-action@v4\n      #   with:\n      #     token: ${{ secrets.CODECOV_TOKEN }}\n      #     flags: backend,${{ runner.os }}\n","repository_owner":"kaqijiang","repository_name":"auto-gpt-zh","tokens_count":1351,"workflow":"name: AutoGPT Platform - Backend CI\n\non:\n  push:\n    branches: [master, dev, ci-test*]\n    paths:\n    - .github/workflows/platform-backend-ci.yml\n    - autogpt_platform/backend/**\n    - autogpt_platform/autogpt_libs/**\n  pull_request:\n    branches: [master, dev, release-*]\n    paths:\n    - .github/workflows/platform-backend-ci.yml\n    - autogpt_platform/backend/**\n    - autogpt_platform/autogpt_libs/**\n  merge_group:\n\nconcurrency:\n  group: ${{ format('backend-ci-{0}', github.head_ref && format('{0}-{1}', \n    github.event_name, github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ startsWith(github.event_name, 'pull_request') }}\n\ndefaults:\n  run:\n    shell: bash\n    working-directory: autogpt_platform/backend\n\njobs:\n  test:\n    permissions:\n      contents: read\n    timeout-minutes: 30\n    strategy:\n      fail-fast: false\n      matrix:\n        python-version: ['3.10']\n    runs-on: ubuntu-latest\n\n    services:\n      redis:\n        image: bitnami/redis:6.2\n        env:\n          REDIS_PASSWORD: testpassword\n        ports:\n        - 6379:6379\n      rabbitmq:\n        image: rabbitmq:3.12-management\n        ports:\n        - 5672:5672\n        - 15672:15672\n        env:\n          RABBITMQ_DEFAULT_USER: ${{ env.RABBITMQ_DEFAULT_USER }}\n          RABBITMQ_DEFAULT_PASS: ${{ env.RABBITMQ_DEFAULT_PASS }}\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      with:\n        fetch-depth: 0\n        submodules: true\n\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v5\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Setup Supabase\n      uses: supabase/setup-cli@v1\n      with:\n        version: latest\n\n    - id: get_date\n      name: Get date\n      run: echo \"date=$(date +'%Y-%m-%d')\" >> $GITHUB_OUTPUT\n\n    - name: Set up Python dependency cache\n      uses: actions/cache@v4\n      with:\n        path: ~/.cache/pypoetry\n        key: poetry-${{ runner.os }}-${{ \n          hashFiles('autogpt_platform/backend/poetry.lock') }}\n\n    - name: Install Poetry (Unix)\n      run: |\n        curl -sSL https://install.python-poetry.org | python3 -\n\n        if [ \"${{ runner.os }}\" = \"macOS\" ]; then\n          PATH=\"$HOME/.local/bin:$PATH\"\n          echo \"$HOME/.local/bin\" >> $GITHUB_PATH\n        fi\n\n    - name: Check poetry.lock\n      run: |\n        poetry lock\n\n        if ! git diff --quiet poetry.lock; then\n          echo \"Error: poetry.lock not up to date.\"\n          echo\n          git diff poetry.lock\n          exit 1\n        fi\n\n    - name: Install Python dependencies\n      run: poetry install\n\n    - name: Generate Prisma Client\n      run: poetry run prisma generate\n\n    - id: supabase\n      name: Start Supabase\n      working-directory: .\n      run: |\n        supabase init\n        supabase start --exclude postgres-meta,realtime,storage-api,imgproxy,inbucket,studio,edge-runtime,logflare,vector,supavisor\n        supabase status -o env | sed 's/=\"/=/; s/\"$//' >> $GITHUB_OUTPUT\n       # outputs:\n        # DB_URL, API_URL, GRAPHQL_URL, ANON_KEY, SERVICE_ROLE_KEY, JWT_SECRET\n\n    - name: Run Database Migrations\n      run: poetry run prisma migrate dev --name updates\n      env:\n        DATABASE_URL: ${{ steps.supabase.outputs.DB_URL }}\n\n    - id: lint\n      name: Run Linter\n      run: poetry run lint\n\n    - name: Run pytest with coverage\n      run: |\n        if [[ \"${{ runner.debug }}\" == \"1\" ]]; then\n          poetry run pytest -s -vv -o log_cli=true -o log_cli_level=DEBUG test\n        else\n          poetry run pytest -s -vv test\n        fi\n      if: success() || (failure() && steps.lint.outcome == 'failure')\n      env:\n        LOG_LEVEL: ${{ runner.debug && 'DEBUG' || 'INFO' }}\n        DATABASE_URL: ${{ steps.supabase.outputs.DB_URL }}\n        SUPABASE_URL: ${{ steps.supabase.outputs.API_URL }}\n        SUPABASE_SERVICE_ROLE_KEY: ${{ steps.supabase.outputs.SERVICE_ROLE_KEY \n          }}\n        SUPABASE_JWT_SECRET: ${{ steps.supabase.outputs.JWT_SECRET }}\n        REDIS_HOST: localhost\n        REDIS_PORT: '6379'\n        REDIS_PASSWORD: testpassword\n\n    env:\n      CI: true\n      PLAIN_OUTPUT: true\n      RUN_ENV: local\n      PORT: 8080\n      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n      # We know these are here, don't report this as a security vulnerability\n      # This is used as the default credential for the entire system's RabbitMQ instance\n      # If you want to replace this, you can do so by making our entire system generate\n      # new credentials for each local user and update the environment variables in\n      # the backend service, docker composes, and examples\n      RABBITMQ_DEFAULT_USER: rabbitmq_user_default\n      RABBITMQ_DEFAULT_PASS: k0VMxyIJF9S35f3x2uaw5IWAl6Y536O7\n\n      # - name: Upload coverage reports to Codecov\n      #   uses: codecov/codecov-action@v4\n      #   with:\n      #     token: ${{ secrets.CODECOV_TOKEN }}\n      #     flags: backend,${{ runner.os }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `AutoGPT Platform - Backend CI` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master, a branch named dev or a branch whose name matches ci-test*. Only if at least one path of push event matches a pattern in the paths filter(.github/workflows/platform-backend-ci.yml, autogpt_platform/backend/** or autogpt_platform/autogpt_libs/**), the workflow runs. 2) The workflow would run whenever there is a pull_request event targeting: a branch named master, a branch named dev or a branch whose name matches release-*. Only if at least one path of pull_request event matches a pattern in the paths filter(.github/workflows/platform-backend-ci.yml, autogpt_platform/backend/** or autogpt_platform/autogpt_libs/**), the workflow runs. 3) there is activity relating to a merge group in a merge queue. For all run steps in the workflow, default shell is set to bash and default working directory is set to autogpt_platform/backend. Only a single workflow using the ${{ format('backend-ci-{0}', github.head_ref && format('{0}-{1}', github.event_name, github.event.pull_request.number) || github.sha) }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `test`. ","prompt_level2":"Generate a GitHub Workflow named `AutoGPT Platform - Backend CI` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master, a branch named dev or a branch whose name matches ci-test*. Only if at least one path of push event matches a pattern in the paths filter(.github/workflows/platform-backend-ci.yml, autogpt_platform/backend/** or autogpt_platform/autogpt_libs/**), the workflow runs. 2) The workflow would run whenever there is a pull_request event targeting: a branch named master, a branch named dev or a branch whose name matches release-*. Only if at least one path of pull_request event matches a pattern in the paths filter(.github/workflows/platform-backend-ci.yml, autogpt_platform/backend/** or autogpt_platform/autogpt_libs/**), the workflow runs. 3) there is activity relating to a merge group in a merge queue. For all run steps in the workflow, default shell is set to bash and default working directory is set to autogpt_platform/backend. Only a single workflow using the ${{ format('backend-ci-{0}', github.head_ref && format('{0}-{1}', github.event_name, github.event.pull_request.number) || github.sha) }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `test`. The job `test` has 13 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up Python ${{ matrix.python-version }}`. The 3rd step is named `Setup Supabase`. The 4th step is named `Get date` and its id is `get_date`. The 5th step is named `Set up Python dependency cache`. The 6th step is named `Install Poetry (Unix)`. The 7th step is named `Check poetry.lock`. The 8th step is named `Install Python dependencies`. The 9th step is named `Generate Prisma Client`. The 10th step is named `Start Supabase` and its id is `supabase`. The 11th step is named `Run Database Migrations`. The 12th step is named `Run Linter` and its id is `lint`. The 13th step is named `Run pytest with coverage`. ","prompt_level3":"Generate a GitHub Workflow named `AutoGPT Platform - Backend CI` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master, a branch named dev or a branch whose name matches ci-test*. Only if at least one path of push event matches a pattern in the paths filter(.github/workflows/platform-backend-ci.yml, autogpt_platform/backend/** or autogpt_platform/autogpt_libs/**), the workflow runs. 2) The workflow would run whenever there is a pull_request event targeting: a branch named master, a branch named dev or a branch whose name matches release-*. Only if at least one path of pull_request event matches a pattern in the paths filter(.github/workflows/platform-backend-ci.yml, autogpt_platform/backend/** or autogpt_platform/autogpt_libs/**), the workflow runs. 3) there is activity relating to a merge group in a merge queue. For all run steps in the workflow, default shell is set to bash and default working directory is set to autogpt_platform/backend. Only a single workflow using the ${{ format('backend-ci-{0}', github.head_ref && format('{0}-{1}', github.event_name, github.event.pull_request.number) || github.sha) }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `test`. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `python-version` has one value: 3.10. The job defines a service called redis which will be created using the Docker image `bitnami/redis:6.2`. The service container sets an environment variable to use: `REDIS_PASSWORD` is set to `testpassword`. For communication, the port 6379 on the Docker host is mapped to port 6379 on the service container. The job defines a service called rabbitmq which will be created using the Docker image `rabbitmq:3.12-management`. The service container sets 2 environment variables to use: `RABBITMQ_DEFAULT_USER` is set to `${{ env.RABBITMQ_DEFAULT_USER }}` and `RABBITMQ_DEFAULT_PASS` is set to `${{ env.RABBITMQ_DEFAULT_PASS }}`. For communication, the port 5672 on the Docker host is mapped to port 5672 on the service container and the port 15672 on the Docker host is mapped to port 15672 on the service container. The job `test` modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting only applies to the job `test`. The job sets 7 environment variables to use: `CI` is set to `True`, `PLAIN_OUTPUT` is set to `True`, `RUN_ENV` is set to `local`, `PORT` is set to `8080`, `OPENAI_API_KEY` is set to `${{ secrets.OPENAI_API_KEY }}`, `RABBITMQ_DEFAULT_USER` is set to `rabbitmq_user_default` and `RABBITMQ_DEFAULT_PASS` is set to `k0VMxyIJF9S35f3x2uaw5IWAl6Y536O7`. The maximum number of minutes to run the job is 30. The job `test` has 13 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines 2 input parameters for the action: `fetch-depth` is set to `0` and `submodules` is set to `True`. The 2nd step is named `Set up Python ${{ matrix.python-version }}`. This step runs action `actions/setup-python` tagged as v5. The step defines an input parameter for the action: `python-version` is set to `${{ matrix.python-version }}`. The 3rd step is named `Setup Supabase`. This step runs action `supabase/setup-cli` tagged as v1. The step defines an input parameter for the action: `version` is set to `latest`. The 4th step is named `Get date` and its id is `get_date`. This step runs a script: `echo \"date=$(date +'%Y-%m-%d')\" >> $GITHUB_OUTPUT`. The 5th step is named `Set up Python dependency cache`. This step runs action `actions/cache` tagged as v4. The step defines 2 input parameters for the action: `path` is set to `~/.cache/pypoetry` and `key` is set to `poetry-${{ runner.os }}-${{ hashFiles('autogpt_platform/backend/poetry.lock') }}`. The 6th step is named `Install Poetry (Unix)`. This step runs a script: `curl -sSL https://install.python-poetry.org | python3 -\n\nif [ \"${{ runner.os }}\" = \"macOS\" ]; then\n  PATH=\"$HOME/.local/bin:$PATH\"\n  echo \"$HOME/.local/bin\" >> $GITHUB_PATH\nfi\n`. The 7th step is named `Check poetry.lock`. This step runs a script: `poetry lock\n\nif ! git diff --quiet poetry.lock; then\n  echo \"Error: poetry.lock not up to date.\"\n  echo\n  git diff poetry.lock\n  exit 1\nfi\n`. The 8th step is named `Install Python dependencies`. This step runs a script: `poetry install`. The 9th step is named `Generate Prisma Client`. This step runs a script: `poetry run prisma generate`. The 10th step is named `Start Supabase` and its id is `supabase`. This step runs a script: `supabase init\nsupabase start --exclude postgres-meta,realtime,storage-api,imgproxy,inbucket,studio,edge-runtime,logflare,vector,supavisor\nsupabase status -o env | sed 's/=\"/=/; s/\"$//' >> $GITHUB_OUTPUT\n`. The 11th step is named `Run Database Migrations`. The step sets an environment variable to use: `DATABASE_URL` is set to `${{ steps.supabase.outputs.DB_URL }}`. This step runs a script: `poetry run prisma migrate dev --name updates`. The 12th step is named `Run Linter` and its id is `lint`. This step runs a script: `poetry run lint`. The 13th step is named `Run pytest with coverage`. This step will run only if the condition(success() || (failure() && steps.lint.outcome == 'failure')) is met. The step sets 8 environment variables to use: `LOG_LEVEL` is set to `${{ runner.debug && 'DEBUG' || 'INFO' }}`, `DATABASE_URL` is set to `${{ steps.supabase.outputs.DB_URL }}`, `SUPABASE_URL` is set to `${{ steps.supabase.outputs.API_URL }}`, `SUPABASE_SERVICE_ROLE_KEY` is set to `${{ steps.supabase.outputs.SERVICE_ROLE_KEY }}`, `SUPABASE_JWT_SECRET` is set to `${{ steps.supabase.outputs.JWT_SECRET }}`, `REDIS_HOST` is set to `localhost`, `REDIS_PORT` is set to `6379` and `REDIS_PASSWORD` is set to `testpassword`. This step runs a script: `if [[ \"${{ runner.debug }}\" == \"1\" ]]; then\n  poetry run pytest -s -vv -o log_cli=true -o log_cli_level=DEBUG test\nelse\n  poetry run pytest -s -vv test\nfi\n`. ","nb_triggers":3,"triggers":["merge_group","pull_request","push"],"nb_jobs":1,"nb_actions":4,"actions":["actions/cache","actions/checkout","actions/setup-python","supabase/setup-cli"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v5","name":"actions/setup-python"},{"version":"v1","name":"supabase/setup-cli"},{"version":"v4","name":"actions/cache"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":13,"cyclomatic_complexity":1}
{"id":57412,"repository_id":94667745,"mainLanguage":"Rust","file_name":"update-lockfiles.yml","file_content":"# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Update lockfiles scheduled\nrun-name: ${{ github.workflow }}\non:\n  schedule:\n    # Runs 22:00 UTC every Tuesday\n  - cron: 0 22 * * 2\n\npermissions:\n  contents: read\n  id-token: write\n\njobs:\n  cargo-update-runtime-lockfiles-and-sdk-lockfile:\n    name: Run cargo update on the runtime lockfiles and the SDK lockfile\n    # Don't run on forked repositories\n    if: github.repository == 'smithy-lang/smithy-rs'\n    uses: ./.github/workflows/pull-request-updating-lockfiles.yml\n    with:\n      base_branch: main\n      force_update_on_broken_dependencies: false\n    secrets:\n      DOCKER_LOGIN_TOKEN_PASSPHRASE: ${{ secrets.DOCKER_LOGIN_TOKEN_PASSPHRASE }}\n      SMITHY_RS_PUBLIC_ECR_PUSH_ROLE_ARN: ${{ secrets.SMITHY_RS_PUBLIC_ECR_PUSH_ROLE_ARN }}\n      RELEASE_AUTOMATION_BOT_PAT: ${{ secrets.RELEASE_AUTOMATION_BOT_PAT }}\n","repository_owner":"smithy-lang","repository_name":"smithy-rs","tokens_count":255,"workflow":"# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Update lockfiles scheduled\nrun-name: ${{ github.workflow }}\non:\n  schedule:\n    # Runs 22:00 UTC every Tuesday\n  - cron: 0 22 * * 2\n\npermissions:\n  contents: read\n  id-token: write\n\njobs:\n  cargo-update-runtime-lockfiles-and-sdk-lockfile:\n    name: Run cargo update on the runtime lockfiles and the SDK lockfile\n    # Don't run on forked repositories\n    if: github.repository == 'smithy-lang/smithy-rs'\n    uses: ./.github/workflows/pull-request-updating-lockfiles.yml\n    with:\n      base_branch: main\n      force_update_on_broken_dependencies: false\n    secrets:\n      DOCKER_LOGIN_TOKEN_PASSPHRASE: ${{ secrets.DOCKER_LOGIN_TOKEN_PASSPHRASE \n        }}\n      SMITHY_RS_PUBLIC_ECR_PUSH_ROLE_ARN: ${{ \n        secrets.SMITHY_RS_PUBLIC_ECR_PUSH_ROLE_ARN }}\n      RELEASE_AUTOMATION_BOT_PAT: ${{ secrets.RELEASE_AUTOMATION_BOT_PAT }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Update lockfiles scheduled` for a GitHub repository whose primary programming language is Rust. The name for workflow runs is set to `${{ github.workflow }}`. This workflow will be triggered by an event: the scheduled time has come: at 10:00 pm, only on tuesday. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Run cargo update on the runtime lockfiles and the SDK lockfile` and its job id is `cargo-update-runtime-lockfiles-and-sdk-lockfile`. ","prompt_level2":"Generate a GitHub Workflow named `Update lockfiles scheduled` for a GitHub repository whose primary programming language is Rust. The name for workflow runs is set to `${{ github.workflow }}`. This workflow will be triggered by an event: the scheduled time has come: at 10:00 pm, only on tuesday. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Run cargo update on the runtime lockfiles and the SDK lockfile` and its job id is `cargo-update-runtime-lockfiles-and-sdk-lockfile`. ","prompt_level3":"Generate a GitHub Workflow named `Update lockfiles scheduled` for a GitHub repository whose primary programming language is Rust. The name for workflow runs is set to `${{ github.workflow }}`. This workflow will be triggered by an event: the scheduled time has come: at 10:00 pm, only on tuesday. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Run cargo update on the runtime lockfiles and the SDK lockfile` and its job id is `cargo-update-runtime-lockfiles-and-sdk-lockfile`. This job will run only if the condition(github.repository == 'smithy-lang/smithy-rs') is met. This job will call a reusable workflow located at `./.github/workflows/pull-request-updating-lockfiles.yml`. The job will pass 2 inputs to the called workflow: the input `base_branch` is `main` and the input `force_update_on_broken_dependencies` is `False`. The job will pass 3 secrets to the called workflow: the secret `DOCKER_LOGIN_TOKEN_PASSPHRASE` is `${{ secrets.DOCKER_LOGIN_TOKEN_PASSPHRASE }}`, the secret `SMITHY_RS_PUBLIC_ECR_PUSH_ROLE_ARN` is `${{ secrets.SMITHY_RS_PUBLIC_ECR_PUSH_ROLE_ARN }}` and the secret `RELEASE_AUTOMATION_BOT_PAT` is `${{ secrets.RELEASE_AUTOMATION_BOT_PAT }}`. ","nb_triggers":1,"triggers":["schedule"],"nb_jobs":1,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["./.github/workflows/pull-request-updating-lockfiles.yml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":47430,"repository_id":3490588,"mainLanguage":"C","file_name":"event-nightly.yml","file_content":"name: Event Nightly\n\npermissions:\n  id-token: write\n  contents: read\n\non:\n  push:\n    branches:\n      - main\n      - master\n      - '[0-9]+.[0-9]+.[0-9]+'\n      - '[0-9]+.[0-9]+'\n  schedule:\n    - cron: '20 20 * * *' # 20:20 UTC every day\n  workflow_dispatch:\n    inputs:\n      redis-ref:\n        description: 'Redis ref to checkout'\n        required: true\n        default: 'unstable'\njobs:\n  prepare-values:\n    runs-on: ubuntu-latest\n    outputs:\n      redis-ref: ${{ steps.set-env.outputs.redis-ref }}\n    steps:\n      - name: set env\n        id: set-env\n        run: |\n          echo \"redis-ref=${{ inputs.redis-ref || 'unstable' }}\" >> $GITHUB_OUTPUT  # todo change per version/tag\n  build-linux-x86:\n    uses: ./.github/workflows/flow-linux-x86.yml\n    needs: [prepare-values]\n    with:\n      os: bionic focal jammy rocky8 rocky9 bullseye amazonlinux2 mariner2 azurelinux3\n      redis-ref: ${{needs.prepare-values.outputs.redis-ref}}\n    secrets: inherit\n  ubuntu-arm64:\n    uses: ./.github/workflows/flow-ubuntu-arm.yml\n    needs: [prepare-values]\n    with:\n      redis-ref: ${{needs.prepare-values.outputs.redis-ref}}\n    secrets: inherit\n  macos:\n    uses: ./.github/workflows/flow-macos.yml\n    needs: [prepare-values]\n    with:\n      redis-ref: ${{needs.prepare-values.outputs.redis-ref}}\n    secrets: inherit\n  alpine:\n    uses: ./.github/workflows/flow-alpine.yml\n    needs: [prepare-values]\n    with:\n      redis-ref: ${{needs.prepare-values.outputs.redis-ref}}\n    secrets: inherit\n  linux-valgrind:\n    uses: ./.github/workflows/flow-linux-x86.yml\n    needs: [prepare-values]\n    with:\n      os: jammy\n      redis-ref: ${{needs.prepare-values.outputs.redis-ref}}\n      run_valgrind: true\n    secrets: inherit\n  linux-sanitizer:\n    uses: ./.github/workflows/flow-linux-x86.yml\n    needs: [prepare-values]\n    with:\n      os: jammy\n      redis-ref: ${{needs.prepare-values.outputs.redis-ref}}\n      run_sanitizer: true\n    secrets: inherit\n  spellcheck:\n    uses: ./.github/workflows/flow-spellcheck.yml\n    secrets: inherit\n  linter:\n    uses: ./.github/workflows/flow-linter.yml\n    secrets: inherit\n","repository_owner":"redisbloom","repository_name":"redisbloom","tokens_count":595,"workflow":"name: Event Nightly\n\npermissions:\n  id-token: write\n  contents: read\n\non:\n  push:\n    branches:\n    - main\n    - master\n    - '[0-9]+.[0-9]+.[0-9]+'\n    - '[0-9]+.[0-9]+'\n  schedule:\n  - cron: 20 20 * * *     # 20:20 UTC every day\n  workflow_dispatch:\n    inputs:\n      redis-ref:\n        description: Redis ref to checkout\n        required: true\n        default: unstable\njobs:\n  prepare-values:\n    runs-on: ubuntu-latest\n    outputs:\n      redis-ref: ${{ steps.set-env.outputs.redis-ref }}\n    steps:\n    - name: set env\n      id: set-env\n      run: |\n        echo \"redis-ref=${{ inputs.redis-ref || 'unstable' }}\" >> $GITHUB_OUTPUT  # todo change per version/tag\n  build-linux-x86:\n    uses: ./.github/workflows/flow-linux-x86.yml\n    needs: [prepare-values]\n    with:\n      os: bionic focal jammy rocky8 rocky9 bullseye amazonlinux2 mariner2 \n        azurelinux3\n      redis-ref: ${{needs.prepare-values.outputs.redis-ref}}\n    secrets: inherit\n  ubuntu-arm64:\n    uses: ./.github/workflows/flow-ubuntu-arm.yml\n    needs: [prepare-values]\n    with:\n      redis-ref: ${{needs.prepare-values.outputs.redis-ref}}\n    secrets: inherit\n  macos:\n    uses: ./.github/workflows/flow-macos.yml\n    needs: [prepare-values]\n    with:\n      redis-ref: ${{needs.prepare-values.outputs.redis-ref}}\n    secrets: inherit\n  alpine:\n    uses: ./.github/workflows/flow-alpine.yml\n    needs: [prepare-values]\n    with:\n      redis-ref: ${{needs.prepare-values.outputs.redis-ref}}\n    secrets: inherit\n  linux-valgrind:\n    uses: ./.github/workflows/flow-linux-x86.yml\n    needs: [prepare-values]\n    with:\n      os: jammy\n      redis-ref: ${{needs.prepare-values.outputs.redis-ref}}\n      run_valgrind: true\n    secrets: inherit\n  linux-sanitizer:\n    uses: ./.github/workflows/flow-linux-x86.yml\n    needs: [prepare-values]\n    with:\n      os: jammy\n      redis-ref: ${{needs.prepare-values.outputs.redis-ref}}\n      run_sanitizer: true\n    secrets: inherit\n  spellcheck:\n    uses: ./.github/workflows/flow-spellcheck.yml\n    secrets: inherit\n  linter:\n    uses: ./.github/workflows/flow-linter.yml\n    secrets: inherit\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Event Nightly` for a GitHub repository whose primary programming language is C. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main, a branch named master, a branch whose name matches [0-9]+.[0-9]+.[0-9]+ or a branch whose name matches [0-9]+.[0-9]+. 2) the scheduled time has come: at 08:20 pm. 3) someone manually triggers the workflow. This workflow receives an input: redis-ref-this input represents redis ref to checkout, it must be supplied and its default value is unstable. The workflow modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `id-token` scope and read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 9 jobs. The job id of the 1st job is `prepare-values`. The job id of the 2nd job is `build-linux-x86`. The job id of the 3rd job is `ubuntu-arm64`. The job id of the 4th job is `macos`. The job id of the 5th job is `alpine`. The job id of the 6th job is `linux-valgrind`. The job id of the 7th job is `linux-sanitizer`. The job id of the 8th job is `spellcheck`. The job id of the 9th job is `linter`. ","prompt_level2":"Generate a GitHub Workflow named `Event Nightly` for a GitHub repository whose primary programming language is C. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main, a branch named master, a branch whose name matches [0-9]+.[0-9]+.[0-9]+ or a branch whose name matches [0-9]+.[0-9]+. 2) the scheduled time has come: at 08:20 pm. 3) someone manually triggers the workflow. This workflow receives an input: redis-ref-this input represents redis ref to checkout, it must be supplied and its default value is unstable. The workflow modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `id-token` scope and read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 9 jobs. The job id of the 1st job is `prepare-values`. The job `prepare-values` has one step. The 1st step is named `set env` and its id is `set-env`. The job id of the 2nd job is `build-linux-x86`. The job id of the 3rd job is `ubuntu-arm64`. The job id of the 4th job is `macos`. The job id of the 5th job is `alpine`. The job id of the 6th job is `linux-valgrind`. The job id of the 7th job is `linux-sanitizer`. The job id of the 8th job is `spellcheck`. The job id of the 9th job is `linter`. ","prompt_level3":"Generate a GitHub Workflow named `Event Nightly` for a GitHub repository whose primary programming language is C. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main, a branch named master, a branch whose name matches [0-9]+.[0-9]+.[0-9]+ or a branch whose name matches [0-9]+.[0-9]+. 2) the scheduled time has come: at 08:20 pm. 3) someone manually triggers the workflow. This workflow receives an input: redis-ref-this input represents redis ref to checkout, it must be supplied and its default value is unstable. The workflow modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `id-token` scope and read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 9 jobs. The job id of the 1st job is `prepare-values`. This job will run on ubuntu-latest runner. The job `prepare-values` has one step. The 1st step is named `set env` and its id is `set-env`. This step runs a script: `echo \"redis-ref=${{ inputs.redis-ref || 'unstable' }}\" >> $GITHUB_OUTPUT  # todo change per version/tag\n`. This job has an output: `redis-ref` is defined as ${{ steps.set-env.outputs.redis-ref }}. The job id of the 2nd job is `build-linux-x86`. Before this job runs, `prepare-values` must complete successfully. This job will call a reusable workflow located at `./.github/workflows/flow-linux-x86.yml`. The job will pass 2 inputs to the called workflow: the input `os` is `bionic focal jammy rocky8 rocky9 bullseye amazonlinux2 mariner2 azurelinux3` and the input `redis-ref` is `${{needs.prepare-values.outputs.redis-ref}}`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. The job id of the 3rd job is `ubuntu-arm64`. Before this job runs, `prepare-values` must complete successfully. This job will call a reusable workflow located at `./.github/workflows/flow-ubuntu-arm.yml`. The job will pass an input to the called workflow: the input `redis-ref` is `${{needs.prepare-values.outputs.redis-ref}}`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. The job id of the 4th job is `macos`. Before this job runs, `prepare-values` must complete successfully. This job will call a reusable workflow located at `./.github/workflows/flow-macos.yml`. The job will pass an input to the called workflow: the input `redis-ref` is `${{needs.prepare-values.outputs.redis-ref}}`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. The job id of the 5th job is `alpine`. Before this job runs, `prepare-values` must complete successfully. This job will call a reusable workflow located at `./.github/workflows/flow-alpine.yml`. The job will pass an input to the called workflow: the input `redis-ref` is `${{needs.prepare-values.outputs.redis-ref}}`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. The job id of the 6th job is `linux-valgrind`. Before this job runs, `prepare-values` must complete successfully. This job will call a reusable workflow located at `./.github/workflows/flow-linux-x86.yml`. The job will pass 3 inputs to the called workflow: the input `os` is `jammy`, the input `redis-ref` is `${{needs.prepare-values.outputs.redis-ref}}` and the input `run_valgrind` is `True`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. The job id of the 7th job is `linux-sanitizer`. Before this job runs, `prepare-values` must complete successfully. This job will call a reusable workflow located at `./.github/workflows/flow-linux-x86.yml`. The job will pass 3 inputs to the called workflow: the input `os` is `jammy`, the input `redis-ref` is `${{needs.prepare-values.outputs.redis-ref}}` and the input `run_sanitizer` is `True`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. The job id of the 8th job is `spellcheck`. This job will call a reusable workflow located at `./.github/workflows/flow-spellcheck.yml`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. The job id of the 9th job is `linter`. This job will call a reusable workflow located at `./.github/workflows/flow-linter.yml`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. ","nb_triggers":3,"triggers":["push","schedule","workflow_dispatch"],"nb_jobs":9,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":8,"reusable_workflows":["./.github/workflows/flow-alpine.yml","./.github/workflows/flow-linter.yml","./.github/workflows/flow-linux-x86.yml","./.github/workflows/flow-linux-x86.yml","./.github/workflows/flow-linux-x86.yml","./.github/workflows/flow-macos.yml","./.github/workflows/flow-spellcheck.yml","./.github/workflows/flow-ubuntu-arm.yml"],"nb_steps":1,"cyclomatic_complexity":8}
{"id":51845,"repository_id":3993791,"mainLanguage":"Python","file_name":"test-linux-qt6.yml","file_content":"name: Linux tests with PyQt6\n\non:\n  push:\n    branches:\n      - master\n      - 6.*\n    paths:\n      - '.github/scripts/install.sh'\n      - '.github/scripts/run_tests.sh'\n      - '.github/workflows/test-linux-qt6.yml'\n      - 'requirements/*.yml'\n      - 'MANIFEST.in'\n      - '**.bat'\n      - '**.py'\n      - '**.sh'\n      - '!installers-conda/**'\n\n  pull_request:\n    branches:\n      - master\n      - 6.*\n    paths:\n      - '.github/scripts/install.sh'\n      - '.github/scripts/run_tests.sh'\n      - '.github/workflows/test-linux-qt6.yml'\n      - 'requirements/*.yml'\n      - 'MANIFEST.in'\n      - '**.bat'\n      - '**.py'\n      - '**.sh'\n      - '!installers-conda/**'\n\n  workflow_call:\n\n  workflow_dispatch:\n    inputs:\n      ssh:\n        # github_cli: gh workflow run test-linux-qt6.yml --ref <branch> -f ssh=true\n        description: 'Enable ssh debugging'\n        required: false\n        default: false\n        type: boolean\n\nconcurrency:\n  group: test-linux-qt6-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  ENABLE_SSH: ${{ github.event_name == 'workflow_dispatch' && inputs.ssh }}\n\njobs:\n  build:\n    # Use this to disable the workflow\n    # if: false\n    name: Linux - Py${{ matrix.PYTHON_VERSION }}, ${{ matrix.SPYDER_QT_BINDING }}, ${{ matrix.INSTALL_TYPE }}, ${{ matrix.TEST_TYPE }}\n    runs-on: ubuntu-22.04\n    env:\n      CI: 'true'\n      QTCONSOLE_TESTING: 'true'\n      CODECOV_TOKEN: \"56731c25-9b1f-4340-8b58-35739bfbc52d\"\n      OS: 'linux'\n      PYTHON_VERSION: ${{ matrix.PYTHON_VERSION }}\n      RUN_SLOW: ${{ matrix.TEST_TYPE == 'slow' }}\n      USE_CONDA: ${{ matrix.INSTALL_TYPE == 'conda' }}\n      USE_GDB: 'false'\n      SPYDER_QT_BINDING: ${{ matrix.SPYDER_QT_BINDING }}\n    strategy:\n      fail-fast: false\n      matrix:\n        INSTALL_TYPE: ['pip']  # conda has no PyQt6 package\n        PYTHON_VERSION: ['3.10']\n        TEST_TYPE: ['fast', 'slow']\n        SPYDER_QT_BINDING: ['pyqt6'] # TODO add 'pyside6' once Spyder supports it\n    timeout-minutes: 90\n    steps:\n      - name: Setup Remote SSH Connection\n        if: env.ENABLE_SSH == 'true'\n        uses: mxschmitt/action-tmate@v3\n        timeout-minutes: 60\n        with:\n          detached: true\n      - name: Checkout Pull Requests\n        if: github.event_name == 'pull_request'\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ github.event.pull_request.head.sha }}\n      - name: Checkout Push\n        if: github.event_name != 'pull_request'\n        uses: actions/checkout@v4\n      - name: Fetch branches\n        run: git fetch --prune --unshallow\n      - name: Install dependencies\n        shell: bash\n        run: |\n          sudo apt-get update --fix-missing\n          sudo apt-get install -qq pyqt5-dev-tools libxcb-xinerama0 libxcb-cursor0 xterm --fix-missing\n      - name: Cache pip\n        uses: actions/cache@v4\n        with:\n          path: ~/.cache/pip\n          key: ${{ runner.os }}-cachepip-install${{ matrix.INSTALL_TYPE }}-${{ env.CACHE_NUMBER }}-${{ hashFiles('setup.py') }}\n      - name: Create conda test environment\n        if: env.USE_CONDA == 'true'\n        uses: mamba-org/setup-micromamba@v2\n        with:\n          micromamba-version: '1.5.10-0'\n          environment-file: requirements/main.yml\n          environment-name: test\n          cache-downloads: true\n          create-args: python=${{ matrix.PYTHON_VERSION }}\n      - name: Create pip test environment\n        if: env.USE_CONDA != 'true'\n        uses: mamba-org/setup-micromamba@v2\n        with:\n          micromamba-version: '1.5.10-0'\n          environment-name: test\n          cache-downloads: true\n          create-args: python=${{ matrix.PYTHON_VERSION }}\n          condarc: |\n            channels:\n              - conda-forge\n      - name: Install additional dependencies\n        shell: bash -l {0}\n        run: bash -l .github/scripts/install.sh\n      - name: Show conda test environment\n        if: env.USE_CONDA == 'true'\n        shell: bash -l {0}\n        run: |\n          micromamba info\n          micromamba list\n      - name: Show pip test environment\n        if: env.USE_CONDA != 'true'\n        shell: bash -l {0}\n        run: |\n          micromamba info\n          micromamba list\n          pip list\n      - name: Run manifest checks\n        shell: bash -l {0}\n        run: check-manifest\n      - name: Run tests with gdb\n        if: env.USE_GDB == 'true'\n        shell: bash -l {0}\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: xvfb-run --auto-servernum gdb -return-child-result -batch -ex r -ex py-bt --args python runtests.py -s\n      - name: Run tests\n        shell: bash -l {0}\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          QT_API: ${{ matrix.SPYDER_QT_BINDING }}\n          PYTEST_QT_API: ${{ matrix.SPYDER_QT_BINDING }}\n        run: |\n          rm -f pytest_log.txt  # Must remove any log file from a previous run\n          .github/scripts/run_tests.sh -n 0 || \\\n          .github/scripts/run_tests.sh -n 1 || \\\n          .github/scripts/run_tests.sh -n 2 || \\\n          .github/scripts/run_tests.sh -n 3\n      - name: Coverage\n        uses: codecov/codecov-action@v4\n        with:\n          fail_ci_if_error: false\n          verbose: true\n","repository_owner":"spyder-ide","repository_name":"spyder","tokens_count":1445,"workflow":"name: Linux tests with PyQt6\n\non:\n  push:\n    branches:\n    - master\n    - 6.*\n    paths:\n    - .github/scripts/install.sh\n    - .github/scripts/run_tests.sh\n    - .github/workflows/test-linux-qt6.yml\n    - requirements/*.yml\n    - MANIFEST.in\n    - '**.bat'\n    - '**.py'\n    - '**.sh'\n    - '!installers-conda/**'\n\n  pull_request:\n    branches:\n    - master\n    - 6.*\n    paths:\n    - .github/scripts/install.sh\n    - .github/scripts/run_tests.sh\n    - .github/workflows/test-linux-qt6.yml\n    - requirements/*.yml\n    - MANIFEST.in\n    - '**.bat'\n    - '**.py'\n    - '**.sh'\n    - '!installers-conda/**'\n\n  workflow_call:\n\n  workflow_dispatch:\n    inputs:\n      ssh:\n        # github_cli: gh workflow run test-linux-qt6.yml --ref <branch> -f ssh=true\n        description: Enable ssh debugging\n        required: false\n        default: false\n        type: boolean\n\nconcurrency:\n  group: test-linux-qt6-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  ENABLE_SSH: ${{ github.event_name == 'workflow_dispatch' && inputs.ssh }}\n\njobs:\n  build:\n    # Use this to disable the workflow\n    # if: false\n    name: Linux - Py${{ matrix.PYTHON_VERSION }}, ${{ matrix.SPYDER_QT_BINDING \n      }}, ${{ matrix.INSTALL_TYPE }}, ${{ matrix.TEST_TYPE }}\n    runs-on: ubuntu-22.04\n    env:\n      CI: 'true'\n      QTCONSOLE_TESTING: 'true'\n      CODECOV_TOKEN: 56731c25-9b1f-4340-8b58-35739bfbc52d\n      OS: linux\n      PYTHON_VERSION: ${{ matrix.PYTHON_VERSION }}\n      RUN_SLOW: ${{ matrix.TEST_TYPE == 'slow' }}\n      USE_CONDA: ${{ matrix.INSTALL_TYPE == 'conda' }}\n      USE_GDB: 'false'\n      SPYDER_QT_BINDING: ${{ matrix.SPYDER_QT_BINDING }}\n    strategy:\n      fail-fast: false\n      matrix:\n        INSTALL_TYPE: [pip]    # conda has no PyQt6 package\n        PYTHON_VERSION: ['3.10']\n        TEST_TYPE: [fast, slow]\n        SPYDER_QT_BINDING: [pyqt6]   # TODO add 'pyside6' once Spyder supports it\n    timeout-minutes: 90\n    steps:\n    - name: Setup Remote SSH Connection\n      if: env.ENABLE_SSH == 'true'\n      uses: mxschmitt/action-tmate@v3\n      timeout-minutes: 60\n      with:\n        detached: true\n    - name: Checkout Pull Requests\n      if: github.event_name == 'pull_request'\n      uses: actions/checkout@v4\n      with:\n        ref: ${{ github.event.pull_request.head.sha }}\n    - name: Checkout Push\n      if: github.event_name != 'pull_request'\n      uses: actions/checkout@v4\n    - name: Fetch branches\n      run: git fetch --prune --unshallow\n    - name: Install dependencies\n      shell: bash\n      run: |\n        sudo apt-get update --fix-missing\n        sudo apt-get install -qq pyqt5-dev-tools libxcb-xinerama0 libxcb-cursor0 xterm --fix-missing\n    - name: Cache pip\n      uses: actions/cache@v4\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-cachepip-install${{ matrix.INSTALL_TYPE }}-${{ \n          env.CACHE_NUMBER }}-${{ hashFiles('setup.py') }}\n    - name: Create conda test environment\n      if: env.USE_CONDA == 'true'\n      uses: mamba-org/setup-micromamba@v2\n      with:\n        micromamba-version: 1.5.10-0\n        environment-file: requirements/main.yml\n        environment-name: test\n        cache-downloads: true\n        create-args: python=${{ matrix.PYTHON_VERSION }}\n    - name: Create pip test environment\n      if: env.USE_CONDA != 'true'\n      uses: mamba-org/setup-micromamba@v2\n      with:\n        micromamba-version: 1.5.10-0\n        environment-name: test\n        cache-downloads: true\n        create-args: python=${{ matrix.PYTHON_VERSION }}\n        condarc: |\n          channels:\n            - conda-forge\n    - name: Install additional dependencies\n      shell: bash -l {0}\n      run: bash -l .github/scripts/install.sh\n    - name: Show conda test environment\n      if: env.USE_CONDA == 'true'\n      shell: bash -l {0}\n      run: |\n        micromamba info\n        micromamba list\n    - name: Show pip test environment\n      if: env.USE_CONDA != 'true'\n      shell: bash -l {0}\n      run: |\n        micromamba info\n        micromamba list\n        pip list\n    - name: Run manifest checks\n      shell: bash -l {0}\n      run: check-manifest\n    - name: Run tests with gdb\n      if: env.USE_GDB == 'true'\n      shell: bash -l {0}\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      run: xvfb-run --auto-servernum gdb -return-child-result -batch -ex r -ex \n        py-bt --args python runtests.py -s\n    - name: Run tests\n      shell: bash -l {0}\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        QT_API: ${{ matrix.SPYDER_QT_BINDING }}\n        PYTEST_QT_API: ${{ matrix.SPYDER_QT_BINDING }}\n      run: |\n        rm -f pytest_log.txt  # Must remove any log file from a previous run\n        .github/scripts/run_tests.sh -n 0 || \\\n        .github/scripts/run_tests.sh -n 1 || \\\n        .github/scripts/run_tests.sh -n 2 || \\\n        .github/scripts/run_tests.sh -n 3\n    - name: Coverage\n      uses: codecov/codecov-action@v4\n      with:\n        fail_ci_if_error: false\n        verbose: true\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Linux tests with PyQt6` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master or a branch whose name matches 6.*. Only if at least one path of push event matches a pattern in the paths filter(.github/scripts/install.sh, .github/scripts/run_tests.sh, .github/workflows/test-linux-qt6.yml, requirements/*.yml, MANIFEST.in, **.bat, **.py, **.sh or !installers-conda/**), the workflow runs. 2) The workflow would run whenever there is a pull_request event targeting: a branch named master or a branch whose name matches 6.*. Only if at least one path of pull_request event matches a pattern in the paths filter(.github/scripts/install.sh, .github/scripts/run_tests.sh, .github/workflows/test-linux-qt6.yml, requirements/*.yml, MANIFEST.in, **.bat, **.py, **.sh or !installers-conda/**), the workflow runs. 3) it is called from another workflow. 4) someone manually triggers the workflow. This workflow receives an input: ssh-this input represents enable ssh debugging, it is optional, its default value is False and the data type is boolean. The workflow sets an environment variable to use: `ENABLE_SSH` is set to `${{ github.event_name == 'workflow_dispatch' && inputs.ssh }}`. Only a single workflow using the test-linux-qt6-${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The 1st job is named `Linux - Py${{ matrix.PYTHON_VERSION }}, ${{ matrix.SPYDER_QT_BINDING }}, ${{ matrix.INSTALL_TYPE }}, ${{ matrix.TEST_TYPE }}` and its job id is `build`. ","prompt_level2":"Generate a GitHub Workflow named `Linux tests with PyQt6` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master or a branch whose name matches 6.*. Only if at least one path of push event matches a pattern in the paths filter(.github/scripts/install.sh, .github/scripts/run_tests.sh, .github/workflows/test-linux-qt6.yml, requirements/*.yml, MANIFEST.in, **.bat, **.py, **.sh or !installers-conda/**), the workflow runs. 2) The workflow would run whenever there is a pull_request event targeting: a branch named master or a branch whose name matches 6.*. Only if at least one path of pull_request event matches a pattern in the paths filter(.github/scripts/install.sh, .github/scripts/run_tests.sh, .github/workflows/test-linux-qt6.yml, requirements/*.yml, MANIFEST.in, **.bat, **.py, **.sh or !installers-conda/**), the workflow runs. 3) it is called from another workflow. 4) someone manually triggers the workflow. This workflow receives an input: ssh-this input represents enable ssh debugging, it is optional, its default value is False and the data type is boolean. The workflow sets an environment variable to use: `ENABLE_SSH` is set to `${{ github.event_name == 'workflow_dispatch' && inputs.ssh }}`. Only a single workflow using the test-linux-qt6-${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The 1st job is named `Linux - Py${{ matrix.PYTHON_VERSION }}, ${{ matrix.SPYDER_QT_BINDING }}, ${{ matrix.INSTALL_TYPE }}, ${{ matrix.TEST_TYPE }}` and its job id is `build`. The job `build` has 15 steps. The 1st step is named `Setup Remote SSH Connection`. The 2nd step is named `Checkout repository`. The 3rd step is named `Checkout repository`. The 4th step is named `Fetch branches`. The 5th step is named `Install dependencies`. The 6th step is named `Cache pip`. The 7th step is named `Create conda test environment`. The 8th step is named `Create pip test environment`. The 9th step is named `Install additional dependencies`. The 10th step is named `Show conda test environment`. The 11th step is named `Show pip test environment`. The 12th step is named `Run manifest checks`. The 13th step is named `Run tests with gdb`. The 14th step is named `Run tests`. The 15th step is named `Coverage`. ","prompt_level3":"Generate a GitHub Workflow named `Linux tests with PyQt6` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master or a branch whose name matches 6.*. Only if at least one path of push event matches a pattern in the paths filter(.github/scripts/install.sh, .github/scripts/run_tests.sh, .github/workflows/test-linux-qt6.yml, requirements/*.yml, MANIFEST.in, **.bat, **.py, **.sh or !installers-conda/**), the workflow runs. 2) The workflow would run whenever there is a pull_request event targeting: a branch named master or a branch whose name matches 6.*. Only if at least one path of pull_request event matches a pattern in the paths filter(.github/scripts/install.sh, .github/scripts/run_tests.sh, .github/workflows/test-linux-qt6.yml, requirements/*.yml, MANIFEST.in, **.bat, **.py, **.sh or !installers-conda/**), the workflow runs. 3) it is called from another workflow. 4) someone manually triggers the workflow. This workflow receives an input: ssh-this input represents enable ssh debugging, it is optional, its default value is False and the data type is boolean. The workflow sets an environment variable to use: `ENABLE_SSH` is set to `${{ github.event_name == 'workflow_dispatch' && inputs.ssh }}`. Only a single workflow using the test-linux-qt6-${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The 1st job is named `Linux - Py${{ matrix.PYTHON_VERSION }}, ${{ matrix.SPYDER_QT_BINDING }}, ${{ matrix.INSTALL_TYPE }}, ${{ matrix.TEST_TYPE }}` and its job id is `build`. This job will run on ubuntu-22.04 runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `INSTALL_TYPE` has one value: pip. The variable `PYTHON_VERSION` has one value: 3.10. The variable `TEST_TYPE` has 2 values: fast and slow. The variable `SPYDER_QT_BINDING` has one value: pyqt6. The job sets 9 environment variables to use: `CI` is set to `true`, `QTCONSOLE_TESTING` is set to `true`, `CODECOV_TOKEN` is set to `56731c25-9b1f-4340-8b58-35739bfbc52d`, `OS` is set to `linux`, `PYTHON_VERSION` is set to `${{ matrix.PYTHON_VERSION }}`, `RUN_SLOW` is set to `${{ matrix.TEST_TYPE == 'slow' }}`, `USE_CONDA` is set to `${{ matrix.INSTALL_TYPE == 'conda' }}`, `USE_GDB` is set to `false` and `SPYDER_QT_BINDING` is set to `${{ matrix.SPYDER_QT_BINDING }}`. The maximum number of minutes to run the job is 90. The job `build` has 15 steps. The 1st step is named `Setup Remote SSH Connection`. This step will run only if the condition(env.ENABLE_SSH == 'true') is met. This step runs action `mxschmitt/action-tmate` tagged as v3. The step defines an input parameter for the action: `detached` is set to `True`. The maximum number of minutes to run the step is 60. The 2nd step is named `Checkout repository`. This step will run only if the condition(github.event_name == 'pull_request') is met. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `ref` is set to `${{ github.event.pull_request.head.sha }}`. The 3rd step is named `Checkout repository`. This step will run only if the condition(github.event_name != 'pull_request') is met. This step runs action `actions/checkout` tagged as v4. The 4th step is named `Fetch branches`. This step runs a script: `git fetch --prune --unshallow`. The 5th step is named `Install dependencies`. This step uses bash to run a script: `sudo apt-get update --fix-missing\nsudo apt-get install -qq pyqt5-dev-tools libxcb-xinerama0 libxcb-cursor0 xterm --fix-missing\n`. The 6th step is named `Cache pip`. This step runs action `actions/cache` tagged as v4. The step defines 2 input parameters for the action: `path` is set to `~/.cache/pip` and `key` is set to `${{ runner.os }}-cachepip-install${{ matrix.INSTALL_TYPE }}-${{ env.CACHE_NUMBER }}-${{ hashFiles('setup.py') }}`. The 7th step is named `Create conda test environment`. This step will run only if the condition(env.USE_CONDA == 'true') is met. This step runs action `mamba-org/setup-micromamba` tagged as v2. The step defines 5 input parameters for the action: `micromamba-version` is set to `1.5.10-0`, `environment-file` is set to `requirements/main.yml`, `environment-name` is set to `test`, `cache-downloads` is set to `True` and `create-args` is set to `python=${{ matrix.PYTHON_VERSION }}`. The 8th step is named `Create pip test environment`. This step will run only if the condition(env.USE_CONDA != 'true') is met. This step runs action `mamba-org/setup-micromamba` tagged as v2. The step defines 5 input parameters for the action: `micromamba-version` is set to `1.5.10-0`, `environment-name` is set to `test`, `cache-downloads` is set to `True`, `create-args` is set to `python=${{ matrix.PYTHON_VERSION }}` and `condarc` is set to `channels:\n  - conda-forge\n`. The 9th step is named `Install additional dependencies`. This step uses a custom shell bash -l {0} to run a script: `bash -l .github/scripts/install.sh`. The 10th step is named `Show conda test environment`. This step will run only if the condition(env.USE_CONDA == 'true') is met. This step uses a custom shell bash -l {0} to run a script: `micromamba info\nmicromamba list\n`. The 11th step is named `Show pip test environment`. This step will run only if the condition(env.USE_CONDA != 'true') is met. This step uses a custom shell bash -l {0} to run a script: `micromamba info\nmicromamba list\npip list\n`. The 12th step is named `Run manifest checks`. This step uses a custom shell bash -l {0} to run a script: `check-manifest`. The 13th step is named `Run tests with gdb`. This step will run only if the condition(env.USE_GDB == 'true') is met. The step sets an environment variable to use: `GITHUB_TOKEN` is set to `${{ secrets.GITHUB_TOKEN }}`. This step uses a custom shell bash -l {0} to run a script: `xvfb-run --auto-servernum gdb -return-child-result -batch -ex r -ex py-bt --args python runtests.py -s`. The 14th step is named `Run tests`. The step sets 3 environment variables to use: `GITHUB_TOKEN` is set to `${{ secrets.GITHUB_TOKEN }}`, `QT_API` is set to `${{ matrix.SPYDER_QT_BINDING }}` and `PYTEST_QT_API` is set to `${{ matrix.SPYDER_QT_BINDING }}`. This step uses a custom shell bash -l {0} to run a script: `rm -f pytest_log.txt  # Must remove any log file from a previous run\n.github/scripts/run_tests.sh -n 0 || \\\n.github/scripts/run_tests.sh -n 1 || \\\n.github/scripts/run_tests.sh -n 2 || \\\n.github/scripts/run_tests.sh -n 3\n`. The 15th step is named `Coverage`. This step runs action `codecov/codecov-action` tagged as v4. The step defines 2 input parameters for the action: `fail_ci_if_error` is set to `False` and `verbose` is set to `True`. ","nb_triggers":4,"triggers":["pull_request","push","workflow_call","workflow_dispatch"],"nb_jobs":1,"nb_actions":7,"actions":["actions/cache","actions/checkout","actions/checkout","codecov/codecov-action","mamba-org/setup-micromamba","mamba-org/setup-micromamba","mxschmitt/action-tmate"],"actions_details":[{"version":"v3","name":"mxschmitt/action-tmate"},{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/cache"},{"version":"v2","name":"mamba-org/setup-micromamba"},{"version":"v2","name":"mamba-org/setup-micromamba"},{"version":"v4","name":"codecov/codecov-action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":15,"cyclomatic_complexity":1}
{"id":23264,"repository_id":56876108,"mainLanguage":"TypeScript","file_name":"upgrade-tests.yml","file_content":"name: Run upgrade tests\non:\n  workflow_dispatch:\n\nenv:\n  PNPM_VERSION: 10.2\n  NODE_VERSION: 18.x\n\njobs:\n  build-all-artifacts:\n    runs-on: ubuntu-latest\n    container:\n      image: mcr.microsoft.com/playwright:v1.50.0-jammy\n    strategy:\n      matrix:\n        env: [hydrogen]\n        extension_type: [chrome]\n\n    environment: ${{ matrix.env }}\n\n    env:\n      # FEATURE flags\n      FEATURE_PRIVACY_SETTINGS: \"true\"\n      FEATURE_EXPERIMENTAL_SETTINGS: \"false\"\n      FEATURE_BETA_FEATURES: \"false\"\n      FEATURE_BANXA: \"true\"\n      FEATURE_LAYERSWAP: \"true\"\n      FEATURE_ORBITER: \"true\"\n      FEATURE_MULTISIG: \"true\"\n      ENABLE_TOKEN_DETAILS: \"true\"\n      FEATURE_DEFI_DECOMPOSITION: \"true\"\n\n      # API URLs\n      ARGENT_API_BASE_URL: ${{ vars.ARGENT_API_BASE_URL }}\n      ARGENT_X_STATUS_URL: ${{ vars.ARGENT_X_STATUS_URL }}\n      ARGENT_X_NEWS_URL: ${{ vars.ARGENT_X_NEWS_URL }}\n      # API ENVIRONMENT\n      ARGENT_X_ENVIRONMENT: ${{ matrix.env }}\n\n      # Sentry\n      SENTRY_DSN: ${{ secrets.SENTRY_DSN }}\n      SENTRY_AUTH_TOKEN: ${{ secrets.SENTRY_AUTH_TOKEN }}\n      SENTRY_ORG: ${{ secrets.SENTRY_ORG }}\n      SENTRY_PROJECT: ${{ secrets.SENTRY_PROJECT }}\n      SENTRY_ENVIRONMENT: \"staging\"\n\n      # Misc\n      RAMP_API_KEY: ${{ secrets.RAMP_API_KEY }}\n      SAFE_ENV_VARS: false\n      MULTICALL_MAX_BATCH_SIZE: 20\n      NEW_CAIRO_0_ENABLED: false\n      TOPPER_PEM_KEY: ${{ secrets.TOPPER_PEM_KEY }}\n      # Refresh intervals\n      FAST: 20 # 20s\n      MEDIUM: 60 # 60s\n      SLOW: 60 * 5 # 5m\n      VERY_SLOW: 24 * 60 * 60 # 1d\n      MIN_LEDGER_APP_VERSION: 2.2.0\n\n    steps:\n      # Setup Project\n      - uses: actions/checkout@v4\n\n      - uses: pnpm/action-setup@v4\n        name: Install pnpm\n        id: pnpm-install\n        with:\n          version: ${{ env.PNPM_VERSION }}\n          run_install: false\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: \"pnpm\"\n\n      - name: Get pnpm store directory\n        id: pnpm-cache\n        shell: bash\n        run: |\n          echo \"STORE_PATH=$(pnpm store path)\" >> $GITHUB_OUTPUT\n\n      - uses: actions/cache@v4\n        name: Setup pnpm cache\n        with:\n          path: ${{ steps.pnpm-cache.outputs.STORE_PATH }}\n          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}\n          restore-keys: |\n            ${{ runner.os }}-pnpm-store-\n\n      - name: Set Sentry Release name (rc)\n        run: |\n          PACKAGE_VERSION=$(grep -m1 '\"version\":' ./packages/extension/package.json | awk -F: '{ print $2 }' | sed 's/[\", ]//g')\n          echo \"SENTRY_RELEASE=${PACKAGE_VERSION}-rc__${GITHUB_SHA}\" >> $GITHUB_ENV\n\n      - name: Setup project\n        run: pnpm run setup\n\n      - name: Build extension for ${{ matrix.extension_type }}\n        run: |\n          if [ \"${{ matrix.extension_type }}\" = \"firefox\" ]; then\n            echo \"Building extension using manifest v2\"\n            MANIFEST_VERSION=v2 pnpm run build:extension\n          else\n            echo \"Building extension using manifest v3\"\n            MANIFEST_VERSION=v3 pnpm run build:extension\n          fi\n\n      - name: Check bundle size for ${{ matrix.extension_type }}\n        run: pnpm check-bundle-size\n\n      - name: Use Cache\n        uses: actions/cache@v4\n        with:\n          path: ./*\n          key: ${{ github.sha }}-${{ matrix.extension_type }}-${{ matrix.env }}\n\n      - name: Set filename prefix\n        run: echo \"FILENAME_PREFIX=$(echo argent-x-${{ matrix.env }}-${{ github.ref_name }} | tr / -)\" >> $GITHUB_ENV\n\n      - name: Install zip\n        run: apt-get update && apt-get install -y zip\n\n      - name: Create ${{ matrix.extension_type }} zip\n        run: (cd ./packages/extension/dist && zip -r \"../../../${{ env.FILENAME_PREFIX }}-${{ matrix.extension_type }}\" .)\n\n      - name: Upload ${{ matrix.extension_type }} extension\n        uses: actions/upload-artifact@v4\n        with:\n          name: ${{ env.FILENAME_PREFIX }}-${{ matrix.extension_type }}\n          path: \"*-${{ matrix.extension_type }}.zip\"\n          retention-days: 3\n\n  test-e2e-upgrade:\n    runs-on: ubuntu-latest\n    container:\n      image: mcr.microsoft.com/playwright:v1.50.0-jammy\n    needs: [build-all-artifacts]\n    strategy:\n      matrix:\n        project: [ArgentX]\n        shardIndex: [1]\n        shardTotal: [1]\n    env:\n      #default\n      ARGENT_X_ENVIRONMENT: \"hydrogen\"\n      ARGENT_API_BASE_URL: ${{ secrets.ARGENT_API_BASE_URL }}\n\n      ## BANK ACCOUNT, USED FOR FUND OTHER ACCOUNTS\n      E2E_SENDER_ADDRESSES: ${{ secrets.E2E_SENDER_ADDRESSES_SEPOLIA }}\n      E2E_SENDER_PRIVATEKEYS: ${{ secrets.E2E_SENDER_PRIVATEKEYS_SEPOLIA }}\n      ARGENT_SEPOLIA_RPC_URL: ${{ secrets.ARGENT_SEPOLIA_RPC_URL }}\n\n      E2E_TESTNET_SEED1: ${{ secrets.E2E_TESTNET_SEED1 }}\n      E2E_TESTNET_SEED3: ${{ secrets.E2E_TESTNET_SEED3 }}\n      E2E_TESTNET_SEED4: ${{ secrets.E2E_TESTNET_SEED4 }}\n      E2E_ACCOUNT_1_SEED2: ${{ secrets.E2E_ACCOUNT_1_SEED2 }}\n      ## BANK ACCOUNT, USED FOR FUND OTHER ACCOUNTS\n      E2E_SENDER_SEED: ${{ secrets.E2E_SENDER_SEED }}\n      E2E_EXTENSION_PASSWORD: ${{ secrets.E2E_EXTENSION_PASSWORD }}\n\n      E2E_SPOK_CAMPAIGN_URL: ${{ secrets.E2E_SPOK_CAMPAIGN_URL }}\n      E2E_SPOK_CAMPAIGN_NAME: ${{ secrets.E2E_SPOK_CAMPAIGN_NAME }}\n\n      E2E_USE_STRK_AS_FEE_TOKEN: ${{ secrets.E2E_USE_STRK_AS_FEE_TOKEN }}\n      E2E_SKIP_TX_TESTS: ${{ secrets.E2E_SKIP_TX_TESTS}}\n      E2E_LOG_INFO: ${{ secrets.E2E_LOG_INFO }}\n      E2E_GUARDIAN_EMAIL: ${{ secrets.E2E_GUARDIAN_EMAIL }}\n      E2E_MIG_ACCOUNT_ADDRESS: ${{ secrets.E2E_MIG_ACCOUNT_ADDRESS }}\n      E2E_ACCOUNT_TO_IMPORT_AND_TX: ${{ secrets.E2E_ACCOUNT_TO_IMPORT_AND_TX }}\n      E2E_ACCOUNTS_TO_IMPORT: ${{ secrets.E2E_ACCOUNTS_TO_IMPORT }}\n      E2E_ACCOUNTS_TO_IMPORT_PROD: ${{ secrets.E2E_ACCOUNTS_TO_IMPORT_PROD }}\n      E2E_QA_UTILS_AUTH_TOKEN: ${{ secrets.E2E_QA_UTILS_AUTH_TOKEN }}\n      E2E_QA_UTILS_URL: ${{ secrets.E2E_QA_UTILS_URL }}\n      E2E_REPO: ${{ secrets.E2E_REPO }}\n      E2E_REPO_TOKEN: ${{ secrets.E2E_REPO_TOKEN }}\n      E2E_REPO_OWNER: ${{ secrets.E2E_REPO_OWNER }}\n      E2E_REPO_RELEASE_NAME: ${{ secrets.E2E_REPO_RELEASE_NAME }}\n\n      # Refresh intervals\n      REFRESH_INTERVAL_FAST: 20 # 1s\n      REFRESH_INTERVAL_MEDIUM: 20 # 5s\n      REFRESH_INTERVAL_SLOW: 20 # 20s\n      REFRESH_INTERVAL_VERY_SLOW: 60 * 10 # 10m\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: pnpm/action-setup@v4\n        name: Install pnpm\n        id: pnpm-install\n        with:\n          version: ${{ env.PNPM_VERSION }}\n          run_install: false\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: \"pnpm\"\n\n      - name: Restore pnpm cache\n        uses: actions/cache/restore@v4\n        with:\n          path: ~/.pnpm-store\n          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}\n          restore-keys: |\n            ${{ runner.os }}-pnpm-store-\n\n      - name: Restore cached build\n        uses: actions/cache/restore@v4\n        with:\n          path: ./*\n          key: ${{ github.sha }}-chrome-${{ env.ARGENT_X_ENVIRONMENT }} # test-e2e is always run against chrome-hydrogen build\n\n      - name: Install dependencies\n        run: pnpm install --frozen-lockfile\n\n      - name: Run e2e tests\n        run: xvfb-run --auto-servernum pnpm test:e2e:upgrade --project=${{ matrix.project }} --shard=${{ matrix.shardIndex }}/${{ matrix.shardTotal }}\n\n      - name: Upload artifacts\n        uses: actions/upload-artifact@v4\n        if: always()\n        with:\n          name: test-artifacts-upgrade-${{ matrix.shardIndex }}\n          path: |\n            packages/e2e/artifacts/playwright/\n            !packages/e2e/artifacts/playwright/*.webm\n          retention-days: 5\n\n      - name: Upload blob report to GitHub Actions Artifacts\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: all-blob-reports-upgrade-${{ matrix.shardIndex }}\n          path: packages/e2e/blob-report/\n          retention-days: 5\n","repository_owner":"argentlabs","repository_name":"argent-x","tokens_count":2276,"workflow":"name: Run upgrade tests\non:\n  workflow_dispatch:\n\nenv:\n  PNPM_VERSION: 10.2\n  NODE_VERSION: 18.x\n\njobs:\n  build-all-artifacts:\n    runs-on: ubuntu-latest\n    container:\n      image: mcr.microsoft.com/playwright:v1.50.0-jammy\n    strategy:\n      matrix:\n        env: [hydrogen]\n        extension_type: [chrome]\n\n    environment: ${{ matrix.env }}\n\n    env:\n      # FEATURE flags\n      FEATURE_PRIVACY_SETTINGS: 'true'\n      FEATURE_EXPERIMENTAL_SETTINGS: 'false'\n      FEATURE_BETA_FEATURES: 'false'\n      FEATURE_BANXA: 'true'\n      FEATURE_LAYERSWAP: 'true'\n      FEATURE_ORBITER: 'true'\n      FEATURE_MULTISIG: 'true'\n      ENABLE_TOKEN_DETAILS: 'true'\n      FEATURE_DEFI_DECOMPOSITION: 'true'\n\n      # API URLs\n      ARGENT_API_BASE_URL: ${{ vars.ARGENT_API_BASE_URL }}\n      ARGENT_X_STATUS_URL: ${{ vars.ARGENT_X_STATUS_URL }}\n      ARGENT_X_NEWS_URL: ${{ vars.ARGENT_X_NEWS_URL }}\n      # API ENVIRONMENT\n      ARGENT_X_ENVIRONMENT: ${{ matrix.env }}\n\n      # Sentry\n      SENTRY_DSN: ${{ secrets.SENTRY_DSN }}\n      SENTRY_AUTH_TOKEN: ${{ secrets.SENTRY_AUTH_TOKEN }}\n      SENTRY_ORG: ${{ secrets.SENTRY_ORG }}\n      SENTRY_PROJECT: ${{ secrets.SENTRY_PROJECT }}\n      SENTRY_ENVIRONMENT: staging\n\n      # Misc\n      RAMP_API_KEY: ${{ secrets.RAMP_API_KEY }}\n      SAFE_ENV_VARS: false\n      MULTICALL_MAX_BATCH_SIZE: 20\n      NEW_CAIRO_0_ENABLED: false\n      TOPPER_PEM_KEY: ${{ secrets.TOPPER_PEM_KEY }}\n      # Refresh intervals\n      FAST: 20 # 20s\n      MEDIUM: 60 # 60s\n      SLOW: 60 * 5 # 5m\n      VERY_SLOW: 24 * 60 * 60 # 1d\n      MIN_LEDGER_APP_VERSION: 2.2.0\n\n    steps:\n      # Setup Project\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - uses: pnpm/action-setup@v4\n      name: Install pnpm\n      id: pnpm-install\n      with:\n        version: ${{ env.PNPM_VERSION }}\n        run_install: false\n\n    - name: Setup Node ${{ env.NODE_VERSION }}\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ env.NODE_VERSION }}\n        cache: pnpm\n\n    - name: Get pnpm store directory\n      id: pnpm-cache\n      shell: bash\n      run: |\n        echo \"STORE_PATH=$(pnpm store path)\" >> $GITHUB_OUTPUT\n\n    - uses: actions/cache@v4\n      name: Setup pnpm cache\n      with:\n        path: ${{ steps.pnpm-cache.outputs.STORE_PATH }}\n        key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}\n        restore-keys: |\n          ${{ runner.os }}-pnpm-store-\n\n    - name: Set Sentry Release name (rc)\n      run: |\n        PACKAGE_VERSION=$(grep -m1 '\"version\":' ./packages/extension/package.json | awk -F: '{ print $2 }' | sed 's/[\", ]//g')\n        echo \"SENTRY_RELEASE=${PACKAGE_VERSION}-rc__${GITHUB_SHA}\" >> $GITHUB_ENV\n\n    - name: Setup project\n      run: pnpm run setup\n\n    - name: Build extension for ${{ matrix.extension_type }}\n      run: |\n        if [ \"${{ matrix.extension_type }}\" = \"firefox\" ]; then\n          echo \"Building extension using manifest v2\"\n          MANIFEST_VERSION=v2 pnpm run build:extension\n        else\n          echo \"Building extension using manifest v3\"\n          MANIFEST_VERSION=v3 pnpm run build:extension\n        fi\n\n    - name: Check bundle size for ${{ matrix.extension_type }}\n      run: pnpm check-bundle-size\n\n    - name: Use Cache\n      uses: actions/cache@v4\n      with:\n        path: ./*\n        key: ${{ github.sha }}-${{ matrix.extension_type }}-${{ matrix.env }}\n\n    - name: Set filename prefix\n      run: echo \"FILENAME_PREFIX=$(echo argent-x-${{ matrix.env }}-${{ \n        github.ref_name }} | tr / -)\" >> $GITHUB_ENV\n\n    - name: Install zip\n      run: apt-get update && apt-get install -y zip\n\n    - name: Create ${{ matrix.extension_type }} zip\n      run: (cd ./packages/extension/dist && zip -r \"../../../${{ \n        env.FILENAME_PREFIX }}-${{ matrix.extension_type }}\" .)\n\n    - name: Upload ${{ matrix.extension_type }} extension\n      uses: actions/upload-artifact@v4\n      with:\n        name: ${{ env.FILENAME_PREFIX }}-${{ matrix.extension_type }}\n        path: '*-${{ matrix.extension_type }}.zip'\n        retention-days: 3\n\n  test-e2e-upgrade:\n    runs-on: ubuntu-latest\n    container:\n      image: mcr.microsoft.com/playwright:v1.50.0-jammy\n    needs: [build-all-artifacts]\n    strategy:\n      matrix:\n        project: [ArgentX]\n        shardIndex: [1]\n        shardTotal: [1]\n    env:\n      #default\n      ARGENT_X_ENVIRONMENT: hydrogen\n      ARGENT_API_BASE_URL: ${{ secrets.ARGENT_API_BASE_URL }}\n\n      ## BANK ACCOUNT, USED FOR FUND OTHER ACCOUNTS\n      E2E_SENDER_ADDRESSES: ${{ secrets.E2E_SENDER_ADDRESSES_SEPOLIA }}\n      E2E_SENDER_PRIVATEKEYS: ${{ secrets.E2E_SENDER_PRIVATEKEYS_SEPOLIA }}\n      ARGENT_SEPOLIA_RPC_URL: ${{ secrets.ARGENT_SEPOLIA_RPC_URL }}\n\n      E2E_TESTNET_SEED1: ${{ secrets.E2E_TESTNET_SEED1 }}\n      E2E_TESTNET_SEED3: ${{ secrets.E2E_TESTNET_SEED3 }}\n      E2E_TESTNET_SEED4: ${{ secrets.E2E_TESTNET_SEED4 }}\n      E2E_ACCOUNT_1_SEED2: ${{ secrets.E2E_ACCOUNT_1_SEED2 }}\n      ## BANK ACCOUNT, USED FOR FUND OTHER ACCOUNTS\n      E2E_SENDER_SEED: ${{ secrets.E2E_SENDER_SEED }}\n      E2E_EXTENSION_PASSWORD: ${{ secrets.E2E_EXTENSION_PASSWORD }}\n\n      E2E_SPOK_CAMPAIGN_URL: ${{ secrets.E2E_SPOK_CAMPAIGN_URL }}\n      E2E_SPOK_CAMPAIGN_NAME: ${{ secrets.E2E_SPOK_CAMPAIGN_NAME }}\n\n      E2E_USE_STRK_AS_FEE_TOKEN: ${{ secrets.E2E_USE_STRK_AS_FEE_TOKEN }}\n      E2E_SKIP_TX_TESTS: ${{ secrets.E2E_SKIP_TX_TESTS}}\n      E2E_LOG_INFO: ${{ secrets.E2E_LOG_INFO }}\n      E2E_GUARDIAN_EMAIL: ${{ secrets.E2E_GUARDIAN_EMAIL }}\n      E2E_MIG_ACCOUNT_ADDRESS: ${{ secrets.E2E_MIG_ACCOUNT_ADDRESS }}\n      E2E_ACCOUNT_TO_IMPORT_AND_TX: ${{ secrets.E2E_ACCOUNT_TO_IMPORT_AND_TX }}\n      E2E_ACCOUNTS_TO_IMPORT: ${{ secrets.E2E_ACCOUNTS_TO_IMPORT }}\n      E2E_ACCOUNTS_TO_IMPORT_PROD: ${{ secrets.E2E_ACCOUNTS_TO_IMPORT_PROD }}\n      E2E_QA_UTILS_AUTH_TOKEN: ${{ secrets.E2E_QA_UTILS_AUTH_TOKEN }}\n      E2E_QA_UTILS_URL: ${{ secrets.E2E_QA_UTILS_URL }}\n      E2E_REPO: ${{ secrets.E2E_REPO }}\n      E2E_REPO_TOKEN: ${{ secrets.E2E_REPO_TOKEN }}\n      E2E_REPO_OWNER: ${{ secrets.E2E_REPO_OWNER }}\n      E2E_REPO_RELEASE_NAME: ${{ secrets.E2E_REPO_RELEASE_NAME }}\n\n      # Refresh intervals\n      REFRESH_INTERVAL_FAST: 20 # 1s\n      REFRESH_INTERVAL_MEDIUM: 20 # 5s\n      REFRESH_INTERVAL_SLOW: 20 # 20s\n      REFRESH_INTERVAL_VERY_SLOW: 60 * 10 # 10m\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - uses: pnpm/action-setup@v4\n      name: Install pnpm\n      id: pnpm-install\n      with:\n        version: ${{ env.PNPM_VERSION }}\n        run_install: false\n\n    - name: Setup Node ${{ env.NODE_VERSION }}\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ env.NODE_VERSION }}\n        cache: pnpm\n\n    - name: Restore pnpm cache\n      uses: actions/cache/restore@v4\n      with:\n        path: ~/.pnpm-store\n        key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}\n        restore-keys: |\n          ${{ runner.os }}-pnpm-store-\n\n    - name: Restore cached build\n      uses: actions/cache/restore@v4\n      with:\n        path: ./*\n        key: ${{ github.sha }}-chrome-${{ env.ARGENT_X_ENVIRONMENT }}   # test-e2e is always run against chrome-hydrogen build\n\n    - name: Install dependencies\n      run: pnpm install --frozen-lockfile\n\n    - name: Run e2e tests\n      run: xvfb-run --auto-servernum pnpm test:e2e:upgrade --project=${{ \n        matrix.project }} --shard=${{ matrix.shardIndex }}/${{ matrix.shardTotal\n        }}\n\n    - name: Upload artifacts\n      uses: actions/upload-artifact@v4\n      if: always()\n      with:\n        name: test-artifacts-upgrade-${{ matrix.shardIndex }}\n        path: |\n          packages/e2e/artifacts/playwright/\n          !packages/e2e/artifacts/playwright/*.webm\n        retention-days: 5\n\n    - name: Upload blob report to GitHub Actions Artifacts\n      if: always()\n      uses: actions/upload-artifact@v4\n      with:\n        name: all-blob-reports-upgrade-${{ matrix.shardIndex }}\n        path: packages/e2e/blob-report/\n        retention-days: 5\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Run upgrade tests` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by an event: someone manually triggers the workflow. The workflow sets 2 environment variables to use: `PNPM_VERSION` is set to `10.2` and `NODE_VERSION` is set to `18.x`. The workflow has 2 jobs. The job id of the 1st job is `build-all-artifacts`. The job id of the 2nd job is `test-e2e-upgrade`. ","prompt_level2":"Generate a GitHub Workflow named `Run upgrade tests` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by an event: someone manually triggers the workflow. The workflow sets 2 environment variables to use: `PNPM_VERSION` is set to `10.2` and `NODE_VERSION` is set to `18.x`. The workflow has 2 jobs. The job id of the 1st job is `build-all-artifacts`. The job `build-all-artifacts` has 14 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Install pnpm` and its id is `pnpm-install`. The 3rd step is named `Setup Node ${{ env.NODE_VERSION }}`. The 4th step is named `Get pnpm store directory` and its id is `pnpm-cache`. The 5th step is named `Setup pnpm cache`. The 6th step is named `Set Sentry Release name (rc)`. The 7th step is named `Setup project`. The 8th step is named `Build extension for ${{ matrix.extension_type }}`. The 9th step is named `Check bundle size for ${{ matrix.extension_type }}`. The 10th step is named `Use Cache`. The 11th step is named `Set filename prefix`. The 12th step is named `Install zip`. The 13th step is named `Create ${{ matrix.extension_type }} zip`. The 14th step is named `Upload ${{ matrix.extension_type }} extension`. The job id of the 2nd job is `test-e2e-upgrade`. The job `test-e2e-upgrade` has 9 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Install pnpm` and its id is `pnpm-install`. The 3rd step is named `Setup Node ${{ env.NODE_VERSION }}`. The 4th step is named `Restore pnpm cache`. The 5th step is named `Restore cached build`. The 6th step is named `Install dependencies`. The 7th step is named `Run e2e tests`. The 8th step is named `Upload artifacts`. The 9th step is named `Upload blob report to GitHub Actions Artifacts`. ","prompt_level3":"Generate a GitHub Workflow named `Run upgrade tests` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by an event: someone manually triggers the workflow. The workflow sets 2 environment variables to use: `PNPM_VERSION` is set to `10.2` and `NODE_VERSION` is set to `18.x`. The workflow has 2 jobs. The job id of the 1st job is `build-all-artifacts`. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `env` has one value: hydrogen. The variable `extension_type` has one value: chrome. The job creates a Docker container that uses `mcr.microsoft.com/playwright:v1.50.0-jammy` image. The job sets 28 environment variables to use: `FEATURE_PRIVACY_SETTINGS` is set to `true`, `FEATURE_EXPERIMENTAL_SETTINGS` is set to `false`, `FEATURE_BETA_FEATURES` is set to `false`, `FEATURE_BANXA` is set to `true`, `FEATURE_LAYERSWAP` is set to `true`, `FEATURE_ORBITER` is set to `true`, `FEATURE_MULTISIG` is set to `true`, `ENABLE_TOKEN_DETAILS` is set to `true`, `FEATURE_DEFI_DECOMPOSITION` is set to `true`, `ARGENT_API_BASE_URL` is set to `${{ vars.ARGENT_API_BASE_URL }}`, `ARGENT_X_STATUS_URL` is set to `${{ vars.ARGENT_X_STATUS_URL }}`, `ARGENT_X_NEWS_URL` is set to `${{ vars.ARGENT_X_NEWS_URL }}`, `ARGENT_X_ENVIRONMENT` is set to `${{ matrix.env }}`, `SENTRY_DSN` is set to `${{ secrets.SENTRY_DSN }}`, `SENTRY_AUTH_TOKEN` is set to `${{ secrets.SENTRY_AUTH_TOKEN }}`, `SENTRY_ORG` is set to `${{ secrets.SENTRY_ORG }}`, `SENTRY_PROJECT` is set to `${{ secrets.SENTRY_PROJECT }}`, `SENTRY_ENVIRONMENT` is set to `staging`, `RAMP_API_KEY` is set to `${{ secrets.RAMP_API_KEY }}`, `SAFE_ENV_VARS` is set to `False`, `MULTICALL_MAX_BATCH_SIZE` is set to `20`, `NEW_CAIRO_0_ENABLED` is set to `False`, `TOPPER_PEM_KEY` is set to `${{ secrets.TOPPER_PEM_KEY }}`, `FAST` is set to `20`, `MEDIUM` is set to `60`, `SLOW` is set to `60 * 5`, `VERY_SLOW` is set to `24 * 60 * 60` and `MIN_LEDGER_APP_VERSION` is set to `2.2.0`. This job references ${{ matrix.env }} environment. The job `build-all-artifacts` has 14 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Install pnpm` and its id is `pnpm-install`. This step runs action `pnpm/action-setup` tagged as v4. The step defines 2 input parameters for the action: `version` is set to `${{ env.PNPM_VERSION }}` and `run_install` is set to `False`. The 3rd step is named `Setup Node ${{ env.NODE_VERSION }}`. This step runs action `actions/setup-node` tagged as v4. The step defines 2 input parameters for the action: `node-version` is set to `${{ env.NODE_VERSION }}` and `cache` is set to `pnpm`. The 4th step is named `Get pnpm store directory` and its id is `pnpm-cache`. This step uses bash to run a script: `echo \"STORE_PATH=$(pnpm store path)\" >> $GITHUB_OUTPUT\n`. The 5th step is named `Setup pnpm cache`. This step runs action `actions/cache` tagged as v4. The step defines 3 input parameters for the action: `path` is set to `${{ steps.pnpm-cache.outputs.STORE_PATH }}`, `key` is set to `${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}` and `restore-keys` is set to `${{ runner.os }}-pnpm-store-\n`. The 6th step is named `Set Sentry Release name (rc)`. This step runs a script: `PACKAGE_VERSION=$(grep -m1 '\"version\":' ./packages/extension/package.json | awk -F: '{ print $2 }' | sed 's/[\", ]//g')\necho \"SENTRY_RELEASE=${PACKAGE_VERSION}-rc__${GITHUB_SHA}\" >> $GITHUB_ENV\n`. The 7th step is named `Setup project`. This step runs a script: `pnpm run setup`. The 8th step is named `Build extension for ${{ matrix.extension_type }}`. This step runs a script: `if [ \"${{ matrix.extension_type }}\" = \"firefox\" ]; then\n  echo \"Building extension using manifest v2\"\n  MANIFEST_VERSION=v2 pnpm run build:extension\nelse\n  echo \"Building extension using manifest v3\"\n  MANIFEST_VERSION=v3 pnpm run build:extension\nfi\n`. The 9th step is named `Check bundle size for ${{ matrix.extension_type }}`. This step runs a script: `pnpm check-bundle-size`. The 10th step is named `Use Cache`. This step runs action `actions/cache` tagged as v4. The step defines 2 input parameters for the action: `path` is set to `./*` and `key` is set to `${{ github.sha }}-${{ matrix.extension_type }}-${{ matrix.env }}`. The 11th step is named `Set filename prefix`. This step runs a script: `echo \"FILENAME_PREFIX=$(echo argent-x-${{ matrix.env }}-${{ github.ref_name }} | tr / -)\" >> $GITHUB_ENV`. The 12th step is named `Install zip`. This step runs a script: `apt-get update && apt-get install -y zip`. The 13th step is named `Create ${{ matrix.extension_type }} zip`. This step runs a script: `(cd ./packages/extension/dist && zip -r \"../../../${{ env.FILENAME_PREFIX }}-${{ matrix.extension_type }}\" .)`. The 14th step is named `Upload ${{ matrix.extension_type }} extension`. This step runs action `actions/upload-artifact` tagged as v4. The step defines 3 input parameters for the action: `name` is set to `${{ env.FILENAME_PREFIX }}-${{ matrix.extension_type }}`, `path` is set to `*-${{ matrix.extension_type }}.zip` and `retention-days` is set to `3`. The job id of the 2nd job is `test-e2e-upgrade`. Before this job runs, `build-all-artifacts` must complete successfully. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `project` has one value: ArgentX. The variable `shardIndex` has one value: 1. The variable `shardTotal` has one value: 1. The job creates a Docker container that uses `mcr.microsoft.com/playwright:v1.50.0-jammy` image. The job sets 31 environment variables to use: `ARGENT_X_ENVIRONMENT` is set to `hydrogen`, `ARGENT_API_BASE_URL` is set to `${{ secrets.ARGENT_API_BASE_URL }}`, `E2E_SENDER_ADDRESSES` is set to `${{ secrets.E2E_SENDER_ADDRESSES_SEPOLIA }}`, `E2E_SENDER_PRIVATEKEYS` is set to `${{ secrets.E2E_SENDER_PRIVATEKEYS_SEPOLIA }}`, `ARGENT_SEPOLIA_RPC_URL` is set to `${{ secrets.ARGENT_SEPOLIA_RPC_URL }}`, `E2E_TESTNET_SEED1` is set to `${{ secrets.E2E_TESTNET_SEED1 }}`, `E2E_TESTNET_SEED3` is set to `${{ secrets.E2E_TESTNET_SEED3 }}`, `E2E_TESTNET_SEED4` is set to `${{ secrets.E2E_TESTNET_SEED4 }}`, `E2E_ACCOUNT_1_SEED2` is set to `${{ secrets.E2E_ACCOUNT_1_SEED2 }}`, `E2E_SENDER_SEED` is set to `${{ secrets.E2E_SENDER_SEED }}`, `E2E_EXTENSION_PASSWORD` is set to `${{ secrets.E2E_EXTENSION_PASSWORD }}`, `E2E_SPOK_CAMPAIGN_URL` is set to `${{ secrets.E2E_SPOK_CAMPAIGN_URL }}`, `E2E_SPOK_CAMPAIGN_NAME` is set to `${{ secrets.E2E_SPOK_CAMPAIGN_NAME }}`, `E2E_USE_STRK_AS_FEE_TOKEN` is set to `${{ secrets.E2E_USE_STRK_AS_FEE_TOKEN }}`, `E2E_SKIP_TX_TESTS` is set to `${{ secrets.E2E_SKIP_TX_TESTS}}`, `E2E_LOG_INFO` is set to `${{ secrets.E2E_LOG_INFO }}`, `E2E_GUARDIAN_EMAIL` is set to `${{ secrets.E2E_GUARDIAN_EMAIL }}`, `E2E_MIG_ACCOUNT_ADDRESS` is set to `${{ secrets.E2E_MIG_ACCOUNT_ADDRESS }}`, `E2E_ACCOUNT_TO_IMPORT_AND_TX` is set to `${{ secrets.E2E_ACCOUNT_TO_IMPORT_AND_TX }}`, `E2E_ACCOUNTS_TO_IMPORT` is set to `${{ secrets.E2E_ACCOUNTS_TO_IMPORT }}`, `E2E_ACCOUNTS_TO_IMPORT_PROD` is set to `${{ secrets.E2E_ACCOUNTS_TO_IMPORT_PROD }}`, `E2E_QA_UTILS_AUTH_TOKEN` is set to `${{ secrets.E2E_QA_UTILS_AUTH_TOKEN }}`, `E2E_QA_UTILS_URL` is set to `${{ secrets.E2E_QA_UTILS_URL }}`, `E2E_REPO` is set to `${{ secrets.E2E_REPO }}`, `E2E_REPO_TOKEN` is set to `${{ secrets.E2E_REPO_TOKEN }}`, `E2E_REPO_OWNER` is set to `${{ secrets.E2E_REPO_OWNER }}`, `E2E_REPO_RELEASE_NAME` is set to `${{ secrets.E2E_REPO_RELEASE_NAME }}`, `REFRESH_INTERVAL_FAST` is set to `20`, `REFRESH_INTERVAL_MEDIUM` is set to `20`, `REFRESH_INTERVAL_SLOW` is set to `20` and `REFRESH_INTERVAL_VERY_SLOW` is set to `60 * 10`. The job `test-e2e-upgrade` has 9 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Install pnpm` and its id is `pnpm-install`. This step runs action `pnpm/action-setup` tagged as v4. The step defines 2 input parameters for the action: `version` is set to `${{ env.PNPM_VERSION }}` and `run_install` is set to `False`. The 3rd step is named `Setup Node ${{ env.NODE_VERSION }}`. This step runs action `actions/setup-node` tagged as v4. The step defines 2 input parameters for the action: `node-version` is set to `${{ env.NODE_VERSION }}` and `cache` is set to `pnpm`. The 4th step is named `Restore pnpm cache`. This step runs action `actions/cache/restore` tagged as v4. The step defines 3 input parameters for the action: `path` is set to `~/.pnpm-store`, `key` is set to `${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}` and `restore-keys` is set to `${{ runner.os }}-pnpm-store-\n`. The 5th step is named `Restore cached build`. This step runs action `actions/cache/restore` tagged as v4. The step defines 2 input parameters for the action: `path` is set to `./*` and `key` is set to `${{ github.sha }}-chrome-${{ env.ARGENT_X_ENVIRONMENT }}`. The 6th step is named `Install dependencies`. This step runs a script: `pnpm install --frozen-lockfile`. The 7th step is named `Run e2e tests`. This step runs a script: `xvfb-run --auto-servernum pnpm test:e2e:upgrade --project=${{ matrix.project }} --shard=${{ matrix.shardIndex }}/${{ matrix.shardTotal }}`. The 8th step is named `Upload artifacts`. This step will run only if the condition(always()) is met. This step runs action `actions/upload-artifact` tagged as v4. The step defines 3 input parameters for the action: `name` is set to `test-artifacts-upgrade-${{ matrix.shardIndex }}`, `path` is set to `packages/e2e/artifacts/playwright/\n!packages/e2e/artifacts/playwright/*.webm\n` and `retention-days` is set to `5`. The 9th step is named `Upload blob report to GitHub Actions Artifacts`. This step will run only if the condition(always()) is met. This step runs action `actions/upload-artifact` tagged as v4. The step defines 3 input parameters for the action: `name` is set to `all-blob-reports-upgrade-${{ matrix.shardIndex }}`, `path` is set to `packages/e2e/blob-report/` and `retention-days` is set to `5`. ","nb_triggers":1,"triggers":["workflow_dispatch"],"nb_jobs":2,"nb_actions":13,"actions":["actions/cache","actions/cache","actions/cache/restore","actions/cache/restore","actions/checkout","actions/checkout","actions/setup-node","actions/setup-node","actions/upload-artifact","actions/upload-artifact","actions/upload-artifact","pnpm/action-setup","pnpm/action-setup"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"pnpm/action-setup"},{"version":"v4","name":"actions/setup-node"},{"version":"v4","name":"actions/cache"},{"version":"v4","name":"actions/cache"},{"version":"v4","name":"actions/upload-artifact"},{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"pnpm/action-setup"},{"version":"v4","name":"actions/setup-node"},{"version":"v4","name":"actions/cache/restore"},{"version":"v4","name":"actions/cache/restore"},{"version":"v4","name":"actions/upload-artifact"},{"version":"v4","name":"actions/upload-artifact"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":23,"cyclomatic_complexity":1}
{"id":2698,"repository_id":95228815,"mainLanguage":"Nix","file_name":"build.yml","file_content":"name: Test Build\n\non:\n  push:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    container: pgxn/pgxn-tools\n    strategy:\n      matrix:\n        pg: [12, 13, 14, 15, 16, 17]\n    name:  Postgres ${{ matrix.pg }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Start PostgreSQL ${{ matrix.pg }}\n        run: pg-start ${{ matrix.pg }}\n      - name: Setup Rust Cache\n        uses: Swatinem/rust-cache@v2\n      - name: Setup Rust\n        uses: dtolnay/rust-toolchain@stable\n      - name: Test on PostgreSQL ${{ matrix.pg }}\n        run: pgrx-build-test\n","repository_owner":"frectonz","repository_name":"pglite-fusion","tokens_count":181,"workflow":"name: Test Build\n\non:\n  push:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    container: pgxn/pgxn-tools\n    strategy:\n      matrix:\n        pg: [12, 13, 14, 15, 16, 17]\n    name:  Postgres ${{ matrix.pg }}\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v4\n    - name: Start PostgreSQL ${{ matrix.pg }}\n      run: pg-start ${{ matrix.pg }}\n    - name: Setup Rust Cache\n      uses: Swatinem/rust-cache@v2\n    - name: Setup Rust\n      uses: dtolnay/rust-toolchain@stable\n    - name: Test on PostgreSQL ${{ matrix.pg }}\n      run: pgrx-build-test\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Test Build` for a GitHub repository whose primary programming language is Nix. This workflow will be triggered by an event: a commit or tag is pushed, or a repository is cloned. The workflow has one job. The 1st job is named ` Postgres ${{ matrix.pg }}` and its job id is `build`. ","prompt_level2":"Generate a GitHub Workflow named `Test Build` for a GitHub repository whose primary programming language is Nix. This workflow will be triggered by an event: a commit or tag is pushed, or a repository is cloned. The workflow has one job. The 1st job is named ` Postgres ${{ matrix.pg }}` and its job id is `build`. The job `build` has 5 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Start PostgreSQL ${{ matrix.pg }}`. The 3rd step is named `Setup Rust Cache`. The 4th step is named `Setup Rust`. The 5th step is named `Test on PostgreSQL ${{ matrix.pg }}`. ","prompt_level3":"Generate a GitHub Workflow named `Test Build` for a GitHub repository whose primary programming language is Nix. This workflow will be triggered by an event: a commit or tag is pushed, or a repository is cloned. The workflow has one job. The 1st job is named ` Postgres ${{ matrix.pg }}` and its job id is `build`. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `pg` has 6 values: 12, 13, 14, 15, 16 and 17. The job creates a Docker container that uses `pgxn/pgxn-tools` image. The job `build` has 5 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Start PostgreSQL ${{ matrix.pg }}`. This step runs a script: `pg-start ${{ matrix.pg }}`. The 3rd step is named `Setup Rust Cache`. This step runs action `Swatinem/rust-cache` tagged as v2. The 4th step is named `Setup Rust`. This step runs action `dtolnay/rust-toolchain` from the stable branch. The 5th step is named `Test on PostgreSQL ${{ matrix.pg }}`. This step runs a script: `pgrx-build-test`. ","nb_triggers":1,"triggers":["push"],"nb_jobs":1,"nb_actions":3,"actions":["Swatinem/rust-cache","actions/checkout","dtolnay/rust-toolchain"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v2","name":"Swatinem/rust-cache"},{"version":"stable","name":"dtolnay/rust-toolchain"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":5,"cyclomatic_complexity":1}
{"id":45370,"repository_id":94556628,"mainLanguage":"Python","file_name":"airflow-distributions-tests.yml","file_content":"# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n---\nname: Non-core Distribution tests\non:  # yamllint disable-line rule:truthy\n  workflow_call:\n    inputs:\n      # Static inputs defined to choose which distribution to test to run\n      distribution-name:\n        description: \"The name of the distribution to test\"\n        required: true\n        type: string\n      distribution-cmd-format:\n        description: \"The type of distribution to test\"  # eg prepare-task-sdk-distributions\n        required: true\n        type: string\n      test-type:\n        description: \"distribution test type\"  # eg task-sdk-tests\n        required: true\n        type: string\n      # Environment inputs\n      runs-on-as-json-default:\n        description: \"The array of labels (in json form) determining default runner used for the build.\"\n        required: true\n        type: string\n      default-python-version:\n        description: \"Which version of python should be used by default\"\n        required: true\n        type: string\n      python-versions:\n        description: \"JSON-formatted array of Python versions to build images from\"\n        required: true\n        type: string\n      use-uv:\n        description: \"Whether to use uv to build the image (true/false)\"\n        required: true\n        type: string\n      canary-run:\n        description: \"Whether this is a canary run (true/false)\"\n        required: true\n        type: string\npermissions:\n  contents: read\njobs:\n  distributions-tests:\n    timeout-minutes: 80\n    name: ${{ inputs.distribution-name }}:P${{ matrix.python-version }} tests\n    runs-on: ${{ fromJSON(inputs.runs-on-as-json-default) }}\n    strategy:\n      fail-fast: false\n      matrix:\n        python-version: \"${{fromJSON(inputs.python-versions)}}\"\n    env:\n      GITHUB_REPOSITORY: ${{ github.repository }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      GITHUB_USERNAME: ${{ github.actor }}\n      INCLUDE_NOT_READY_PROVIDERS: \"true\"\n      PYTHON_MAJOR_MINOR_VERSION: \"${{ inputs.default-python-version }}\"\n      VERBOSE: \"true\"\n    steps:\n      - name: \"Cleanup repo\"\n        shell: bash\n        run: docker run -v \"${GITHUB_WORKSPACE}:/workspace\" -u 0:0 bash -c \"rm -rf /workspace/*\"\n      - name: \"Checkout ${{ github.ref }} ( ${{ github.sha }} )\"\n        uses: actions/checkout@v4\n        with:\n          persist-credentials: false\n      - name: \"Prepare breeze & CI image: ${{ matrix.python-version }}\"\n        uses: ./.github/actions/prepare_breeze_and_image\n        with:\n          platform: \"linux/amd64\"\n          python: ${{ matrix.python-version }}\n          use-uv: ${{ inputs.use-uv }}\n      - name: \"Cleanup dist files\"\n        run: rm -fv ./dist/*\n      # Conditional steps based on the distribution name\n      - name: \"Prepare Airflow ${{inputs.distribution-name}}: wheel\"\n        env:\n          DISTRIBUTION_TYPE: \"${{ inputs.distribution-cmd-format }}\"\n        run: >\n          breeze release-management \"${DISTRIBUTION_TYPE}\" --distribution-format wheel\n      - name: \"Verify wheel packages with twine\"\n        run: |\n          uv tool uninstall twine || true\n          uv tool install twine && twine check dist/*.whl\n      - name: >\n          Run unit tests for Airflow ${{inputs.distribution-name}}:Python ${{ matrix.python-version }}\n        env:\n          PYTHON_VERSION: \"${{ matrix.python-version }}\"\n          TEST_TYPE: \"${{ inputs.test-type }}\"\n        run: >\n          breeze testing \"${TEST_TYPE}\" --python \"${PYTHON_VERSION}\"\n","repository_owner":"apache","repository_name":"airflow","tokens_count":966,"workflow":"name: Non-core Distribution tests\non:  # yamllint disable-line rule:truthy\n  workflow_call:\n    inputs:\n      # Static inputs defined to choose which distribution to test to run\n      distribution-name:\n        description: The name of the distribution to test\n        required: true\n        type: string\n      distribution-cmd-format:\n        description: The type of distribution to test    # eg prepare-task-sdk-distributions\n        required: true\n        type: string\n      test-type:\n        description: distribution test type    # eg task-sdk-tests\n        required: true\n        type: string\n      # Environment inputs\n      runs-on-as-json-default:\n        description: The array of labels (in json form) determining default \n          runner used for the build.\n        required: true\n        type: string\n      default-python-version:\n        description: Which version of python should be used by default\n        required: true\n        type: string\n      python-versions:\n        description: JSON-formatted array of Python versions to build images \n          from\n        required: true\n        type: string\n      use-uv:\n        description: Whether to use uv to build the image (true/false)\n        required: true\n        type: string\n      canary-run:\n        description: Whether this is a canary run (true/false)\n        required: true\n        type: string\npermissions:\n  contents: read\njobs:\n  distributions-tests:\n    timeout-minutes: 80\n    name: ${{ inputs.distribution-name }}:P${{ matrix.python-version }} tests\n    runs-on: ${{ fromJSON(inputs.runs-on-as-json-default) }}\n    strategy:\n      fail-fast: false\n      matrix:\n        python-version: ${{fromJSON(inputs.python-versions)}}\n    env:\n      GITHUB_REPOSITORY: ${{ github.repository }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      GITHUB_USERNAME: ${{ github.actor }}\n      INCLUDE_NOT_READY_PROVIDERS: 'true'\n      PYTHON_MAJOR_MINOR_VERSION: ${{ inputs.default-python-version }}\n      VERBOSE: 'true'\n    steps:\n    - name: Cleanup repo\n      shell: bash\n      run: docker run -v \"${GITHUB_WORKSPACE}:/workspace\" -u 0:0 bash -c \"rm -rf\n        /workspace/*\"\n    - name: Checkout ${{ github.ref }} ( ${{ github.sha }} )\n      uses: actions/checkout@v4\n      with:\n        persist-credentials: false\n    - name: 'Prepare breeze & CI image: ${{ matrix.python-version }}'\n      uses: ./.github/actions/prepare_breeze_and_image\n      with:\n        platform: linux/amd64\n        python: ${{ matrix.python-version }}\n        use-uv: ${{ inputs.use-uv }}\n    - name: Cleanup dist files\n      run: rm -fv ./dist/*\n      # Conditional steps based on the distribution name\n    - name: 'Prepare Airflow ${{inputs.distribution-name}}: wheel'\n      env:\n        DISTRIBUTION_TYPE: ${{ inputs.distribution-cmd-format }}\n      run: >\n        breeze release-management \"${DISTRIBUTION_TYPE}\" --distribution-format wheel\n    - name: Verify wheel packages with twine\n      run: |\n        uv tool uninstall twine || true\n        uv tool install twine && twine check dist/*.whl\n    - name: >\n        Run unit tests for Airflow ${{inputs.distribution-name}}:Python ${{ matrix.python-version\n        }}\n      env:\n        PYTHON_VERSION: ${{ matrix.python-version }}\n        TEST_TYPE: ${{ inputs.test-type }}\n      run: >\n        breeze testing \"${TEST_TYPE}\" --python \"${PYTHON_VERSION}\"\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Non-core Distribution tests` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 8 inputs: distribution-name-this input represents the name of the distribution to test, it must be supplied and the data type is string; distribution-cmd-format-this input represents the type of distribution to test, it must be supplied and the data type is string; test-type-this input represents distribution test type, it must be supplied and the data type is string; runs-on-as-json-default-this input represents the array of labels (in json form) determining default runner used for the build., it must be supplied and the data type is string; default-python-version-this input represents which version of python should be used by default, it must be supplied and the data type is string; python-versions-this input represents json-formatted array of python versions to build images from, it must be supplied and the data type is string; use-uv-this input represents whether to use uv to build the image (true/false), it must be supplied and the data type is string; canary-run-this input represents whether this is a canary run (true/false), it must be supplied and the data type is string. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `${{ inputs.distribution-name }}:P${{ matrix.python-version }} tests` and its job id is `distributions-tests`. ","prompt_level2":"Generate a GitHub Workflow named `Non-core Distribution tests` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 8 inputs: distribution-name-this input represents the name of the distribution to test, it must be supplied and the data type is string; distribution-cmd-format-this input represents the type of distribution to test, it must be supplied and the data type is string; test-type-this input represents distribution test type, it must be supplied and the data type is string; runs-on-as-json-default-this input represents the array of labels (in json form) determining default runner used for the build., it must be supplied and the data type is string; default-python-version-this input represents which version of python should be used by default, it must be supplied and the data type is string; python-versions-this input represents json-formatted array of python versions to build images from, it must be supplied and the data type is string; use-uv-this input represents whether to use uv to build the image (true/false), it must be supplied and the data type is string; canary-run-this input represents whether this is a canary run (true/false), it must be supplied and the data type is string. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `${{ inputs.distribution-name }}:P${{ matrix.python-version }} tests` and its job id is `distributions-tests`. The job `distributions-tests` has 7 steps. The 1st step is named `Cleanup repo`. The 2nd step is named `Checkout repository`. The 3rd step is named `Prepare breeze & CI image: ${{ matrix.python-version }}`. The 4th step is named `Cleanup dist files`. The 5th step is named `Prepare Airflow ${{inputs.distribution-name}}: wheel`. The 6th step is named `Verify wheel packages with twine`. The 7th step is named `Run unit tests for Airflow ${{inputs.distribution-name}}:Python ${{ matrix.python-version }}\n`. ","prompt_level3":"Generate a GitHub Workflow named `Non-core Distribution tests` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 8 inputs: distribution-name-this input represents the name of the distribution to test, it must be supplied and the data type is string; distribution-cmd-format-this input represents the type of distribution to test, it must be supplied and the data type is string; test-type-this input represents distribution test type, it must be supplied and the data type is string; runs-on-as-json-default-this input represents the array of labels (in json form) determining default runner used for the build., it must be supplied and the data type is string; default-python-version-this input represents which version of python should be used by default, it must be supplied and the data type is string; python-versions-this input represents json-formatted array of python versions to build images from, it must be supplied and the data type is string; use-uv-this input represents whether to use uv to build the image (true/false), it must be supplied and the data type is string; canary-run-this input represents whether this is a canary run (true/false), it must be supplied and the data type is string. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `${{ inputs.distribution-name }}:P${{ matrix.python-version }} tests` and its job id is `distributions-tests`. This job will run on ${{ fromJSON(inputs.runs-on-as-json-default) }} runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `python-version` has 37 values: $, {, {, f, r, o, m, J, S, O, N, (, i, n, p, u, t, s, ., p, y, t, h, o, n, -, v, e, r, s, i, o, n, s, ), } and }. The job sets 6 environment variables to use: `GITHUB_REPOSITORY` is set to `${{ github.repository }}`, `GITHUB_TOKEN` is set to `${{ secrets.GITHUB_TOKEN }}`, `GITHUB_USERNAME` is set to `${{ github.actor }}`, `INCLUDE_NOT_READY_PROVIDERS` is set to `true`, `PYTHON_MAJOR_MINOR_VERSION` is set to `${{ inputs.default-python-version }}` and `VERBOSE` is set to `true`. The maximum number of minutes to run the job is 80. The job `distributions-tests` has 7 steps. The 1st step is named `Cleanup repo`. This step uses bash to run a script: `docker run -v \"${GITHUB_WORKSPACE}:/workspace\" -u 0:0 bash -c \"rm -rf /workspace/*\"`. The 2nd step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `persist-credentials` is set to `False`. The 3rd step is named `Prepare breeze & CI image: ${{ matrix.python-version }}`. This step runs action `./.github/actions/prepare_breeze_and_image`.The step defines 3 input parameters for the action: `platform` is set to `linux/amd64`, `python` is set to `${{ matrix.python-version }}` and `use-uv` is set to `${{ inputs.use-uv }}`. The 4th step is named `Cleanup dist files`. This step runs a script: `rm -fv ./dist/*`. The 5th step is named `Prepare Airflow ${{inputs.distribution-name}}: wheel`. The step sets an environment variable to use: `DISTRIBUTION_TYPE` is set to `${{ inputs.distribution-cmd-format }}`. This step runs a script: `breeze release-management \"${DISTRIBUTION_TYPE}\" --distribution-format wheel\n`. The 6th step is named `Verify wheel packages with twine`. This step runs a script: `uv tool uninstall twine || true\nuv tool install twine && twine check dist/*.whl\n`. The 7th step is named `Run unit tests for Airflow ${{inputs.distribution-name}}:Python ${{ matrix.python-version }}\n`. The step sets 2 environment variables to use: `PYTHON_VERSION` is set to `${{ matrix.python-version }}` and `TEST_TYPE` is set to `${{ inputs.test-type }}`. This step runs a script: `breeze testing \"${TEST_TYPE}\" --python \"${PYTHON_VERSION}\"\n`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":2,"actions":["./.github/actions/prepare_breeze_and_image","actions/checkout"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":null,"name":"./.github/actions/prepare_breeze_and_image"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":7,"cyclomatic_complexity":1}
{"id":52484,"repository_id":7472156,"mainLanguage":"JavaScript","file_name":"node-pretest.yml","file_content":"name: 'Tests: pretest/posttest'\n\non: [pull_request, push]\n\npermissions:\n  contents: read\n\njobs:\n  tests:\n    uses: ljharb/actions/.github/workflows/pretest.yml@main\n","repository_owner":"form-data","repository_name":"form-data","tokens_count":47,"workflow":"name: 'Tests: pretest/posttest'\n\non: [pull_request, push]\n\npermissions:\n  contents: read\n\njobs:\n  tests:\n    uses: ljharb/actions/.github/workflows/pretest.yml@main\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Tests: pretest/posttest` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) there is activity relating to a pull request. 2) a commit or tag is pushed, or a repository is cloned. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `tests`. ","prompt_level2":"Generate a GitHub Workflow named `Tests: pretest/posttest` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) there is activity relating to a pull request. 2) a commit or tag is pushed, or a repository is cloned. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `tests`. ","prompt_level3":"Generate a GitHub Workflow named `Tests: pretest/posttest` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) there is activity relating to a pull request. 2) a commit or tag is pushed, or a repository is cloned. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `tests`. This job will call a reusable workflow located at `ljharb/actions/.github/workflows/pretest.yml@main`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":1,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["ljharb/actions/.github/workflows/pretest.yml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":49436,"repository_id":46291537,"mainLanguage":"C++","file_name":"rebuild-llvm20.yml","file_content":"# Copyright 2025 Intel Corporation\n# SPDX-License-Identifier: BSD-3-Clause\n\nname: Rebuild LLVM 20.1\n\npermissions: read-all\n\non:\n  push:\n    branches:\n      - main\n      - '**rebuild_llvm**'\n    paths:\n      - \"llvm_patches/*20_1*\"\n      - \"scripts/alloy.py\"\n      - \"superbuild/*\"\n      - \".github/workflows/rebuild-llvm20.yml\"\n      - \".github/workflows/reusable.rebuild.yml\"\n  workflow_dispatch:\n\njobs:\n  llvm20:\n    concurrency:\n      group: ${{ github.workflow }}-${{ github.ref }}-${{ matrix.lto }}-${{ matrix.asserts }}-${{ matrix.arch }}\n      cancel-in-progress: true\n    strategy:\n      fail-fast: false\n      matrix:\n        lto: ['ON', 'OFF']\n        asserts: ['ON', 'OFF']\n        arch: ['x86', 'aarch64']\n    uses: ./.github/workflows/reusable.rebuild.yml\n    with:\n      version: '20.1'\n      full_version: '20.1.2'\n      lto: ${{ matrix.lto }}\n      asserts: ${{ matrix.asserts }}\n      arch: ${{ matrix.arch }}\n      ubuntu: '22.04'\n      win_sdk: '10.0.18362.0'\n","repository_owner":"ispc","repository_name":"ispc","tokens_count":302,"workflow":"# Copyright 2025 Intel Corporation\n# SPDX-License-Identifier: BSD-3-Clause\n\nname: Rebuild LLVM 20.1\n\npermissions: read-all\n\non:\n  push:\n    branches:\n    - main\n    - '**rebuild_llvm**'\n    paths:\n    - llvm_patches/*20_1*\n    - scripts/alloy.py\n    - superbuild/*\n    - .github/workflows/rebuild-llvm20.yml\n    - .github/workflows/reusable.rebuild.yml\n  workflow_dispatch:\n\njobs:\n  llvm20:\n    concurrency:\n      group: ${{ github.workflow }}-${{ github.ref }}-${{ matrix.lto }}-${{ \n        matrix.asserts }}-${{ matrix.arch }}\n      cancel-in-progress: true\n    strategy:\n      fail-fast: false\n      matrix:\n        lto: [ON, OFF]\n        asserts: [ON, OFF]\n        arch: [x86, aarch64]\n    uses: ./.github/workflows/reusable.rebuild.yml\n    with:\n      version: '20.1'\n      full_version: 20.1.2\n      lto: ${{ matrix.lto }}\n      asserts: ${{ matrix.asserts }}\n      arch: ${{ matrix.arch }}\n      ubuntu: '22.04'\n      win_sdk: 10.0.18362.0\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Rebuild LLVM 20.1` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main or a branch whose name matches **rebuild_llvm**. Only if at least one path of push event matches a pattern in the paths filter(llvm_patches/*20_1*, scripts/alloy.py, superbuild/*, .github/workflows/rebuild-llvm20.yml or .github/workflows/reusable.rebuild.yml), the workflow runs. 2) someone manually triggers the workflow. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `llvm20`. ","prompt_level2":"Generate a GitHub Workflow named `Rebuild LLVM 20.1` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main or a branch whose name matches **rebuild_llvm**. Only if at least one path of push event matches a pattern in the paths filter(llvm_patches/*20_1*, scripts/alloy.py, superbuild/*, .github/workflows/rebuild-llvm20.yml or .github/workflows/reusable.rebuild.yml), the workflow runs. 2) someone manually triggers the workflow. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `llvm20`. ","prompt_level3":"Generate a GitHub Workflow named `Rebuild LLVM 20.1` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main or a branch whose name matches **rebuild_llvm**. Only if at least one path of push event matches a pattern in the paths filter(llvm_patches/*20_1*, scripts/alloy.py, superbuild/*, .github/workflows/rebuild-llvm20.yml or .github/workflows/reusable.rebuild.yml), the workflow runs. 2) someone manually triggers the workflow. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `llvm20`. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `lto` has 2 values: True and False. The variable `asserts` has 2 values: True and False. The variable `arch` has 2 values: x86 and aarch64. Only a single job using the ${{ github.workflow }}-${{ github.ref }}-${{ matrix.lto }}-${{ matrix.asserts }}-${{ matrix.arch }} concurrency group will run at a time. When this job is queued, any currently running job in the same concurrency group will be canceled. This job will call a reusable workflow located at `./.github/workflows/reusable.rebuild.yml`. The job will pass 7 inputs to the called workflow: the input `version` is `20.1`, the input `full_version` is `20.1.2`, the input `lto` is `${{ matrix.lto }}`, the input `asserts` is `${{ matrix.asserts }}`, the input `arch` is `${{ matrix.arch }}`, the input `ubuntu` is `22.04` and the input `win_sdk` is `10.0.18362.0`. ","nb_triggers":2,"triggers":["push","workflow_dispatch"],"nb_jobs":1,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["./.github/workflows/reusable.rebuild.yml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":59049,"repository_id":94532470,"mainLanguage":"Python","file_name":"layer_govcloud.yml","file_content":"name: Layer Deployment (GovCloud)\n\n# GovCloud Layer Publish\n# ---\n# This workflow publishes a specific layer version in an AWS account based on the environment input.\n#\n# Using a matrix, we pull each architecture and python version of the layer and store them as artifacts\n# we upload them to each of the GovCloud AWS accounts.\n#\n# A number of safety checks are performed to ensure safety.\n\non:\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: Deployment environment\n        type: choice\n        options:\n          - Gamma\n          - Prod\n        required: true\n      version:\n        description: Layer version to duplicate\n        type: string\n        required: true\n  workflow_call:\n    inputs:\n      environment:\n        description: Deployment environment\n        type: string\n        required: true\n      version:\n        description: Layer version to duplicate\n        type: string\n        required: true\n\nrun-name: Layer Deployment (GovCloud) - ${{ inputs.environment }}\n\npermissions:\n  contents: read\n\njobs:\n  download:\n    runs-on: ubuntu-latest\n    permissions:\n      id-token: write\n      contents: read\n    strategy:\n      matrix:\n        layer:\n          - AWSLambdaPowertoolsPythonV3-python39\n          - AWSLambdaPowertoolsPythonV3-python310\n          - AWSLambdaPowertoolsPythonV3-python311\n          - AWSLambdaPowertoolsPythonV3-python312\n          - AWSLambdaPowertoolsPythonV3-python313\n        arch:\n          - arm64\n          - x86_64\n    environment: Prod (Readonly)\n    steps:\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@f24d7193d98baebaeacc7e2227925dd47cc267f5 # v4.2.0\n        with:\n          role-to-assume: ${{ secrets.AWS_IAM_ROLE }}\n          aws-region: us-east-1\n          mask-aws-account-id: true\n      - name: Grab Zip\n        run: |\n          aws --region us-east-1 lambda get-layer-version-by-arn --arn arn:aws:lambda:us-east-1:017000801446:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ inputs.version }} --query 'Content.Location' | xargs curl -L -o ${{ matrix.layer }}_${{ matrix.arch }}.zip\n          aws --region us-east-1 lambda get-layer-version-by-arn --arn arn:aws:lambda:us-east-1:017000801446:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ inputs.version }} > ${{ matrix.layer }}_${{ matrix.arch }}.json\n      - name: Store Zip\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: ${{ matrix.layer }}_${{ matrix.arch }}.zip\n          path: ${{ matrix.layer }}_${{ matrix.arch }}.zip\n          retention-days: 1\n          if-no-files-found: error\n      - name: Store Metadata\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: ${{ matrix.layer }}_${{ matrix.arch }}.json\n          path: ${{ matrix.layer }}_${{ matrix.arch }}.json\n          retention-days: 1\n          if-no-files-found: error\n\n  copy_east:\n    name: Copy (East)\n    needs: download\n    runs-on: ubuntu-latest\n    permissions:\n      id-token: write\n      contents: read\n    strategy:\n      matrix:\n        layer:\n          - AWSLambdaPowertoolsPythonV3-python39\n          - AWSLambdaPowertoolsPythonV3-python310\n          - AWSLambdaPowertoolsPythonV3-python311\n          - AWSLambdaPowertoolsPythonV3-python312\n          - AWSLambdaPowertoolsPythonV3-python313\n        arch:\n          - arm64\n          - x86_64\n    environment: GovCloud ${{ inputs.environment }} (East)\n    steps:\n      - name: Download Zip\n        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0\n        with:\n          name: ${{ matrix.layer }}_${{ matrix.arch }}.zip\n      - name: Download Metadata\n        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0\n        with:\n          name: ${{ matrix.layer }}_${{ matrix.arch }}.json\n      - name: Verify Layer Signature\n        run: |\n          SHA=$(jq -r '.Content.CodeSha256' '${{ matrix.layer }}_${{ matrix.arch }}.json')\n          test \"$(openssl dgst -sha256 -binary ${{ matrix.layer }}_${{ matrix.arch }}.zip | openssl enc -base64)\" == \"$SHA\" && echo \"SHA OK: ${SHA}\" || exit 1\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@f24d7193d98baebaeacc7e2227925dd47cc267f5 # v4.2.0\n        with:\n          role-to-assume: ${{ secrets.AWS_IAM_ROLE }}\n          aws-region: us-gov-east-1\n          mask-aws-account-id: true\n      - name: Create Layer\n        id: create-layer\n        run: |\n          LAYER_VERSION=$(aws --region us-gov-east-1 lambda publish-layer-version \\\n            --layer-name ${{ matrix.layer }}-${{ matrix.arch }} \\\n            --zip-file fileb://./${{ matrix.layer }}_${{ matrix.arch }}.zip \\\n            --compatible-runtimes \"$(jq -r '.CompatibleRuntimes[0]' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n            --compatible-architectures \"$(jq  -r '.CompatibleArchitectures[0]' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n            --license-info \"MIT-0\" \\\n            --description \"$(jq -r '.Description' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n            --query 'Version' \\\n            --output text)\n\n          echo \"LAYER_VERSION=$LAYER_VERSION\" >> \"$GITHUB_OUTPUT\"\n\n          aws --region us-gov-east-1 lambda add-layer-version-permission \\\n            --layer-name '${{ matrix.layer }}-${{ matrix.arch }}' \\\n            --statement-id 'PublicLayer' \\\n            --action lambda:GetLayerVersion \\\n            --principal '*' \\\n            --version-number \"$LAYER_VERSION\"\n      - name: Verify Layer\n        env:\n          LAYER_VERSION: ${{ steps.create-layer.outputs.LAYER_VERSION }}\n        run: |\n          REMOTE_SHA=$(aws --region us-gov-east-1 lambda get-layer-version-by-arn --arn 'arn:aws-us-gov:lambda:us-gov-east-1:${{ secrets.AWS_ACCOUNT_ID }}:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ env.LAYER_VERSION }}' --query 'Content.CodeSha256' --output text)\n          SHA=$(jq -r '.Content.CodeSha256' '${{ matrix.layer }}_${{ matrix.arch }}.json')\n          test \"$REMOTE_SHA\" == \"$SHA\" && echo \"SHA OK: ${SHA}\" || exit 1\n          aws --region us-gov-east-1 lambda get-layer-version-by-arn --arn 'arn:aws-us-gov:lambda:us-gov-east-1:${{ secrets.AWS_ACCOUNT_ID }}:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ env.LAYER_VERSION }}' --output table\n\n  copy_west:\n    name: Copy (West)\n    needs: download\n    runs-on: ubuntu-latest\n    permissions:\n      id-token: write\n      contents: read\n    strategy:\n      matrix:\n        layer:\n          - AWSLambdaPowertoolsPythonV3-python39\n          - AWSLambdaPowertoolsPythonV3-python310\n          - AWSLambdaPowertoolsPythonV3-python311\n          - AWSLambdaPowertoolsPythonV3-python312\n          - AWSLambdaPowertoolsPythonV3-python313\n        arch:\n          - arm64\n          - x86_64\n    environment:\n      name: GovCloud ${{ inputs.environment }} (West)\n    steps:\n      - name: Download Zip\n        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0\n        with:\n          name: ${{ matrix.layer }}_${{ matrix.arch }}.zip\n      - name: Download Metadata\n        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0\n        with:\n          name: ${{ matrix.layer }}_${{ matrix.arch }}.json\n      - name: Verify Layer Signature\n        run: |\n          SHA=$(jq -r '.Content.CodeSha256' '${{ matrix.layer }}_${{ matrix.arch }}.json')\n          test \"$(openssl dgst -sha256 -binary ${{ matrix.layer }}_${{ matrix.arch }}.zip | openssl enc -base64)\" == \"$SHA\" && echo \"SHA OK: ${SHA}\" || exit 1\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@f24d7193d98baebaeacc7e2227925dd47cc267f5 # v4.2.0\n        with:\n          role-to-assume: ${{ secrets.AWS_IAM_ROLE }}\n          aws-region: us-gov-west-1\n          mask-aws-account-id: true\n      - name: Create Layer\n        id: create-layer\n        run: |\n          LAYER_VERSION=$(aws --region us-gov-west-1 lambda publish-layer-version \\\n            --layer-name ${{ matrix.layer }}-${{ matrix.arch }} \\\n            --zip-file fileb://./${{ matrix.layer }}_${{ matrix.arch }}.zip \\\n            --compatible-runtimes \"$(jq -r '.CompatibleRuntimes[0]' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n            --compatible-architectures \"$(jq  -r '.CompatibleArchitectures[0]' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n            --license-info \"MIT-0\" \\\n            --description \"$(jq -r '.Description' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n            --query 'Version' \\\n            --output text)\n\n          echo \"LAYER_VERSION=$LAYER_VERSION\" >> \"$GITHUB_OUTPUT\"\n\n          aws --region us-gov-west-1 lambda add-layer-version-permission \\\n            --layer-name '${{ matrix.layer }}-${{ matrix.arch }}' \\\n            --statement-id 'PublicLayer' \\\n            --action lambda:GetLayerVersion \\\n            --principal '*' \\\n            --version-number \"$LAYER_VERSION\"\n      - name: Verify Layer\n        env:\n          LAYER_VERSION: ${{ steps.create-layer.outputs.LAYER_VERSION }}\n        run: |\n          REMOTE_SHA=$(aws --region us-gov-west-1 lambda get-layer-version-by-arn --arn 'arn:aws-us-gov:lambda:us-gov-west-1:${{ secrets.AWS_ACCOUNT_ID }}:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ env.LAYER_VERSION }}' --query 'Content.CodeSha256' --output text)\n          SHA=$(jq -r '.Content.CodeSha256' '${{ matrix.layer }}_${{ matrix.arch }}.json')\n          test \"$REMOTE_SHA\" == \"$SHA\" && echo \"SHA OK: ${SHA}\" || exit 1\n          aws --region us-gov-west-1 lambda get-layer-version-by-arn --arn 'arn:aws-us-gov:lambda:us-gov-west-1:${{ secrets.AWS_ACCOUNT_ID }}:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ env.LAYER_VERSION }}' --output table\n","repository_owner":"aws-powertools","repository_name":"powertools-lambda-python","tokens_count":2802,"workflow":"name: Layer Deployment (GovCloud)\n\n# GovCloud Layer Publish\n# ---\n# This workflow publishes a specific layer version in an AWS account based on the environment input.\n#\n# Using a matrix, we pull each architecture and python version of the layer and store them as artifacts\n# we upload them to each of the GovCloud AWS accounts.\n#\n# A number of safety checks are performed to ensure safety.\n\non:\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: Deployment environment\n        type: choice\n        options:\n        - Gamma\n        - Prod\n        required: true\n      version:\n        description: Layer version to duplicate\n        type: string\n        required: true\n  workflow_call:\n    inputs:\n      environment:\n        description: Deployment environment\n        type: string\n        required: true\n      version:\n        description: Layer version to duplicate\n        type: string\n        required: true\n\nrun-name: Layer Deployment (GovCloud) - ${{ inputs.environment }}\n\npermissions:\n  contents: read\n\njobs:\n  download:\n    runs-on: ubuntu-latest\n    permissions:\n      id-token: write\n      contents: read\n    strategy:\n      matrix:\n        layer:\n        - AWSLambdaPowertoolsPythonV3-python39\n        - AWSLambdaPowertoolsPythonV3-python310\n        - AWSLambdaPowertoolsPythonV3-python311\n        - AWSLambdaPowertoolsPythonV3-python312\n        - AWSLambdaPowertoolsPythonV3-python313\n        arch:\n        - arm64\n        - x86_64\n    environment: Prod (Readonly)\n    steps:\n    - name: Configure AWS Credentials\n      uses: \n        aws-actions/configure-aws-credentials@f24d7193d98baebaeacc7e2227925dd47cc267f5       # v4.2.0\n      with:\n        role-to-assume: ${{ secrets.AWS_IAM_ROLE }}\n        aws-region: us-east-1\n        mask-aws-account-id: true\n    - name: Grab Zip\n      run: |\n        aws --region us-east-1 lambda get-layer-version-by-arn --arn arn:aws:lambda:us-east-1:017000801446:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ inputs.version }} --query 'Content.Location' | xargs curl -L -o ${{ matrix.layer }}_${{ matrix.arch }}.zip\n        aws --region us-east-1 lambda get-layer-version-by-arn --arn arn:aws:lambda:us-east-1:017000801446:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ inputs.version }} > ${{ matrix.layer }}_${{ matrix.arch }}.json\n    - name: Store Zip\n      uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02   # v4.6.2\n      with:\n        name: ${{ matrix.layer }}_${{ matrix.arch }}.zip\n        path: ${{ matrix.layer }}_${{ matrix.arch }}.zip\n        retention-days: 1\n        if-no-files-found: error\n    - name: Store Metadata\n      uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02   # v4.6.2\n      with:\n        name: ${{ matrix.layer }}_${{ matrix.arch }}.json\n        path: ${{ matrix.layer }}_${{ matrix.arch }}.json\n        retention-days: 1\n        if-no-files-found: error\n\n  copy_east:\n    name: Copy (East)\n    needs: download\n    runs-on: ubuntu-latest\n    permissions:\n      id-token: write\n      contents: read\n    strategy:\n      matrix:\n        layer:\n        - AWSLambdaPowertoolsPythonV3-python39\n        - AWSLambdaPowertoolsPythonV3-python310\n        - AWSLambdaPowertoolsPythonV3-python311\n        - AWSLambdaPowertoolsPythonV3-python312\n        - AWSLambdaPowertoolsPythonV3-python313\n        arch:\n        - arm64\n        - x86_64\n    environment: GovCloud ${{ inputs.environment }} (East)\n    steps:\n    - name: Download Zip\n      uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093   # v4.3.0\n      with:\n        name: ${{ matrix.layer }}_${{ matrix.arch }}.zip\n    - name: Download Metadata\n      uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093   # v4.3.0\n      with:\n        name: ${{ matrix.layer }}_${{ matrix.arch }}.json\n    - name: Verify Layer Signature\n      run: |\n        SHA=$(jq -r '.Content.CodeSha256' '${{ matrix.layer }}_${{ matrix.arch }}.json')\n        test \"$(openssl dgst -sha256 -binary ${{ matrix.layer }}_${{ matrix.arch }}.zip | openssl enc -base64)\" == \"$SHA\" && echo \"SHA OK: ${SHA}\" || exit 1\n    - name: Configure AWS Credentials\n      uses: \n        aws-actions/configure-aws-credentials@f24d7193d98baebaeacc7e2227925dd47cc267f5       # v4.2.0\n      with:\n        role-to-assume: ${{ secrets.AWS_IAM_ROLE }}\n        aws-region: us-gov-east-1\n        mask-aws-account-id: true\n    - name: Create Layer\n      id: create-layer\n      run: |\n        LAYER_VERSION=$(aws --region us-gov-east-1 lambda publish-layer-version \\\n          --layer-name ${{ matrix.layer }}-${{ matrix.arch }} \\\n          --zip-file fileb://./${{ matrix.layer }}_${{ matrix.arch }}.zip \\\n          --compatible-runtimes \"$(jq -r '.CompatibleRuntimes[0]' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n          --compatible-architectures \"$(jq  -r '.CompatibleArchitectures[0]' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n          --license-info \"MIT-0\" \\\n          --description \"$(jq -r '.Description' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n          --query 'Version' \\\n          --output text)\n\n        echo \"LAYER_VERSION=$LAYER_VERSION\" >> \"$GITHUB_OUTPUT\"\n\n        aws --region us-gov-east-1 lambda add-layer-version-permission \\\n          --layer-name '${{ matrix.layer }}-${{ matrix.arch }}' \\\n          --statement-id 'PublicLayer' \\\n          --action lambda:GetLayerVersion \\\n          --principal '*' \\\n          --version-number \"$LAYER_VERSION\"\n    - name: Verify Layer\n      env:\n        LAYER_VERSION: ${{ steps.create-layer.outputs.LAYER_VERSION }}\n      run: |\n        REMOTE_SHA=$(aws --region us-gov-east-1 lambda get-layer-version-by-arn --arn 'arn:aws-us-gov:lambda:us-gov-east-1:${{ secrets.AWS_ACCOUNT_ID }}:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ env.LAYER_VERSION }}' --query 'Content.CodeSha256' --output text)\n        SHA=$(jq -r '.Content.CodeSha256' '${{ matrix.layer }}_${{ matrix.arch }}.json')\n        test \"$REMOTE_SHA\" == \"$SHA\" && echo \"SHA OK: ${SHA}\" || exit 1\n        aws --region us-gov-east-1 lambda get-layer-version-by-arn --arn 'arn:aws-us-gov:lambda:us-gov-east-1:${{ secrets.AWS_ACCOUNT_ID }}:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ env.LAYER_VERSION }}' --output table\n\n  copy_west:\n    name: Copy (West)\n    needs: download\n    runs-on: ubuntu-latest\n    permissions:\n      id-token: write\n      contents: read\n    strategy:\n      matrix:\n        layer:\n        - AWSLambdaPowertoolsPythonV3-python39\n        - AWSLambdaPowertoolsPythonV3-python310\n        - AWSLambdaPowertoolsPythonV3-python311\n        - AWSLambdaPowertoolsPythonV3-python312\n        - AWSLambdaPowertoolsPythonV3-python313\n        arch:\n        - arm64\n        - x86_64\n    environment:\n      name: GovCloud ${{ inputs.environment }} (West)\n    steps:\n    - name: Download Zip\n      uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093   # v4.3.0\n      with:\n        name: ${{ matrix.layer }}_${{ matrix.arch }}.zip\n    - name: Download Metadata\n      uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093   # v4.3.0\n      with:\n        name: ${{ matrix.layer }}_${{ matrix.arch }}.json\n    - name: Verify Layer Signature\n      run: |\n        SHA=$(jq -r '.Content.CodeSha256' '${{ matrix.layer }}_${{ matrix.arch }}.json')\n        test \"$(openssl dgst -sha256 -binary ${{ matrix.layer }}_${{ matrix.arch }}.zip | openssl enc -base64)\" == \"$SHA\" && echo \"SHA OK: ${SHA}\" || exit 1\n    - name: Configure AWS Credentials\n      uses: \n        aws-actions/configure-aws-credentials@f24d7193d98baebaeacc7e2227925dd47cc267f5       # v4.2.0\n      with:\n        role-to-assume: ${{ secrets.AWS_IAM_ROLE }}\n        aws-region: us-gov-west-1\n        mask-aws-account-id: true\n    - name: Create Layer\n      id: create-layer\n      run: |\n        LAYER_VERSION=$(aws --region us-gov-west-1 lambda publish-layer-version \\\n          --layer-name ${{ matrix.layer }}-${{ matrix.arch }} \\\n          --zip-file fileb://./${{ matrix.layer }}_${{ matrix.arch }}.zip \\\n          --compatible-runtimes \"$(jq -r '.CompatibleRuntimes[0]' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n          --compatible-architectures \"$(jq  -r '.CompatibleArchitectures[0]' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n          --license-info \"MIT-0\" \\\n          --description \"$(jq -r '.Description' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n          --query 'Version' \\\n          --output text)\n\n        echo \"LAYER_VERSION=$LAYER_VERSION\" >> \"$GITHUB_OUTPUT\"\n\n        aws --region us-gov-west-1 lambda add-layer-version-permission \\\n          --layer-name '${{ matrix.layer }}-${{ matrix.arch }}' \\\n          --statement-id 'PublicLayer' \\\n          --action lambda:GetLayerVersion \\\n          --principal '*' \\\n          --version-number \"$LAYER_VERSION\"\n    - name: Verify Layer\n      env:\n        LAYER_VERSION: ${{ steps.create-layer.outputs.LAYER_VERSION }}\n      run: |\n        REMOTE_SHA=$(aws --region us-gov-west-1 lambda get-layer-version-by-arn --arn 'arn:aws-us-gov:lambda:us-gov-west-1:${{ secrets.AWS_ACCOUNT_ID }}:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ env.LAYER_VERSION }}' --query 'Content.CodeSha256' --output text)\n        SHA=$(jq -r '.Content.CodeSha256' '${{ matrix.layer }}_${{ matrix.arch }}.json')\n        test \"$REMOTE_SHA\" == \"$SHA\" && echo \"SHA OK: ${SHA}\" || exit 1\n        aws --region us-gov-west-1 lambda get-layer-version-by-arn --arn 'arn:aws-us-gov:lambda:us-gov-west-1:${{ secrets.AWS_ACCOUNT_ID }}:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ env.LAYER_VERSION }}' --output table\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Layer Deployment (GovCloud)` for a GitHub repository whose primary programming language is Python. The name for workflow runs is set to `Layer Deployment (GovCloud) - ${{ inputs.environment }}`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives 2 inputs: environment-this input represents deployment environment, the data type is choice, it has options including Gamma and Prod and it must be supplied; version-this input represents layer version to duplicate, the data type is string and it must be supplied. 2) this workflow is called by another workflow. This workflow receives 2 inputs: environment-this input represents deployment environment, the data type is string and it must be supplied; version-this input represents layer version to duplicate, the data type is string and it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 3 jobs. The job id of the 1st job is `download`. The 2nd job is named `Copy (East)` and its job id is `copy_east`. The 3rd job is named `Copy (West)` and its job id is `copy_west`. ","prompt_level2":"Generate a GitHub Workflow named `Layer Deployment (GovCloud)` for a GitHub repository whose primary programming language is Python. The name for workflow runs is set to `Layer Deployment (GovCloud) - ${{ inputs.environment }}`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives 2 inputs: environment-this input represents deployment environment, the data type is choice, it has options including Gamma and Prod and it must be supplied; version-this input represents layer version to duplicate, the data type is string and it must be supplied. 2) this workflow is called by another workflow. This workflow receives 2 inputs: environment-this input represents deployment environment, the data type is string and it must be supplied; version-this input represents layer version to duplicate, the data type is string and it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 3 jobs. The job id of the 1st job is `download`. The job `download` has 4 steps. The 1st step is named `Configure AWS Credentials`. The 2nd step is named `Grab Zip`. The 3rd step is named `Store Zip`. The 4th step is named `Store Metadata`. The 2nd job is named `Copy (East)` and its job id is `copy_east`. The job `copy_east` has 6 steps. The 1st step is named `Download Zip`. The 2nd step is named `Download Metadata`. The 3rd step is named `Verify Layer Signature`. The 4th step is named `Configure AWS Credentials`. The 5th step is named `Create Layer` and its id is `create-layer`. The 6th step is named `Verify Layer`. The 3rd job is named `Copy (West)` and its job id is `copy_west`. The job `copy_west` has 6 steps. The 1st step is named `Download Zip`. The 2nd step is named `Download Metadata`. The 3rd step is named `Verify Layer Signature`. The 4th step is named `Configure AWS Credentials`. The 5th step is named `Create Layer` and its id is `create-layer`. The 6th step is named `Verify Layer`. ","prompt_level3":"Generate a GitHub Workflow named `Layer Deployment (GovCloud)` for a GitHub repository whose primary programming language is Python. The name for workflow runs is set to `Layer Deployment (GovCloud) - ${{ inputs.environment }}`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives 2 inputs: environment-this input represents deployment environment, the data type is choice, it has options including Gamma and Prod and it must be supplied; version-this input represents layer version to duplicate, the data type is string and it must be supplied. 2) this workflow is called by another workflow. This workflow receives 2 inputs: environment-this input represents deployment environment, the data type is string and it must be supplied; version-this input represents layer version to duplicate, the data type is string and it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 3 jobs. The job id of the 1st job is `download`. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `layer` has 5 values: AWSLambdaPowertoolsPythonV3-python39, AWSLambdaPowertoolsPythonV3-python310, AWSLambdaPowertoolsPythonV3-python311, AWSLambdaPowertoolsPythonV3-python312 and AWSLambdaPowertoolsPythonV3-python313. The variable `arch` has 2 values: arm64 and x86_64. The job `download` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `id-token` scope and read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting only applies to the job `download`. This job references Prod (Readonly) environment. The job `download` has 4 steps. The 1st step is named `Configure AWS Credentials`. This step runs action `aws-actions/configure-aws-credentials` whose commit is f24d7193d98baebaeacc7e2227925dd47cc267f5. The step defines 3 input parameters for the action: `role-to-assume` is set to `${{ secrets.AWS_IAM_ROLE }}`, `aws-region` is set to `us-east-1` and `mask-aws-account-id` is set to `True`. The 2nd step is named `Grab Zip`. This step runs a script: `aws --region us-east-1 lambda get-layer-version-by-arn --arn arn:aws:lambda:us-east-1:017000801446:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ inputs.version }} --query 'Content.Location' | xargs curl -L -o ${{ matrix.layer }}_${{ matrix.arch }}.zip\naws --region us-east-1 lambda get-layer-version-by-arn --arn arn:aws:lambda:us-east-1:017000801446:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ inputs.version }} > ${{ matrix.layer }}_${{ matrix.arch }}.json\n`. The 3rd step is named `Store Zip`. This step runs action `actions/upload-artifact` whose commit is ea165f8d65b6e75b540449e92b4886f43607fa02. The step defines 4 input parameters for the action: `name` is set to `${{ matrix.layer }}_${{ matrix.arch }}.zip`, `path` is set to `${{ matrix.layer }}_${{ matrix.arch }}.zip`, `retention-days` is set to `1` and `if-no-files-found` is set to `error`. The 4th step is named `Store Metadata`. This step runs action `actions/upload-artifact` whose commit is ea165f8d65b6e75b540449e92b4886f43607fa02. The step defines 4 input parameters for the action: `name` is set to `${{ matrix.layer }}_${{ matrix.arch }}.json`, `path` is set to `${{ matrix.layer }}_${{ matrix.arch }}.json`, `retention-days` is set to `1` and `if-no-files-found` is set to `error`. The 2nd job is named `Copy (East)` and its job id is `copy_east`. Before this job runs, `download` must complete successfully. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `layer` has 5 values: AWSLambdaPowertoolsPythonV3-python39, AWSLambdaPowertoolsPythonV3-python310, AWSLambdaPowertoolsPythonV3-python311, AWSLambdaPowertoolsPythonV3-python312 and AWSLambdaPowertoolsPythonV3-python313. The variable `arch` has 2 values: arm64 and x86_64. The job `copy_east` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `id-token` scope and read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting only applies to the job `copy_east`. This job references GovCloud ${{ inputs.environment }} (East) environment. The job `copy_east` has 6 steps. The 1st step is named `Download Zip`. This step runs action `actions/download-artifact` whose commit is d3f86a106a0bac45b974a628896c90dbdf5c8093. The step defines an input parameter for the action: `name` is set to `${{ matrix.layer }}_${{ matrix.arch }}.zip`. The 2nd step is named `Download Metadata`. This step runs action `actions/download-artifact` whose commit is d3f86a106a0bac45b974a628896c90dbdf5c8093. The step defines an input parameter for the action: `name` is set to `${{ matrix.layer }}_${{ matrix.arch }}.json`. The 3rd step is named `Verify Layer Signature`. This step runs a script: `SHA=$(jq -r '.Content.CodeSha256' '${{ matrix.layer }}_${{ matrix.arch }}.json')\ntest \"$(openssl dgst -sha256 -binary ${{ matrix.layer }}_${{ matrix.arch }}.zip | openssl enc -base64)\" == \"$SHA\" && echo \"SHA OK: ${SHA}\" || exit 1\n`. The 4th step is named `Configure AWS Credentials`. This step runs action `aws-actions/configure-aws-credentials` whose commit is f24d7193d98baebaeacc7e2227925dd47cc267f5. The step defines 3 input parameters for the action: `role-to-assume` is set to `${{ secrets.AWS_IAM_ROLE }}`, `aws-region` is set to `us-gov-east-1` and `mask-aws-account-id` is set to `True`. The 5th step is named `Create Layer` and its id is `create-layer`. This step runs a script: `LAYER_VERSION=$(aws --region us-gov-east-1 lambda publish-layer-version \\\n  --layer-name ${{ matrix.layer }}-${{ matrix.arch }} \\\n  --zip-file fileb://./${{ matrix.layer }}_${{ matrix.arch }}.zip \\\n  --compatible-runtimes \"$(jq -r '.CompatibleRuntimes[0]' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n  --compatible-architectures \"$(jq  -r '.CompatibleArchitectures[0]' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n  --license-info \"MIT-0\" \\\n  --description \"$(jq -r '.Description' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n  --query 'Version' \\\n  --output text)\n\necho \"LAYER_VERSION=$LAYER_VERSION\" >> \"$GITHUB_OUTPUT\"\n\naws --region us-gov-east-1 lambda add-layer-version-permission \\\n  --layer-name '${{ matrix.layer }}-${{ matrix.arch }}' \\\n  --statement-id 'PublicLayer' \\\n  --action lambda:GetLayerVersion \\\n  --principal '*' \\\n  --version-number \"$LAYER_VERSION\"\n`. The 6th step is named `Verify Layer`. The step sets an environment variable to use: `LAYER_VERSION` is set to `${{ steps.create-layer.outputs.LAYER_VERSION }}`. This step runs a script: `REMOTE_SHA=$(aws --region us-gov-east-1 lambda get-layer-version-by-arn --arn 'arn:aws-us-gov:lambda:us-gov-east-1:${{ secrets.AWS_ACCOUNT_ID }}:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ env.LAYER_VERSION }}' --query 'Content.CodeSha256' --output text)\nSHA=$(jq -r '.Content.CodeSha256' '${{ matrix.layer }}_${{ matrix.arch }}.json')\ntest \"$REMOTE_SHA\" == \"$SHA\" && echo \"SHA OK: ${SHA}\" || exit 1\naws --region us-gov-east-1 lambda get-layer-version-by-arn --arn 'arn:aws-us-gov:lambda:us-gov-east-1:${{ secrets.AWS_ACCOUNT_ID }}:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ env.LAYER_VERSION }}' --output table\n`. The 3rd job is named `Copy (West)` and its job id is `copy_west`. Before this job runs, `download` must complete successfully. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `layer` has 5 values: AWSLambdaPowertoolsPythonV3-python39, AWSLambdaPowertoolsPythonV3-python310, AWSLambdaPowertoolsPythonV3-python311, AWSLambdaPowertoolsPythonV3-python312 and AWSLambdaPowertoolsPythonV3-python313. The variable `arch` has 2 values: arm64 and x86_64. The job `copy_west` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `id-token` scope and read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting only applies to the job `copy_west`. This job references GovCloud ${{ inputs.environment }} (West) environment. The job `copy_west` has 6 steps. The 1st step is named `Download Zip`. This step runs action `actions/download-artifact` whose commit is d3f86a106a0bac45b974a628896c90dbdf5c8093. The step defines an input parameter for the action: `name` is set to `${{ matrix.layer }}_${{ matrix.arch }}.zip`. The 2nd step is named `Download Metadata`. This step runs action `actions/download-artifact` whose commit is d3f86a106a0bac45b974a628896c90dbdf5c8093. The step defines an input parameter for the action: `name` is set to `${{ matrix.layer }}_${{ matrix.arch }}.json`. The 3rd step is named `Verify Layer Signature`. This step runs a script: `SHA=$(jq -r '.Content.CodeSha256' '${{ matrix.layer }}_${{ matrix.arch }}.json')\ntest \"$(openssl dgst -sha256 -binary ${{ matrix.layer }}_${{ matrix.arch }}.zip | openssl enc -base64)\" == \"$SHA\" && echo \"SHA OK: ${SHA}\" || exit 1\n`. The 4th step is named `Configure AWS Credentials`. This step runs action `aws-actions/configure-aws-credentials` whose commit is f24d7193d98baebaeacc7e2227925dd47cc267f5. The step defines 3 input parameters for the action: `role-to-assume` is set to `${{ secrets.AWS_IAM_ROLE }}`, `aws-region` is set to `us-gov-west-1` and `mask-aws-account-id` is set to `True`. The 5th step is named `Create Layer` and its id is `create-layer`. This step runs a script: `LAYER_VERSION=$(aws --region us-gov-west-1 lambda publish-layer-version \\\n  --layer-name ${{ matrix.layer }}-${{ matrix.arch }} \\\n  --zip-file fileb://./${{ matrix.layer }}_${{ matrix.arch }}.zip \\\n  --compatible-runtimes \"$(jq -r '.CompatibleRuntimes[0]' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n  --compatible-architectures \"$(jq  -r '.CompatibleArchitectures[0]' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n  --license-info \"MIT-0\" \\\n  --description \"$(jq -r '.Description' '${{ matrix.layer }}_${{ matrix.arch }}.json')\" \\\n  --query 'Version' \\\n  --output text)\n\necho \"LAYER_VERSION=$LAYER_VERSION\" >> \"$GITHUB_OUTPUT\"\n\naws --region us-gov-west-1 lambda add-layer-version-permission \\\n  --layer-name '${{ matrix.layer }}-${{ matrix.arch }}' \\\n  --statement-id 'PublicLayer' \\\n  --action lambda:GetLayerVersion \\\n  --principal '*' \\\n  --version-number \"$LAYER_VERSION\"\n`. The 6th step is named `Verify Layer`. The step sets an environment variable to use: `LAYER_VERSION` is set to `${{ steps.create-layer.outputs.LAYER_VERSION }}`. This step runs a script: `REMOTE_SHA=$(aws --region us-gov-west-1 lambda get-layer-version-by-arn --arn 'arn:aws-us-gov:lambda:us-gov-west-1:${{ secrets.AWS_ACCOUNT_ID }}:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ env.LAYER_VERSION }}' --query 'Content.CodeSha256' --output text)\nSHA=$(jq -r '.Content.CodeSha256' '${{ matrix.layer }}_${{ matrix.arch }}.json')\ntest \"$REMOTE_SHA\" == \"$SHA\" && echo \"SHA OK: ${SHA}\" || exit 1\naws --region us-gov-west-1 lambda get-layer-version-by-arn --arn 'arn:aws-us-gov:lambda:us-gov-west-1:${{ secrets.AWS_ACCOUNT_ID }}:layer:${{ matrix.layer }}-${{ matrix.arch }}:${{ env.LAYER_VERSION }}' --output table\n`. ","nb_triggers":2,"triggers":["workflow_call","workflow_dispatch"],"nb_jobs":3,"nb_actions":9,"actions":["actions/download-artifact","actions/download-artifact","actions/download-artifact","actions/download-artifact","actions/upload-artifact","actions/upload-artifact","aws-actions/configure-aws-credentials","aws-actions/configure-aws-credentials","aws-actions/configure-aws-credentials"],"actions_details":[{"version":"f24d7193d98baebaeacc7e2227925dd47cc267f5","name":"aws-actions/configure-aws-credentials"},{"version":"ea165f8d65b6e75b540449e92b4886f43607fa02","name":"actions/upload-artifact"},{"version":"ea165f8d65b6e75b540449e92b4886f43607fa02","name":"actions/upload-artifact"},{"version":"d3f86a106a0bac45b974a628896c90dbdf5c8093","name":"actions/download-artifact"},{"version":"d3f86a106a0bac45b974a628896c90dbdf5c8093","name":"actions/download-artifact"},{"version":"f24d7193d98baebaeacc7e2227925dd47cc267f5","name":"aws-actions/configure-aws-credentials"},{"version":"d3f86a106a0bac45b974a628896c90dbdf5c8093","name":"actions/download-artifact"},{"version":"d3f86a106a0bac45b974a628896c90dbdf5c8093","name":"actions/download-artifact"},{"version":"f24d7193d98baebaeacc7e2227925dd47cc267f5","name":"aws-actions/configure-aws-credentials"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":16,"cyclomatic_complexity":2}
{"id":60050,"repository_id":3275848,"mainLanguage":"Java","file_name":"docs-cleanup.yml","file_content":"name: docs-cleanup\n\non:\n  pull_request_target:\n    types:\n      - closed\n\njobs:\n  docs-preview:\n    uses: elastic/docs-builder/.github/workflows/preview-cleanup.yml@main\n    permissions:\n      contents: none\n      id-token: write\n      deployments: write\n","repository_owner":"elastic","repository_name":"apm-agent-java","tokens_count":63,"workflow":"name: docs-cleanup\n\non:\n  pull_request_target:\n    types:\n    - closed\n\njobs:\n  docs-preview:\n    uses: elastic/docs-builder/.github/workflows/preview-cleanup.yml@main\n    permissions:\n      contents: none\n      id-token: write\n      deployments: write\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `docs-cleanup` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by an event: a pull request is closed. The workflow has one job. The job id of the 1st job is `docs-preview`. ","prompt_level2":"Generate a GitHub Workflow named `docs-cleanup` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by an event: a pull request is closed. The workflow has one job. The job id of the 1st job is `docs-preview`. ","prompt_level3":"Generate a GitHub Workflow named `docs-cleanup` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by an event: a pull request is closed. The workflow has one job. The job id of the 1st job is `docs-preview`. The job `docs-preview` modifies the default permissions for the GITHUB_TOKEN: none access is granted to the GITHUB_TOKEN in the `contents` scope, write access is granted to the GITHUB_TOKEN in the `id-token` scope and write access is granted to the GITHUB_TOKEN in the `deployments` scope. This permission setting only applies to the job `docs-preview`. This job will call a reusable workflow located at `elastic/docs-builder/.github/workflows/preview-cleanup.yml@main`. ","nb_triggers":1,"triggers":["pull_request_target"],"nb_jobs":1,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["elastic/docs-builder/.github/workflows/preview-cleanup.yml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":52114,"repository_id":69698058,"mainLanguage":"JavaScript","file_name":"type-check.yml","file_content":"name: \"Types: check published types\"\n\non: [pull_request, push]\n\npermissions:\n  contents: read\n\njobs:\n  test:\n    name: TS ${{ matrix.ts_version }}, \"${{ matrix.ts_lib }}\"\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ts_version:\n          # The official ESLint types are not compatible with TS 3.9\n          # - 3.9\n          - '4.0'\n          - 4.1\n          - 4.2\n          - 4.3\n          - 4.4\n          - 4.5\n          - '5.0'\n          - 5.5\n          - 5.6\n        ts_lib:\n          - es2015\n          - es2015,dom\n          - es2020\n          - esnext\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          persist-credentials: false\n          show-progress: false\n\n      - uses: ljharb/actions/node/install@main\n        name: 'nvm install lts/* && npm install'\n        with:\n          node-version: 'lts/*'\n          skip-ls-check: true\n\n      - name: build types\n        run: npm run build-types\n\n      # Pack the lib into a tarball so that when we install the lib later in the\n      # test-published-types directory, it's only install `dependencies` of the\n      # lib.\n      - name: pack the lib\n        run: npm pack --pack-destination /tmp/\n\n      - name: find the packed lib\n        run: echo \"ESLINT_PLUGIN_REACT_PATH=$(ls /tmp/eslint-plugin-react*.tgz | tail -n 1)\" >> $GITHUB_ENV\n\n      - name: show the path to the packed lib\n        run: echo \"$ESLINT_PLUGIN_REACT_PATH\"\n\n      - name: npm install working directory\n        run: npm install\n        working-directory: test-published-types\n\n      - name: install eslint-plugin-react and typescript version ${{ matrix.ts_version }}\n        run: npm install --no-save \"$ESLINT_PLUGIN_REACT_PATH\" typescript@${{ matrix.ts_version }}\n        working-directory: test-published-types\n\n      - name: show installed typescript version\n        run: npm list typescript --depth=0\n        working-directory: test-published-types\n\n      - name: show installed eslint-plugin-react version\n        run: npm list eslint-plugin-react --depth=0\n        working-directory: test-published-types\n\n      - name: check types with lib \"${{ matrix.ts_lib }}\"\n        run: npx tsc --lib ${{ matrix.ts_lib }}\n        working-directory: test-published-types\n","repository_owner":"jsx-eslint","repository_name":"eslint-plugin-react","tokens_count":596,"workflow":"name: 'Types: check published types'\n\non: [pull_request, push]\n\npermissions:\n  contents: read\n\njobs:\n  test:\n    name: TS ${{ matrix.ts_version }}, \"${{ matrix.ts_lib }}\"\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ts_version:\n          # The official ESLint types are not compatible with TS 3.9\n          # - 3.9\n        - '4.0'\n        - 4.1\n        - 4.2\n        - 4.3\n        - 4.4\n        - 4.5\n        - '5.0'\n        - 5.5\n        - 5.6\n        ts_lib:\n        - es2015\n        - es2015,dom\n        - es2020\n        - esnext\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      with:\n        persist-credentials: false\n        show-progress: false\n\n    - uses: ljharb/actions/node/install@main\n      name: nvm install lts/* && npm install\n      with:\n        node-version: lts/*\n        skip-ls-check: true\n\n    - name: build types\n      run: npm run build-types\n\n      # Pack the lib into a tarball so that when we install the lib later in the\n      # test-published-types directory, it's only install `dependencies` of the\n      # lib.\n    - name: pack the lib\n      run: npm pack --pack-destination /tmp/\n\n    - name: find the packed lib\n      run: echo \"ESLINT_PLUGIN_REACT_PATH=$(ls /tmp/eslint-plugin-react*.tgz | \n        tail -n 1)\" >> $GITHUB_ENV\n\n    - name: show the path to the packed lib\n      run: echo \"$ESLINT_PLUGIN_REACT_PATH\"\n\n    - name: npm install working directory\n      run: npm install\n      working-directory: test-published-types\n\n    - name: install eslint-plugin-react and typescript version ${{ \n        matrix.ts_version }}\n      run: npm install --no-save \"$ESLINT_PLUGIN_REACT_PATH\" typescript@${{ \n        matrix.ts_version }}\n      working-directory: test-published-types\n\n    - name: show installed typescript version\n      run: npm list typescript --depth=0\n      working-directory: test-published-types\n\n    - name: show installed eslint-plugin-react version\n      run: npm list eslint-plugin-react --depth=0\n      working-directory: test-published-types\n\n    - name: check types with lib \"${{ matrix.ts_lib }}\"\n      run: npx tsc --lib ${{ matrix.ts_lib }}\n      working-directory: test-published-types\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Types: check published types` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) there is activity relating to a pull request. 2) a commit or tag is pushed, or a repository is cloned. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `TS ${{ matrix.ts_version }}, \"${{ matrix.ts_lib }}\"` and its job id is `test`. ","prompt_level2":"Generate a GitHub Workflow named `Types: check published types` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) there is activity relating to a pull request. 2) a commit or tag is pushed, or a repository is cloned. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `TS ${{ matrix.ts_version }}, \"${{ matrix.ts_lib }}\"` and its job id is `test`. The job `test` has 11 steps. The 1st step is named `Checkout repository`. The 2nd step is named `nvm install lts/* && npm install`. The 3rd step is named `build types`. The 4th step is named `pack the lib`. The 5th step is named `find the packed lib`. The 6th step is named `show the path to the packed lib`. The 7th step is named `npm install working directory`. The 8th step is named `install eslint-plugin-react and typescript version ${{ matrix.ts_version }}`. The 9th step is named `show installed typescript version`. The 10th step is named `show installed eslint-plugin-react version`. The 11th step is named `check types with lib \"${{ matrix.ts_lib }}\"`. ","prompt_level3":"Generate a GitHub Workflow named `Types: check published types` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) there is activity relating to a pull request. 2) a commit or tag is pushed, or a repository is cloned. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `TS ${{ matrix.ts_version }}, \"${{ matrix.ts_lib }}\"` and its job id is `test`. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `ts_version` has 9 values: 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 5.0, 5.5 and 5.6. The variable `ts_lib` has 4 values: es2015, es2015,dom, es2020 and esnext. The job `test` has 11 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines 2 input parameters for the action: `persist-credentials` is set to `False` and `show-progress` is set to `False`. The 2nd step is named `nvm install lts/* && npm install`. This step runs action `ljharb/actions/node/install` from the main branch. The step defines 2 input parameters for the action: `node-version` is set to `lts/*` and `skip-ls-check` is set to `True`. The 3rd step is named `build types`. This step runs a script: `npm run build-types`. The 4th step is named `pack the lib`. This step runs a script: `npm pack --pack-destination /tmp/`. The 5th step is named `find the packed lib`. This step runs a script: `echo \"ESLINT_PLUGIN_REACT_PATH=$(ls /tmp/eslint-plugin-react*.tgz | tail -n 1)\" >> $GITHUB_ENV`. The 6th step is named `show the path to the packed lib`. This step runs a script: `echo \"$ESLINT_PLUGIN_REACT_PATH\"`. The 7th step is named `npm install working directory`. This step runs a script: `npm install`. The 8th step is named `install eslint-plugin-react and typescript version ${{ matrix.ts_version }}`. This step runs a script: `npm install --no-save \"$ESLINT_PLUGIN_REACT_PATH\" typescript@${{ matrix.ts_version }}`. The 9th step is named `show installed typescript version`. This step runs a script: `npm list typescript --depth=0`. The 10th step is named `show installed eslint-plugin-react version`. This step runs a script: `npm list eslint-plugin-react --depth=0`. The 11th step is named `check types with lib \"${{ matrix.ts_lib }}\"`. This step runs a script: `npx tsc --lib ${{ matrix.ts_lib }}`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","ljharb/actions/node/install"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"main","name":"ljharb/actions/node/install"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":11,"cyclomatic_complexity":1}
{"id":15826,"repository_id":95155853,"mainLanguage":"Dart","file_name":"flutter_blue_plus_android.yml","file_content":"name: Publish Flutter Blue Plus Android\non:\n  push:\n    tags:\n      - 'flutter_blue_plus_android-[0-9]+.[0-9]+.[0-9]+'\njobs:\n  publish:\n    permissions:\n      id-token: write\n    uses: dart-lang/setup-dart/.github/workflows/publish.yml@v1\n    with:\n      working-directory: packages/flutter_blue_plus_android\n","repository_owner":"chipweinberger","repository_name":"flutter_blue_plus","tokens_count":85,"workflow":"name: Publish Flutter Blue Plus Android\non:\n  push:\n    tags:\n    - flutter_blue_plus_android-[0-9]+.[0-9]+.[0-9]+\njobs:\n  publish:\n    permissions:\n      id-token: write\n    uses: dart-lang/setup-dart/.github/workflows/publish.yml@v1\n    with:\n      working-directory: packages/flutter_blue_plus_android\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Publish Flutter Blue Plus Android` for a GitHub repository whose primary programming language is Dart. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a tag whose name matches flutter_blue_plus_android-[0-9]+.[0-9]+.[0-9]+. The workflow has one job. The job id of the 1st job is `publish`. ","prompt_level2":"Generate a GitHub Workflow named `Publish Flutter Blue Plus Android` for a GitHub repository whose primary programming language is Dart. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a tag whose name matches flutter_blue_plus_android-[0-9]+.[0-9]+.[0-9]+. The workflow has one job. The job id of the 1st job is `publish`. ","prompt_level3":"Generate a GitHub Workflow named `Publish Flutter Blue Plus Android` for a GitHub repository whose primary programming language is Dart. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a tag whose name matches flutter_blue_plus_android-[0-9]+.[0-9]+.[0-9]+. The workflow has one job. The job id of the 1st job is `publish`. The job `publish` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting only applies to the job `publish`. This job will call a reusable workflow located at `dart-lang/setup-dart/.github/workflows/publish.yml@v1`. The job will pass an input to the called workflow: the input `working-directory` is `packages/flutter_blue_plus_android`. ","nb_triggers":1,"triggers":["push"],"nb_jobs":1,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["dart-lang/setup-dart/.github/workflows/publish.yml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":4785,"repository_id":3983520,"mainLanguage":"Python","file_name":"test_with_free_threaded_python.yml","file_content":"---\n# Runs tests suite with free threaded python.\n#\n###\nname: test free threaded python\n\non:\n    schedule:\n    # Run every 1rst of the month\n    -   cron: 0 8 1 * *\n\n    # Allows you to run this workflow manually from the Actions tab\n    workflow_dispatch:\n\nconcurrency:\n    group: ${{ github.workflow }}-${{ github.ref }}\n    cancel-in-progress: true\n\n# Force to use color\nenv:\n    FORCE_COLOR: true\n\njobs:\n\n    test_and_coverage:\n        if: github.repository == 'nilearn/nilearn'\n        name: 'Test with ${{ matrix.py }} on ${{ matrix.os }}: ${{ matrix.description }}'\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                description: [latest dependencies]\n                py: [3.13t]\n                os: [ubuntu-latest, macos-latest, windows-latest]\n                env: [plotting]\n        steps:\n        -   uses: actions/checkout@v4\n        -   name: Install the latest version of uv\n            uses: astral-sh/setup-uv@v6\n        -   name: Setup python\n            uses: actions/setup-python@v5\n            with:\n                python-version: ${{ matrix.py }}\n                allow-prereleases: true\n        -   name: Install tox\n            run: uv tool install tox --with=tox-uv --with=tox-gh-actions\n        -   name: Show tox config\n            run: tox c\n        -   name: Run test suite\n            run: |\n                tox run --list-dependencies -e ${{ matrix.env }} -- nilearn\n                tox run -e plot_test_timing\n        -   name: Upload test report\n            if: success() || failure()\n            uses: actions/upload-artifact@v4\n            with:\n                name: ${{ matrix.os }}_${{ matrix.py }}_${{ matrix.description }}_report.html\n                path: report.html\n        -   name: Upload test timings\n            if: success() || failure()\n            uses: actions/upload-artifact@v4\n            with:\n                name: ${{ matrix.os }}_${{ matrix.py }}_${{ matrix.description }}_pytest_output\n                path: results/pytest_output\n","repository_owner":"nilearn","repository_name":"nilearn","tokens_count":495,"workflow":"# Runs tests suite with free threaded python.\n#\n###\nname: test free threaded python\n\non:\n  schedule:\n    # Run every 1rst of the month\n  - cron: 0 8 1 * *\n\n    # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\n# Force to use color\nenv:\n  FORCE_COLOR: true\n\njobs:\n\n  test_and_coverage:\n    if: github.repository == 'nilearn/nilearn'\n    name: 'Test with ${{ matrix.py }} on ${{ matrix.os }}: ${{ matrix.description\n      }}'\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: true\n      matrix:\n        description: [latest dependencies]\n        py: [3.13t]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        env: [plotting]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n    - name: Install the latest version of uv\n      uses: astral-sh/setup-uv@v6\n    - name: Setup python\n      uses: actions/setup-python@v5\n      with:\n        python-version: ${{ matrix.py }}\n        allow-prereleases: true\n    - name: Install tox\n      run: uv tool install tox --with=tox-uv --with=tox-gh-actions\n    - name: Show tox config\n      run: tox c\n    - name: Run test suite\n      run: |\n        tox run --list-dependencies -e ${{ matrix.env }} -- nilearn\n        tox run -e plot_test_timing\n    - name: Upload test report\n      if: success() || failure()\n      uses: actions/upload-artifact@v4\n      with:\n        name: ${{ matrix.os }}_${{ matrix.py }}_${{ matrix.description \n          }}_report.html\n        path: report.html\n    - name: Upload test timings\n      if: success() || failure()\n      uses: actions/upload-artifact@v4\n      with:\n        name: ${{ matrix.os }}_${{ matrix.py }}_${{ matrix.description \n          }}_pytest_output\n        path: results/pytest_output\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `test free threaded python` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 08:00 am, on day 1 of the month. 2) someone manually triggers the workflow. The workflow sets an environment variable to use: `FORCE_COLOR` is set to `True`. Only a single workflow using the ${{ github.workflow }}-${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The 1st job is named `Test with ${{ matrix.py }} on ${{ matrix.os }}: ${{ matrix.description }}` and its job id is `test_and_coverage`. ","prompt_level2":"Generate a GitHub Workflow named `test free threaded python` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 08:00 am, on day 1 of the month. 2) someone manually triggers the workflow. The workflow sets an environment variable to use: `FORCE_COLOR` is set to `True`. Only a single workflow using the ${{ github.workflow }}-${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The 1st job is named `Test with ${{ matrix.py }} on ${{ matrix.os }}: ${{ matrix.description }}` and its job id is `test_and_coverage`. The job `test_and_coverage` has 8 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Install the latest version of uv`. The 3rd step is named `Setup python`. The 4th step is named `Install tox`. The 5th step is named `Show tox config`. The 6th step is named `Run test suite`. The 7th step is named `Upload test report`. The 8th step is named `Upload test timings`. ","prompt_level3":"Generate a GitHub Workflow named `test free threaded python` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 08:00 am, on day 1 of the month. 2) someone manually triggers the workflow. The workflow sets an environment variable to use: `FORCE_COLOR` is set to `True`. Only a single workflow using the ${{ github.workflow }}-${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The 1st job is named `Test with ${{ matrix.py }} on ${{ matrix.os }}: ${{ matrix.description }}` and its job id is `test_and_coverage`. This job will run only if the condition(github.repository == 'nilearn/nilearn') is met. This job will run on ${{ matrix.os }} runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `description` has one value: latest dependencies. The variable `py` has one value: 3.13t. The variable `os` has 3 values: ubuntu-latest, macos-latest and windows-latest. The variable `env` has one value: plotting. If any job run in the matrix fails, all in-progress and queued jobs in the matrix will be canceled. The job `test_and_coverage` has 8 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Install the latest version of uv`. This step runs action `astral-sh/setup-uv` tagged as v6. The 3rd step is named `Setup python`. This step runs action `actions/setup-python` tagged as v5. The step defines 2 input parameters for the action: `python-version` is set to `${{ matrix.py }}` and `allow-prereleases` is set to `True`. The 4th step is named `Install tox`. This step runs a script: `uv tool install tox --with=tox-uv --with=tox-gh-actions`. The 5th step is named `Show tox config`. This step runs a script: `tox c`. The 6th step is named `Run test suite`. This step runs a script: `tox run --list-dependencies -e ${{ matrix.env }} -- nilearn\ntox run -e plot_test_timing\n`. The 7th step is named `Upload test report`. This step will run only if the condition(success() || failure()) is met. This step runs action `actions/upload-artifact` tagged as v4. The step defines 2 input parameters for the action: `name` is set to `${{ matrix.os }}_${{ matrix.py }}_${{ matrix.description }}_report.html` and `path` is set to `report.html`. The 8th step is named `Upload test timings`. This step will run only if the condition(success() || failure()) is met. This step runs action `actions/upload-artifact` tagged as v4. The step defines 2 input parameters for the action: `name` is set to `${{ matrix.os }}_${{ matrix.py }}_${{ matrix.description }}_pytest_output` and `path` is set to `results/pytest_output`. ","nb_triggers":2,"triggers":["schedule","workflow_dispatch"],"nb_jobs":1,"nb_actions":5,"actions":["actions/checkout","actions/setup-python","actions/upload-artifact","actions/upload-artifact","astral-sh/setup-uv"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v6","name":"astral-sh/setup-uv"},{"version":"v5","name":"actions/setup-python"},{"version":"v4","name":"actions/upload-artifact"},{"version":"v4","name":"actions/upload-artifact"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":8,"cyclomatic_complexity":1}
{"id":29922,"repository_id":48444973,"mainLanguage":"Shell","file_name":"test_application.yml","file_content":"name: Test AnonSurf Installation on kali-rolling\n\non:\n  pull_request: # Trigger on all pull requests\n    branches:\n      - '**' # All branches for pull requests\n  push: # Trigger on pushes to specific branches\n    branches:\n      - master # Only on merges to master\n\njobs:\n  test-script:\n    runs-on: ubuntu-latest\n    container:\n      image: kalilinux/kali-rolling:latest  # Use a Kali Linux environment\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    - name: Install dependencies\n      run: |\n        export DEBIAN_FRONTEND=noninteractive\n        apt-get update\n        apt-get install -y ca-certificates curl bleachbit tor iptables\n\n    - name: Run Installer Script\n      run: |\n        chmod +x installer.sh\n        ./installer.sh\n\n    - name: Verify Installation\n      run: |\n        which anonsurf || { echo \"ERROR: anonsurf is not installed.\"; exit 1; }\n\n# We can't test anonsurf in a runner due to the way the runner is configured, but at least this tests the build and install in kali-rolling\n","repository_owner":"und3rf10w","repository_name":"kali-anonsurf","tokens_count":257,"workflow":"name: Test AnonSurf Installation on kali-rolling\n\non:\n  pull_request: # Trigger on all pull requests\n    branches:\n    - '**'   # All branches for pull requests\n  push: # Trigger on pushes to specific branches\n    branches:\n    - master   # Only on merges to master\n\njobs:\n  test-script:\n    runs-on: ubuntu-latest\n    container:\n      image: kalilinux/kali-rolling:latest  # Use a Kali Linux environment\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    - name: Install dependencies\n      run: |\n        export DEBIAN_FRONTEND=noninteractive\n        apt-get update\n        apt-get install -y ca-certificates curl bleachbit tor iptables\n\n    - name: Run Installer Script\n      run: |\n        chmod +x installer.sh\n        ./installer.sh\n\n    - name: Verify Installation\n      run: |\n        which anonsurf || { echo \"ERROR: anonsurf is not installed.\"; exit 1; }\n\n# We can't test anonsurf in a runner due to the way the runner is configured, but at least this tests the build and install in kali-rolling\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Test AnonSurf Installation on kali-rolling` for a GitHub repository whose primary programming language is Shell. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a pull_request event targeting: a branch whose name matches **. 2) The workflow would run whenever there is a push event to: a branch named master. The workflow has one job. The job id of the 1st job is `test-script`. ","prompt_level2":"Generate a GitHub Workflow named `Test AnonSurf Installation on kali-rolling` for a GitHub repository whose primary programming language is Shell. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a pull_request event targeting: a branch whose name matches **. 2) The workflow would run whenever there is a push event to: a branch named master. The workflow has one job. The job id of the 1st job is `test-script`. The job `test-script` has 4 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Install dependencies`. The 3rd step is named `Run Installer Script`. The 4th step is named `Verify Installation`. ","prompt_level3":"Generate a GitHub Workflow named `Test AnonSurf Installation on kali-rolling` for a GitHub repository whose primary programming language is Shell. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a pull_request event targeting: a branch whose name matches **. 2) The workflow would run whenever there is a push event to: a branch named master. The workflow has one job. The job id of the 1st job is `test-script`. This job will run on ubuntu-latest runner. The job creates a Docker container that uses `kalilinux/kali-rolling:latest` image. The job `test-script` has 4 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v2. The 2nd step is named `Install dependencies`. This step runs a script: `export DEBIAN_FRONTEND=noninteractive\napt-get update\napt-get install -y ca-certificates curl bleachbit tor iptables\n`. The 3rd step is named `Run Installer Script`. This step runs a script: `chmod +x installer.sh\n./installer.sh\n`. The 4th step is named `Verify Installation`. This step runs a script: `which anonsurf || { echo \"ERROR: anonsurf is not installed.\"; exit 1; }\n`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":1,"nb_actions":1,"actions":["actions/checkout"],"actions_details":[{"version":"v2","name":"actions/checkout"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":4,"cyclomatic_complexity":1}
{"id":29396,"repository_id":329629,"mainLanguage":"Java","file_name":"issue-labeler.yml","file_content":"name: Issue Form Labeler\non:\n  issues:\n    types: [ opened ]\n\njobs:\n  label-issues:\n    runs-on: ubuntu-latest\n    permissions:\n      issues: write\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Parse bug report form\n        id: bug-parser\n        uses: stefanbuck/github-issue-parser@v3\n        with:\n          template-path: .github/ISSUE_TEMPLATE/bug-report.yml\n        continue-on-error: true\n\n      - name: Parse feature proposal form\n        id: feature-parser\n        uses: stefanbuck/github-issue-parser@v3\n        with:\n          template-path: .github/ISSUE_TEMPLATE/feature_proposal.yml\n        continue-on-error: true\n\n      - name: Apply labels from bug report\n        uses: redhat-plumbers-in-action/advanced-issue-labeler@v3\n        with:\n          issue-form: ${{ steps.bug-parser.outputs.jsonString }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          config-path: .github/issue-labeler-config.yml\n        continue-on-error: true\n\n      - name: Apply labels from feature proposal\n        uses: redhat-plumbers-in-action/advanced-issue-labeler@v3\n        with:\n          issue-form: ${{ steps.feature-parser.outputs.jsonString }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          config-path: .github/issue-labeler-config.yml\n        continue-on-error: true\n\n      - name: Clean up labeled sections\n        uses: actions/github-script@v6\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          script: |\n            const issueNumber = context.issue.number;\n            const originalBody = context.payload.issue.body;\n            const owner = context.repo.owner;\n            const repo = context.repo.repo;\n\n            const headingsToRemove = [\n              '### What version of Selenium are you currently using?',\n              '### The following statements are true',\n              '### Did this work for you before?',\n              '### If yes, what version of Selenium did it work with?',\n              '### Operating System',\n              '### Selenium Language Binding',\n              '### Which browsers are you experiencing the issue with?',\n              '### Are you using Selenium Grid?',\n              '### Does this apply to specific language bindings?',\n              '### What part(s) of Selenium does this relate to?'\n            ];\n\n            const form = JSON.parse(process.env.FORM_JSON || '{}');\n            const lastGood = form?.[\"last-good\"]?.trim();\n\n            // Conditionally remove Debugging Logs\n            const logs = form?.logs?.trim();\n            const isLogsEmpty = !logs || logs === '```logs\\n\\n```' || logs === '```logs```';\n\n            if (isLogsEmpty) {\n              headingsToRemove.push('### Debugging Logs');\n            }\n\n            const lines = originalBody.split(/\\r?\\n/);\n            const cleanedLines = [];\n\n            let skip = false;\n            for (let i = 0; i < lines.length; i++) {\n              const line = lines[i];\n              const trimmed = line.trim();\n\n              if (headingsToRemove.includes(trimmed)) {\n                skip = true;\n                continue;\n              }\n\n              if (skip) {\n                if (trimmed.startsWith('###')) {\n                  skip = false;\n                  i--; // Reprocess this heading\n                }\n                continue;\n              }\n\n              cleanedLines.push(line);\n            }\n\n            let finalBody = cleanedLines.join('\\n').trim();\n\n            if (lastGood) {\n              finalBody += `\\n\\n---\\n **Last known working version:** \\`${lastGood}\\``;\n            }\n\n            await github.rest.issues.update({\n              owner,\n              repo,\n              issue_number: issueNumber,\n              body: finalBody\n            });\n        env:\n          FORM_JSON: ${{ steps.bug-parser.outputs.jsonString }}\n\n      - name: Get latest Selenium version\n        id: get-version\n        uses: actions/github-script@v6\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          script: |\n            const { data: latestRelease } = await github.rest.repos.getLatestRelease({\n              owner: 'SeleniumHQ',\n              repo: 'selenium'\n            });\n\n            const latestTag = latestRelease.tag_name;\n            const versionMatch = latestTag.match(/[vV]?(?:selenium-)?(\\d+\\.\\d+(?:\\.\\d+)?)/);\n\n            if (!versionMatch) {\n              core.setFailed(`Couldn't parse version from tag: ${latestTag}`);\n              return;\n            }\n\n            const fullVersion = versionMatch[1];\n            const [major, minor] = fullVersion.split('.');\n            const latestVersion = `${major}.${minor}`;\n\n            console.log(`Latest version: ${latestVersion}`);\n            core.setOutput('version', latestVersion);\n\n      - name: Compare user version\n        id: version-check\n        uses: actions/github-script@v6\n        with:\n          script: |\n            const form = JSON.parse(process.env.FORM_JSON || '{}');\n            const userVersion = form?.[\"selenium-version\"]?.trim() || \"\";\n            const latest = process.env.LATEST_VERSION;\n\n            const [umaj, umin] = userVersion.split('.').map(n => parseInt(n, 10));\n            const [lmaj, lmin] = latest.split('.').map(n => parseInt(n, 10));\n\n            const isOutdated = umaj < lmaj || (umaj === lmaj && umin < lmin);\n\n            core.setOutput(\"user-version\", userVersion);\n            core.setOutput(\"latest-version\", latest);\n            core.setOutput(\"is-outdated\", isOutdated);\n        env:\n          FORM_JSON: ${{ steps.bug-parser.outputs.jsonString }}\n          LATEST_VERSION: ${{ steps.get-version.outputs.version }}\n\n      - name: Comment if version is outdated\n        id: comment-version\n        if: steps.version-check.outputs.is-outdated == 'true'\n        uses: peter-evans/create-or-update-comment@v4\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          issue-number: ${{ github.event.issue.number }}\n          body: |\n             You reported using Selenium version `${{ steps.version-check.outputs.user-version }}`, but the latest release is `${{ steps.version-check.outputs.latest-version }}`.\n\n            Please verify that this issue still occurs with the latest version. If it no longer applies, you can close this issue or update your comment.\n\n            *This issue will be marked \"awaiting answer\" and may be closed automatically if no response is received.*\n\n      - name: Add label\n        if: steps.version-check.outputs.is-outdated == 'true'\n        uses: actions-ecosystem/action-add-labels@v1\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          labels: J-awaiting answer\n      - name: Remove label\n        if: steps.version-check.outputs.is-outdated == 'true'\n        uses: actions-ecosystem/action-remove-labels@v1\n        with:\n          labels: A-needs-triaging\n","repository_owner":"seleniumhq","repository_name":"selenium","tokens_count":1485,"workflow":"name: Issue Form Labeler\non:\n  issues:\n    types: [opened]\n\njobs:\n  label-issues:\n    runs-on: ubuntu-latest\n    permissions:\n      issues: write\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Parse bug report form\n      id: bug-parser\n      uses: stefanbuck/github-issue-parser@v3\n      with:\n        template-path: .github/ISSUE_TEMPLATE/bug-report.yml\n      continue-on-error: true\n\n    - name: Parse feature proposal form\n      id: feature-parser\n      uses: stefanbuck/github-issue-parser@v3\n      with:\n        template-path: .github/ISSUE_TEMPLATE/feature_proposal.yml\n      continue-on-error: true\n\n    - name: Apply labels from bug report\n      uses: redhat-plumbers-in-action/advanced-issue-labeler@v3\n      with:\n        issue-form: ${{ steps.bug-parser.outputs.jsonString }}\n        token: ${{ secrets.GITHUB_TOKEN }}\n        config-path: .github/issue-labeler-config.yml\n      continue-on-error: true\n\n    - name: Apply labels from feature proposal\n      uses: redhat-plumbers-in-action/advanced-issue-labeler@v3\n      with:\n        issue-form: ${{ steps.feature-parser.outputs.jsonString }}\n        token: ${{ secrets.GITHUB_TOKEN }}\n        config-path: .github/issue-labeler-config.yml\n      continue-on-error: true\n\n    - name: Clean up labeled sections\n      uses: actions/github-script@v6\n      with:\n        github-token: ${{ secrets.GITHUB_TOKEN }}\n        script: |\n          const issueNumber = context.issue.number;\n          const originalBody = context.payload.issue.body;\n          const owner = context.repo.owner;\n          const repo = context.repo.repo;\n\n          const headingsToRemove = [\n            '### What version of Selenium are you currently using?',\n            '### The following statements are true',\n            '### Did this work for you before?',\n            '### If yes, what version of Selenium did it work with?',\n            '### Operating System',\n            '### Selenium Language Binding',\n            '### Which browsers are you experiencing the issue with?',\n            '### Are you using Selenium Grid?',\n            '### Does this apply to specific language bindings?',\n            '### What part(s) of Selenium does this relate to?'\n          ];\n\n          const form = JSON.parse(process.env.FORM_JSON || '{}');\n          const lastGood = form?.[\"last-good\"]?.trim();\n\n          // Conditionally remove Debugging Logs\n          const logs = form?.logs?.trim();\n          const isLogsEmpty = !logs || logs === '```logs\\n\\n```' || logs === '```logs```';\n\n          if (isLogsEmpty) {\n            headingsToRemove.push('### Debugging Logs');\n          }\n\n          const lines = originalBody.split(/\\r?\\n/);\n          const cleanedLines = [];\n\n          let skip = false;\n          for (let i = 0; i < lines.length; i++) {\n            const line = lines[i];\n            const trimmed = line.trim();\n\n            if (headingsToRemove.includes(trimmed)) {\n              skip = true;\n              continue;\n            }\n\n            if (skip) {\n              if (trimmed.startsWith('###')) {\n                skip = false;\n                i--; // Reprocess this heading\n              }\n              continue;\n            }\n\n            cleanedLines.push(line);\n          }\n\n          let finalBody = cleanedLines.join('\\n').trim();\n\n          if (lastGood) {\n            finalBody += `\\n\\n---\\n **Last known working version:** \\`${lastGood}\\``;\n          }\n\n          await github.rest.issues.update({\n            owner,\n            repo,\n            issue_number: issueNumber,\n            body: finalBody\n          });\n      env:\n        FORM_JSON: ${{ steps.bug-parser.outputs.jsonString }}\n\n    - name: Get latest Selenium version\n      id: get-version\n      uses: actions/github-script@v6\n      with:\n        github-token: ${{ secrets.GITHUB_TOKEN }}\n        script: |\n          const { data: latestRelease } = await github.rest.repos.getLatestRelease({\n            owner: 'SeleniumHQ',\n            repo: 'selenium'\n          });\n\n          const latestTag = latestRelease.tag_name;\n          const versionMatch = latestTag.match(/[vV]?(?:selenium-)?(\\d+\\.\\d+(?:\\.\\d+)?)/);\n\n          if (!versionMatch) {\n            core.setFailed(`Couldn't parse version from tag: ${latestTag}`);\n            return;\n          }\n\n          const fullVersion = versionMatch[1];\n          const [major, minor] = fullVersion.split('.');\n          const latestVersion = `${major}.${minor}`;\n\n          console.log(`Latest version: ${latestVersion}`);\n          core.setOutput('version', latestVersion);\n\n    - name: Compare user version\n      id: version-check\n      uses: actions/github-script@v6\n      with:\n        script: |\n          const form = JSON.parse(process.env.FORM_JSON || '{}');\n          const userVersion = form?.[\"selenium-version\"]?.trim() || \"\";\n          const latest = process.env.LATEST_VERSION;\n\n          const [umaj, umin] = userVersion.split('.').map(n => parseInt(n, 10));\n          const [lmaj, lmin] = latest.split('.').map(n => parseInt(n, 10));\n\n          const isOutdated = umaj < lmaj || (umaj === lmaj && umin < lmin);\n\n          core.setOutput(\"user-version\", userVersion);\n          core.setOutput(\"latest-version\", latest);\n          core.setOutput(\"is-outdated\", isOutdated);\n      env:\n        FORM_JSON: ${{ steps.bug-parser.outputs.jsonString }}\n        LATEST_VERSION: ${{ steps.get-version.outputs.version }}\n\n    - name: Comment if version is outdated\n      id: comment-version\n      if: steps.version-check.outputs.is-outdated == 'true'\n      uses: peter-evans/create-or-update-comment@v4\n      with:\n        token: ${{ secrets.GITHUB_TOKEN }}\n        issue-number: ${{ github.event.issue.number }}\n        body: |\n           You reported using Selenium version `${{ steps.version-check.outputs.user-version }}`, but the latest release is `${{ steps.version-check.outputs.latest-version }}`.\n\n          Please verify that this issue still occurs with the latest version. If it no longer applies, you can close this issue or update your comment.\n\n          *This issue will be marked \"awaiting answer\" and may be closed automatically if no response is received.*\n\n    - name: Add label\n      if: steps.version-check.outputs.is-outdated == 'true'\n      uses: actions-ecosystem/action-add-labels@v1\n      with:\n        github_token: ${{ secrets.GITHUB_TOKEN }}\n        labels: J-awaiting answer\n    - name: Remove label\n      if: steps.version-check.outputs.is-outdated == 'true'\n      uses: actions-ecosystem/action-remove-labels@v1\n      with:\n        labels: A-needs-triaging\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Issue Form Labeler` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by an event: an issue is opened. The workflow has one job. The job id of the 1st job is `label-issues`. ","prompt_level2":"Generate a GitHub Workflow named `Issue Form Labeler` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by an event: an issue is opened. The workflow has one job. The job id of the 1st job is `label-issues`. The job `label-issues` has 11 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Parse bug report form` and its id is `bug-parser`. The 3rd step is named `Parse feature proposal form` and its id is `feature-parser`. The 4th step is named `Apply labels from bug report`. The 5th step is named `Apply labels from feature proposal`. The 6th step is named `Clean up labeled sections`. The 7th step is named `Get latest Selenium version` and its id is `get-version`. The 8th step is named `Compare user version` and its id is `version-check`. The 9th step is named `Comment if version is outdated` and its id is `comment-version`. The 10th step is named `Add label`. The 11th step is named `Remove label`. ","prompt_level3":"Generate a GitHub Workflow named `Issue Form Labeler` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by an event: an issue is opened. The workflow has one job. The job id of the 1st job is `label-issues`. This job will run on ubuntu-latest runner. The job `label-issues` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `issues` scope. This permission setting only applies to the job `label-issues`. The job `label-issues` has 11 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v3. The 2nd step is named `Parse bug report form` and its id is `bug-parser`. This step runs action `stefanbuck/github-issue-parser` tagged as v3. The step defines an input parameter for the action: `template-path` is set to `.github/ISSUE_TEMPLATE/bug-report.yml`. When this step fails, the job will move on to the next step. The 3rd step is named `Parse feature proposal form` and its id is `feature-parser`. This step runs action `stefanbuck/github-issue-parser` tagged as v3. The step defines an input parameter for the action: `template-path` is set to `.github/ISSUE_TEMPLATE/feature_proposal.yml`. When this step fails, the job will move on to the next step. The 4th step is named `Apply labels from bug report`. This step runs action `redhat-plumbers-in-action/advanced-issue-labeler` tagged as v3. The step defines 3 input parameters for the action: `issue-form` is set to `${{ steps.bug-parser.outputs.jsonString }}`, `token` is set to `${{ secrets.GITHUB_TOKEN }}` and `config-path` is set to `.github/issue-labeler-config.yml`. When this step fails, the job will move on to the next step. The 5th step is named `Apply labels from feature proposal`. This step runs action `redhat-plumbers-in-action/advanced-issue-labeler` tagged as v3. The step defines 3 input parameters for the action: `issue-form` is set to `${{ steps.feature-parser.outputs.jsonString }}`, `token` is set to `${{ secrets.GITHUB_TOKEN }}` and `config-path` is set to `.github/issue-labeler-config.yml`. When this step fails, the job will move on to the next step. The 6th step is named `Clean up labeled sections`. The step sets an environment variable to use: `FORM_JSON` is set to `${{ steps.bug-parser.outputs.jsonString }}`. This step runs action `actions/github-script` tagged as v6. The step defines 2 input parameters for the action: `github-token` is set to `${{ secrets.GITHUB_TOKEN }}` and `script` is set to `const issueNumber = context.issue.number;\nconst originalBody = context.payload.issue.body;\nconst owner = context.repo.owner;\nconst repo = context.repo.repo;\n\nconst headingsToRemove = [\n  '### What version of Selenium are you currently using?',\n  '### The following statements are true',\n  '### Did this work for you before?',\n  '### If yes, what version of Selenium did it work with?',\n  '### Operating System',\n  '### Selenium Language Binding',\n  '### Which browsers are you experiencing the issue with?',\n  '### Are you using Selenium Grid?',\n  '### Does this apply to specific language bindings?',\n  '### What part(s) of Selenium does this relate to?'\n];\n\nconst form = JSON.parse(process.env.FORM_JSON || '{}');\nconst lastGood = form?.[\"last-good\"]?.trim();\n\n// Conditionally remove Debugging Logs\nconst logs = form?.logs?.trim();\nconst isLogsEmpty = !logs || logs === '```logs\\n\\n```' || logs === '```logs```';\n\nif (isLogsEmpty) {\n  headingsToRemove.push('### Debugging Logs');\n}\n\nconst lines = originalBody.split(/\\r?\\n/);\nconst cleanedLines = [];\n\nlet skip = false;\nfor (let i = 0; i < lines.length; i++) {\n  const line = lines[i];\n  const trimmed = line.trim();\n\n  if (headingsToRemove.includes(trimmed)) {\n    skip = true;\n    continue;\n  }\n\n  if (skip) {\n    if (trimmed.startsWith('###')) {\n      skip = false;\n      i--; // Reprocess this heading\n    }\n    continue;\n  }\n\n  cleanedLines.push(line);\n}\n\nlet finalBody = cleanedLines.join('\\n').trim();\n\nif (lastGood) {\n  finalBody += `\\n\\n---\\n **Last known working version:** \\`${lastGood}\\``;\n}\n\nawait github.rest.issues.update({\n  owner,\n  repo,\n  issue_number: issueNumber,\n  body: finalBody\n});\n`. The 7th step is named `Get latest Selenium version` and its id is `get-version`. This step runs action `actions/github-script` tagged as v6. The step defines 2 input parameters for the action: `github-token` is set to `${{ secrets.GITHUB_TOKEN }}` and `script` is set to `const { data: latestRelease } = await github.rest.repos.getLatestRelease({\n  owner: 'SeleniumHQ',\n  repo: 'selenium'\n});\n\nconst latestTag = latestRelease.tag_name;\nconst versionMatch = latestTag.match(/[vV]?(?:selenium-)?(\\d+\\.\\d+(?:\\.\\d+)?)/);\n\nif (!versionMatch) {\n  core.setFailed(`Couldn't parse version from tag: ${latestTag}`);\n  return;\n}\n\nconst fullVersion = versionMatch[1];\nconst [major, minor] = fullVersion.split('.');\nconst latestVersion = `${major}.${minor}`;\n\nconsole.log(`Latest version: ${latestVersion}`);\ncore.setOutput('version', latestVersion);\n`. The 8th step is named `Compare user version` and its id is `version-check`. The step sets 2 environment variables to use: `FORM_JSON` is set to `${{ steps.bug-parser.outputs.jsonString }}` and `LATEST_VERSION` is set to `${{ steps.get-version.outputs.version }}`. This step runs action `actions/github-script` tagged as v6. The step defines an input parameter for the action: `script` is set to `const form = JSON.parse(process.env.FORM_JSON || '{}');\nconst userVersion = form?.[\"selenium-version\"]?.trim() || \"\";\nconst latest = process.env.LATEST_VERSION;\n\nconst [umaj, umin] = userVersion.split('.').map(n => parseInt(n, 10));\nconst [lmaj, lmin] = latest.split('.').map(n => parseInt(n, 10));\n\nconst isOutdated = umaj < lmaj || (umaj === lmaj && umin < lmin);\n\ncore.setOutput(\"user-version\", userVersion);\ncore.setOutput(\"latest-version\", latest);\ncore.setOutput(\"is-outdated\", isOutdated);\n`. The 9th step is named `Comment if version is outdated` and its id is `comment-version`. This step will run only if the condition(steps.version-check.outputs.is-outdated == 'true') is met. This step runs action `peter-evans/create-or-update-comment` tagged as v4. The step defines 3 input parameters for the action: `token` is set to `${{ secrets.GITHUB_TOKEN }}`, `issue-number` is set to `${{ github.event.issue.number }}` and `body` is set to ` You reported using Selenium version `${{ steps.version-check.outputs.user-version }}`, but the latest release is `${{ steps.version-check.outputs.latest-version }}`.\n\nPlease verify that this issue still occurs with the latest version. If it no longer applies, you can close this issue or update your comment.\n\n*This issue will be marked \"awaiting answer\" and may be closed automatically if no response is received.*\n`. The 10th step is named `Add label`. This step will run only if the condition(steps.version-check.outputs.is-outdated == 'true') is met. This step runs action `actions-ecosystem/action-add-labels` tagged as v1. The step defines 2 input parameters for the action: `github_token` is set to `${{ secrets.GITHUB_TOKEN }}` and `labels` is set to `J-awaiting answer`. The 11th step is named `Remove label`. This step will run only if the condition(steps.version-check.outputs.is-outdated == 'true') is met. This step runs action `actions-ecosystem/action-remove-labels` tagged as v1. The step defines an input parameter for the action: `labels` is set to `A-needs-triaging`. ","nb_triggers":1,"triggers":["issues"],"nb_jobs":1,"nb_actions":11,"actions":["actions-ecosystem/action-add-labels","actions-ecosystem/action-remove-labels","actions/checkout","actions/github-script","actions/github-script","actions/github-script","peter-evans/create-or-update-comment","redhat-plumbers-in-action/advanced-issue-labeler","redhat-plumbers-in-action/advanced-issue-labeler","stefanbuck/github-issue-parser","stefanbuck/github-issue-parser"],"actions_details":[{"version":"v3","name":"actions/checkout"},{"version":"v3","name":"stefanbuck/github-issue-parser"},{"version":"v3","name":"stefanbuck/github-issue-parser"},{"version":"v3","name":"redhat-plumbers-in-action/advanced-issue-labeler"},{"version":"v3","name":"redhat-plumbers-in-action/advanced-issue-labeler"},{"version":"v6","name":"actions/github-script"},{"version":"v6","name":"actions/github-script"},{"version":"v6","name":"actions/github-script"},{"version":"v4","name":"peter-evans/create-or-update-comment"},{"version":"v1","name":"actions-ecosystem/action-add-labels"},{"version":"v1","name":"actions-ecosystem/action-remove-labels"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":11,"cyclomatic_complexity":1}
{"id":6949,"repository_id":71303086,"mainLanguage":"Python","file_name":"release-upload.yml","file_content":"# Copyright (c) 2024-2025, NVIDIA CORPORATION & AFFILIATES. ALL RIGHTS RESERVED.\n#\n# SPDX-License-Identifier: Apache-2.0\n\nname: \"CI: Upload git archive\"\n\non:\n  workflow_call:\n    inputs:\n      git-tag:\n        type: string\n        required: true\n\nconcurrency:\n  # Concurrency group that uses the workflow name and PR number if available\n  # or commit SHA as a fallback. If a new build is triggered under that\n  # concurrency group while a previous build is running it will be canceled.\n  # Repeated pushes to a PR will cancel all previous builds, while multiple\n  # merges to main will not cancel.\n  group: ${{ github.workflow }}-${{ github.ref_name || github.sha }}\n  cancel-in-progress: true\n\npermissions:\n  contents: write\n\njobs:\n  # create source archive and upload it to the published release\n  # URL to the archive: https://github.com/NVIDIA/<repo>/releases/download/<tag>/<repo>-<tag>.tar.gz\n  upload:\n    if: ${{ !github.event.repository.fork }}\n    runs-on: ubuntu-latest\n    env:\n      ARCHIVE_NAME: ${{ github.event.repository.name }}-${{ inputs.git-tag }}\n    steps:\n      - name: Checkout Source\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n          ref: ${{ inputs.git-tag }}\n\n      - name: Create Release Directory\n        run: mkdir -p release\n\n      - name: Archive Source\n        run: >\n          git archive\n          --format=tar.gz\n          --prefix=\"${{ env.ARCHIVE_NAME }}/\"\n          --output=\"release/${{ env.ARCHIVE_NAME }}.tar.gz\"\n          ${{ inputs.git-tag }}\n\n      - name: Compute Checksum\n        run: >\n          sha256sum \"release/${{ env.ARCHIVE_NAME }}.tar.gz\"\n          | awk '{print $1}'\n          > \"release/${{ env.ARCHIVE_NAME }}.tar.gz.sha256sum\"\n\n      - name: Upload Archive\n        env:\n          GH_TOKEN: ${{ github.token }}\n        run: >\n          gh release upload\n          --clobber \"${{ inputs.git-tag }}\"\n          --repo \"${{ github.repository }}\"\n          release/*\n","repository_owner":"nvidia","repository_name":"cuda-python","tokens_count":492,"workflow":"# Copyright (c) 2024-2025, NVIDIA CORPORATION & AFFILIATES. ALL RIGHTS RESERVED.\n#\n# SPDX-License-Identifier: Apache-2.0\n\nname: 'CI: Upload git archive'\n\non:\n  workflow_call:\n    inputs:\n      git-tag:\n        type: string\n        required: true\n\nconcurrency:\n  # Concurrency group that uses the workflow name and PR number if available\n  # or commit SHA as a fallback. If a new build is triggered under that\n  # concurrency group while a previous build is running it will be canceled.\n  # Repeated pushes to a PR will cancel all previous builds, while multiple\n  # merges to main will not cancel.\n  group: ${{ github.workflow }}-${{ github.ref_name || github.sha }}\n  cancel-in-progress: true\n\npermissions:\n  contents: write\n\njobs:\n  # create source archive and upload it to the published release\n  # URL to the archive: https://github.com/NVIDIA/<repo>/releases/download/<tag>/<repo>-<tag>.tar.gz\n  upload:\n    if: ${{ !github.event.repository.fork }}\n    runs-on: ubuntu-latest\n    env:\n      ARCHIVE_NAME: ${{ github.event.repository.name }}-${{ inputs.git-tag }}\n    steps:\n    - name: Checkout Source\n      uses: actions/checkout@v4\n      with:\n        fetch-depth: 0\n        ref: ${{ inputs.git-tag }}\n\n    - name: Create Release Directory\n      run: mkdir -p release\n\n    - name: Archive Source\n      run: >\n        git archive\n        --format=tar.gz\n        --prefix=\"${{ env.ARCHIVE_NAME }}/\"\n        --output=\"release/${{ env.ARCHIVE_NAME }}.tar.gz\"\n        ${{ inputs.git-tag }}\n\n    - name: Compute Checksum\n      run: >\n        sha256sum \"release/${{ env.ARCHIVE_NAME }}.tar.gz\"\n        | awk '{print $1}'\n        > \"release/${{ env.ARCHIVE_NAME }}.tar.gz.sha256sum\"\n\n    - name: Upload Archive\n      env:\n        GH_TOKEN: ${{ github.token }}\n      run: >\n        gh release upload\n        --clobber \"${{ inputs.git-tag }}\"\n        --repo \"${{ github.repository }}\"\n        release/*\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `CI: Upload git archive` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives an input: git-tag-the data type is string and it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. Only a single workflow using the ${{ github.workflow }}-${{ github.ref_name || github.sha }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `upload`. ","prompt_level2":"Generate a GitHub Workflow named `CI: Upload git archive` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives an input: git-tag-the data type is string and it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. Only a single workflow using the ${{ github.workflow }}-${{ github.ref_name || github.sha }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `upload`. The job `upload` has 5 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Create Release Directory`. The 3rd step is named `Archive Source`. The 4th step is named `Compute Checksum`. The 5th step is named `Upload Archive`. ","prompt_level3":"Generate a GitHub Workflow named `CI: Upload git archive` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives an input: git-tag-the data type is string and it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. Only a single workflow using the ${{ github.workflow }}-${{ github.ref_name || github.sha }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `upload`. This job will run only if the condition(${{ !github.event.repository.fork }}) is met. This job will run on ubuntu-latest runner. The job sets an environment variable to use: `ARCHIVE_NAME` is set to `${{ github.event.repository.name }}-${{ inputs.git-tag }}`. The job `upload` has 5 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines 2 input parameters for the action: `fetch-depth` is set to `0` and `ref` is set to `${{ inputs.git-tag }}`. The 2nd step is named `Create Release Directory`. This step runs a script: `mkdir -p release`. The 3rd step is named `Archive Source`. This step runs a script: `git archive --format=tar.gz --prefix=\"${{ env.ARCHIVE_NAME }}/\" --output=\"release/${{ env.ARCHIVE_NAME }}.tar.gz\" ${{ inputs.git-tag }}\n`. The 4th step is named `Compute Checksum`. This step runs a script: `sha256sum \"release/${{ env.ARCHIVE_NAME }}.tar.gz\" | awk '{print $1}' > \"release/${{ env.ARCHIVE_NAME }}.tar.gz.sha256sum\"\n`. The 5th step is named `Upload Archive`. The step sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. This step runs a script: `gh release upload --clobber \"${{ inputs.git-tag }}\" --repo \"${{ github.repository }}\" release/*\n`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":1,"actions":["actions/checkout"],"actions_details":[{"version":"v4","name":"actions/checkout"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":5,"cyclomatic_complexity":1}
{"id":53537,"repository_id":3495378,"mainLanguage":"C","file_name":"ci_workflow_old.yml","file_content":"# SPDX-License-Identifier: BSD-3-Clause\n# Copyright (c) Contributors to the OpenEXR Project.\n#\n# GitHub Actions workflow file\n# https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions\n\nname: CI-old\n\n# Build for VFX reference platform prior to 2023, which requires a\n# workaround to run an old version of glibc required by the ASWF Docker\n# images.\n#\n# This doesn't easily integrate with the existing CI workflow, and it\n# can be depreciated entirely once we've moved beyond support for the\n# old CentOS-based VFX reference platform years.\n#\n# See this discussion for details:\n# https://academysoftwarefdn.slack.com/archives/C0169RX7MMK/p1732574400981949\n\n\n# Run on all changes except:\n# - doc file changes\n# - changes to the website, *except* for \"website/src\", since that\n#   code needs validation.  The website has a separate workflow\n# - changes to the bazel config, since it has its own workflow\n# - changes to the python bindings\n# - changes to workflows other than this one\n\non:\n  push:\n    paths:\n      - '**'\n      - '!**.md'\n      - '!website/**'\n      - 'website/src/**'\n      - '!bazel/**'\n      - '!src/wrappers/**'\n      - '!share/ci/**'\n      - '!.github/workflows/**'\n      - '.github/workflows/ci_workflow_old.yml'\n  pull_request:\n    paths:\n      - '**'\n      - '!**.md'\n      - '!website/**'\n      - 'website/src/**'\n      - '!bazel/**'\n      - '!src/wrappers/**'\n      - '!share/ci/**'\n      - '!.github/workflows/**'\n      - '.github/workflows/ci_workflow_old.yml'\n\npermissions:\n  contents: read\n\njobs:\n\n  linux:\n    name: 'Linux vfx${{ matrix.vfx-cy }}' \n    runs-on: ubuntu-latest\n    container:\n      image: aswf/ci-openexr:${{ matrix.vfx-cy }}\n      volumes:\n        - /node20217:/node20217:rw,rshared\n        - /node20217:/__e/node20:ro,rshared\n\n    strategy:\n      matrix:\n        include:\n\n          - build: 2022\n            vfx-cy: 2022\n\n          - build: 2021\n            vfx-cy: 2021\n\n    steps:\n      - name: install nodejs20glibc2.17\n        run: |\n          curl --silent https://unofficial-builds.nodejs.org/download/release/v20.18.1/node-v20.18.1-linux-x64-glibc-217.tar.xz | tar -xJ --strip-components 1 -C /node20217 -f -\n      - name: Checkout\n        uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3.6.0\n      - name: Create build directories\n        run: |\n          mkdir _install\n          mkdir _build\n      - name: Configure\n        run: |\n          cmake -B _build -S . \\\n                -DCMAKE_INSTALL_PREFIX=_install \\\n                -DCMAKE_VERBOSE_MAKEFILE:BOOL='ON'\n      - name: Build\n        run: |\n          cmake --build _build \\\n                --target install \\\n                --config Release\n      - name: Test\n        run: |\n          ctest -T Test \\\n                -C Release \\\n                --timeout 7200 \\\n                --output-on-failure \\\n                -VV\n        working-directory: _build\n\n","repository_owner":"academysoftwarefoundation","repository_name":"openexr","tokens_count":854,"workflow":"# SPDX-License-Identifier: BSD-3-Clause\n# Copyright (c) Contributors to the OpenEXR Project.\n#\n# GitHub Actions workflow file\n# https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions\n\nname: CI-old\n\n# Build for VFX reference platform prior to 2023, which requires a\n# workaround to run an old version of glibc required by the ASWF Docker\n# images.\n#\n# This doesn't easily integrate with the existing CI workflow, and it\n# can be depreciated entirely once we've moved beyond support for the\n# old CentOS-based VFX reference platform years.\n#\n# See this discussion for details:\n# https://academysoftwarefdn.slack.com/archives/C0169RX7MMK/p1732574400981949\n\n\n# Run on all changes except:\n# - doc file changes\n# - changes to the website, *except* for \"website/src\", since that\n#   code needs validation.  The website has a separate workflow\n# - changes to the bazel config, since it has its own workflow\n# - changes to the python bindings\n# - changes to workflows other than this one\n\non:\n  push:\n    paths:\n    - '**'\n    - '!**.md'\n    - '!website/**'\n    - website/src/**\n    - '!bazel/**'\n    - '!src/wrappers/**'\n    - '!share/ci/**'\n    - '!.github/workflows/**'\n    - .github/workflows/ci_workflow_old.yml\n  pull_request:\n    paths:\n    - '**'\n    - '!**.md'\n    - '!website/**'\n    - website/src/**\n    - '!bazel/**'\n    - '!src/wrappers/**'\n    - '!share/ci/**'\n    - '!.github/workflows/**'\n    - .github/workflows/ci_workflow_old.yml\n\npermissions:\n  contents: read\n\njobs:\n\n  linux:\n    name: Linux vfx${{ matrix.vfx-cy }}\n    runs-on: ubuntu-latest\n    container:\n      image: aswf/ci-openexr:${{ matrix.vfx-cy }}\n      volumes:\n      - /node20217:/node20217:rw,rshared\n      - /node20217:/__e/node20:ro,rshared\n\n    strategy:\n      matrix:\n        include:\n\n        - build: 2022\n          vfx-cy: 2022\n\n        - build: 2021\n          vfx-cy: 2021\n\n    steps:\n    - name: install nodejs20glibc2.17\n      run: |\n        curl --silent https://unofficial-builds.nodejs.org/download/release/v20.18.1/node-v20.18.1-linux-x64-glibc-217.tar.xz | tar -xJ --strip-components 1 -C /node20217 -f -\n    - name: Checkout\n      uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744   # v3.6.0\n    - name: Create build directories\n      run: |\n        mkdir _install\n        mkdir _build\n    - name: Configure\n      run: |\n        cmake -B _build -S . \\\n              -DCMAKE_INSTALL_PREFIX=_install \\\n              -DCMAKE_VERBOSE_MAKEFILE:BOOL='ON'\n    - name: Build\n      run: |\n        cmake --build _build \\\n              --target install \\\n              --config Release\n    - name: Test\n      run: |\n        ctest -T Test \\\n              -C Release \\\n              --timeout 7200 \\\n              --output-on-failure \\\n              -VV\n      working-directory: _build\n\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `CI-old` for a GitHub repository whose primary programming language is C. This workflow will be triggered by multiple events: 1) Only if at least one path of push event matches a pattern in the paths filter(**, !**.md, !website/**, website/src/**, !bazel/**, !src/wrappers/**, !share/ci/**, !.github/workflows/** or .github/workflows/ci_workflow_old.yml), the workflow runs. 2) Only if at least one path of pull_request event matches a pattern in the paths filter(**, !**.md, !website/**, website/src/**, !bazel/**, !src/wrappers/**, !share/ci/**, !.github/workflows/** or .github/workflows/ci_workflow_old.yml), the workflow runs. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Linux vfx${{ matrix.vfx-cy }}` and its job id is `linux`. ","prompt_level2":"Generate a GitHub Workflow named `CI-old` for a GitHub repository whose primary programming language is C. This workflow will be triggered by multiple events: 1) Only if at least one path of push event matches a pattern in the paths filter(**, !**.md, !website/**, website/src/**, !bazel/**, !src/wrappers/**, !share/ci/**, !.github/workflows/** or .github/workflows/ci_workflow_old.yml), the workflow runs. 2) Only if at least one path of pull_request event matches a pattern in the paths filter(**, !**.md, !website/**, website/src/**, !bazel/**, !src/wrappers/**, !share/ci/**, !.github/workflows/** or .github/workflows/ci_workflow_old.yml), the workflow runs. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Linux vfx${{ matrix.vfx-cy }}` and its job id is `linux`. The job `linux` has 6 steps. The 1st step is named `install nodejs20glibc2.17`. The 2nd step is named `Checkout repository`. The 3rd step is named `Create build directories`. The 4th step is named `Configure`. The 5th step is named `Build`. The 6th step is named `Test`. ","prompt_level3":"Generate a GitHub Workflow named `CI-old` for a GitHub repository whose primary programming language is C. This workflow will be triggered by multiple events: 1) Only if at least one path of push event matches a pattern in the paths filter(**, !**.md, !website/**, website/src/**, !bazel/**, !src/wrappers/**, !share/ci/**, !.github/workflows/** or .github/workflows/ci_workflow_old.yml), the workflow runs. 2) Only if at least one path of pull_request event matches a pattern in the paths filter(**, !**.md, !website/**, website/src/**, !bazel/**, !src/wrappers/**, !share/ci/**, !.github/workflows/** or .github/workflows/ci_workflow_old.yml), the workflow runs. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Linux vfx${{ matrix.vfx-cy }}` and its job id is `linux`. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. For each object in the [{'build': 2022, 'vfx-cy': 2022}, {'build': 2021, 'vfx-cy': 2021}] list, the key:value pairs in the object will be added to each of the matrix combinations if none of the key:value pairs overwrite any of the original matrix values. If the object cannot be added to any of the matrix combinations, a new matrix combination will be created instead. The job creates a Docker container that uses `aswf/ci-openexr:${{ matrix.vfx-cy }}` image. The container also sets an array of volumes to use: /node20217:/node20217:rw,rshared and /node20217:/__e/node20:ro,rshared. The job `linux` has 6 steps. The 1st step is named `install nodejs20glibc2.17`. This step runs a script: `curl --silent https://unofficial-builds.nodejs.org/download/release/v20.18.1/node-v20.18.1-linux-x64-glibc-217.tar.xz | tar -xJ --strip-components 1 -C /node20217 -f -\n`. The 2nd step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is f43a0e5ff2bd294095638e18286ca9a3d1956744. The 3rd step is named `Create build directories`. This step runs a script: `mkdir _install\nmkdir _build\n`. The 4th step is named `Configure`. This step runs a script: `cmake -B _build -S . \\\n      -DCMAKE_INSTALL_PREFIX=_install \\\n      -DCMAKE_VERBOSE_MAKEFILE:BOOL='ON'\n`. The 5th step is named `Build`. This step runs a script: `cmake --build _build \\\n      --target install \\\n      --config Release\n`. The 6th step is named `Test`. This step runs a script: `ctest -T Test \\\n      -C Release \\\n      --timeout 7200 \\\n      --output-on-failure \\\n      -VV\n`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":1,"nb_actions":1,"actions":["actions/checkout"],"actions_details":[{"version":"f43a0e5ff2bd294095638e18286ca9a3d1956744","name":"actions/checkout"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":6,"cyclomatic_complexity":1}
{"id":26607,"repository_id":95255975,"mainLanguage":"Python","file_name":"ci.yml","file_content":"# This workflow builds, tests and lints the project\nname: Build, Test & Lint\n\non:\n  workflow_call:\n  workflow_dispatch:\n\njobs:\n  test:\n    name: Run\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [\"3.12\"]\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4\n      with:\n        lfs: true\n\n    - name: Checkout LFS objects\n      run: git lfs pull\n\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Install Poetry\n      uses: snok/install-poetry@76e04a911780d5b312d89783f7b1cd627778900a # v1\n      with:\n        version: 1.7.1\n        virtualenvs-create: true\n        virtualenvs-in-project: true\n\n    - name: Load cached venv\n      id: cached-poetry-dependencies\n      uses: actions/cache@5a3ec84eff668545956fd18022155c47e93e2684 # v4\n      with:\n        path: .venv\n        key: venv-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('**/poetry.lock') }}\n\n    - name: Install dependencies\n      run: poetry install --with dev\n\n    - name: Run linting\n      run: make lint\n\n    - name: Run tests\n      run: make test\n\n    - name: Run security checks\n      run: make security\n\n    - name: Build package\n      run: make build\n","repository_owner":"stacklok","repository_name":"codegate","tokens_count":480,"workflow":"# This workflow builds, tests and lints the project\nname: Build, Test & Lint\n\non:\n  workflow_call:\n  workflow_dispatch:\n\njobs:\n  test:\n    name: Run\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: ['3.12']\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4\n      with:\n        lfs: true\n\n    - name: Checkout LFS objects\n      run: git lfs pull\n\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Install Poetry\n      uses: snok/install-poetry@76e04a911780d5b312d89783f7b1cd627778900a # v1\n      with:\n        version: 1.7.1\n        virtualenvs-create: true\n        virtualenvs-in-project: true\n\n    - name: Load cached venv\n      id: cached-poetry-dependencies\n      uses: actions/cache@5a3ec84eff668545956fd18022155c47e93e2684 # v4\n      with:\n        path: .venv\n        key: venv-${{ runner.os }}-${{ matrix.python-version }}-${{ \n          hashFiles('**/poetry.lock') }}\n\n    - name: Install dependencies\n      run: poetry install --with dev\n\n    - name: Run linting\n      run: make lint\n\n    - name: Run tests\n      run: make test\n\n    - name: Run security checks\n      run: make security\n\n    - name: Build package\n      run: make build\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Build, Test & Lint` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) it is called from another workflow. 2) someone manually triggers the workflow. The workflow has one job. The 1st job is named `Run` and its job id is `test`. ","prompt_level2":"Generate a GitHub Workflow named `Build, Test & Lint` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) it is called from another workflow. 2) someone manually triggers the workflow. The workflow has one job. The 1st job is named `Run` and its job id is `test`. The job `test` has 10 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Checkout LFS objects`. The 3rd step is named `Set up Python ${{ matrix.python-version }}`. The 4th step is named `Install Poetry`. The 5th step is named `Load cached venv` and its id is `cached-poetry-dependencies`. The 6th step is named `Install dependencies`. The 7th step is named `Run linting`. The 8th step is named `Run tests`. The 9th step is named `Run security checks`. The 10th step is named `Build package`. ","prompt_level3":"Generate a GitHub Workflow named `Build, Test & Lint` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) it is called from another workflow. 2) someone manually triggers the workflow. The workflow has one job. The 1st job is named `Run` and its job id is `test`. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `python-version` has one value: 3.12. The job `test` has 10 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is 11bd71901bbe5b1630ceea73d27597364c9af683. The step defines an input parameter for the action: `lfs` is set to `True`. The 2nd step is named `Checkout LFS objects`. This step runs a script: `git lfs pull`. The 3rd step is named `Set up Python ${{ matrix.python-version }}`. This step runs action `actions/setup-python` whose commit is a26af69be951a213d495a4c3e4e4022e16d87065. The step defines an input parameter for the action: `python-version` is set to `${{ matrix.python-version }}`. The 4th step is named `Install Poetry`. This step runs action `snok/install-poetry` whose commit is 76e04a911780d5b312d89783f7b1cd627778900a. The step defines 3 input parameters for the action: `version` is set to `1.7.1`, `virtualenvs-create` is set to `True` and `virtualenvs-in-project` is set to `True`. The 5th step is named `Load cached venv` and its id is `cached-poetry-dependencies`. This step runs action `actions/cache` whose commit is 5a3ec84eff668545956fd18022155c47e93e2684. The step defines 2 input parameters for the action: `path` is set to `.venv` and `key` is set to `venv-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('**/poetry.lock') }}`. The 6th step is named `Install dependencies`. This step runs a script: `poetry install --with dev`. The 7th step is named `Run linting`. This step runs a script: `make lint`. The 8th step is named `Run tests`. This step runs a script: `make test`. The 9th step is named `Run security checks`. This step runs a script: `make security`. The 10th step is named `Build package`. This step runs a script: `make build`. ","nb_triggers":2,"triggers":["workflow_call","workflow_dispatch"],"nb_jobs":1,"nb_actions":4,"actions":["actions/cache","actions/checkout","actions/setup-python","snok/install-poetry"],"actions_details":[{"version":"11bd71901bbe5b1630ceea73d27597364c9af683","name":"actions/checkout"},{"version":"a26af69be951a213d495a4c3e4e4022e16d87065","name":"actions/setup-python"},{"version":"76e04a911780d5b312d89783f7b1cd627778900a","name":"snok/install-poetry"},{"version":"5a3ec84eff668545956fd18022155c47e93e2684","name":"actions/cache"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":10,"cyclomatic_complexity":1}
{"id":60647,"repository_id":95171511,"mainLanguage":"C++","file_name":"snap-publish-candidate.yml","file_content":"name: Snap Publish\n\non:\n  push:\n    branches:\n      - develop\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.number && format('pr{0}', github.event.number) || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  Snap:\n    runs-on: ubuntu-latest\n\n    timeout-minutes: 30\n\n    strategy:\n      matrix:\n        platform:\n          - amd64\n          - armhf\n          - arm64\n\n    steps:\n      - name: Check out code\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0  # needed for version determination\n\n      - id: build-snap\n        name: Build the snap\n        uses: snapcore/action-build@v1\n\n      - name: Publish the snap\n        uses: snapcore/action-publish@v1\n        env:\n          SNAPCRAFT_STORE_CREDENTIALS: ${{ secrets.STORE_LOGIN }}\n        with:\n          snap: ${{ steps.build-snap.outputs.snap }}\n          release: edge\n\n","repository_owner":"miracle-wm-org","repository_name":"miracle-wm","tokens_count":224,"workflow":"name: Snap Publish\n\non:\n  push:\n    branches:\n    - develop\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.number && format('pr{0}', \n    github.event.number) || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  Snap:\n    runs-on: ubuntu-latest\n\n    timeout-minutes: 30\n\n    strategy:\n      matrix:\n        platform:\n        - amd64\n        - armhf\n        - arm64\n\n    steps:\n    - name: Check out code\n      uses: actions/checkout@v4\n      with:\n        fetch-depth: 0    # needed for version determination\n\n    - id: build-snap\n      name: Build the snap\n      uses: snapcore/action-build@v1\n\n    - name: Publish the snap\n      uses: snapcore/action-publish@v1\n      env:\n        SNAPCRAFT_STORE_CREDENTIALS: ${{ secrets.STORE_LOGIN }}\n      with:\n        snap: ${{ steps.build-snap.outputs.snap }}\n        release: edge\n\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Snap Publish` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a branch named develop. Only a single workflow using the ${{ github.workflow }}-${{ github.event.number && format('pr{0}', github.event.number) || github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `Snap`. ","prompt_level2":"Generate a GitHub Workflow named `Snap Publish` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a branch named develop. Only a single workflow using the ${{ github.workflow }}-${{ github.event.number && format('pr{0}', github.event.number) || github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `Snap`. The job `Snap` has 3 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Build the snap` and its id is `build-snap`. The 3rd step is named `Publish the snap`. ","prompt_level3":"Generate a GitHub Workflow named `Snap Publish` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a branch named develop. Only a single workflow using the ${{ github.workflow }}-${{ github.event.number && format('pr{0}', github.event.number) || github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `Snap`. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `platform` has 3 values: amd64, armhf and arm64. The maximum number of minutes to run the job is 30. The job `Snap` has 3 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `fetch-depth` is set to `0`. The 2nd step is named `Build the snap` and its id is `build-snap`. This step runs action `snapcore/action-build` tagged as v1. The 3rd step is named `Publish the snap`. The step sets an environment variable to use: `SNAPCRAFT_STORE_CREDENTIALS` is set to `${{ secrets.STORE_LOGIN }}`. This step runs action `snapcore/action-publish` tagged as v1. The step defines 2 input parameters for the action: `snap` is set to `${{ steps.build-snap.outputs.snap }}` and `release` is set to `edge`. ","nb_triggers":1,"triggers":["push"],"nb_jobs":1,"nb_actions":3,"actions":["actions/checkout","snapcore/action-build","snapcore/action-publish"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v1","name":"snapcore/action-build"},{"version":"v1","name":"snapcore/action-publish"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":3,"cyclomatic_complexity":1}
{"id":64276,"repository_id":3272431,"mainLanguage":"Java","file_name":"dispatch.javadoc.yml","file_content":"name: 'Dispatch: Deploy Javadoc'\n\non:\n  workflow_dispatch:\n    inputs:\n      target_tag:\n        description: 'Version to generate javadoc'\n        required: true\n      replace_latest:\n        description: 'Replace the latest folder'\n        type: boolean\n\njobs:\n  javadocs:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.target_tag }}\n\n      - uses: actions/setup-java@v4\n        with:\n          java-version: '21'\n          distribution: 'adopt'\n          cache: gradle\n\n      - name: Setup Gradle\n        uses: gradle/actions/setup-gradle@v4\n\n      - name: build javadoc\n        run: ./gradlew javadoc\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          GITHUB_VERSION: ${{ inputs.target_tag }}\n\n      - name: Copy javadoc to deploy folder\n        run: |\n          mkdir -p build/docs/javadoc-deploy/${{ inputs.target_tag }}\n          cp -r build/docs/javadoc/* build/docs/javadoc-deploy/${{ inputs.target_tag }}\n\n      - name: Copy javadoc to latest folder\n        if: inputs.replace_latest\n        run: |\n          mkdir -p build/docs/javadoc-deploy/latest\n          cp -r build/docs/javadoc/* build/docs/javadoc-deploy/latest\n\n      - name: Deploy javadoc to gh pages\n        uses: JamesIves/github-pages-deploy-action@v4\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          folder: build/docs/javadoc-deploy\n          branch: javadoc\n          target-folder: javadoc\n          clean: false\n          commit-message: Deploy javadoc for ${{ inputs.target_tag }}\n","repository_owner":"multiverse","repository_name":"multiverse-core","tokens_count":388,"workflow":"name: 'Dispatch: Deploy Javadoc'\n\non:\n  workflow_dispatch:\n    inputs:\n      target_tag:\n        description: Version to generate javadoc\n        required: true\n      replace_latest:\n        description: Replace the latest folder\n        type: boolean\n\njobs:\n  javadocs:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      with:\n        ref: ${{ inputs.target_tag }}\n\n    - name: Setup Java 21\n      uses: actions/setup-java@v4\n      with:\n        java-version: '21'\n        distribution: adopt\n        cache: gradle\n\n    - name: Setup Gradle\n      uses: gradle/actions/setup-gradle@v4\n\n    - name: build javadoc\n      run: ./gradlew javadoc\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        GITHUB_VERSION: ${{ inputs.target_tag }}\n\n    - name: Copy javadoc to deploy folder\n      run: |\n        mkdir -p build/docs/javadoc-deploy/${{ inputs.target_tag }}\n        cp -r build/docs/javadoc/* build/docs/javadoc-deploy/${{ inputs.target_tag }}\n\n    - name: Copy javadoc to latest folder\n      if: inputs.replace_latest\n      run: |\n        mkdir -p build/docs/javadoc-deploy/latest\n        cp -r build/docs/javadoc/* build/docs/javadoc-deploy/latest\n\n    - name: Deploy javadoc to gh pages\n      uses: JamesIves/github-pages-deploy-action@v4\n      with:\n        token: ${{ secrets.GITHUB_TOKEN }}\n        folder: build/docs/javadoc-deploy\n        branch: javadoc\n        target-folder: javadoc\n        clean: false\n        commit-message: Deploy javadoc for ${{ inputs.target_tag }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Dispatch: Deploy Javadoc` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 2 inputs: target_tag-this input represents version to generate javadoc and it must be supplied; replace_latest-this input represents replace the latest folder and the data type is boolean. The workflow has one job. The job id of the 1st job is `javadocs`. ","prompt_level2":"Generate a GitHub Workflow named `Dispatch: Deploy Javadoc` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 2 inputs: target_tag-this input represents version to generate javadoc and it must be supplied; replace_latest-this input represents replace the latest folder and the data type is boolean. The workflow has one job. The job id of the 1st job is `javadocs`. The job `javadocs` has 7 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Setup Java 21`. The 3rd step is named `Setup Gradle`. The 4th step is named `build javadoc`. The 5th step is named `Copy javadoc to deploy folder`. The 6th step is named `Copy javadoc to latest folder`. The 7th step is named `Deploy javadoc to gh pages`. ","prompt_level3":"Generate a GitHub Workflow named `Dispatch: Deploy Javadoc` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 2 inputs: target_tag-this input represents version to generate javadoc and it must be supplied; replace_latest-this input represents replace the latest folder and the data type is boolean. The workflow has one job. The job id of the 1st job is `javadocs`. This job will run on ubuntu-latest runner. The job `javadocs` has 7 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `ref` is set to `${{ inputs.target_tag }}`. The 2nd step is named `Setup Java 21`. This step runs action `actions/setup-java` tagged as v4. The step defines 3 input parameters for the action: `java-version` is set to `21`, `distribution` is set to `adopt` and `cache` is set to `gradle`. The 3rd step is named `Setup Gradle`. This step runs action `gradle/actions/setup-gradle` tagged as v4. The 4th step is named `build javadoc`. The step sets 2 environment variables to use: `GITHUB_TOKEN` is set to `${{ secrets.GITHUB_TOKEN }}` and `GITHUB_VERSION` is set to `${{ inputs.target_tag }}`. This step runs a script: `./gradlew javadoc`. The 5th step is named `Copy javadoc to deploy folder`. This step runs a script: `mkdir -p build/docs/javadoc-deploy/${{ inputs.target_tag }}\ncp -r build/docs/javadoc/* build/docs/javadoc-deploy/${{ inputs.target_tag }}\n`. The 6th step is named `Copy javadoc to latest folder`. This step will run only if the condition(inputs.replace_latest) is met. This step runs a script: `mkdir -p build/docs/javadoc-deploy/latest\ncp -r build/docs/javadoc/* build/docs/javadoc-deploy/latest\n`. The 7th step is named `Deploy javadoc to gh pages`. This step runs action `JamesIves/github-pages-deploy-action` tagged as v4. The step defines 6 input parameters for the action: `token` is set to `${{ secrets.GITHUB_TOKEN }}`, `folder` is set to `build/docs/javadoc-deploy`, `branch` is set to `javadoc`, `target-folder` is set to `javadoc`, `clean` is set to `False` and `commit-message` is set to `Deploy javadoc for ${{ inputs.target_tag }}`. ","nb_triggers":1,"triggers":["workflow_dispatch"],"nb_jobs":1,"nb_actions":4,"actions":["JamesIves/github-pages-deploy-action","actions/checkout","actions/setup-java","gradle/actions/setup-gradle"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/setup-java"},{"version":"v4","name":"gradle/actions/setup-gradle"},{"version":"v4","name":"JamesIves/github-pages-deploy-action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":7,"cyclomatic_complexity":1}
{"id":33538,"repository_id":61686483,"mainLanguage":"Python","file_name":"release_and_deploy.yml","file_content":"# release_and_deploy\nname: Release and Deploy\n\non:\n  push:\n    tags:\n      - 'release-v*.*.*'\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.x'\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install setuptools wheel twine\n\n      - name: Build and publish package\n        env:\n          TWINE_USERNAME: ${{ secrets.PYPI_USERNAME }}\n          TWINE_PASSWORD: ${{ secrets.PYPI_PASSWORD }}\n        run: |\n          python setup.py sdist bdist_wheel\n          twine upload dist/*\n\n      - name: Create GitHub release\n        uses: softprops/action-gh-release@v2\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n","repository_owner":"akfamily","repository_name":"akshare","tokens_count":211,"workflow":"# release_and_deploy\nname: Release and Deploy\n\non:\n  push:\n    tags:\n    - release-v*.*.*\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Set up Python\n      uses: actions/setup-python@v5\n      with:\n        python-version: 3.x\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install setuptools wheel twine\n\n    - name: Build and publish package\n      env:\n        TWINE_USERNAME: ${{ secrets.PYPI_USERNAME }}\n        TWINE_PASSWORD: ${{ secrets.PYPI_PASSWORD }}\n      run: |\n        python setup.py sdist bdist_wheel\n        twine upload dist/*\n\n    - name: Create GitHub release\n      uses: softprops/action-gh-release@v2\n      with:\n        token: ${{ secrets.GITHUB_TOKEN }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Release and Deploy` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a tag whose name matches release-v*.*.*. The workflow has one job. The job id of the 1st job is `deploy`. ","prompt_level2":"Generate a GitHub Workflow named `Release and Deploy` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a tag whose name matches release-v*.*.*. The workflow has one job. The job id of the 1st job is `deploy`. The job `deploy` has 5 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up Python`. The 3rd step is named `Install dependencies`. The 4th step is named `Build and publish package`. The 5th step is named `Create GitHub release`. ","prompt_level3":"Generate a GitHub Workflow named `Release and Deploy` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a tag whose name matches release-v*.*.*. The workflow has one job. The job id of the 1st job is `deploy`. This job will run on ubuntu-latest runner. The job `deploy` has 5 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Set up Python`. This step runs action `actions/setup-python` tagged as v5. The step defines an input parameter for the action: `python-version` is set to `3.x`. The 3rd step is named `Install dependencies`. This step runs a script: `python -m pip install --upgrade pip\npip install setuptools wheel twine\n`. The 4th step is named `Build and publish package`. The step sets 2 environment variables to use: `TWINE_USERNAME` is set to `${{ secrets.PYPI_USERNAME }}` and `TWINE_PASSWORD` is set to `${{ secrets.PYPI_PASSWORD }}`. This step runs a script: `python setup.py sdist bdist_wheel\ntwine upload dist/*\n`. The 5th step is named `Create GitHub release`. This step runs action `softprops/action-gh-release` tagged as v2. The step defines an input parameter for the action: `token` is set to `${{ secrets.GITHUB_TOKEN }}`. ","nb_triggers":1,"triggers":["push"],"nb_jobs":1,"nb_actions":3,"actions":["actions/checkout","actions/setup-python","softprops/action-gh-release"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v5","name":"actions/setup-python"},{"version":"v2","name":"softprops/action-gh-release"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":5,"cyclomatic_complexity":1}
{"id":3147,"repository_id":3978477,"mainLanguage":"C++","file_name":"build-cibw.yml","file_content":"# This workflow builds the Python wheels using cibuildwheel and uploads them to TestPyPI.\n# It can be triggered on push to the develop branch or manually via Github Actions.\n\nname: Build Wheels (cibuildwheel)\n\non:\n  push:\n    branches:\n      - develop\n  workflow_dispatch:\n\njobs:\n  # Get the system time and store it in an output. This is used to tag the wheels.\n  # This needs to be done in a separate job so that each matrix job in build_wheels can\n  # access the same timestamp.\n  get_system_time:\n    name: Get System Time\n    runs-on: ubuntu-latest\n    outputs:\n      timestamp: ${{ steps.get_time.outputs.timestamp }}\n    steps:\n      - name: Get system time\n        id: get_time\n        run: echo \"timestamp=$(date +'%Y%m%d%H%M')\" >> \"$GITHUB_OUTPUT\"\n\n  build_wheels:\n    name: Build Wheels\n    needs: get_system_time\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          # Linux x86_64\n          - os: ubuntu-latest\n            python_version: \"3.10\"\n            cibw_python_version: 310\n            platform_id: manylinux_x86_64\n            manylinux_image: manylinux2014\n          - os: ubuntu-latest\n            python_version: \"3.11\"\n            cibw_python_version: 311\n            platform_id: manylinux_x86_64\n            manylinux_image: manylinux2014\n          - os: ubuntu-latest\n            python_version: \"3.12\"\n            cibw_python_version: 312\n            platform_id: manylinux_x86_64\n            manylinux_image: manylinux2014\n          - os: ubuntu-latest\n            python_version: \"3.13\"\n            cibw_python_version: 313\n            platform_id: manylinux_x86_64\n            manylinux_image: manylinux2014\n\n          # Linux aarch64\n          - os: ubuntu-24.04-arm\n            python_version: \"3.10\"\n            cibw_python_version: 310\n            platform_id: manylinux_aarch64\n            manylinux_image: manylinux2014\n          - os: ubuntu-24.04-arm\n            python_version: \"3.11\"\n            cibw_python_version: 311\n            platform_id: manylinux_aarch64\n            manylinux_image: manylinux2014\n          - os: ubuntu-24.04-arm\n            python_version: \"3.12\"\n            cibw_python_version: 312\n            platform_id: manylinux_aarch64\n            manylinux_image: manylinux2014\n          - os: ubuntu-24.04-arm\n            python_version: \"3.13\"\n            cibw_python_version: 313\n            platform_id: manylinux_aarch64\n            manylinux_image: manylinux2014\n\n          # MacOS x86_64\n          - os: macos-13\n            python_version: \"3.10\"\n            cibw_python_version: 310\n            platform_id: macosx_x86_64\n          - os: macos-13\n            python_version: \"3.11\"\n            cibw_python_version: 311\n            platform_id: macosx_x86_64\n          - os: macos-13\n            python_version: \"3.12\"\n            cibw_python_version: 312\n            platform_id: macosx_x86_64\n          - os: macos-13\n            python_version: \"3.13\"\n            cibw_python_version: 313\n            platform_id: macosx_x86_64\n\n          # MacOS arm64\n          - os: macos-14\n            python_version: \"3.10\"\n            cibw_python_version: 310\n            platform_id: macosx_arm64\n          - os: macos-14\n            python_version: \"3.11\"\n            cibw_python_version: 311\n            platform_id: macosx_arm64\n          - os: macos-14\n            python_version: \"3.12\"\n            cibw_python_version: 312\n            platform_id: macosx_arm64\n          - os: macos-14\n            python_version: \"3.13\"\n            cibw_python_version: 313\n            platform_id: macosx_arm64\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Python ${{ matrix.python_version }}\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python_version }}\n\n      # Set the DEVELOP flag and the TIMESTAMP environment variables. This is used in the\n      # top-level CMakeLists.txt to generate the GTSAM_VERSION_STRING.\n      - name: Set Develop Flag\n        run: |\n          echo \"DEVELOP=1\" >> $GITHUB_ENV\n          echo \"TIMESTAMP=${{ needs.get_system_time.outputs.timestamp }}\" >> $GITHUB_ENV\n\n      - name: Install Dependencies\n        run: |\n          python3 -m pip install -r python/dev_requirements.txt\n          if [ \"$RUNNER_OS\" == \"Linux\" ]; then\n            sudo apt-get install -y wget libicu-dev python3-pip python3-setuptools libboost-all-dev ninja-build\n          elif [ \"$RUNNER_OS\" == \"macOS\" ]; then\n            brew install wget icu4c boost ninja python-setuptools\n          else\n            echo \"$RUNNER_OS not supported\"\n            exit 1\n          fi\n\n      # We first build the Python wrapper module on the host machine. This is done because cibuildwheel\n      # expects a setup.py file to be present in the project directory.\n      #\n      # The Python wrapper module is then rebuilt within the cibuildwheel container before building\n      # the wheels to ensure platform compatibility.\n      - name: Run CMake\n        run: |\n          cmake . -B build -DGTSAM_BUILD_PYTHON=1 -DGTSAM_PYTHON_VERSION=${{ matrix.python_version }}\n\n      # If on macOS, we previously installed boost using homebrew for the first build.\n      # We need to uninstall it before building the wheels with cibuildwheel, which will\n      # install boost from source.\n      - name: Uninstall Boost (MacOS)\n        if: runner.os == 'macOS'\n        run: |\n          brew uninstall boost\n\n      - name: Build and test wheels\n        env:\n          # Generate the platform identifier. See https://cibuildwheel.pypa.io/en/stable/options/#build-skip.\n          CIBW_BUILD: cp${{ matrix.cibw_python_version }}-${{ matrix.platform_id }}\n          CIBW_MANYLINUX_X86_64_IMAGE: ${{ matrix.manylinux_image }}\n          CIBW_MANYLINUX_AARCH64_IMAGE: ${{ matrix.manylinux_image }}\n          CIBW_ARCHS: all\n          CIBW_ENVIRONMENT_PASS_LINUX: DEVELOP TIMESTAMP\n\n          # Set the minimum required MacOS version for the wheels.\n          MACOSX_DEPLOYMENT_TARGET: 10.15\n\n          # Set DYLD_LIBRARY_PATH to REPAIR_LIBRARY_PATH, which is set in cibw_before_all.sh. REPAIR_LIBRARY_PATH\n          # simply appends BOOST_LIBRARYDIR to the path, which is required during during link-time repair.\n          CIBW_REPAIR_WHEEL_COMMAND_MACOS: DYLD_LIBRARY_PATH=$REPAIR_LIBRARY_PATH delocate-wheel --require-archs {delocate_archs} -w {dest_dir} -v {wheel}\n\n          # Use build instead of pip wheel to build the wheels. This is recommended by PyPA.\n          # See https://cibuildwheel.pypa.io/en/stable/options/#build-frontend.\n          CIBW_BUILD_FRONTEND: \"build\"\n          CIBW_BEFORE_ALL: bash .github/scripts/python_wheels/cibw_before_all.sh ${{ matrix.python_version }} {project}\n\n          CIBW_BUILD_VERBOSITY: 1\n\n        run: bash .github/scripts/python_wheels/build_wheels.sh\n\n      - name: Store artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: cibw-wheels-cp${{ matrix.cibw_python_version }}-${{ matrix.platform_id }}\n          path: wheelhouse/*.whl\n\n  upload_all:\n    name: Upload All\n    needs: build_wheels\n    runs-on: ubuntu-latest\n    permissions:\n      id-token: write\n    steps:\n      - name: Download Artifacts\n        uses: actions/download-artifact@v4\n        with:\n          path: dist/\n          merge-multiple: true\n\n      - name: Publish to PyPI\n        uses: pypa/gh-action-pypi-publish@release/v1\n        with:\n          verbose: true\n          packages-dir: dist/\n          # repository-url: https://test.pypi.org/legacy/\n","repository_owner":"borglab","repository_name":"gtsam","tokens_count":2051,"workflow":"# This workflow builds the Python wheels using cibuildwheel and uploads them to TestPyPI.\n# It can be triggered on push to the develop branch or manually via Github Actions.\n\nname: Build Wheels (cibuildwheel)\n\non:\n  push:\n    branches:\n    - develop\n  workflow_dispatch:\n\njobs:\n  # Get the system time and store it in an output. This is used to tag the wheels.\n  # This needs to be done in a separate job so that each matrix job in build_wheels can\n  # access the same timestamp.\n  get_system_time:\n    name: Get System Time\n    runs-on: ubuntu-latest\n    outputs:\n      timestamp: ${{ steps.get_time.outputs.timestamp }}\n    steps:\n    - name: Get system time\n      id: get_time\n      run: echo \"timestamp=$(date +'%Y%m%d%H%M')\" >> \"$GITHUB_OUTPUT\"\n\n  build_wheels:\n    name: Build Wheels\n    needs: get_system_time\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          # Linux x86_64\n        - os: ubuntu-latest\n          python_version: '3.10'\n          cibw_python_version: 310\n          platform_id: manylinux_x86_64\n          manylinux_image: manylinux2014\n        - os: ubuntu-latest\n          python_version: '3.11'\n          cibw_python_version: 311\n          platform_id: manylinux_x86_64\n          manylinux_image: manylinux2014\n        - os: ubuntu-latest\n          python_version: '3.12'\n          cibw_python_version: 312\n          platform_id: manylinux_x86_64\n          manylinux_image: manylinux2014\n        - os: ubuntu-latest\n          python_version: '3.13'\n          cibw_python_version: 313\n          platform_id: manylinux_x86_64\n          manylinux_image: manylinux2014\n\n          # Linux aarch64\n        - os: ubuntu-24.04-arm\n          python_version: '3.10'\n          cibw_python_version: 310\n          platform_id: manylinux_aarch64\n          manylinux_image: manylinux2014\n        - os: ubuntu-24.04-arm\n          python_version: '3.11'\n          cibw_python_version: 311\n          platform_id: manylinux_aarch64\n          manylinux_image: manylinux2014\n        - os: ubuntu-24.04-arm\n          python_version: '3.12'\n          cibw_python_version: 312\n          platform_id: manylinux_aarch64\n          manylinux_image: manylinux2014\n        - os: ubuntu-24.04-arm\n          python_version: '3.13'\n          cibw_python_version: 313\n          platform_id: manylinux_aarch64\n          manylinux_image: manylinux2014\n\n          # MacOS x86_64\n        - os: macos-13\n          python_version: '3.10'\n          cibw_python_version: 310\n          platform_id: macosx_x86_64\n        - os: macos-13\n          python_version: '3.11'\n          cibw_python_version: 311\n          platform_id: macosx_x86_64\n        - os: macos-13\n          python_version: '3.12'\n          cibw_python_version: 312\n          platform_id: macosx_x86_64\n        - os: macos-13\n          python_version: '3.13'\n          cibw_python_version: 313\n          platform_id: macosx_x86_64\n\n          # MacOS arm64\n        - os: macos-14\n          python_version: '3.10'\n          cibw_python_version: 310\n          platform_id: macosx_arm64\n        - os: macos-14\n          python_version: '3.11'\n          cibw_python_version: 311\n          platform_id: macosx_arm64\n        - os: macos-14\n          python_version: '3.12'\n          cibw_python_version: 312\n          platform_id: macosx_arm64\n        - os: macos-14\n          python_version: '3.13'\n          cibw_python_version: 313\n          platform_id: macosx_arm64\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v4\n\n    - name: Set up Python ${{ matrix.python_version }}\n      uses: actions/setup-python@v5\n      with:\n        python-version: ${{ matrix.python_version }}\n\n      # Set the DEVELOP flag and the TIMESTAMP environment variables. This is used in the\n      # top-level CMakeLists.txt to generate the GTSAM_VERSION_STRING.\n    - name: Set Develop Flag\n      run: |\n        echo \"DEVELOP=1\" >> $GITHUB_ENV\n        echo \"TIMESTAMP=${{ needs.get_system_time.outputs.timestamp }}\" >> $GITHUB_ENV\n\n    - name: Install Dependencies\n      run: |\n        python3 -m pip install -r python/dev_requirements.txt\n        if [ \"$RUNNER_OS\" == \"Linux\" ]; then\n          sudo apt-get install -y wget libicu-dev python3-pip python3-setuptools libboost-all-dev ninja-build\n        elif [ \"$RUNNER_OS\" == \"macOS\" ]; then\n          brew install wget icu4c boost ninja python-setuptools\n        else\n          echo \"$RUNNER_OS not supported\"\n          exit 1\n        fi\n\n      # We first build the Python wrapper module on the host machine. This is done because cibuildwheel\n      # expects a setup.py file to be present in the project directory.\n      #\n      # The Python wrapper module is then rebuilt within the cibuildwheel container before building\n      # the wheels to ensure platform compatibility.\n    - name: Run CMake\n      run: |\n        cmake . -B build -DGTSAM_BUILD_PYTHON=1 -DGTSAM_PYTHON_VERSION=${{ matrix.python_version }}\n\n      # If on macOS, we previously installed boost using homebrew for the first build.\n      # We need to uninstall it before building the wheels with cibuildwheel, which will\n      # install boost from source.\n    - name: Uninstall Boost (MacOS)\n      if: runner.os == 'macOS'\n      run: |\n        brew uninstall boost\n\n    - name: Build and test wheels\n      env:\n          # Generate the platform identifier. See https://cibuildwheel.pypa.io/en/stable/options/#build-skip.\n        CIBW_BUILD: cp${{ matrix.cibw_python_version }}-${{ matrix.platform_id \n          }}\n        CIBW_MANYLINUX_X86_64_IMAGE: ${{ matrix.manylinux_image }}\n        CIBW_MANYLINUX_AARCH64_IMAGE: ${{ matrix.manylinux_image }}\n        CIBW_ARCHS: all\n        CIBW_ENVIRONMENT_PASS_LINUX: DEVELOP TIMESTAMP\n\n          # Set the minimum required MacOS version for the wheels.\n        MACOSX_DEPLOYMENT_TARGET: 10.15\n\n          # Set DYLD_LIBRARY_PATH to REPAIR_LIBRARY_PATH, which is set in cibw_before_all.sh. REPAIR_LIBRARY_PATH\n          # simply appends BOOST_LIBRARYDIR to the path, which is required during during link-time repair.\n        CIBW_REPAIR_WHEEL_COMMAND_MACOS: DYLD_LIBRARY_PATH=$REPAIR_LIBRARY_PATH \n          delocate-wheel --require-archs {delocate_archs} -w {dest_dir} -v \n          {wheel}\n\n          # Use build instead of pip wheel to build the wheels. This is recommended by PyPA.\n          # See https://cibuildwheel.pypa.io/en/stable/options/#build-frontend.\n        CIBW_BUILD_FRONTEND: build\n        CIBW_BEFORE_ALL: bash .github/scripts/python_wheels/cibw_before_all.sh \n          ${{ matrix.python_version }} {project}\n\n        CIBW_BUILD_VERBOSITY: 1\n\n      run: bash .github/scripts/python_wheels/build_wheels.sh\n\n    - name: Store artifacts\n      uses: actions/upload-artifact@v4\n      with:\n        name: cibw-wheels-cp${{ matrix.cibw_python_version }}-${{ \n          matrix.platform_id }}\n        path: wheelhouse/*.whl\n\n  upload_all:\n    name: Upload All\n    needs: build_wheels\n    runs-on: ubuntu-latest\n    permissions:\n      id-token: write\n    steps:\n    - name: Download Artifacts\n      uses: actions/download-artifact@v4\n      with:\n        path: dist/\n        merge-multiple: true\n\n    - name: Publish to PyPI\n      uses: pypa/gh-action-pypi-publish@release/v1\n      with:\n        verbose: true\n        packages-dir: dist/\n          # repository-url: https://test.pypi.org/legacy/\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Build Wheels (cibuildwheel)` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named develop. 2) someone manually triggers the workflow. The workflow has 3 jobs. The 1st job is named `Get System Time` and its job id is `get_system_time`. The 2nd job is named `Build Wheels` and its job id is `build_wheels`. The 3rd job is named `Upload All` and its job id is `upload_all`. ","prompt_level2":"Generate a GitHub Workflow named `Build Wheels (cibuildwheel)` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named develop. 2) someone manually triggers the workflow. The workflow has 3 jobs. The 1st job is named `Get System Time` and its job id is `get_system_time`. The job `get_system_time` has one step. The 1st step is named `Get system time` and its id is `get_time`. The 2nd job is named `Build Wheels` and its job id is `build_wheels`. The job `build_wheels` has 8 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up Python ${{ matrix.python_version }}`. The 3rd step is named `Set Develop Flag`. The 4th step is named `Install Dependencies`. The 5th step is named `Run CMake`. The 6th step is named `Uninstall Boost (MacOS)`. The 7th step is named `Build and test wheels`. The 8th step is named `Store artifacts`. The 3rd job is named `Upload All` and its job id is `upload_all`. The job `upload_all` has 2 steps. The 1st step is named `Download Artifacts`. The 2nd step is named `Publish to PyPI`. ","prompt_level3":"Generate a GitHub Workflow named `Build Wheels (cibuildwheel)` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named develop. 2) someone manually triggers the workflow. The workflow has 3 jobs. The 1st job is named `Get System Time` and its job id is `get_system_time`. This job will run on ubuntu-latest runner. The job `get_system_time` has one step. The 1st step is named `Get system time` and its id is `get_time`. This step runs a script: `echo \"timestamp=$(date +'%Y%m%d%H%M')\" >> \"$GITHUB_OUTPUT\"`. This job has an output: `timestamp` is defined as ${{ steps.get_time.outputs.timestamp }}. The 2nd job is named `Build Wheels` and its job id is `build_wheels`. Before this job runs, `get_system_time` must complete successfully. This job will run on ${{ matrix.os }} runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. For each object in the [{'os': 'ubuntu-latest', 'python_version': '3.10', 'cibw_python_version': 310, 'platform_id': 'manylinux_x86_64', 'manylinux_image': 'manylinux2014'}, {'os': 'ubuntu-latest', 'python_version': '3.11', 'cibw_python_version': 311, 'platform_id': 'manylinux_x86_64', 'manylinux_image': 'manylinux2014'}, {'os': 'ubuntu-latest', 'python_version': '3.12', 'cibw_python_version': 312, 'platform_id': 'manylinux_x86_64', 'manylinux_image': 'manylinux2014'}, {'os': 'ubuntu-latest', 'python_version': '3.13', 'cibw_python_version': 313, 'platform_id': 'manylinux_x86_64', 'manylinux_image': 'manylinux2014'}, {'os': 'ubuntu-24.04-arm', 'python_version': '3.10', 'cibw_python_version': 310, 'platform_id': 'manylinux_aarch64', 'manylinux_image': 'manylinux2014'}, {'os': 'ubuntu-24.04-arm', 'python_version': '3.11', 'cibw_python_version': 311, 'platform_id': 'manylinux_aarch64', 'manylinux_image': 'manylinux2014'}, {'os': 'ubuntu-24.04-arm', 'python_version': '3.12', 'cibw_python_version': 312, 'platform_id': 'manylinux_aarch64', 'manylinux_image': 'manylinux2014'}, {'os': 'ubuntu-24.04-arm', 'python_version': '3.13', 'cibw_python_version': 313, 'platform_id': 'manylinux_aarch64', 'manylinux_image': 'manylinux2014'}, {'os': 'macos-13', 'python_version': '3.10', 'cibw_python_version': 310, 'platform_id': 'macosx_x86_64'}, {'os': 'macos-13', 'python_version': '3.11', 'cibw_python_version': 311, 'platform_id': 'macosx_x86_64'}, {'os': 'macos-13', 'python_version': '3.12', 'cibw_python_version': 312, 'platform_id': 'macosx_x86_64'}, {'os': 'macos-13', 'python_version': '3.13', 'cibw_python_version': 313, 'platform_id': 'macosx_x86_64'}, {'os': 'macos-14', 'python_version': '3.10', 'cibw_python_version': 310, 'platform_id': 'macosx_arm64'}, {'os': 'macos-14', 'python_version': '3.11', 'cibw_python_version': 311, 'platform_id': 'macosx_arm64'}, {'os': 'macos-14', 'python_version': '3.12', 'cibw_python_version': 312, 'platform_id': 'macosx_arm64'}, {'os': 'macos-14', 'python_version': '3.13', 'cibw_python_version': 313, 'platform_id': 'macosx_arm64'}] list, the key:value pairs in the object will be added to each of the matrix combinations if none of the key:value pairs overwrite any of the original matrix values. If the object cannot be added to any of the matrix combinations, a new matrix combination will be created instead. The job `build_wheels` has 8 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Set up Python ${{ matrix.python_version }}`. This step runs action `actions/setup-python` tagged as v5. The step defines an input parameter for the action: `python-version` is set to `${{ matrix.python_version }}`. The 3rd step is named `Set Develop Flag`. This step runs a script: `echo \"DEVELOP=1\" >> $GITHUB_ENV\necho \"TIMESTAMP=${{ needs.get_system_time.outputs.timestamp }}\" >> $GITHUB_ENV\n`. The 4th step is named `Install Dependencies`. This step runs a script: `python3 -m pip install -r python/dev_requirements.txt\nif [ \"$RUNNER_OS\" == \"Linux\" ]; then\n  sudo apt-get install -y wget libicu-dev python3-pip python3-setuptools libboost-all-dev ninja-build\nelif [ \"$RUNNER_OS\" == \"macOS\" ]; then\n  brew install wget icu4c boost ninja python-setuptools\nelse\n  echo \"$RUNNER_OS not supported\"\n  exit 1\nfi\n`. The 5th step is named `Run CMake`. This step runs a script: `cmake . -B build -DGTSAM_BUILD_PYTHON=1 -DGTSAM_PYTHON_VERSION=${{ matrix.python_version }}\n`. The 6th step is named `Uninstall Boost (MacOS)`. This step will run only if the condition(runner.os == 'macOS') is met. This step runs a script: `brew uninstall boost\n`. The 7th step is named `Build and test wheels`. The step sets 10 environment variables to use: `CIBW_BUILD` is set to `cp${{ matrix.cibw_python_version }}-${{ matrix.platform_id }}`, `CIBW_MANYLINUX_X86_64_IMAGE` is set to `${{ matrix.manylinux_image }}`, `CIBW_MANYLINUX_AARCH64_IMAGE` is set to `${{ matrix.manylinux_image }}`, `CIBW_ARCHS` is set to `all`, `CIBW_ENVIRONMENT_PASS_LINUX` is set to `DEVELOP TIMESTAMP`, `MACOSX_DEPLOYMENT_TARGET` is set to `10.15`, `CIBW_REPAIR_WHEEL_COMMAND_MACOS` is set to `DYLD_LIBRARY_PATH=$REPAIR_LIBRARY_PATH delocate-wheel --require-archs {delocate_archs} -w {dest_dir} -v {wheel}`, `CIBW_BUILD_FRONTEND` is set to `build`, `CIBW_BEFORE_ALL` is set to `bash .github/scripts/python_wheels/cibw_before_all.sh ${{ matrix.python_version }} {project}` and `CIBW_BUILD_VERBOSITY` is set to `1`. This step runs a script: `bash .github/scripts/python_wheels/build_wheels.sh`. The 8th step is named `Store artifacts`. This step runs action `actions/upload-artifact` tagged as v4. The step defines 2 input parameters for the action: `name` is set to `cibw-wheels-cp${{ matrix.cibw_python_version }}-${{ matrix.platform_id }}` and `path` is set to `wheelhouse/*.whl`. The 3rd job is named `Upload All` and its job id is `upload_all`. Before this job runs, `build_wheels` must complete successfully. This job will run on ubuntu-latest runner. The job `upload_all` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting only applies to the job `upload_all`. The job `upload_all` has 2 steps. The 1st step is named `Download Artifacts`. This step runs action `actions/download-artifact` tagged as v4. The step defines 2 input parameters for the action: `path` is set to `dist/` and `merge-multiple` is set to `True`. The 2nd step is named `Publish to PyPI`. This step runs action `pypa/gh-action-pypi-publish` from the release/v1 branch. The step defines 2 input parameters for the action: `verbose` is set to `True` and `packages-dir` is set to `dist/`. ","nb_triggers":2,"triggers":["push","workflow_dispatch"],"nb_jobs":3,"nb_actions":5,"actions":["actions/checkout","actions/download-artifact","actions/setup-python","actions/upload-artifact","pypa/gh-action-pypi-publish"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v5","name":"actions/setup-python"},{"version":"v4","name":"actions/upload-artifact"},{"version":"v4","name":"actions/download-artifact"},{"version":"release/v1","name":"pypa/gh-action-pypi-publish"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":11,"cyclomatic_complexity":1}
{"id":62474,"repository_id":94694176,"mainLanguage":"PHP","file_name":"verify-release.yml","file_content":"name: Verify release\n\non:\n  # Run whenever a release is published.\n  release:\n    types: [published]\n  # And whenever this workflow is updated.\n  push:\n    paths:\n      - '.github/workflows/verify-release.yml'\n  pull_request:\n    paths:\n      - '.github/workflows/verify-release.yml'\n  # Allow manually triggering the workflow.\n  workflow_dispatch:\n\n# Cancels all previous workflow runs for the same branch that have not yet completed.\nconcurrency:\n  # The concurrency group contains the workflow name and the branch name.\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  ##################################################################################\n  # Verify the release is available in all the right places and works as expected. #\n  ##################################################################################\n  verify-available-downloads:\n    runs-on: ubuntu-latest\n\n    # Only run this workflow in the context of this repo.\n    if: github.repository_owner == 'PHPCSStandards'\n\n    strategy:\n      fail-fast: false\n      matrix:\n        download_flavour:\n          - \"Release assets\"\n          - \"Unversioned web\"\n          - \"Versioned web\"\n        pharfile:\n          - 'phpcs'\n          - 'phpcbf'\n\n    name: \"${{ matrix.download_flavour }}: ${{ matrix.pharfile }}\"\n\n    steps:\n      - name: Retrieve latest release info\n        uses: octokit/request-action@v2.x\n        id: get_latest_release\n        with:\n          route: GET /repos/PHPCSStandards/PHP_CodeSniffer/releases/latest\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: \"DEBUG: Show API request failure status\"\n        if: ${{ failure() }}\n        run: \"echo No release found. Request failed with status ${{ steps.get_latest_release.outputs.status }}\"\n\n      - name: Grab latest tag name from API response\n        id: version\n        run: |\n          echo \"TAG=${{ fromJson(steps.get_latest_release.outputs.data).tag_name }}\" >> \"$GITHUB_OUTPUT\"\n\n      - name: \"DEBUG: Show tag name found in API response\"\n        run: \"echo ${{ steps.version.outputs.TAG }}\"\n\n      - name: Set source URL and file name\n        id: source\n        shell: bash\n        run: |\n          if [[ \"${{ matrix.download_flavour }}\" == \"Release assets\" ]]; then\n            echo 'SRC=https://github.com/PHPCSStandards/PHP_CodeSniffer/releases/latest/download/' >> \"$GITHUB_OUTPUT\"\n            echo \"FILE=${{ matrix.pharfile }}.phar\" >> \"$GITHUB_OUTPUT\"\n          elif [[ \"${{ matrix.download_flavour }}\" == \"Unversioned web\" ]]; then\n            echo 'SRC=https://phars.phpcodesniffer.com/' >> \"$GITHUB_OUTPUT\"\n            echo \"FILE=${{ matrix.pharfile }}.phar\" >> \"$GITHUB_OUTPUT\"\n          else\n            echo 'SRC=https://phars.phpcodesniffer.com/phars/' >> \"$GITHUB_OUTPUT\"\n            echo \"FILE=${{ matrix.pharfile }}-${{ steps.version.outputs.TAG }}.phar\" >> \"$GITHUB_OUTPUT\"\n          fi\n\n      - name: Verify PHAR file is available and download\n        run: \"wget -O ${{ steps.source.outputs.FILE }} ${{ steps.source.outputs.SRC }}${{ steps.source.outputs.FILE }}\"\n\n      - name: Verify signature file is available and download\n        run: \"wget -O ${{ steps.source.outputs.FILE }}.asc ${{ steps.source.outputs.SRC }}${{ steps.source.outputs.FILE }}.asc\"\n\n      - name: \"DEBUG: List files\"\n        run: ls -Rlh\n\n      - name: Verify attestation of the PHAR file\n        run: gh attestation verify ${{ steps.source.outputs.FILE }} -o PHPCSStandards\n        env:\n          GH_TOKEN: ${{ github.token }}\n          GH_FORCE_TTY: true\n\n      - name: Download public key\n        env:\n          FINGERPRINT: \"0x689DAD778FF08760E046228BA978220305CD5C32\"\n        run: gpg --keyserver \"hkps://keys.openpgp.org\" --recv-keys \"$FINGERPRINT\"\n\n      - name: Verify signature of the PHAR file\n        run: gpg --verify ${{ steps.source.outputs.FILE }}.asc ${{ steps.source.outputs.FILE }}\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: 'latest'\n          ini-values: error_reporting=-1, display_errors=On\n          coverage: none\n\n      # Note: the `.` is in the command to make it work for both PHPCS as well PHPCBF.\n      - name: Verify the PHAR is nominally functional\n        run: php ${{ steps.source.outputs.FILE }} . -e --standard=PSR12\n\n      - name: Grab the version\n        id: asset_version\n        env:\n          FILE_NAME: ${{ steps.source.outputs.FILE }}\n        # yamllint disable-line rule:line-length\n        run: echo \"VERSION=$(php \"$FILE_NAME\" --version | grep --only-matching --max-count=1 --extended-regexp '\\b[0-9]+(\\.[0-9]+)+')\" >> \"$GITHUB_OUTPUT\"\n\n      - name: \"DEBUG: Show grabbed version\"\n        run: echo ${{ steps.asset_version.outputs.VERSION }}\n\n      - name: Fail the build if the PHAR is not the correct version\n        if: ${{ steps.asset_version.outputs.VERSION != steps.version.outputs.TAG }}\n        run: exit 1\n\n  # #########################################\n  # Verify install via PHIVE.\n  # #########################################\n  verify-phive:\n    runs-on: ubuntu-latest\n\n    # Only run this workflow in the context of this repo.\n    if: github.repository_owner == 'PHPCSStandards'\n\n    strategy:\n      fail-fast: false\n      matrix:\n        pharfile:\n          - 'phpcs'\n          - 'phpcbf'\n\n    name: \"PHIVE: ${{ matrix.pharfile }}\"\n\n    steps:\n      - name: Retrieve latest release info\n        uses: octokit/request-action@v2.x\n        id: get_latest_release\n        with:\n          route: GET /repos/PHPCSStandards/PHP_CodeSniffer/releases/latest\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: \"DEBUG: Show API request failure status\"\n        if: ${{ failure() }}\n        run: \"echo No release found. Request failed with status ${{ steps.get_latest_release.outputs.status }}\"\n\n      - name: Grab latest tag name from API response\n        id: version\n        run: |\n          echo \"TAG=${{ fromJson(steps.get_latest_release.outputs.data).tag_name }}\" >> \"$GITHUB_OUTPUT\"\n\n      - name: \"DEBUG: Show tag name found in API response\"\n        run: \"echo ${{ steps.version.outputs.TAG }}\"\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: 'latest'\n          ini-values: error_reporting=-1, display_errors=On\n          coverage: none\n          tools: phive\n\n      - name: Install\n        run: phive install ${{ matrix.pharfile }} --copy --trust-gpg-keys 689DAD778FF08760E046228BA978220305CD5C32\n\n      - name: \"DEBUG: List files\"\n        run: ls -R\n\n      - name: Verify attestation of the PHAR file\n        run: gh attestation verify ./tools/${{ matrix.pharfile }} -o PHPCSStandards\n        env:\n          GH_TOKEN: ${{ github.token }}\n          GH_FORCE_TTY: true\n\n      # Note: the `.` is in the command to make it work for both PHPCS as well PHPCBF.\n      - name: Verify the PHAR is nominally functional\n        run: php ./tools/${{ matrix.pharfile }} . -e --standard=PSR12\n\n      - name: Grab the version\n        id: asset_version\n        env:\n          FILE_NAME: ./tools/${{ matrix.pharfile }}\n        # yamllint disable-line rule:line-length\n        run: echo \"VERSION=$(php \"$FILE_NAME\" --version | grep --only-matching --max-count=1 --extended-regexp '\\b[0-9]+(\\.[0-9]+)+')\" >> \"$GITHUB_OUTPUT\"\n\n      - name: \"DEBUG: Show grabbed version\"\n        run: echo ${{ steps.asset_version.outputs.VERSION }}\n\n      - name: Fail the build if the PHAR is not the correct version\n        if: ${{ steps.asset_version.outputs.VERSION != steps.version.outputs.TAG }}\n        run: exit 1\n","repository_owner":"PHPCSStandards","repository_name":"PHP_CodeSniffer","tokens_count":1910,"workflow":"name: Verify release\n\non:\n  # Run whenever a release is published.\n  release:\n    types: [published]\n  # And whenever this workflow is updated.\n  push:\n    paths:\n    - .github/workflows/verify-release.yml\n  pull_request:\n    paths:\n    - .github/workflows/verify-release.yml\n  # Allow manually triggering the workflow.\n  workflow_dispatch:\n\n# Cancels all previous workflow runs for the same branch that have not yet completed.\nconcurrency:\n  # The concurrency group contains the workflow name and the branch name.\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  ##################################################################################\n  # Verify the release is available in all the right places and works as expected. #\n  ##################################################################################\n  verify-available-downloads:\n    runs-on: ubuntu-latest\n\n    # Only run this workflow in the context of this repo.\n    if: github.repository_owner == 'PHPCSStandards'\n\n    strategy:\n      fail-fast: false\n      matrix:\n        download_flavour:\n        - Release assets\n        - Unversioned web\n        - Versioned web\n        pharfile:\n        - phpcs\n        - phpcbf\n\n    name: '${{ matrix.download_flavour }}: ${{ matrix.pharfile }}'\n\n    steps:\n    - name: Retrieve latest release info\n      uses: octokit/request-action@v2.x\n      id: get_latest_release\n      with:\n        route: GET /repos/PHPCSStandards/PHP_CodeSniffer/releases/latest\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n    - name: 'DEBUG: Show API request failure status'\n      if: ${{ failure() }}\n      run: echo No release found. Request failed with status ${{ \n        steps.get_latest_release.outputs.status }}\n\n    - name: Grab latest tag name from API response\n      id: version\n      run: |\n        echo \"TAG=${{ fromJson(steps.get_latest_release.outputs.data).tag_name }}\" >> \"$GITHUB_OUTPUT\"\n\n    - name: 'DEBUG: Show tag name found in API response'\n      run: echo ${{ steps.version.outputs.TAG }}\n\n    - name: Set source URL and file name\n      id: source\n      shell: bash\n      run: |\n        if [[ \"${{ matrix.download_flavour }}\" == \"Release assets\" ]]; then\n          echo 'SRC=https://github.com/PHPCSStandards/PHP_CodeSniffer/releases/latest/download/' >> \"$GITHUB_OUTPUT\"\n          echo \"FILE=${{ matrix.pharfile }}.phar\" >> \"$GITHUB_OUTPUT\"\n        elif [[ \"${{ matrix.download_flavour }}\" == \"Unversioned web\" ]]; then\n          echo 'SRC=https://phars.phpcodesniffer.com/' >> \"$GITHUB_OUTPUT\"\n          echo \"FILE=${{ matrix.pharfile }}.phar\" >> \"$GITHUB_OUTPUT\"\n        else\n          echo 'SRC=https://phars.phpcodesniffer.com/phars/' >> \"$GITHUB_OUTPUT\"\n          echo \"FILE=${{ matrix.pharfile }}-${{ steps.version.outputs.TAG }}.phar\" >> \"$GITHUB_OUTPUT\"\n        fi\n\n    - name: Verify PHAR file is available and download\n      run: wget -O ${{ steps.source.outputs.FILE }} ${{ steps.source.outputs.SRC\n        }}${{ steps.source.outputs.FILE }}\n\n    - name: Verify signature file is available and download\n      run: wget -O ${{ steps.source.outputs.FILE }}.asc ${{ \n        steps.source.outputs.SRC }}${{ steps.source.outputs.FILE }}.asc\n\n    - name: 'DEBUG: List files'\n      run: ls -Rlh\n\n    - name: Verify attestation of the PHAR file\n      run: gh attestation verify ${{ steps.source.outputs.FILE }} -o \n        PHPCSStandards\n      env:\n        GH_TOKEN: ${{ github.token }}\n        GH_FORCE_TTY: true\n\n    - name: Download public key\n      env:\n        FINGERPRINT: '0x689DAD778FF08760E046228BA978220305CD5C32'\n      run: gpg --keyserver \"hkps://keys.openpgp.org\" --recv-keys \"$FINGERPRINT\"\n\n    - name: Verify signature of the PHAR file\n      run: gpg --verify ${{ steps.source.outputs.FILE }}.asc ${{ \n        steps.source.outputs.FILE }}\n\n    - name: Setup PHP\n      uses: shivammathur/setup-php@v2\n      with:\n        php-version: latest\n        ini-values: error_reporting=-1, display_errors=On\n        coverage: none\n\n      # Note: the `.` is in the command to make it work for both PHPCS as well PHPCBF.\n    - name: Verify the PHAR is nominally functional\n      run: php ${{ steps.source.outputs.FILE }} . -e --standard=PSR12\n\n    - name: Grab the version\n      id: asset_version\n      env:\n        FILE_NAME: ${{ steps.source.outputs.FILE }}\n        # yamllint disable-line rule:line-length\n      run: echo \"VERSION=$(php \"$FILE_NAME\" --version | grep --only-matching \n        --max-count=1 --extended-regexp '\\b[0-9]+(\\.[0-9]+)+')\" >> \n        \"$GITHUB_OUTPUT\"\n\n    - name: 'DEBUG: Show grabbed version'\n      run: echo ${{ steps.asset_version.outputs.VERSION }}\n\n    - name: Fail the build if the PHAR is not the correct version\n      if: ${{ steps.asset_version.outputs.VERSION != steps.version.outputs.TAG \n        }}\n      run: exit 1\n\n  # #########################################\n  # Verify install via PHIVE.\n  # #########################################\n  verify-phive:\n    runs-on: ubuntu-latest\n\n    # Only run this workflow in the context of this repo.\n    if: github.repository_owner == 'PHPCSStandards'\n\n    strategy:\n      fail-fast: false\n      matrix:\n        pharfile:\n        - phpcs\n        - phpcbf\n\n    name: 'PHIVE: ${{ matrix.pharfile }}'\n\n    steps:\n    - name: Retrieve latest release info\n      uses: octokit/request-action@v2.x\n      id: get_latest_release\n      with:\n        route: GET /repos/PHPCSStandards/PHP_CodeSniffer/releases/latest\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n    - name: 'DEBUG: Show API request failure status'\n      if: ${{ failure() }}\n      run: echo No release found. Request failed with status ${{ \n        steps.get_latest_release.outputs.status }}\n\n    - name: Grab latest tag name from API response\n      id: version\n      run: |\n        echo \"TAG=${{ fromJson(steps.get_latest_release.outputs.data).tag_name }}\" >> \"$GITHUB_OUTPUT\"\n\n    - name: 'DEBUG: Show tag name found in API response'\n      run: echo ${{ steps.version.outputs.TAG }}\n\n    - name: Setup PHP\n      uses: shivammathur/setup-php@v2\n      with:\n        php-version: latest\n        ini-values: error_reporting=-1, display_errors=On\n        coverage: none\n        tools: phive\n\n    - name: Install\n      run: phive install ${{ matrix.pharfile }} --copy --trust-gpg-keys \n        689DAD778FF08760E046228BA978220305CD5C32\n\n    - name: 'DEBUG: List files'\n      run: ls -R\n\n    - name: Verify attestation of the PHAR file\n      run: gh attestation verify ./tools/${{ matrix.pharfile }} -o \n        PHPCSStandards\n      env:\n        GH_TOKEN: ${{ github.token }}\n        GH_FORCE_TTY: true\n\n      # Note: the `.` is in the command to make it work for both PHPCS as well PHPCBF.\n    - name: Verify the PHAR is nominally functional\n      run: php ./tools/${{ matrix.pharfile }} . -e --standard=PSR12\n\n    - name: Grab the version\n      id: asset_version\n      env:\n        FILE_NAME: ./tools/${{ matrix.pharfile }}\n        # yamllint disable-line rule:line-length\n      run: echo \"VERSION=$(php \"$FILE_NAME\" --version | grep --only-matching \n        --max-count=1 --extended-regexp '\\b[0-9]+(\\.[0-9]+)+')\" >> \n        \"$GITHUB_OUTPUT\"\n\n    - name: 'DEBUG: Show grabbed version'\n      run: echo ${{ steps.asset_version.outputs.VERSION }}\n\n    - name: Fail the build if the PHAR is not the correct version\n      if: ${{ steps.asset_version.outputs.VERSION != steps.version.outputs.TAG \n        }}\n      run: exit 1\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Verify release` for a GitHub repository whose primary programming language is PHP. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) Only if at least one path of push event matches a pattern in the paths filter(.github/workflows/verify-release.yml), the workflow runs. 3) Only if at least one path of pull_request event matches a pattern in the paths filter(.github/workflows/verify-release.yml), the workflow runs. 4) someone manually triggers the workflow. Only a single workflow using the ${{ github.workflow }}-${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has 2 jobs. The 1st job is named `${{ matrix.download_flavour }}: ${{ matrix.pharfile }}` and its job id is `verify-available-downloads`. The 2nd job is named `PHIVE: ${{ matrix.pharfile }}` and its job id is `verify-phive`. ","prompt_level2":"Generate a GitHub Workflow named `Verify release` for a GitHub repository whose primary programming language is PHP. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) Only if at least one path of push event matches a pattern in the paths filter(.github/workflows/verify-release.yml), the workflow runs. 3) Only if at least one path of pull_request event matches a pattern in the paths filter(.github/workflows/verify-release.yml), the workflow runs. 4) someone manually triggers the workflow. Only a single workflow using the ${{ github.workflow }}-${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has 2 jobs. The 1st job is named `${{ matrix.download_flavour }}: ${{ matrix.pharfile }}` and its job id is `verify-available-downloads`. The job `verify-available-downloads` has 16 steps. The 1st step is named `Retrieve latest release info` and its id is `get_latest_release`. The 2nd step is named `DEBUG: Show API request failure status`. The 3rd step is named `Grab latest tag name from API response` and its id is `version`. The 4th step is named `DEBUG: Show tag name found in API response`. The 5th step is named `Set source URL and file name` and its id is `source`. The 6th step is named `Verify PHAR file is available and download`. The 7th step is named `Verify signature file is available and download`. The 8th step is named `DEBUG: List files`. The 9th step is named `Verify attestation of the PHAR file`. The 10th step is named `Download public key`. The 11th step is named `Verify signature of the PHAR file`. The 12th step is named `Setup PHP`. The 13th step is named `Verify the PHAR is nominally functional`. The 14th step is named `Grab the version` and its id is `asset_version`. The 15th step is named `DEBUG: Show grabbed version`. The 16th step is named `Fail the build if the PHAR is not the correct version`. The 2nd job is named `PHIVE: ${{ matrix.pharfile }}` and its job id is `verify-phive`. The job `verify-phive` has 12 steps. The 1st step is named `Retrieve latest release info` and its id is `get_latest_release`. The 2nd step is named `DEBUG: Show API request failure status`. The 3rd step is named `Grab latest tag name from API response` and its id is `version`. The 4th step is named `DEBUG: Show tag name found in API response`. The 5th step is named `Setup PHP`. The 6th step is named `Install`. The 7th step is named `DEBUG: List files`. The 8th step is named `Verify attestation of the PHAR file`. The 9th step is named `Verify the PHAR is nominally functional`. The 10th step is named `Grab the version` and its id is `asset_version`. The 11th step is named `DEBUG: Show grabbed version`. The 12th step is named `Fail the build if the PHAR is not the correct version`. ","prompt_level3":"Generate a GitHub Workflow named `Verify release` for a GitHub repository whose primary programming language is PHP. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) Only if at least one path of push event matches a pattern in the paths filter(.github/workflows/verify-release.yml), the workflow runs. 3) Only if at least one path of pull_request event matches a pattern in the paths filter(.github/workflows/verify-release.yml), the workflow runs. 4) someone manually triggers the workflow. Only a single workflow using the ${{ github.workflow }}-${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has 2 jobs. The 1st job is named `${{ matrix.download_flavour }}: ${{ matrix.pharfile }}` and its job id is `verify-available-downloads`. This job will run only if the condition(github.repository_owner == 'PHPCSStandards') is met. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `download_flavour` has 3 values: Release assets, Unversioned web and Versioned web. The variable `pharfile` has 2 values: phpcs and phpcbf. The job `verify-available-downloads` has 16 steps. The 1st step is named `Retrieve latest release info` and its id is `get_latest_release`. The step sets an environment variable to use: `GITHUB_TOKEN` is set to `${{ secrets.GITHUB_TOKEN }}`. This step runs action `octokit/request-action` from the v2.x branch. The step defines an input parameter for the action: `route` is set to `GET /repos/PHPCSStandards/PHP_CodeSniffer/releases/latest`. The 2nd step is named `DEBUG: Show API request failure status`. This step will run only if the condition(${{ failure() }}) is met. This step runs a script: `echo No release found. Request failed with status ${{ steps.get_latest_release.outputs.status }}`. The 3rd step is named `Grab latest tag name from API response` and its id is `version`. This step runs a script: `echo \"TAG=${{ fromJson(steps.get_latest_release.outputs.data).tag_name }}\" >> \"$GITHUB_OUTPUT\"\n`. The 4th step is named `DEBUG: Show tag name found in API response`. This step runs a script: `echo ${{ steps.version.outputs.TAG }}`. The 5th step is named `Set source URL and file name` and its id is `source`. This step uses bash to run a script: `if [[ \"${{ matrix.download_flavour }}\" == \"Release assets\" ]]; then\n  echo 'SRC=https://github.com/PHPCSStandards/PHP_CodeSniffer/releases/latest/download/' >> \"$GITHUB_OUTPUT\"\n  echo \"FILE=${{ matrix.pharfile }}.phar\" >> \"$GITHUB_OUTPUT\"\nelif [[ \"${{ matrix.download_flavour }}\" == \"Unversioned web\" ]]; then\n  echo 'SRC=https://phars.phpcodesniffer.com/' >> \"$GITHUB_OUTPUT\"\n  echo \"FILE=${{ matrix.pharfile }}.phar\" >> \"$GITHUB_OUTPUT\"\nelse\n  echo 'SRC=https://phars.phpcodesniffer.com/phars/' >> \"$GITHUB_OUTPUT\"\n  echo \"FILE=${{ matrix.pharfile }}-${{ steps.version.outputs.TAG }}.phar\" >> \"$GITHUB_OUTPUT\"\nfi\n`. The 6th step is named `Verify PHAR file is available and download`. This step runs a script: `wget -O ${{ steps.source.outputs.FILE }} ${{ steps.source.outputs.SRC }}${{ steps.source.outputs.FILE }}`. The 7th step is named `Verify signature file is available and download`. This step runs a script: `wget -O ${{ steps.source.outputs.FILE }}.asc ${{ steps.source.outputs.SRC }}${{ steps.source.outputs.FILE }}.asc`. The 8th step is named `DEBUG: List files`. This step runs a script: `ls -Rlh`. The 9th step is named `Verify attestation of the PHAR file`. The step sets 2 environment variables to use: `GH_TOKEN` is set to `${{ github.token }}` and `GH_FORCE_TTY` is set to `True`. This step runs a script: `gh attestation verify ${{ steps.source.outputs.FILE }} -o PHPCSStandards`. The 10th step is named `Download public key`. The step sets an environment variable to use: `FINGERPRINT` is set to `0x689DAD778FF08760E046228BA978220305CD5C32`. This step runs a script: `gpg --keyserver \"hkps://keys.openpgp.org\" --recv-keys \"$FINGERPRINT\"`. The 11th step is named `Verify signature of the PHAR file`. This step runs a script: `gpg --verify ${{ steps.source.outputs.FILE }}.asc ${{ steps.source.outputs.FILE }}`. The 12th step is named `Setup PHP`. This step runs action `shivammathur/setup-php` tagged as v2. The step defines 3 input parameters for the action: `php-version` is set to `latest`, `ini-values` is set to `error_reporting=-1, display_errors=On` and `coverage` is set to `none`. The 13th step is named `Verify the PHAR is nominally functional`. This step runs a script: `php ${{ steps.source.outputs.FILE }} . -e --standard=PSR12`. The 14th step is named `Grab the version` and its id is `asset_version`. The step sets an environment variable to use: `FILE_NAME` is set to `${{ steps.source.outputs.FILE }}`. This step runs a script: `echo \"VERSION=$(php \"$FILE_NAME\" --version | grep --only-matching --max-count=1 --extended-regexp '\\b[0-9]+(\\.[0-9]+)+')\" >> \"$GITHUB_OUTPUT\"`. The 15th step is named `DEBUG: Show grabbed version`. This step runs a script: `echo ${{ steps.asset_version.outputs.VERSION }}`. The 16th step is named `Fail the build if the PHAR is not the correct version`. This step will run only if the condition(${{ steps.asset_version.outputs.VERSION != steps.version.outputs.TAG }}) is met. This step runs a script: `exit 1`. The 2nd job is named `PHIVE: ${{ matrix.pharfile }}` and its job id is `verify-phive`. This job will run only if the condition(github.repository_owner == 'PHPCSStandards') is met. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `pharfile` has 2 values: phpcs and phpcbf. The job `verify-phive` has 12 steps. The 1st step is named `Retrieve latest release info` and its id is `get_latest_release`. The step sets an environment variable to use: `GITHUB_TOKEN` is set to `${{ secrets.GITHUB_TOKEN }}`. This step runs action `octokit/request-action` from the v2.x branch. The step defines an input parameter for the action: `route` is set to `GET /repos/PHPCSStandards/PHP_CodeSniffer/releases/latest`. The 2nd step is named `DEBUG: Show API request failure status`. This step will run only if the condition(${{ failure() }}) is met. This step runs a script: `echo No release found. Request failed with status ${{ steps.get_latest_release.outputs.status }}`. The 3rd step is named `Grab latest tag name from API response` and its id is `version`. This step runs a script: `echo \"TAG=${{ fromJson(steps.get_latest_release.outputs.data).tag_name }}\" >> \"$GITHUB_OUTPUT\"\n`. The 4th step is named `DEBUG: Show tag name found in API response`. This step runs a script: `echo ${{ steps.version.outputs.TAG }}`. The 5th step is named `Setup PHP`. This step runs action `shivammathur/setup-php` tagged as v2. The step defines 4 input parameters for the action: `php-version` is set to `latest`, `ini-values` is set to `error_reporting=-1, display_errors=On`, `coverage` is set to `none` and `tools` is set to `phive`. The 6th step is named `Install`. This step runs a script: `phive install ${{ matrix.pharfile }} --copy --trust-gpg-keys 689DAD778FF08760E046228BA978220305CD5C32`. The 7th step is named `DEBUG: List files`. This step runs a script: `ls -R`. The 8th step is named `Verify attestation of the PHAR file`. The step sets 2 environment variables to use: `GH_TOKEN` is set to `${{ github.token }}` and `GH_FORCE_TTY` is set to `True`. This step runs a script: `gh attestation verify ./tools/${{ matrix.pharfile }} -o PHPCSStandards`. The 9th step is named `Verify the PHAR is nominally functional`. This step runs a script: `php ./tools/${{ matrix.pharfile }} . -e --standard=PSR12`. The 10th step is named `Grab the version` and its id is `asset_version`. The step sets an environment variable to use: `FILE_NAME` is set to `./tools/${{ matrix.pharfile }}`. This step runs a script: `echo \"VERSION=$(php \"$FILE_NAME\" --version | grep --only-matching --max-count=1 --extended-regexp '\\b[0-9]+(\\.[0-9]+)+')\" >> \"$GITHUB_OUTPUT\"`. The 11th step is named `DEBUG: Show grabbed version`. This step runs a script: `echo ${{ steps.asset_version.outputs.VERSION }}`. The 12th step is named `Fail the build if the PHAR is not the correct version`. This step will run only if the condition(${{ steps.asset_version.outputs.VERSION != steps.version.outputs.TAG }}) is met. This step runs a script: `exit 1`. ","nb_triggers":4,"triggers":["pull_request","push","release","workflow_dispatch"],"nb_jobs":2,"nb_actions":4,"actions":["octokit/request-action","octokit/request-action","shivammathur/setup-php","shivammathur/setup-php"],"actions_details":[{"version":"v2.x","name":"octokit/request-action"},{"version":"v2","name":"shivammathur/setup-php"},{"version":"v2.x","name":"octokit/request-action"},{"version":"v2","name":"shivammathur/setup-php"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":28,"cyclomatic_complexity":2}
{"id":1439,"repository_id":48988728,"mainLanguage":"Shell","file_name":"scheduled-runs.yml","file_content":"name: \n\non:\n  pull_request:\n    paths:  # only changes to this workflow itself trigger PR testing\n    - .github/workflows/scheduled-runs.yml\n  schedule:\n  - cron: 3 5 * * *  # run daily at 5:03 UTC\n  workflow_dispatch:  # manual trigger\n\npermissions:\n  contents: read\n\nrun-name: >-\n  \n  Nightly run of\n  ${{\n      github.event.pull_request.number && 'PR' || ''\n  }}${{\n      !github.event.pull_request.number && 'Commit' || ''\n  }}\n  ${{ github.event.pull_request.number || github.sha }}\n  triggered by: ${{ github.event_name }} of ${{\n    github.ref\n  }} ${{\n    github.ref_type\n  }}\n  (workflow run ID: ${{\n    github.run_id\n  }}; number: ${{\n    github.run_number\n  }}; attempt: ${{\n    github.run_attempt\n  }})\n\njobs:\n  main-ci-cd-pipeline:\n    name:  Main CI/CD pipeline\n    uses: ./.github/workflows/ci-cd.yml\n    secrets: inherit\n","repository_owner":"antonbabenko","repository_name":"pre-commit-terraform","tokens_count":251,"workflow":"name: \n\non:\n  pull_request:\n    paths:  # only changes to this workflow itself trigger PR testing\n    - .github/workflows/scheduled-runs.yml\n  schedule:\n  - cron: 3 5 * * *  # run daily at 5:03 UTC\n  workflow_dispatch:  # manual trigger\n\npermissions:\n  contents: read\n\nrun-name: >-\n  \n  Nightly run of\n  ${{\n      github.event.pull_request.number && 'PR' || ''\n  }}${{\n      !github.event.pull_request.number && 'Commit' || ''\n  }}\n  ${{ github.event.pull_request.number || github.sha }}\n  triggered by: ${{ github.event_name }} of ${{\n    github.ref\n  }} ${{\n    github.ref_type\n  }}\n  (workflow run ID: ${{\n    github.run_id\n  }}; number: ${{\n    github.run_number\n  }}; attempt: ${{\n    github.run_attempt\n  }})\n\njobs:\n  main-ci-cd-pipeline:\n    name:  Main CI/CD pipeline\n    uses: ./.github/workflows/ci-cd.yml\n    secrets: inherit\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `` for a GitHub repository whose primary programming language is Shell. The name for workflow runs is set to ` Nightly run of ${{\n    github.event.pull_request.number && 'PR' || ''\n}}${{\n    !github.event.pull_request.number && 'Commit' || ''\n}} ${{ github.event.pull_request.number || github.sha }} triggered by: ${{ github.event_name }} of ${{\n  github.ref\n}} ${{\n  github.ref_type\n}} (workflow run ID: ${{\n  github.run_id\n}}; number: ${{\n  github.run_number\n}}; attempt: ${{\n  github.run_attempt\n}})`. This workflow will be triggered by multiple events: 1) Only if at least one path of pull_request event matches a pattern in the paths filter(.github/workflows/scheduled-runs.yml), the workflow runs. 2) the scheduled time has come: at 05:03 am. 3) someone manually triggers the workflow. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named ` Main CI/CD pipeline` and its job id is `main-ci-cd-pipeline`. ","prompt_level2":"Generate a GitHub Workflow named `` for a GitHub repository whose primary programming language is Shell. The name for workflow runs is set to ` Nightly run of ${{\n    github.event.pull_request.number && 'PR' || ''\n}}${{\n    !github.event.pull_request.number && 'Commit' || ''\n}} ${{ github.event.pull_request.number || github.sha }} triggered by: ${{ github.event_name }} of ${{\n  github.ref\n}} ${{\n  github.ref_type\n}} (workflow run ID: ${{\n  github.run_id\n}}; number: ${{\n  github.run_number\n}}; attempt: ${{\n  github.run_attempt\n}})`. This workflow will be triggered by multiple events: 1) Only if at least one path of pull_request event matches a pattern in the paths filter(.github/workflows/scheduled-runs.yml), the workflow runs. 2) the scheduled time has come: at 05:03 am. 3) someone manually triggers the workflow. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named ` Main CI/CD pipeline` and its job id is `main-ci-cd-pipeline`. ","prompt_level3":"Generate a GitHub Workflow named `` for a GitHub repository whose primary programming language is Shell. The name for workflow runs is set to ` Nightly run of ${{\n    github.event.pull_request.number && 'PR' || ''\n}}${{\n    !github.event.pull_request.number && 'Commit' || ''\n}} ${{ github.event.pull_request.number || github.sha }} triggered by: ${{ github.event_name }} of ${{\n  github.ref\n}} ${{\n  github.ref_type\n}} (workflow run ID: ${{\n  github.run_id\n}}; number: ${{\n  github.run_number\n}}; attempt: ${{\n  github.run_attempt\n}})`. This workflow will be triggered by multiple events: 1) Only if at least one path of pull_request event matches a pattern in the paths filter(.github/workflows/scheduled-runs.yml), the workflow runs. 2) the scheduled time has come: at 05:03 am. 3) someone manually triggers the workflow. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named ` Main CI/CD pipeline` and its job id is `main-ci-cd-pipeline`. This job will call a reusable workflow located at `./.github/workflows/ci-cd.yml`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. ","nb_triggers":3,"triggers":["pull_request","schedule","workflow_dispatch"],"nb_jobs":1,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["./.github/workflows/ci-cd.yml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":38047,"repository_id":78545635,"mainLanguage":"JavaScript","file_name":"docker-image.yml","file_content":"name: Dejavu - Docker Publish Workflow\n\non:\n  release:\n    types: [published]\n  repository_dispatch:\n    types: [publish_docker]\n  workflow_dispatch:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout repository with submodules\n      uses: actions/checkout@v3\n      with:\n        submodules: recursive\n        fetch-depth: 0\n\n    - name: Extract version from payload\n      id: get_version\n      if: ${{ github.event_name == 'repository_dispatch' }}\n      run: echo \"version=${{ github.event.client_payload.version }}\" >> $GITHUB_OUTPUT\n\n    - name: Get Version For Release\n      id: get_version_release\n      if: ${{ github.event_name != 'repository_dispatch' }}\n      uses: battila7/get-version-action@v2.2.1\n\n    - name: Determine Version\n      id: set_version\n      run: |\n        if [ -n \"${{ steps.get_version.outputs.version }}\" ]; then\n          echo \"version=${{ steps.get_version.outputs.version }}\" >> $GITHUB_OUTPUT\n        elif [ -n \"${{ steps.get_version_release.outputs.version }}\" ]; then\n          echo \"version=${{ steps.get_version_release.outputs.version }}\" >> $GITHUB_OUTPUT\n        else\n          echo \"Error: Version is not set.\"\n          exit 1\n        fi\n\n    - name: Set up QEMU\n      uses: docker/setup-qemu-action@v2\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - name: Login to DockerHub\n      uses: docker/login-action@v2\n      with:\n        username: ${{ secrets.DOCKERHUB_USERNAME }}\n        password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n    - name: Build and push latest image\n      uses: docker/build-push-action@v4\n      with:\n        context: .\n        push: true\n        platforms: linux/amd64,linux/arm64\n        tags: |\n          appbaseio/dejavu:${{ steps.set_version.outputs.version }}\n          appbaseio/dejavu:latest","repository_owner":"appbaseio","repository_name":"dejavu","tokens_count":459,"workflow":"name: Dejavu - Docker Publish Workflow\n\non:\n  release:\n    types: [published]\n  repository_dispatch:\n    types: [publish_docker]\n  workflow_dispatch:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout repository with submodules\n      uses: actions/checkout@v3\n      with:\n        submodules: recursive\n        fetch-depth: 0\n\n    - name: Extract version from payload\n      id: get_version\n      if: ${{ github.event_name == 'repository_dispatch' }}\n      run: echo \"version=${{ github.event.client_payload.version }}\" >> \n        $GITHUB_OUTPUT\n\n    - name: Get Version For Release\n      id: get_version_release\n      if: ${{ github.event_name != 'repository_dispatch' }}\n      uses: battila7/get-version-action@v2.2.1\n\n    - name: Determine Version\n      id: set_version\n      run: |\n        if [ -n \"${{ steps.get_version.outputs.version }}\" ]; then\n          echo \"version=${{ steps.get_version.outputs.version }}\" >> $GITHUB_OUTPUT\n        elif [ -n \"${{ steps.get_version_release.outputs.version }}\" ]; then\n          echo \"version=${{ steps.get_version_release.outputs.version }}\" >> $GITHUB_OUTPUT\n        else\n          echo \"Error: Version is not set.\"\n          exit 1\n        fi\n\n    - name: Set up QEMU\n      uses: docker/setup-qemu-action@v2\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - name: Login to DockerHub\n      uses: docker/login-action@v2\n      with:\n        username: ${{ secrets.DOCKERHUB_USERNAME }}\n        password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n    - name: Build and push latest image\n      uses: docker/build-push-action@v4\n      with:\n        context: .\n        push: true\n        platforms: linux/amd64,linux/arm64\n        tags: |-\n          appbaseio/dejavu:${{ steps.set_version.outputs.version }}\n          appbaseio/dejavu:latest\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Dejavu - Docker Publish Workflow` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) a GitHub App sends a \"POST\" request to \"/repos/{owner}/{repo}/dispatches\" and its event type includes publish_docker. 3) someone manually triggers the workflow. The workflow has one job. The job id of the 1st job is `build`. ","prompt_level2":"Generate a GitHub Workflow named `Dejavu - Docker Publish Workflow` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) a GitHub App sends a \"POST\" request to \"/repos/{owner}/{repo}/dispatches\" and its event type includes publish_docker. 3) someone manually triggers the workflow. The workflow has one job. The job id of the 1st job is `build`. The job `build` has 8 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Extract version from payload` and its id is `get_version`. The 3rd step is named `Get Version For Release` and its id is `get_version_release`. The 4th step is named `Determine Version` and its id is `set_version`. The 5th step is named `Set up QEMU`. The 6th step is named `Set up Docker Buildx`. The 7th step is named `Login to DockerHub`. The 8th step is named `Build and push latest image`. ","prompt_level3":"Generate a GitHub Workflow named `Dejavu - Docker Publish Workflow` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) a GitHub App sends a \"POST\" request to \"/repos/{owner}/{repo}/dispatches\" and its event type includes publish_docker. 3) someone manually triggers the workflow. The workflow has one job. The job id of the 1st job is `build`. This job will run on ubuntu-latest runner. The job `build` has 8 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v3. The step defines 2 input parameters for the action: `submodules` is set to `recursive` and `fetch-depth` is set to `0`. The 2nd step is named `Extract version from payload` and its id is `get_version`. This step will run only if the condition(${{ github.event_name == 'repository_dispatch' }}) is met. This step runs a script: `echo \"version=${{ github.event.client_payload.version }}\" >> $GITHUB_OUTPUT`. The 3rd step is named `Get Version For Release` and its id is `get_version_release`. This step will run only if the condition(${{ github.event_name != 'repository_dispatch' }}) is met. This step runs action `battila7/get-version-action` tagged as v2.2.1. The 4th step is named `Determine Version` and its id is `set_version`. This step runs a script: `if [ -n \"${{ steps.get_version.outputs.version }}\" ]; then\n  echo \"version=${{ steps.get_version.outputs.version }}\" >> $GITHUB_OUTPUT\nelif [ -n \"${{ steps.get_version_release.outputs.version }}\" ]; then\n  echo \"version=${{ steps.get_version_release.outputs.version }}\" >> $GITHUB_OUTPUT\nelse\n  echo \"Error: Version is not set.\"\n  exit 1\nfi\n`. The 5th step is named `Set up QEMU`. This step runs action `docker/setup-qemu-action` tagged as v2. The 6th step is named `Set up Docker Buildx`. This step runs action `docker/setup-buildx-action` tagged as v2. The 7th step is named `Login to DockerHub`. This step runs action `docker/login-action` tagged as v2. The step defines 2 input parameters for the action: `username` is set to `${{ secrets.DOCKERHUB_USERNAME }}` and `password` is set to `${{ secrets.DOCKERHUB_TOKEN }}`. The 8th step is named `Build and push latest image`. This step runs action `docker/build-push-action` tagged as v4. The step defines 4 input parameters for the action: `context` is set to `.`, `push` is set to `True`, `platforms` is set to `linux/amd64,linux/arm64` and `tags` is set to `appbaseio/dejavu:${{ steps.set_version.outputs.version }}\nappbaseio/dejavu:latest`. ","nb_triggers":3,"triggers":["release","repository_dispatch","workflow_dispatch"],"nb_jobs":1,"nb_actions":6,"actions":["actions/checkout","battila7/get-version-action","docker/build-push-action","docker/login-action","docker/setup-buildx-action","docker/setup-qemu-action"],"actions_details":[{"version":"v3","name":"actions/checkout"},{"version":"v2.2.1","name":"battila7/get-version-action"},{"version":"v2","name":"docker/setup-qemu-action"},{"version":"v2","name":"docker/setup-buildx-action"},{"version":"v2","name":"docker/login-action"},{"version":"v4","name":"docker/build-push-action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":8,"cyclomatic_complexity":1}
{"id":9160,"repository_id":94586448,"mainLanguage":"Python","file_name":"pycafe-dashboards.yml","file_content":"name: PyCafe Playground Links\n\non:\n  workflow_run:\n    workflows: [Build]\n    types:\n      - completed\n\ndefaults:\n  run:\n    working-directory: vizro-core\nenv:\n  PYTHON_VERSION: \"3.12\"\n\njobs:\n  create-status:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n      - name: Install Hatch\n        run: pip install hatch\n      - name: Install Playwright and browser\n        run: |\n          hatch run pip install playwright\n          hatch run playwright install --with-deps chromium\n      # Below: only to have access to vizro-ai latest version in the test_pycafe_links.py and create_pycafe_links_comments.py scripts\n      - name: Install vizro-ai in editable mode to check compatibility with vizro-core and get the version\n        run: |\n          hatch run pip install ../vizro-ai\n      - name: Print PR Number\n        run: |\n          echo \"Pull Request Number: ${{ github.event.workflow_run.pull_requests[0].number }}\"\n      - name: Test if PyCafe links work with PR # Eventually we should merge this with the create_pycafe_links_comments.py script\n        run: |\n          hatch run python ../tools/pycafe/test_pycafe_links.py --github-token ${{ github.token }} --repo-name ${{ github.repository }} --run-id ${{ github.event.workflow_run.id }} --commit-sha ${{ github.event.workflow_run.head_sha }}\n      - name: Create PyCafe links\n        run: |\n          PR_NUMBER=${{ github.event.workflow_run.pull_requests[0].number || '' }}\n          if [ -n \"$PR_NUMBER\" ]; then\n            hatch run python ../tools/pycafe/create_pycafe_links_comments.py --github-token ${{ github.token }} --repo-name ${{ github.repository }} --pr-number $PR_NUMBER --run-id ${{ github.event.workflow_run.id }} --commit-sha ${{ github.event.workflow_run.head_sha }}\n          else\n            hatch run python ../tools/pycafe/create_pycafe_links_comments.py --github-token ${{ github.token }} --repo-name ${{ github.repository }} --run-id ${{ github.event.workflow_run.id }} --commit-sha ${{ github.event.workflow_run.head_sha }}\n          fi\n","repository_owner":"mckinsey","repository_name":"vizro","tokens_count":520,"workflow":"name: PyCafe Playground Links\n\non:\n  workflow_run:\n    workflows: [Build]\n    types:\n    - completed\n\ndefaults:\n  run:\n    working-directory: vizro-core\nenv:\n  PYTHON_VERSION: '3.12'\n\njobs:\n  create-status:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n    - name: Set up Python\n      uses: actions/setup-python@v5\n      with:\n        python-version: ${{ env.PYTHON_VERSION }}\n    - name: Install Hatch\n      run: pip install hatch\n    - name: Install Playwright and browser\n      run: |\n        hatch run pip install playwright\n        hatch run playwright install --with-deps chromium\n      # Below: only to have access to vizro-ai latest version in the test_pycafe_links.py and create_pycafe_links_comments.py scripts\n    - name: Install vizro-ai in editable mode to check compatibility with \n        vizro-core and get the version\n      run: |\n        hatch run pip install ../vizro-ai\n    - name: Print PR Number\n      run: |\n        echo \"Pull Request Number: ${{ github.event.workflow_run.pull_requests[0].number }}\"\n    - name: Test if PyCafe links work with PR   # Eventually we should merge this with the create_pycafe_links_comments.py script\n      run: |\n        hatch run python ../tools/pycafe/test_pycafe_links.py --github-token ${{ github.token }} --repo-name ${{ github.repository }} --run-id ${{ github.event.workflow_run.id }} --commit-sha ${{ github.event.workflow_run.head_sha }}\n    - name: Create PyCafe links\n      run: |\n        PR_NUMBER=${{ github.event.workflow_run.pull_requests[0].number || '' }}\n        if [ -n \"$PR_NUMBER\" ]; then\n          hatch run python ../tools/pycafe/create_pycafe_links_comments.py --github-token ${{ github.token }} --repo-name ${{ github.repository }} --pr-number $PR_NUMBER --run-id ${{ github.event.workflow_run.id }} --commit-sha ${{ github.event.workflow_run.head_sha }}\n        else\n          hatch run python ../tools/pycafe/create_pycafe_links_comments.py --github-token ${{ github.token }} --repo-name ${{ github.repository }} --run-id ${{ github.event.workflow_run.id }} --commit-sha ${{ github.event.workflow_run.head_sha }}\n        fi\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `PyCafe Playground Links` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: the workflow named Build is completed. The workflow sets an environment variable to use: `PYTHON_VERSION` is set to `3.12`. For all run steps in the workflow, default working directory is set to vizro-core. The workflow has one job. The job id of the 1st job is `create-status`. ","prompt_level2":"Generate a GitHub Workflow named `PyCafe Playground Links` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: the workflow named Build is completed. The workflow sets an environment variable to use: `PYTHON_VERSION` is set to `3.12`. For all run steps in the workflow, default working directory is set to vizro-core. The workflow has one job. The job id of the 1st job is `create-status`. The job `create-status` has 8 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up Python`. The 3rd step is named `Install Hatch`. The 4th step is named `Install Playwright and browser`. The 5th step is named `Install vizro-ai in editable mode to check compatibility with vizro-core and get the version`. The 6th step is named `Print PR Number`. The 7th step is named `Test if PyCafe links work with PR`. The 8th step is named `Create PyCafe links`. ","prompt_level3":"Generate a GitHub Workflow named `PyCafe Playground Links` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: the workflow named Build is completed. The workflow sets an environment variable to use: `PYTHON_VERSION` is set to `3.12`. For all run steps in the workflow, default working directory is set to vizro-core. The workflow has one job. The job id of the 1st job is `create-status`. This job will run on ubuntu-latest runner. The job `create-status` has 8 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Set up Python`. This step runs action `actions/setup-python` tagged as v5. The step defines an input parameter for the action: `python-version` is set to `${{ env.PYTHON_VERSION }}`. The 3rd step is named `Install Hatch`. This step runs a script: `pip install hatch`. The 4th step is named `Install Playwright and browser`. This step runs a script: `hatch run pip install playwright\nhatch run playwright install --with-deps chromium\n`. The 5th step is named `Install vizro-ai in editable mode to check compatibility with vizro-core and get the version`. This step runs a script: `hatch run pip install ../vizro-ai\n`. The 6th step is named `Print PR Number`. This step runs a script: `echo \"Pull Request Number: ${{ github.event.workflow_run.pull_requests[0].number }}\"\n`. The 7th step is named `Test if PyCafe links work with PR`. This step runs a script: `hatch run python ../tools/pycafe/test_pycafe_links.py --github-token ${{ github.token }} --repo-name ${{ github.repository }} --run-id ${{ github.event.workflow_run.id }} --commit-sha ${{ github.event.workflow_run.head_sha }}\n`. The 8th step is named `Create PyCafe links`. This step runs a script: `PR_NUMBER=${{ github.event.workflow_run.pull_requests[0].number || '' }}\nif [ -n \"$PR_NUMBER\" ]; then\n  hatch run python ../tools/pycafe/create_pycafe_links_comments.py --github-token ${{ github.token }} --repo-name ${{ github.repository }} --pr-number $PR_NUMBER --run-id ${{ github.event.workflow_run.id }} --commit-sha ${{ github.event.workflow_run.head_sha }}\nelse\n  hatch run python ../tools/pycafe/create_pycafe_links_comments.py --github-token ${{ github.token }} --repo-name ${{ github.repository }} --run-id ${{ github.event.workflow_run.id }} --commit-sha ${{ github.event.workflow_run.head_sha }}\nfi\n`. ","nb_triggers":1,"triggers":["workflow_run"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","actions/setup-python"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v5","name":"actions/setup-python"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":8,"cyclomatic_complexity":1}
{"id":59008,"repository_id":94709333,"mainLanguage":"Swift","file_name":"danger.yml","file_content":"name: CI and Danger\n\non:\n  pull_request:\n    branches:\n      - main\n      - develop\n\njobs:\n  ci:\n    name: CI Build and Tests\n    permissions: write-all\n    runs-on: macos-14\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n\n      - name: Set up Xcode\n        uses: maxim-lobanov/setup-xcode@v1\n        with:\n          xcode-version: '16.1'\n\n      - name: Build Swift Package Manager\n        run: |\n          xcodebuild clean build \\\n            -project Example_SwiftUI/Example_SwiftUI.xcodeproj \\\n            -scheme Example_SwiftUI \\\n            -destination 'platform=iOS Simulator,name=iPhone 16' \\\n\n      - name: Install CocoaPods\n        run: |\n          cd Example\n          pod install\n      \n      - name: Setup Danger\n        run: |\n          git clone https://github.com/DebugSwift/DangerSwift && rm -rf DangerSwift/.git Readme.md\n          mv DangerSwift/* .\n      \n      - name: Test Stage\n        run: |\n          cd Example\n          bundle install\n          bundle exec fastlane test\n\n      - name: Danger Stage\n        run: |\n          brew install danger/tap/danger-js\n          swift build\n          swift run danger-swift ci --verbose\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          DANGER_GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n","repository_owner":"DebugSwift","repository_name":"DebugSwift","tokens_count":328,"workflow":"name: CI and Danger\n\non:\n  pull_request:\n    branches:\n    - main\n    - develop\n\njobs:\n  ci:\n    name: CI Build and Tests\n    permissions: write-all\n    runs-on: macos-14\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Set up Xcode\n      uses: maxim-lobanov/setup-xcode@v1\n      with:\n        xcode-version: '16.1'\n\n    - name: Build Swift Package Manager\n      run: |\n        xcodebuild clean build \\\n          -project Example_SwiftUI/Example_SwiftUI.xcodeproj \\\n          -scheme Example_SwiftUI \\\n          -destination 'platform=iOS Simulator,name=iPhone 16' \\\n\n    - name: Install CocoaPods\n      run: |\n        cd Example\n        pod install\n\n    - name: Setup Danger\n      run: |\n        git clone https://github.com/DebugSwift/DangerSwift && rm -rf DangerSwift/.git Readme.md\n        mv DangerSwift/* .\n\n    - name: Test Stage\n      run: |\n        cd Example\n        bundle install\n        bundle exec fastlane test\n\n    - name: Danger Stage\n      run: |\n        brew install danger/tap/danger-js\n        swift build\n        swift run danger-swift ci --verbose\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        DANGER_GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `CI and Danger` for a GitHub repository whose primary programming language is Swift. This workflow will be triggered by an event: The workflow would run whenever there is a pull_request event targeting: a branch named main or a branch named develop. The workflow has one job. The 1st job is named `CI Build and Tests` and its job id is `ci`. ","prompt_level2":"Generate a GitHub Workflow named `CI and Danger` for a GitHub repository whose primary programming language is Swift. This workflow will be triggered by an event: The workflow would run whenever there is a pull_request event targeting: a branch named main or a branch named develop. The workflow has one job. The 1st job is named `CI Build and Tests` and its job id is `ci`. The job `ci` has 7 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up Xcode`. The 3rd step is named `Build Swift Package Manager`. The 4th step is named `Install CocoaPods`. The 5th step is named `Setup Danger`. The 6th step is named `Test Stage`. The 7th step is named `Danger Stage`. ","prompt_level3":"Generate a GitHub Workflow named `CI and Danger` for a GitHub repository whose primary programming language is Swift. This workflow will be triggered by an event: The workflow would run whenever there is a pull_request event targeting: a branch named main or a branch named develop. The workflow has one job. The 1st job is named `CI Build and Tests` and its job id is `ci`. This job will run on macos-14 runner. The job `ci` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN across all scopes. This permission setting only applies to the job `ci`. The job `ci` has 7 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Set up Xcode`. This step runs action `maxim-lobanov/setup-xcode` tagged as v1. The step defines an input parameter for the action: `xcode-version` is set to `16.1`. The 3rd step is named `Build Swift Package Manager`. This step runs a script: `xcodebuild clean build \\\n  -project Example_SwiftUI/Example_SwiftUI.xcodeproj \\\n  -scheme Example_SwiftUI \\\n  -destination 'platform=iOS Simulator,name=iPhone 16' \\\n`. The 4th step is named `Install CocoaPods`. This step runs a script: `cd Example\npod install\n`. The 5th step is named `Setup Danger`. This step runs a script: `git clone https://github.com/DebugSwift/DangerSwift && rm -rf DangerSwift/.git Readme.md\nmv DangerSwift/* .\n`. The 6th step is named `Test Stage`. This step runs a script: `cd Example\nbundle install\nbundle exec fastlane test\n`. The 7th step is named `Danger Stage`. The step sets 2 environment variables to use: `GITHUB_TOKEN` is set to `${{ secrets.GITHUB_TOKEN }}` and `DANGER_GITHUB_API_TOKEN` is set to `${{ secrets.GITHUB_TOKEN }}`. This step runs a script: `brew install danger/tap/danger-js\nswift build\nswift run danger-swift ci --verbose\n`. ","nb_triggers":1,"triggers":["pull_request"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","maxim-lobanov/setup-xcode"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v1","name":"maxim-lobanov/setup-xcode"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":7,"cyclomatic_complexity":1}
{"id":19676,"repository_id":3976043,"mainLanguage":"C++","file_name":"4_builderpackage_filebeat-package.yml","file_content":"run-name: Build ${{ inputs.system }} filebeat on ${{ inputs.architecture }} ${{ inputs.is_stage && '- is stage' || '' }} ${{ inputs.checksum && '- checksum' || '' }} ${{ inputs.id }}\nname: Build Filebeat\n\non:\n  workflow_dispatch:\n    inputs:\n      architecture:\n        description: |\n          Architecture of the package [amd64, arm64]\n        required: false\n        default: amd64\n        type: choice\n        options:\n          - amd64\n          - arm64\n      system:\n        description: |\n          Package format [deb, rpm]\n        required: false\n        default: deb\n        type: choice\n        options:\n          - deb\n          - rpm\n      revision:\n        description: |\n          Set the value to \"1\" for packages in release format.\n          You can also add other values, such as issue numbers.\n          By default, it is set to \"0\" for development.\n        default: \"0\"\n        type: string\n        required: false\n      is_stage:\n        description: |\n          Build package with release format.\n          By default: false\n        type: boolean\n        required: false\n      checksum:\n        description: Generate package checksum.\n        type: boolean\n        required: false\n      id:\n        type: string\n        description: |\n          ID used to identify the workflow uniquely.\n        required: false\n\n  workflow_call:\n    inputs:\n      architecture:\n        type: string\n        required: false\n      system:\n        type: string\n        required: false\n      revision:\n        default: \"0\"\n        type: string\n        required: false\n      is_stage:\n        type: boolean\n        required: false\n      checksum:\n        type: boolean\n        required: false\n      id:\n        type: string\n        required: false\n\njobs:\n  build-and-upload:\n    runs-on: ubuntu-latest\n    timeout-minutes: 60\n\n    env:\n      FILEBEAT_VERSION: 7.10.2\n      S3_BUCKET_PATH: s3://packages-dev.internal.wazuh.com/development/wazuh/4.x/secondary/filebeat/packages/\n\n    steps:\n      - name: Cancel previous runs\n        uses: fkirc/skip-duplicate-actions@master\n        with:\n          cancel_others: 'true'\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          skip_after_successful_duplicate: 'false'\n\n      - name: Checkout code\n        uses: actions/checkout@v4\n        with:\n          repository: \"elastic/beats\"\n          ref: \"v${{ env.FILEBEAT_VERSION }}\"\n\n      - name: Set up AWS CLI\n        uses: aws-actions/configure-aws-credentials@v1\n        with:\n          aws-access-key-id: ${{ secrets.CI_INTERNAL_DEVELOPMENT_BUCKET_USER_ACCESS_KEY }}\n          aws-secret-access-key: ${{ secrets.CI_INTERNAL_DEVELOPMENT_BUCKET_USER_SECRET_KEY }}\n          aws-region: ${{ secrets.CI_AWS_REGION }}\n\n      - name: Install dependencies\n        run: |\n          sudo apt update -y\n          sudo apt install -y gcc make golang-go python3-pip python3-venv\n          sudo apt install -y apt-transport-https ca-certificates curl software-properties-common\n          curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n          echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n          sudo apt update -y\n          sudo apt install -y docker-ce\n          export PATH=$PATH:/usr/local/go/bin\n          go get -u github.com/magefile/mage\n          echo \"$(go env GOPATH)/bin\" >> $GITHUB_PATH\n\n      - name: Apply patch for Ubuntu build\n        run: |\n          sed -i 's/apt-get install -y --no-install-recommends/DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends/' filebeat/Dockerfile\n\n          sed -i \"s/from: 'centos:7'/from: 'ubuntu:20.04'/g\" dev-tools/packaging/packages.yml\n          sed -i \"s/buildFrom: 'centos:7'/buildFrom: 'ubuntu:20.04'/g\" dev-tools/packaging/packages.yml\n\n          sed -i \"s/microdnf install -y shadow-utils/microdnf install -y findutils shadow-utils/g\" dev-tools/packaging/templates/docker/Dockerfile.elastic-agent.tmpl\n          sed -i '/RUN yum -y --setopt=tsflags=nodocs update && \\\\/, /yum clean all/c\\\n          RUN apt-get update -y && \\\\\\n    DEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends --yes ca-certificates curl libcap2-bin xz-utils && \\\\\\n    apt-get clean && \\\\\\n    exit_code=$? && \\\\\\n    [ $exit_code -eq 0 ] || exit $exit_code' dev-tools/packaging/templates/docker/Dockerfile.elastic-agent.tmpl\n\n          sed -i 's/microdnf install shadow-utils/microdnf install findutils shadow-utils/' dev-tools/packaging/templates/docker/Dockerfile.tmpl\n          sed -i '/RUN yum -y --setopt=tsflags=nodocs update && yum clean all/c\\\n          RUN apt-get update -y && \\\\\\n    DEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends --yes ca-certificates curl libcap2-bin xz-utils && \\\\\\n    apt-get clean && \\\\\\n    exit_code=$? && \\\\\\n    [ $exit_code -eq 0 ] || exit $exit_code' dev-tools/packaging/templates/docker/Dockerfile.tmpl\n\n          sed -i '/func TestDocker(t \\*testing\\.T) {/,/^}$/d' dev-tools/packaging/package_test.go\n\n      - name: Package Filebeat\n        working-directory: filebeat\n        run: |\n          PLATFORMS=linux/${{ inputs.architecture }} PACKAGES=${{ inputs.system }} mage package\n\n      - name: Upload Filebeat package to S3\n        working-directory: filebeat/build/distributions\n        run: |\n          if [ \"${{ inputs.system }}\" = \"rpm\" ]; then\n            if [ \"${{ inputs.architecture }}\" = \"amd64\" ]; then\n              arch=\"x86_64\"\n            elif [ \"${{ inputs.architecture }}\" = \"arm64\" ]; then\n              arch=\"aarch64\"\n            fi\n            revision=\"-${{ inputs.revision }}.\"\n          else\n            arch=\"${{ inputs.architecture }}\"\n            revision=\"-${{ inputs.revision }}_\"\n          fi\n\n          original_file=\"filebeat-oss-${{ env.FILEBEAT_VERSION }}-${arch}.${{ inputs.system }}\"\n          if [ \"${{ inputs.is_stage }}\" = \"false\" ]; then\n            git_hash=$(git rev-parse --short \"$GITHUB_SHA\")\n            renamed_file=\"filebeat-${{ env.FILEBEAT_VERSION }}${revision}${arch}_${git_hash}.${{ inputs.system }}\"\n          else\n            renamed_file=\"filebeat-${{ env.FILEBEAT_VERSION }}${revision}${arch}.${{ inputs.system }}\"\n          fi\n\n          mv \"$original_file\" \"$renamed_file\"\n          aws s3 cp \"$renamed_file\" \"${{ env.S3_BUCKET_PATH }}\"\n          s3uri=\"${{ env.S3_BUCKET_PATH }}$renamed_file\"\n          echo \"S3 URI: ${s3uri}\"\n\n      - name: Upload Filebeat module SHA512 to S3\n        if: ${{ inputs.checksum }}\n        working-directory: filebeat/build/distributions\n        run: |\n          if [ \"${{ inputs.system }}\" = \"rpm\" ]; then\n            if [ \"${{ inputs.architecture }}\" = \"amd64\" ]; then\n              arch=\"x86_64\"\n            elif [ \"${{ inputs.architecture }}\" = \"arm64\" ]; then\n              arch=\"aarch64\"\n            fi\n            revision=\"-${{ inputs.revision }}.\"\n          else\n            arch=\"${{ inputs.architecture }}\"\n            revision=\"-${{ inputs.revision }}_\"\n          fi\n\n          original_file=\"filebeat-oss-${{ env.FILEBEAT_VERSION }}-${arch}.${{ inputs.system }}.sha512\"\n          if [ \"${{ inputs.is_stage }}\" = \"false\" ]; then\n            git_hash=$(git rev-parse --short \"$GITHUB_SHA\")\n            renamed_file=\"filebeat-${{ env.FILEBEAT_VERSION }}${revision}${arch}_${git_hash}.${{ inputs.system }}.sha512\"\n          else\n            renamed_file=\"filebeat-${{ env.FILEBEAT_VERSION }}${revision}${arch}.${{ inputs.system }}.sha512\"\n          fi\n\n          mv \"$original_file\" \"$renamed_file\"\n          aws s3 cp \"$renamed_file\" \"${{ env.S3_BUCKET_PATH }}\"\n          s3uri=\"${{ env.S3_BUCKET_PATH }}$renamed_file\"\n          echo \"S3 sha512 URI: ${s3uri}\"","repository_owner":"wazuh","repository_name":"wazuh","tokens_count":2000,"workflow":"run-name: Build ${{ inputs.system }} filebeat on ${{ inputs.architecture }} ${{ \n  inputs.is_stage && '- is stage' || '' }} ${{ inputs.checksum && '- checksum' \n  || '' }} ${{ inputs.id }}\nname: Build Filebeat\n\non:\n  workflow_dispatch:\n    inputs:\n      architecture:\n        description: |\n          Architecture of the package [amd64, arm64]\n        required: false\n        default: amd64\n        type: choice\n        options:\n        - amd64\n        - arm64\n      system:\n        description: |\n          Package format [deb, rpm]\n        required: false\n        default: deb\n        type: choice\n        options:\n        - deb\n        - rpm\n      revision:\n        description: |\n          Set the value to \"1\" for packages in release format.\n          You can also add other values, such as issue numbers.\n          By default, it is set to \"0\" for development.\n        default: '0'\n        type: string\n        required: false\n      is_stage:\n        description: |\n          Build package with release format.\n          By default: false\n        type: boolean\n        required: false\n      checksum:\n        description: Generate package checksum.\n        type: boolean\n        required: false\n      id:\n        type: string\n        description: |\n          ID used to identify the workflow uniquely.\n        required: false\n\n  workflow_call:\n    inputs:\n      architecture:\n        type: string\n        required: false\n      system:\n        type: string\n        required: false\n      revision:\n        default: '0'\n        type: string\n        required: false\n      is_stage:\n        type: boolean\n        required: false\n      checksum:\n        type: boolean\n        required: false\n      id:\n        type: string\n        required: false\n\njobs:\n  build-and-upload:\n    runs-on: ubuntu-latest\n    timeout-minutes: 60\n\n    env:\n      FILEBEAT_VERSION: 7.10.2\n      S3_BUCKET_PATH: \n        s3://packages-dev.internal.wazuh.com/development/wazuh/4.x/secondary/filebeat/packages/\n\n    steps:\n    - name: Cancel previous runs\n      uses: fkirc/skip-duplicate-actions@master\n      with:\n        cancel_others: 'true'\n        github_token: ${{ secrets.GITHUB_TOKEN }}\n        skip_after_successful_duplicate: 'false'\n\n    - name: Checkout code\n      uses: actions/checkout@v4\n      with:\n        repository: elastic/beats\n        ref: v${{ env.FILEBEAT_VERSION }}\n\n    - name: Set up AWS CLI\n      uses: aws-actions/configure-aws-credentials@v1\n      with:\n        aws-access-key-id: ${{ \n          secrets.CI_INTERNAL_DEVELOPMENT_BUCKET_USER_ACCESS_KEY }}\n        aws-secret-access-key: ${{ \n          secrets.CI_INTERNAL_DEVELOPMENT_BUCKET_USER_SECRET_KEY }}\n        aws-region: ${{ secrets.CI_AWS_REGION }}\n\n    - name: Install dependencies\n      run: |\n        sudo apt update -y\n        sudo apt install -y gcc make golang-go python3-pip python3-venv\n        sudo apt install -y apt-transport-https ca-certificates curl software-properties-common\n        curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n        echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n        sudo apt update -y\n        sudo apt install -y docker-ce\n        export PATH=$PATH:/usr/local/go/bin\n        go get -u github.com/magefile/mage\n        echo \"$(go env GOPATH)/bin\" >> $GITHUB_PATH\n\n    - name: Apply patch for Ubuntu build\n      run: |\n        sed -i 's/apt-get install -y --no-install-recommends/DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends/' filebeat/Dockerfile\n\n        sed -i \"s/from: 'centos:7'/from: 'ubuntu:20.04'/g\" dev-tools/packaging/packages.yml\n        sed -i \"s/buildFrom: 'centos:7'/buildFrom: 'ubuntu:20.04'/g\" dev-tools/packaging/packages.yml\n\n        sed -i \"s/microdnf install -y shadow-utils/microdnf install -y findutils shadow-utils/g\" dev-tools/packaging/templates/docker/Dockerfile.elastic-agent.tmpl\n        sed -i '/RUN yum -y --setopt=tsflags=nodocs update && \\\\/, /yum clean all/c\\\n        RUN apt-get update -y && \\\\\\n    DEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends --yes ca-certificates curl libcap2-bin xz-utils && \\\\\\n    apt-get clean && \\\\\\n    exit_code=$? && \\\\\\n    [ $exit_code -eq 0 ] || exit $exit_code' dev-tools/packaging/templates/docker/Dockerfile.elastic-agent.tmpl\n\n        sed -i 's/microdnf install shadow-utils/microdnf install findutils shadow-utils/' dev-tools/packaging/templates/docker/Dockerfile.tmpl\n        sed -i '/RUN yum -y --setopt=tsflags=nodocs update && yum clean all/c\\\n        RUN apt-get update -y && \\\\\\n    DEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends --yes ca-certificates curl libcap2-bin xz-utils && \\\\\\n    apt-get clean && \\\\\\n    exit_code=$? && \\\\\\n    [ $exit_code -eq 0 ] || exit $exit_code' dev-tools/packaging/templates/docker/Dockerfile.tmpl\n\n        sed -i '/func TestDocker(t \\*testing\\.T) {/,/^}$/d' dev-tools/packaging/package_test.go\n\n    - name: Package Filebeat\n      working-directory: filebeat\n      run: |\n        PLATFORMS=linux/${{ inputs.architecture }} PACKAGES=${{ inputs.system }} mage package\n\n    - name: Upload Filebeat package to S3\n      working-directory: filebeat/build/distributions\n      run: |\n        if [ \"${{ inputs.system }}\" = \"rpm\" ]; then\n          if [ \"${{ inputs.architecture }}\" = \"amd64\" ]; then\n            arch=\"x86_64\"\n          elif [ \"${{ inputs.architecture }}\" = \"arm64\" ]; then\n            arch=\"aarch64\"\n          fi\n          revision=\"-${{ inputs.revision }}.\"\n        else\n          arch=\"${{ inputs.architecture }}\"\n          revision=\"-${{ inputs.revision }}_\"\n        fi\n\n        original_file=\"filebeat-oss-${{ env.FILEBEAT_VERSION }}-${arch}.${{ inputs.system }}\"\n        if [ \"${{ inputs.is_stage }}\" = \"false\" ]; then\n          git_hash=$(git rev-parse --short \"$GITHUB_SHA\")\n          renamed_file=\"filebeat-${{ env.FILEBEAT_VERSION }}${revision}${arch}_${git_hash}.${{ inputs.system }}\"\n        else\n          renamed_file=\"filebeat-${{ env.FILEBEAT_VERSION }}${revision}${arch}.${{ inputs.system }}\"\n        fi\n\n        mv \"$original_file\" \"$renamed_file\"\n        aws s3 cp \"$renamed_file\" \"${{ env.S3_BUCKET_PATH }}\"\n        s3uri=\"${{ env.S3_BUCKET_PATH }}$renamed_file\"\n        echo \"S3 URI: ${s3uri}\"\n\n    - name: Upload Filebeat module SHA512 to S3\n      if: ${{ inputs.checksum }}\n      working-directory: filebeat/build/distributions\n      run: |-\n        if [ \"${{ inputs.system }}\" = \"rpm\" ]; then\n          if [ \"${{ inputs.architecture }}\" = \"amd64\" ]; then\n            arch=\"x86_64\"\n          elif [ \"${{ inputs.architecture }}\" = \"arm64\" ]; then\n            arch=\"aarch64\"\n          fi\n          revision=\"-${{ inputs.revision }}.\"\n        else\n          arch=\"${{ inputs.architecture }}\"\n          revision=\"-${{ inputs.revision }}_\"\n        fi\n\n        original_file=\"filebeat-oss-${{ env.FILEBEAT_VERSION }}-${arch}.${{ inputs.system }}.sha512\"\n        if [ \"${{ inputs.is_stage }}\" = \"false\" ]; then\n          git_hash=$(git rev-parse --short \"$GITHUB_SHA\")\n          renamed_file=\"filebeat-${{ env.FILEBEAT_VERSION }}${revision}${arch}_${git_hash}.${{ inputs.system }}.sha512\"\n        else\n          renamed_file=\"filebeat-${{ env.FILEBEAT_VERSION }}${revision}${arch}.${{ inputs.system }}.sha512\"\n        fi\n\n        mv \"$original_file\" \"$renamed_file\"\n        aws s3 cp \"$renamed_file\" \"${{ env.S3_BUCKET_PATH }}\"\n        s3uri=\"${{ env.S3_BUCKET_PATH }}$renamed_file\"\n        echo \"S3 sha512 URI: ${s3uri}\"\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Build Filebeat` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `Build ${{ inputs.system }} filebeat on ${{ inputs.architecture }} ${{ inputs.is_stage && '- is stage' || '' }} ${{ inputs.checksum && '- checksum' || '' }} ${{ inputs.id }}`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives 6 inputs: architecture-this input represents architecture of the package [amd64, arm64]\n, it is optional, its default value is amd64, the data type is choice and it has options including amd64 and arm64; system-this input represents package format [deb, rpm]\n, it is optional, its default value is deb, the data type is choice and it has options including deb and rpm; revision-this input represents set the value to \"1\" for packages in release format.\nyou can also add other values, such as issue numbers.\nby default, it is set to \"0\" for development.\n, its default value is 0, the data type is string and it is optional; is_stage-this input represents build package with release format.\nby default: false\n, the data type is boolean and it is optional; checksum-this input represents generate package checksum., the data type is boolean and it is optional; id-the data type is string, this input represents id used to identify the workflow uniquely.\n and it is optional. 2) this workflow is called by another workflow. This workflow receives 6 inputs: architecture-the data type is string and it is optional; system-the data type is string and it is optional; revision-its default value is 0, the data type is string and it is optional; is_stage-the data type is boolean and it is optional; checksum-the data type is boolean and it is optional; id-the data type is string and it is optional. The workflow has one job. The job id of the 1st job is `build-and-upload`. ","prompt_level2":"Generate a GitHub Workflow named `Build Filebeat` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `Build ${{ inputs.system }} filebeat on ${{ inputs.architecture }} ${{ inputs.is_stage && '- is stage' || '' }} ${{ inputs.checksum && '- checksum' || '' }} ${{ inputs.id }}`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives 6 inputs: architecture-this input represents architecture of the package [amd64, arm64]\n, it is optional, its default value is amd64, the data type is choice and it has options including amd64 and arm64; system-this input represents package format [deb, rpm]\n, it is optional, its default value is deb, the data type is choice and it has options including deb and rpm; revision-this input represents set the value to \"1\" for packages in release format.\nyou can also add other values, such as issue numbers.\nby default, it is set to \"0\" for development.\n, its default value is 0, the data type is string and it is optional; is_stage-this input represents build package with release format.\nby default: false\n, the data type is boolean and it is optional; checksum-this input represents generate package checksum., the data type is boolean and it is optional; id-the data type is string, this input represents id used to identify the workflow uniquely.\n and it is optional. 2) this workflow is called by another workflow. This workflow receives 6 inputs: architecture-the data type is string and it is optional; system-the data type is string and it is optional; revision-its default value is 0, the data type is string and it is optional; is_stage-the data type is boolean and it is optional; checksum-the data type is boolean and it is optional; id-the data type is string and it is optional. The workflow has one job. The job id of the 1st job is `build-and-upload`. The job `build-and-upload` has 8 steps. The 1st step is named `Cancel previous runs`. The 2nd step is named `Checkout elastic/beats`. The 3rd step is named `Set up AWS CLI`. The 4th step is named `Install dependencies`. The 5th step is named `Apply patch for Ubuntu build`. The 6th step is named `Package Filebeat`. The 7th step is named `Upload Filebeat package to S3`. The 8th step is named `Upload Filebeat module SHA512 to S3`. ","prompt_level3":"Generate a GitHub Workflow named `Build Filebeat` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `Build ${{ inputs.system }} filebeat on ${{ inputs.architecture }} ${{ inputs.is_stage && '- is stage' || '' }} ${{ inputs.checksum && '- checksum' || '' }} ${{ inputs.id }}`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives 6 inputs: architecture-this input represents architecture of the package [amd64, arm64]\n, it is optional, its default value is amd64, the data type is choice and it has options including amd64 and arm64; system-this input represents package format [deb, rpm]\n, it is optional, its default value is deb, the data type is choice and it has options including deb and rpm; revision-this input represents set the value to \"1\" for packages in release format.\nyou can also add other values, such as issue numbers.\nby default, it is set to \"0\" for development.\n, its default value is 0, the data type is string and it is optional; is_stage-this input represents build package with release format.\nby default: false\n, the data type is boolean and it is optional; checksum-this input represents generate package checksum., the data type is boolean and it is optional; id-the data type is string, this input represents id used to identify the workflow uniquely.\n and it is optional. 2) this workflow is called by another workflow. This workflow receives 6 inputs: architecture-the data type is string and it is optional; system-the data type is string and it is optional; revision-its default value is 0, the data type is string and it is optional; is_stage-the data type is boolean and it is optional; checksum-the data type is boolean and it is optional; id-the data type is string and it is optional. The workflow has one job. The job id of the 1st job is `build-and-upload`. This job will run on ubuntu-latest runner. The job sets 2 environment variables to use: `FILEBEAT_VERSION` is set to `7.10.2` and `S3_BUCKET_PATH` is set to `s3://packages-dev.internal.wazuh.com/development/wazuh/4.x/secondary/filebeat/packages/`. The maximum number of minutes to run the job is 60. The job `build-and-upload` has 8 steps. The 1st step is named `Cancel previous runs`. This step runs action `fkirc/skip-duplicate-actions` from the master branch. The step defines 3 input parameters for the action: `cancel_others` is set to `true`, `github_token` is set to `${{ secrets.GITHUB_TOKEN }}` and `skip_after_successful_duplicate` is set to `false`. The 2nd step is named `Checkout elastic/beats`. This step runs action `actions/checkout` tagged as v4. The step defines 2 input parameters for the action: `repository` is set to `elastic/beats` and `ref` is set to `v${{ env.FILEBEAT_VERSION }}`. The 3rd step is named `Set up AWS CLI`. This step runs action `aws-actions/configure-aws-credentials` tagged as v1. The step defines 3 input parameters for the action: `aws-access-key-id` is set to `${{ secrets.CI_INTERNAL_DEVELOPMENT_BUCKET_USER_ACCESS_KEY }}`, `aws-secret-access-key` is set to `${{ secrets.CI_INTERNAL_DEVELOPMENT_BUCKET_USER_SECRET_KEY }}` and `aws-region` is set to `${{ secrets.CI_AWS_REGION }}`. The 4th step is named `Install dependencies`. This step runs a script: `sudo apt update -y\nsudo apt install -y gcc make golang-go python3-pip python3-venv\nsudo apt install -y apt-transport-https ca-certificates curl software-properties-common\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\necho \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\nsudo apt update -y\nsudo apt install -y docker-ce\nexport PATH=$PATH:/usr/local/go/bin\ngo get -u github.com/magefile/mage\necho \"$(go env GOPATH)/bin\" >> $GITHUB_PATH\n`. The 5th step is named `Apply patch for Ubuntu build`. This step runs a script: `sed -i 's/apt-get install -y --no-install-recommends/DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends/' filebeat/Dockerfile\n\nsed -i \"s/from: 'centos:7'/from: 'ubuntu:20.04'/g\" dev-tools/packaging/packages.yml\nsed -i \"s/buildFrom: 'centos:7'/buildFrom: 'ubuntu:20.04'/g\" dev-tools/packaging/packages.yml\n\nsed -i \"s/microdnf install -y shadow-utils/microdnf install -y findutils shadow-utils/g\" dev-tools/packaging/templates/docker/Dockerfile.elastic-agent.tmpl\nsed -i '/RUN yum -y --setopt=tsflags=nodocs update && \\\\/, /yum clean all/c\\\nRUN apt-get update -y && \\\\\\n    DEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends --yes ca-certificates curl libcap2-bin xz-utils && \\\\\\n    apt-get clean && \\\\\\n    exit_code=$? && \\\\\\n    [ $exit_code -eq 0 ] || exit $exit_code' dev-tools/packaging/templates/docker/Dockerfile.elastic-agent.tmpl\n\nsed -i 's/microdnf install shadow-utils/microdnf install findutils shadow-utils/' dev-tools/packaging/templates/docker/Dockerfile.tmpl\nsed -i '/RUN yum -y --setopt=tsflags=nodocs update && yum clean all/c\\\nRUN apt-get update -y && \\\\\\n    DEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends --yes ca-certificates curl libcap2-bin xz-utils && \\\\\\n    apt-get clean && \\\\\\n    exit_code=$? && \\\\\\n    [ $exit_code -eq 0 ] || exit $exit_code' dev-tools/packaging/templates/docker/Dockerfile.tmpl\n\nsed -i '/func TestDocker(t \\*testing\\.T) {/,/^}$/d' dev-tools/packaging/package_test.go\n`. The 6th step is named `Package Filebeat`. This step runs a script: `PLATFORMS=linux/${{ inputs.architecture }} PACKAGES=${{ inputs.system }} mage package\n`. The 7th step is named `Upload Filebeat package to S3`. This step runs a script: `if [ \"${{ inputs.system }}\" = \"rpm\" ]; then\n  if [ \"${{ inputs.architecture }}\" = \"amd64\" ]; then\n    arch=\"x86_64\"\n  elif [ \"${{ inputs.architecture }}\" = \"arm64\" ]; then\n    arch=\"aarch64\"\n  fi\n  revision=\"-${{ inputs.revision }}.\"\nelse\n  arch=\"${{ inputs.architecture }}\"\n  revision=\"-${{ inputs.revision }}_\"\nfi\n\noriginal_file=\"filebeat-oss-${{ env.FILEBEAT_VERSION }}-${arch}.${{ inputs.system }}\"\nif [ \"${{ inputs.is_stage }}\" = \"false\" ]; then\n  git_hash=$(git rev-parse --short \"$GITHUB_SHA\")\n  renamed_file=\"filebeat-${{ env.FILEBEAT_VERSION }}${revision}${arch}_${git_hash}.${{ inputs.system }}\"\nelse\n  renamed_file=\"filebeat-${{ env.FILEBEAT_VERSION }}${revision}${arch}.${{ inputs.system }}\"\nfi\n\nmv \"$original_file\" \"$renamed_file\"\naws s3 cp \"$renamed_file\" \"${{ env.S3_BUCKET_PATH }}\"\ns3uri=\"${{ env.S3_BUCKET_PATH }}$renamed_file\"\necho \"S3 URI: ${s3uri}\"\n`. The 8th step is named `Upload Filebeat module SHA512 to S3`. This step will run only if the condition(${{ inputs.checksum }}) is met. This step runs a script: `if [ \"${{ inputs.system }}\" = \"rpm\" ]; then\n  if [ \"${{ inputs.architecture }}\" = \"amd64\" ]; then\n    arch=\"x86_64\"\n  elif [ \"${{ inputs.architecture }}\" = \"arm64\" ]; then\n    arch=\"aarch64\"\n  fi\n  revision=\"-${{ inputs.revision }}.\"\nelse\n  arch=\"${{ inputs.architecture }}\"\n  revision=\"-${{ inputs.revision }}_\"\nfi\n\noriginal_file=\"filebeat-oss-${{ env.FILEBEAT_VERSION }}-${arch}.${{ inputs.system }}.sha512\"\nif [ \"${{ inputs.is_stage }}\" = \"false\" ]; then\n  git_hash=$(git rev-parse --short \"$GITHUB_SHA\")\n  renamed_file=\"filebeat-${{ env.FILEBEAT_VERSION }}${revision}${arch}_${git_hash}.${{ inputs.system }}.sha512\"\nelse\n  renamed_file=\"filebeat-${{ env.FILEBEAT_VERSION }}${revision}${arch}.${{ inputs.system }}.sha512\"\nfi\n\nmv \"$original_file\" \"$renamed_file\"\naws s3 cp \"$renamed_file\" \"${{ env.S3_BUCKET_PATH }}\"\ns3uri=\"${{ env.S3_BUCKET_PATH }}$renamed_file\"\necho \"S3 sha512 URI: ${s3uri}\"`. ","nb_triggers":2,"triggers":["workflow_call","workflow_dispatch"],"nb_jobs":1,"nb_actions":3,"actions":["actions/checkout","aws-actions/configure-aws-credentials","fkirc/skip-duplicate-actions"],"actions_details":[{"version":"master","name":"fkirc/skip-duplicate-actions"},{"version":"v4","name":"actions/checkout"},{"version":"v1","name":"aws-actions/configure-aws-credentials"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":8,"cyclomatic_complexity":1}
{"id":51587,"repository_id":95266545,"mainLanguage":"Rust","file_name":"binary-verify.yml","file_content":"name: Validate Binaries\n\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: \"The published version, like \\\"0.2.0\\\"\"\n        type: string\n        required: true\n      docker-rc:\n        description: \"-rc or not\"\n        type: boolean\n        default: false\n  workflow_call:\n    inputs:\n      version:\n        description: \"The published version, like \\\"0.2.0\\\"\"\n        type: string\n        required: true\n      docker-rc:\n        description: \"-rc or not\"\n        type: boolean\n        required: true\n\nenv:\n  VERSION: \"${{ inputs.version }}\"\n  RELEASE_TAG: \"v${{ inputs.version }}\"\npermissions:\n  contents: write # don't actually need to write, but this lets us see draft releases\n\njobs:\n  list-targets:\n    uses: ./.github/workflows/list-targets.yml\n\n  dispatch-targets:\n    needs: list-targets\n    runs-on: ubuntu-latest\n    outputs:\n      windows: ${{ steps.run.outputs.windows }}\n      non-windows: ${{ steps.run.outputs.non-windows }}\n    steps:\n      - name: Run\n        id: run\n        run: |\n          set -x\n          echo \"windows=$(<<<\"$VALIDATE_BY_TARGET\" jq -c 'to_entries | map(select(.value == \"windows\")) | map(.key)')\" >> \"$GITHUB_OUTPUT\"\n          echo \"non-windows=$(<<<\"$VALIDATE_BY_TARGET\" jq -c 'to_entries | map(select(.value != \"windows\")) | map(.key)')\" >> \"$GITHUB_OUTPUT\"\n        env:\n          VALIDATE_BY_TARGET: ${{ needs.list-targets.outputs.validate_by_target }}\n          BUILD_BY_TARGET: ${{ needs.list-targets.outputs.build_by_target }}\n\n\n  full-coverage:\n    needs: list-targets\n    runs-on: ubuntu-latest\n    steps:\n\n      - name: Get asset names\n        run: >\n          gh release -R ${{ github.repository }} view \"$RELEASE_TAG\" --json assets | jq -r '.assets | map(.name) | .[]'\n          | sort \n          | sed -E 's/\\.(zip|tar\\.gz)$//'\n          | sort\n          > from-release.txt\n        env:\n          GH_TOKEN: ${{ github.token }}\n\n      - name: Get target names\n        run: <<<\"$TARGET_NAMES\" jq -r '.[] | \"mdq-\\(.)\"' > from-list-targets.txt\n        env:\n          TARGET_NAMES: ${{ needs.list-targets.outputs.names }}\n\n      - name: Validate that they're the same\n        run: diff -y from-list-targets.txt from-release.txt\n\n\n  unix-like:\n    needs: [ list-targets, dispatch-targets ]\n    strategy:\n      matrix:\n        target: ${{ fromJSON(needs.dispatch-targets.outputs.non-windows) }}\n    runs-on: ${{ fromJSON(needs.list-targets.outputs.validate_by_target)[matrix.target] }}-latest\n    steps:\n      - name: Download tarball\n        run: gh release -R ${{ github.repository }} download \"$RELEASE_TAG\" -p mdq-${{ matrix.target }}.tar.gz\n        env:\n          GH_TOKEN: ${{ github.token }}\n\n      - name: Expand\n        run: tar xzvf mdq-${{ matrix.target }}.tar.gz\n\n      - name: Run --version\n        id: mdq-version\n        run: |\n          set -euo pipefail\n          mdq_output=\"$(./mdq --version)\"\n          echo \"version-b64=$(base64 <<<\"$mdq_output\")\" >> \"$GITHUB_OUTPUT\"\n\n      - name: Verify version\n        run:\n          diff -y <(echo \"mdq $VERSION\") <(base64 -d <<<\"$ACTUAL_VERSION\")\n        env:\n          ACTUAL_VERSION: ${{ steps.mdq-version.outputs.version-b64 }}\n\n\n  windows:\n    needs: [ list-targets, dispatch-targets ]\n    runs-on: ${{ fromJSON(needs.list-targets.outputs.validate_by_target)[matrix.target] }}-latest\n    strategy:\n      matrix:\n        target: ${{ fromJSON(needs.dispatch-targets.outputs.windows) }}\n    steps:\n\n      - name: Download zip\n        run: gh release -R ${{ github.repository }} download ${{ env.RELEASE_TAG}} -p mdq-${{ matrix.target }}.zip\n        env:\n          GH_TOKEN: ${{ github.token }}\n\n      - name: Expand\n        run: Expand-Archive mdq-${{ matrix.target }}.zip\n\n      # Use JSON, because base64 is a pain in powershell\n      - name: Run --version\n        id: mdq-version\n        run: |\n          $version_json = .\\mdq-${{ matrix.target }}\\mdq.exe --version | ConvertTo-Json\n          echo \"version_json=$version_json\" > $env:GITHUB_OUTPUT\n\n      - name: Verify version\n        run: |\n          $diff = Compare-Object -CaseSensitive (echo \"mdq $env:VERSION\" | ConvertTo-Json) $env:ACTUAL\n          if ($diff) {\n            Write-Output \"Difference found:\"\n            $diff | Format-Table\n            exit 1\n          }\n        env:\n          ACTUAL: ${{ steps.mdq-version.outputs.version_json }}\n\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Calculate tag\n        id: tag\n        run: |\n          tag=\"${VERSION}\"\n          if [[ ${{ inputs.docker-rc }} == true ]]; then\n            tag=\"${VERSION}-rc\"\n          fi\n          echo \"id=$tag\" >> \"$GITHUB_OUTPUT\"\n\n      - name: Pull tag\n        run: docker pull \"yshavit/mdq:$DOCKER_TAG\"\n        env:\n          DOCKER_TAG: ${{ steps.tag.outputs.id }}\n\n      - name: Run --version\n        id: mdq-version\n        run: |\n          mdq_output=\"$(docker run --rm -i \"yshavit/mdq:$DOCKER_TAG\" --version)\"\n          echo \"version-b64=$(base64 <<<\"$mdq_output\")\" >> \"$GITHUB_OUTPUT\"\n        env:\n          DOCKER_TAG: ${{ steps.tag.outputs.id }}\n\n      - name: Verify version\n        run:\n          diff -y <(echo \"mdq $VERSION\") <(base64 -d <<<\"$ACTUAL_VERSION\")\n        env:\n          ACTUAL_VERSION: ${{ steps.mdq-version.outputs.version-b64 }}\n\n\n  attestations:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Download zip\n        run: gh release -R ${{ github.repository }} download \"$RELEASE_TAG\"\n        env:\n          GH_TOKEN: ${{ github.token }}\n\n      - name: Attestations\n        run: |\n          set -euo pipefail\n          for z_file in *.zip; do\n            echo \"::group::$z_file\"\n            z_dir=\"${z_file}.dir\"\n            mkdir \"$z_dir\"\n            unzip \"$z_file\" -d \"$z_dir\"\n            echo \"Will verify: \" \"$z_dir\"/*\n            gh attestation verify -o ${{ github.repository_owner }} \"$z_dir\"/*\n            echo '::endgroup::'\n          done\n        env:\n          GH_TOKEN: ${{ github.token }}\n","repository_owner":"yshavit","repository_name":"mdq","tokens_count":1545,"workflow":"name: Validate Binaries\n\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: The published version, like \"0.2.0\"\n        type: string\n        required: true\n      docker-rc:\n        description: -rc or not\n        type: boolean\n        default: false\n  workflow_call:\n    inputs:\n      version:\n        description: The published version, like \"0.2.0\"\n        type: string\n        required: true\n      docker-rc:\n        description: -rc or not\n        type: boolean\n        required: true\n\nenv:\n  VERSION: ${{ inputs.version }}\n  RELEASE_TAG: v${{ inputs.version }}\npermissions:\n  contents: write # don't actually need to write, but this lets us see draft releases\n\njobs:\n  list-targets:\n    uses: ./.github/workflows/list-targets.yml\n\n  dispatch-targets:\n    needs: list-targets\n    runs-on: ubuntu-latest\n    outputs:\n      windows: ${{ steps.run.outputs.windows }}\n      non-windows: ${{ steps.run.outputs.non-windows }}\n    steps:\n    - name: Run\n      id: run\n      run: |\n        set -x\n        echo \"windows=$(<<<\"$VALIDATE_BY_TARGET\" jq -c 'to_entries | map(select(.value == \"windows\")) | map(.key)')\" >> \"$GITHUB_OUTPUT\"\n        echo \"non-windows=$(<<<\"$VALIDATE_BY_TARGET\" jq -c 'to_entries | map(select(.value != \"windows\")) | map(.key)')\" >> \"$GITHUB_OUTPUT\"\n      env:\n        VALIDATE_BY_TARGET: ${{ needs.list-targets.outputs.validate_by_target }}\n        BUILD_BY_TARGET: ${{ needs.list-targets.outputs.build_by_target }}\n\n\n  full-coverage:\n    needs: list-targets\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Get asset names\n      run: >\n        gh release -R ${{ github.repository }} view \"$RELEASE_TAG\" --json assets |\n        jq -r '.assets | map(.name) | .[]'\n        | sort  | sed -E 's/\\.(zip|tar\\.gz)$//'\n        | sort\n        > from-release.txt\n      env:\n        GH_TOKEN: ${{ github.token }}\n\n    - name: Get target names\n      run: <<<\"$TARGET_NAMES\" jq -r '.[] | \"mdq-\\(.)\"' > from-list-targets.txt\n      env:\n        TARGET_NAMES: ${{ needs.list-targets.outputs.names }}\n\n    - name: Validate that they're the same\n      run: diff -y from-list-targets.txt from-release.txt\n\n\n  unix-like:\n    needs: [list-targets, dispatch-targets]\n    strategy:\n      matrix:\n        target: ${{ fromJSON(needs.dispatch-targets.outputs.non-windows) }}\n    runs-on: ${{ \n      fromJSON(needs.list-targets.outputs.validate_by_target)[matrix.target] \n      }}-latest\n    steps:\n    - name: Download tarball\n      run: gh release -R ${{ github.repository }} download \"$RELEASE_TAG\" -p \n        mdq-${{ matrix.target }}.tar.gz\n      env:\n        GH_TOKEN: ${{ github.token }}\n\n    - name: Expand\n      run: tar xzvf mdq-${{ matrix.target }}.tar.gz\n\n    - name: Run --version\n      id: mdq-version\n      run: |\n        set -euo pipefail\n        mdq_output=\"$(./mdq --version)\"\n        echo \"version-b64=$(base64 <<<\"$mdq_output\")\" >> \"$GITHUB_OUTPUT\"\n\n    - name: Verify version\n      run: diff -y <(echo \"mdq $VERSION\") <(base64 -d <<<\"$ACTUAL_VERSION\")\n      env:\n        ACTUAL_VERSION: ${{ steps.mdq-version.outputs.version-b64 }}\n\n\n  windows:\n    needs: [list-targets, dispatch-targets]\n    runs-on: ${{ \n      fromJSON(needs.list-targets.outputs.validate_by_target)[matrix.target] \n      }}-latest\n    strategy:\n      matrix:\n        target: ${{ fromJSON(needs.dispatch-targets.outputs.windows) }}\n    steps:\n\n    - name: Download zip\n      run: gh release -R ${{ github.repository }} download ${{ env.RELEASE_TAG}}\n        -p mdq-${{ matrix.target }}.zip\n      env:\n        GH_TOKEN: ${{ github.token }}\n\n    - name: Expand\n      run: Expand-Archive mdq-${{ matrix.target }}.zip\n\n      # Use JSON, because base64 is a pain in powershell\n    - name: Run --version\n      id: mdq-version\n      run: |\n        $version_json = .\\mdq-${{ matrix.target }}\\mdq.exe --version | ConvertTo-Json\n        echo \"version_json=$version_json\" > $env:GITHUB_OUTPUT\n\n    - name: Verify version\n      run: |\n        $diff = Compare-Object -CaseSensitive (echo \"mdq $env:VERSION\" | ConvertTo-Json) $env:ACTUAL\n        if ($diff) {\n          Write-Output \"Difference found:\"\n          $diff | Format-Table\n          exit 1\n        }\n      env:\n        ACTUAL: ${{ steps.mdq-version.outputs.version_json }}\n\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Calculate tag\n      id: tag\n      run: |\n        tag=\"${VERSION}\"\n        if [[ ${{ inputs.docker-rc }} == true ]]; then\n          tag=\"${VERSION}-rc\"\n        fi\n        echo \"id=$tag\" >> \"$GITHUB_OUTPUT\"\n\n    - name: Pull tag\n      run: docker pull \"yshavit/mdq:$DOCKER_TAG\"\n      env:\n        DOCKER_TAG: ${{ steps.tag.outputs.id }}\n\n    - name: Run --version\n      id: mdq-version\n      run: |\n        mdq_output=\"$(docker run --rm -i \"yshavit/mdq:$DOCKER_TAG\" --version)\"\n        echo \"version-b64=$(base64 <<<\"$mdq_output\")\" >> \"$GITHUB_OUTPUT\"\n      env:\n        DOCKER_TAG: ${{ steps.tag.outputs.id }}\n\n    - name: Verify version\n      run: diff -y <(echo \"mdq $VERSION\") <(base64 -d <<<\"$ACTUAL_VERSION\")\n      env:\n        ACTUAL_VERSION: ${{ steps.mdq-version.outputs.version-b64 }}\n\n\n  attestations:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Download zip\n      run: gh release -R ${{ github.repository }} download \"$RELEASE_TAG\"\n      env:\n        GH_TOKEN: ${{ github.token }}\n\n    - name: Attestations\n      run: |\n        set -euo pipefail\n        for z_file in *.zip; do\n          echo \"::group::$z_file\"\n          z_dir=\"${z_file}.dir\"\n          mkdir \"$z_dir\"\n          unzip \"$z_file\" -d \"$z_dir\"\n          echo \"Will verify: \" \"$z_dir\"/*\n          gh attestation verify -o ${{ github.repository_owner }} \"$z_dir\"/*\n          echo '::endgroup::'\n        done\n      env:\n        GH_TOKEN: ${{ github.token }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Validate Binaries` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives 2 inputs: version-this input represents the published version, like \"0.2.0\", the data type is string and it must be supplied; docker-rc-this input represents -rc or not, the data type is boolean and its default value is False. 2) this workflow is called by another workflow. This workflow receives 2 inputs: version-this input represents the published version, like \"0.2.0\", the data type is string and it must be supplied; docker-rc-this input represents -rc or not, the data type is boolean and it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow sets 2 environment variables to use: `VERSION` is set to `${{ inputs.version }}` and `RELEASE_TAG` is set to `v${{ inputs.version }}`. The workflow has 7 jobs. The job id of the 1st job is `list-targets`. The job id of the 2nd job is `dispatch-targets`. The job id of the 3rd job is `full-coverage`. The job id of the 4th job is `unix-like`. The job id of the 5th job is `windows`. The job id of the 6th job is `docker`. The job id of the 7th job is `attestations`. ","prompt_level2":"Generate a GitHub Workflow named `Validate Binaries` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives 2 inputs: version-this input represents the published version, like \"0.2.0\", the data type is string and it must be supplied; docker-rc-this input represents -rc or not, the data type is boolean and its default value is False. 2) this workflow is called by another workflow. This workflow receives 2 inputs: version-this input represents the published version, like \"0.2.0\", the data type is string and it must be supplied; docker-rc-this input represents -rc or not, the data type is boolean and it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow sets 2 environment variables to use: `VERSION` is set to `${{ inputs.version }}` and `RELEASE_TAG` is set to `v${{ inputs.version }}`. The workflow has 7 jobs. The job id of the 1st job is `list-targets`. The job id of the 2nd job is `dispatch-targets`. The job `dispatch-targets` has one step. The 1st step is named `Run` and its id is `run`. The job id of the 3rd job is `full-coverage`. The job `full-coverage` has 3 steps. The 1st step is named `Get asset names`. The 2nd step is named `Get target names`. The 3rd step is named `Validate that they're the same`. The job id of the 4th job is `unix-like`. The job `unix-like` has 4 steps. The 1st step is named `Download tarball`. The 2nd step is named `Expand`. The 3rd step is named `Run --version` and its id is `mdq-version`. The 4th step is named `Verify version`. The job id of the 5th job is `windows`. The job `windows` has 4 steps. The 1st step is named `Download zip`. The 2nd step is named `Expand`. The 3rd step is named `Run --version` and its id is `mdq-version`. The 4th step is named `Verify version`. The job id of the 6th job is `docker`. The job `docker` has 4 steps. The 1st step is named `Calculate tag` and its id is `tag`. The 2nd step is named `Pull tag`. The 3rd step is named `Run --version` and its id is `mdq-version`. The 4th step is named `Verify version`. The job id of the 7th job is `attestations`. The job `attestations` has 2 steps. The 1st step is named `Download zip`. The 2nd step is named `Attestations`. ","prompt_level3":"Generate a GitHub Workflow named `Validate Binaries` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives 2 inputs: version-this input represents the published version, like \"0.2.0\", the data type is string and it must be supplied; docker-rc-this input represents -rc or not, the data type is boolean and its default value is False. 2) this workflow is called by another workflow. This workflow receives 2 inputs: version-this input represents the published version, like \"0.2.0\", the data type is string and it must be supplied; docker-rc-this input represents -rc or not, the data type is boolean and it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow sets 2 environment variables to use: `VERSION` is set to `${{ inputs.version }}` and `RELEASE_TAG` is set to `v${{ inputs.version }}`. The workflow has 7 jobs. The job id of the 1st job is `list-targets`. This job will call a reusable workflow located at `./.github/workflows/list-targets.yml`. The job id of the 2nd job is `dispatch-targets`. Before this job runs, `list-targets` must complete successfully. This job will run on ubuntu-latest runner. The job `dispatch-targets` has one step. The 1st step is named `Run` and its id is `run`. The step sets 2 environment variables to use: `VALIDATE_BY_TARGET` is set to `${{ needs.list-targets.outputs.validate_by_target }}` and `BUILD_BY_TARGET` is set to `${{ needs.list-targets.outputs.build_by_target }}`. This step runs a script: `set -x\necho \"windows=$(<<<\"$VALIDATE_BY_TARGET\" jq -c 'to_entries | map(select(.value == \"windows\")) | map(.key)')\" >> \"$GITHUB_OUTPUT\"\necho \"non-windows=$(<<<\"$VALIDATE_BY_TARGET\" jq -c 'to_entries | map(select(.value != \"windows\")) | map(.key)')\" >> \"$GITHUB_OUTPUT\"\n`. This job has 2 outputs: `windows` is defined as ${{ steps.run.outputs.windows }} and `non-windows` is defined as ${{ steps.run.outputs.non-windows }}. The job id of the 3rd job is `full-coverage`. Before this job runs, `list-targets` must complete successfully. This job will run on ubuntu-latest runner. The job `full-coverage` has 3 steps. The 1st step is named `Get asset names`. The step sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. This step runs a script: `gh release -R ${{ github.repository }} view \"$RELEASE_TAG\" --json assets | jq -r '.assets | map(.name) | .[]' | sort  | sed -E 's/\\.(zip|tar\\.gz)$//' | sort > from-release.txt\n`. The 2nd step is named `Get target names`. The step sets an environment variable to use: `TARGET_NAMES` is set to `${{ needs.list-targets.outputs.names }}`. This step runs a script: `<<<\"$TARGET_NAMES\" jq -r '.[] | \"mdq-\\(.)\"' > from-list-targets.txt`. The 3rd step is named `Validate that they're the same`. This step runs a script: `diff -y from-list-targets.txt from-release.txt`. The job id of the 4th job is `unix-like`. Before this job runs, `list-targets` and `dispatch-targets` must complete successfully. This job will run on ${{ fromJSON(needs.list-targets.outputs.validate_by_target)[matrix.target] }}-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `target` has 59 values: $, {, {,  , f, r, o, m, J, S, O, N, (, n, e, e, d, s, ., d, i, s, p, a, t, c, h, -, t, a, r, g, e, t, s, ., o, u, t, p, u, t, s, ., n, o, n, -, w, i, n, d, o, w, s, ),  , } and }. The job `unix-like` has 4 steps. The 1st step is named `Download tarball`. The step sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. This step runs a script: `gh release -R ${{ github.repository }} download \"$RELEASE_TAG\" -p mdq-${{ matrix.target }}.tar.gz`. The 2nd step is named `Expand`. This step runs a script: `tar xzvf mdq-${{ matrix.target }}.tar.gz`. The 3rd step is named `Run --version` and its id is `mdq-version`. This step runs a script: `set -euo pipefail\nmdq_output=\"$(./mdq --version)\"\necho \"version-b64=$(base64 <<<\"$mdq_output\")\" >> \"$GITHUB_OUTPUT\"\n`. The 4th step is named `Verify version`. The step sets an environment variable to use: `ACTUAL_VERSION` is set to `${{ steps.mdq-version.outputs.version-b64 }}`. This step runs a script: `diff -y <(echo \"mdq $VERSION\") <(base64 -d <<<\"$ACTUAL_VERSION\")`. The job id of the 5th job is `windows`. Before this job runs, `list-targets` and `dispatch-targets` must complete successfully. This job will run on ${{ fromJSON(needs.list-targets.outputs.validate_by_target)[matrix.target] }}-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `target` has 55 values: $, {, {,  , f, r, o, m, J, S, O, N, (, n, e, e, d, s, ., d, i, s, p, a, t, c, h, -, t, a, r, g, e, t, s, ., o, u, t, p, u, t, s, ., w, i, n, d, o, w, s, ),  , } and }. The job `windows` has 4 steps. The 1st step is named `Download zip`. The step sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. This step runs a script: `gh release -R ${{ github.repository }} download ${{ env.RELEASE_TAG}} -p mdq-${{ matrix.target }}.zip`. The 2nd step is named `Expand`. This step runs a script: `Expand-Archive mdq-${{ matrix.target }}.zip`. The 3rd step is named `Run --version` and its id is `mdq-version`. This step runs a script: `$version_json = .\\mdq-${{ matrix.target }}\\mdq.exe --version | ConvertTo-Json\necho \"version_json=$version_json\" > $env:GITHUB_OUTPUT\n`. The 4th step is named `Verify version`. The step sets an environment variable to use: `ACTUAL` is set to `${{ steps.mdq-version.outputs.version_json }}`. This step runs a script: `$diff = Compare-Object -CaseSensitive (echo \"mdq $env:VERSION\" | ConvertTo-Json) $env:ACTUAL\nif ($diff) {\n  Write-Output \"Difference found:\"\n  $diff | Format-Table\n  exit 1\n}\n`. The job id of the 6th job is `docker`. This job will run on ubuntu-latest runner. The job `docker` has 4 steps. The 1st step is named `Calculate tag` and its id is `tag`. This step runs a script: `tag=\"${VERSION}\"\nif [[ ${{ inputs.docker-rc }} == true ]]; then\n  tag=\"${VERSION}-rc\"\nfi\necho \"id=$tag\" >> \"$GITHUB_OUTPUT\"\n`. The 2nd step is named `Pull tag`. The step sets an environment variable to use: `DOCKER_TAG` is set to `${{ steps.tag.outputs.id }}`. This step runs a script: `docker pull \"yshavit/mdq:$DOCKER_TAG\"`. The 3rd step is named `Run --version` and its id is `mdq-version`. The step sets an environment variable to use: `DOCKER_TAG` is set to `${{ steps.tag.outputs.id }}`. This step runs a script: `mdq_output=\"$(docker run --rm -i \"yshavit/mdq:$DOCKER_TAG\" --version)\"\necho \"version-b64=$(base64 <<<\"$mdq_output\")\" >> \"$GITHUB_OUTPUT\"\n`. The 4th step is named `Verify version`. The step sets an environment variable to use: `ACTUAL_VERSION` is set to `${{ steps.mdq-version.outputs.version-b64 }}`. This step runs a script: `diff -y <(echo \"mdq $VERSION\") <(base64 -d <<<\"$ACTUAL_VERSION\")`. The job id of the 7th job is `attestations`. This job will run on ubuntu-latest runner. The job `attestations` has 2 steps. The 1st step is named `Download zip`. The step sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. This step runs a script: `gh release -R ${{ github.repository }} download \"$RELEASE_TAG\"`. The 2nd step is named `Attestations`. The step sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. This step runs a script: `set -euo pipefail\nfor z_file in *.zip; do\n  echo \"::group::$z_file\"\n  z_dir=\"${z_file}.dir\"\n  mkdir \"$z_dir\"\n  unzip \"$z_file\" -d \"$z_dir\"\n  echo \"Will verify: \" \"$z_dir\"/*\n  gh attestation verify -o ${{ github.repository_owner }} \"$z_dir\"/*\n  echo '::endgroup::'\ndone\n`. ","nb_triggers":2,"triggers":["workflow_call","workflow_dispatch"],"nb_jobs":7,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["./.github/workflows/list-targets.yml"],"nb_steps":18,"cyclomatic_complexity":7}
{"id":54008,"repository_id":203942,"mainLanguage":"Java","file_name":"presto-release-prepare.yml","file_content":"name: Presto Stable Release - Prepare\n\non:\n  workflow_dispatch:\n    inputs:\n      prepare_release:\n        description: 'Prepare release branch and tag'\n        type: boolean\n        default: true\n        required: false\n      prepare_release_notes:\n        description: 'Prepare release notes pull request'\n        type: boolean\n        default: true\n        required: false\n\nenv:\n  JAVA_VERSION: '11'\n  JAVA_DISTRIBUTION: 'temurin'\n\njobs:\n  prepare-release-branch:\n    if: ${{ inputs.prepare_release }}\n    runs-on: ubuntu-latest\n    environment: release\n    permissions:\n      contents: write\n\n    steps:\n      - name: Check for master branch\n        if: ${{ github.ref != 'refs/heads/master' }}\n        run: echo \"Invalid branch. This action can only be run on the master branch.\" && exit 1\n\n      - name: Checkout presto source\n        uses: actions/checkout@v4\n        with:\n          token: ${{ secrets.PRESTODB_CI_TOKEN }}\n          ref: master\n          show-progress: false\n          fetch-depth: 5\n\n      - name: Set up JDK\n        uses: actions/setup-java@v4\n        with:\n          java-version: ${{ env.JAVA_VERSION }}\n          distribution: ${{ env.JAVA_DISTRIBUTION }}\n\n      - name: Configure git\n        run: |\n          git config --global --add safe.directory ${{github.workspace}}\n          git config --global user.email \"ci@lists.prestodb.io\"\n          git config --global user.name \"prestodb-ci\"\n          git config --global alias.ls 'log --pretty=format:\"%cd %h %ce: %s\" --date=short --no-merges'\n          git config pull.rebase false\n\n      - name: Set presto release version\n        run: |\n          unset MAVEN_CONFIG && ./mvnw versions:set -DremoveSnapshot -ntp\n\n      - name: Get presto release version\n        id: get-version\n        run: |\n          PRESTO_RELEASE_VERSION=$(mvn org.apache.maven.plugins:maven-help-plugin:3.2.0:evaluate \\\n            -Dexpression=project.version -q -ntp -DforceStdout | tail -n 1)\n          echo \"PRESTO_RELEASE_VERSION=$PRESTO_RELEASE_VERSION\" >> $GITHUB_ENV\n          echo \"PRESTO_RELEASE_VERSION=$PRESTO_RELEASE_VERSION\"\n\n      - name: Prepare release tag and commits\n        run: |\n          git reset --hard\n          unset MAVEN_CONFIG && ./mvnw release:prepare --batch-mode \\\n            -DskipTests \\\n            -DautoVersionSubmodules \\\n            -DdevelopmentVersion=${{ env.PRESTO_RELEASE_VERSION }} \\\n            -DreleaseVersion=${{ env.PRESTO_RELEASE_VERSION }}\n          grep -m 2 \"<version>\" pom.xml\n          echo \"commits on master branch\"\n          git ls -5\n\n      - name: Push release tag, branch and commits\n        run: |\n          echo \"In case this job failed, please delete the tag ${{ env.PRESTO_RELEASE_VERSION }} and the branch release-${{ env.PRESTO_RELEASE_VERSION }}, and re-run the job\"\n          git checkout ${{ env.PRESTO_RELEASE_VERSION }}\n          git switch -c release-${{ env.PRESTO_RELEASE_VERSION }}\n          echo \"Pushing release branch release-${{ env.PRESTO_RELEASE_VERSION }} and tag ${{ env.PRESTO_RELEASE_VERSION }}\"\n\n          echo \"commits on release-${{ env.PRESTO_RELEASE_VERSION }} branch\"\n          git ls -4\n          git push origin release-${{ env.PRESTO_RELEASE_VERSION }} --tags\n          echo -e \"\\nPushed release tag to: ${{ github.server_url }}/${{ github.repository }}/releases/tag/${{ env.PRESTO_RELEASE_VERSION }}\"\n          echo \"Pushed release branch to: ${{ github.server_url }}/${{ github.repository }}/tree/release-${{ env.PRESTO_RELEASE_VERSION }}\"\n\n          echo \"Pushing master branch\"\n          git checkout master\n          echo \"commits on master branch\"\n          git ls -5\n          git push origin master\n\n  prepare-release-notes:\n    needs: prepare-release-branch\n    if: ${{ inputs.prepare_release_notes && always() && (needs.prepare-release-branch.result == 'success' || !inputs.prepare_release) }}\n    runs-on: ubuntu-latest\n    environment: release\n    permissions:\n      contents: write\n\n    steps:\n      - name: Checkout presto source\n        uses: actions/checkout@v4\n        with:\n          ref: master\n          show-progress: false\n\n      - name: Set up JDK\n        uses: actions/setup-java@v4\n        with:\n          java-version: ${{ env.JAVA_VERSION }}\n          distribution: ${{ env.JAVA_DISTRIBUTION }}\n\n      - name: Configure git\n        run: |\n          git config --global --add safe.directory ${{github.workspace}}\n          git config --global user.email \"ci@lists.prestodb.io\"\n          git config --global user.name \"prestodb-ci\"\n          git config pull.rebase false\n\n      - name: Add git upstream\n        run: |\n          git remote add upstream ${{ github.server_url }}/${{ github.repository }}.git\n          git fetch upstream --tags\n          git remote -v\n\n      - name: Create release notes pull request\n        run: |\n          echo \"In case this job failed, please delete the release notes branch(e.g. release-notes-0.292) in repository ${{ github.repository }}, and re-run the job\"\n          ./src/release/release-notes.sh ${{ github.repository_owner }} ${{ secrets.PRESTODB_CI_TOKEN }}\n","repository_owner":"prestodb","repository_name":"presto","tokens_count":1205,"workflow":"name: Presto Stable Release - Prepare\n\non:\n  workflow_dispatch:\n    inputs:\n      prepare_release:\n        description: Prepare release branch and tag\n        type: boolean\n        default: true\n        required: false\n      prepare_release_notes:\n        description: Prepare release notes pull request\n        type: boolean\n        default: true\n        required: false\n\nenv:\n  JAVA_VERSION: '11'\n  JAVA_DISTRIBUTION: temurin\n\njobs:\n  prepare-release-branch:\n    if: ${{ inputs.prepare_release }}\n    runs-on: ubuntu-latest\n    environment: release\n    permissions:\n      contents: write\n\n    steps:\n    - name: Check for master branch\n      if: ${{ github.ref != 'refs/heads/master' }}\n      run: echo \"Invalid branch. This action can only be run on the master \n        branch.\" && exit 1\n\n    - name: Checkout presto source\n      uses: actions/checkout@v4\n      with:\n        token: ${{ secrets.PRESTODB_CI_TOKEN }}\n        ref: master\n        show-progress: false\n        fetch-depth: 5\n\n    - name: Set up JDK\n      uses: actions/setup-java@v4\n      with:\n        java-version: ${{ env.JAVA_VERSION }}\n        distribution: ${{ env.JAVA_DISTRIBUTION }}\n\n    - name: Configure git\n      run: |\n        git config --global --add safe.directory ${{github.workspace}}\n        git config --global user.email \"ci@lists.prestodb.io\"\n        git config --global user.name \"prestodb-ci\"\n        git config --global alias.ls 'log --pretty=format:\"%cd %h %ce: %s\" --date=short --no-merges'\n        git config pull.rebase false\n\n    - name: Set presto release version\n      run: |\n        unset MAVEN_CONFIG && ./mvnw versions:set -DremoveSnapshot -ntp\n\n    - name: Get presto release version\n      id: get-version\n      run: |\n        PRESTO_RELEASE_VERSION=$(mvn org.apache.maven.plugins:maven-help-plugin:3.2.0:evaluate \\\n          -Dexpression=project.version -q -ntp -DforceStdout | tail -n 1)\n        echo \"PRESTO_RELEASE_VERSION=$PRESTO_RELEASE_VERSION\" >> $GITHUB_ENV\n        echo \"PRESTO_RELEASE_VERSION=$PRESTO_RELEASE_VERSION\"\n\n    - name: Prepare release tag and commits\n      run: |\n        git reset --hard\n        unset MAVEN_CONFIG && ./mvnw release:prepare --batch-mode \\\n          -DskipTests \\\n          -DautoVersionSubmodules \\\n          -DdevelopmentVersion=${{ env.PRESTO_RELEASE_VERSION }} \\\n          -DreleaseVersion=${{ env.PRESTO_RELEASE_VERSION }}\n        grep -m 2 \"<version>\" pom.xml\n        echo \"commits on master branch\"\n        git ls -5\n\n    - name: Push release tag, branch and commits\n      run: |\n        echo \"In case this job failed, please delete the tag ${{ env.PRESTO_RELEASE_VERSION }} and the branch release-${{ env.PRESTO_RELEASE_VERSION }}, and re-run the job\"\n        git checkout ${{ env.PRESTO_RELEASE_VERSION }}\n        git switch -c release-${{ env.PRESTO_RELEASE_VERSION }}\n        echo \"Pushing release branch release-${{ env.PRESTO_RELEASE_VERSION }} and tag ${{ env.PRESTO_RELEASE_VERSION }}\"\n\n        echo \"commits on release-${{ env.PRESTO_RELEASE_VERSION }} branch\"\n        git ls -4\n        git push origin release-${{ env.PRESTO_RELEASE_VERSION }} --tags\n        echo -e \"\\nPushed release tag to: ${{ github.server_url }}/${{ github.repository }}/releases/tag/${{ env.PRESTO_RELEASE_VERSION }}\"\n        echo \"Pushed release branch to: ${{ github.server_url }}/${{ github.repository }}/tree/release-${{ env.PRESTO_RELEASE_VERSION }}\"\n\n        echo \"Pushing master branch\"\n        git checkout master\n        echo \"commits on master branch\"\n        git ls -5\n        git push origin master\n\n  prepare-release-notes:\n    needs: prepare-release-branch\n    if: ${{ inputs.prepare_release_notes && always() && \n      (needs.prepare-release-branch.result == 'success' || \n      !inputs.prepare_release) }}\n    runs-on: ubuntu-latest\n    environment: release\n    permissions:\n      contents: write\n\n    steps:\n    - name: Checkout presto source\n      uses: actions/checkout@v4\n      with:\n        ref: master\n        show-progress: false\n\n    - name: Set up JDK\n      uses: actions/setup-java@v4\n      with:\n        java-version: ${{ env.JAVA_VERSION }}\n        distribution: ${{ env.JAVA_DISTRIBUTION }}\n\n    - name: Configure git\n      run: |\n        git config --global --add safe.directory ${{github.workspace}}\n        git config --global user.email \"ci@lists.prestodb.io\"\n        git config --global user.name \"prestodb-ci\"\n        git config pull.rebase false\n\n    - name: Add git upstream\n      run: |\n        git remote add upstream ${{ github.server_url }}/${{ github.repository }}.git\n        git fetch upstream --tags\n        git remote -v\n\n    - name: Create release notes pull request\n      run: |\n        echo \"In case this job failed, please delete the release notes branch(e.g. release-notes-0.292) in repository ${{ github.repository }}, and re-run the job\"\n        ./src/release/release-notes.sh ${{ github.repository_owner }} ${{ secrets.PRESTODB_CI_TOKEN }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Presto Stable Release - Prepare` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 2 inputs: prepare_release-this input represents prepare release branch and tag, the data type is boolean, its default value is True and it is optional; prepare_release_notes-this input represents prepare release notes pull request, the data type is boolean, its default value is True and it is optional. The workflow sets 2 environment variables to use: `JAVA_VERSION` is set to `11` and `JAVA_DISTRIBUTION` is set to `temurin`. The workflow has 2 jobs. The job id of the 1st job is `prepare-release-branch`. The job id of the 2nd job is `prepare-release-notes`. ","prompt_level2":"Generate a GitHub Workflow named `Presto Stable Release - Prepare` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 2 inputs: prepare_release-this input represents prepare release branch and tag, the data type is boolean, its default value is True and it is optional; prepare_release_notes-this input represents prepare release notes pull request, the data type is boolean, its default value is True and it is optional. The workflow sets 2 environment variables to use: `JAVA_VERSION` is set to `11` and `JAVA_DISTRIBUTION` is set to `temurin`. The workflow has 2 jobs. The job id of the 1st job is `prepare-release-branch`. The job `prepare-release-branch` has 8 steps. The 1st step is named `Check for master branch`. The 2nd step is named `Checkout repository`. The 3rd step is named `Set up JDK`. The 4th step is named `Configure git`. The 5th step is named `Set presto release version`. The 6th step is named `Get presto release version` and its id is `get-version`. The 7th step is named `Prepare release tag and commits`. The 8th step is named `Push release tag, branch and commits`. The job id of the 2nd job is `prepare-release-notes`. The job `prepare-release-notes` has 5 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up JDK`. The 3rd step is named `Configure git`. The 4th step is named `Add git upstream`. The 5th step is named `Create release notes pull request`. ","prompt_level3":"Generate a GitHub Workflow named `Presto Stable Release - Prepare` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 2 inputs: prepare_release-this input represents prepare release branch and tag, the data type is boolean, its default value is True and it is optional; prepare_release_notes-this input represents prepare release notes pull request, the data type is boolean, its default value is True and it is optional. The workflow sets 2 environment variables to use: `JAVA_VERSION` is set to `11` and `JAVA_DISTRIBUTION` is set to `temurin`. The workflow has 2 jobs. The job id of the 1st job is `prepare-release-branch`. This job will run only if the condition(${{ inputs.prepare_release }}) is met. This job will run on ubuntu-latest runner. The job `prepare-release-branch` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting only applies to the job `prepare-release-branch`. This job references release environment. The job `prepare-release-branch` has 8 steps. The 1st step is named `Check for master branch`. This step will run only if the condition(${{ github.ref != 'refs/heads/master' }}) is met. This step runs a script: `echo \"Invalid branch. This action can only be run on the master branch.\" && exit 1`. The 2nd step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines 4 input parameters for the action: `token` is set to `${{ secrets.PRESTODB_CI_TOKEN }}`, `ref` is set to `master`, `show-progress` is set to `False` and `fetch-depth` is set to `5`. The 3rd step is named `Set up JDK`. This step runs action `actions/setup-java` tagged as v4. The step defines 2 input parameters for the action: `java-version` is set to `${{ env.JAVA_VERSION }}` and `distribution` is set to `${{ env.JAVA_DISTRIBUTION }}`. The 4th step is named `Configure git`. This step runs a script: `git config --global --add safe.directory ${{github.workspace}}\ngit config --global user.email \"ci@lists.prestodb.io\"\ngit config --global user.name \"prestodb-ci\"\ngit config --global alias.ls 'log --pretty=format:\"%cd %h %ce: %s\" --date=short --no-merges'\ngit config pull.rebase false\n`. The 5th step is named `Set presto release version`. This step runs a script: `unset MAVEN_CONFIG && ./mvnw versions:set -DremoveSnapshot -ntp\n`. The 6th step is named `Get presto release version` and its id is `get-version`. This step runs a script: `PRESTO_RELEASE_VERSION=$(mvn org.apache.maven.plugins:maven-help-plugin:3.2.0:evaluate \\\n  -Dexpression=project.version -q -ntp -DforceStdout | tail -n 1)\necho \"PRESTO_RELEASE_VERSION=$PRESTO_RELEASE_VERSION\" >> $GITHUB_ENV\necho \"PRESTO_RELEASE_VERSION=$PRESTO_RELEASE_VERSION\"\n`. The 7th step is named `Prepare release tag and commits`. This step runs a script: `git reset --hard\nunset MAVEN_CONFIG && ./mvnw release:prepare --batch-mode \\\n  -DskipTests \\\n  -DautoVersionSubmodules \\\n  -DdevelopmentVersion=${{ env.PRESTO_RELEASE_VERSION }} \\\n  -DreleaseVersion=${{ env.PRESTO_RELEASE_VERSION }}\ngrep -m 2 \"<version>\" pom.xml\necho \"commits on master branch\"\ngit ls -5\n`. The 8th step is named `Push release tag, branch and commits`. This step runs a script: `echo \"In case this job failed, please delete the tag ${{ env.PRESTO_RELEASE_VERSION }} and the branch release-${{ env.PRESTO_RELEASE_VERSION }}, and re-run the job\"\ngit checkout ${{ env.PRESTO_RELEASE_VERSION }}\ngit switch -c release-${{ env.PRESTO_RELEASE_VERSION }}\necho \"Pushing release branch release-${{ env.PRESTO_RELEASE_VERSION }} and tag ${{ env.PRESTO_RELEASE_VERSION }}\"\n\necho \"commits on release-${{ env.PRESTO_RELEASE_VERSION }} branch\"\ngit ls -4\ngit push origin release-${{ env.PRESTO_RELEASE_VERSION }} --tags\necho -e \"\\nPushed release tag to: ${{ github.server_url }}/${{ github.repository }}/releases/tag/${{ env.PRESTO_RELEASE_VERSION }}\"\necho \"Pushed release branch to: ${{ github.server_url }}/${{ github.repository }}/tree/release-${{ env.PRESTO_RELEASE_VERSION }}\"\n\necho \"Pushing master branch\"\ngit checkout master\necho \"commits on master branch\"\ngit ls -5\ngit push origin master\n`. The job id of the 2nd job is `prepare-release-notes`. Before this job runs, `prepare-release-branch` must complete successfully. This job will run only if the condition(${{ inputs.prepare_release_notes && always() && (needs.prepare-release-branch.result == 'success' || !inputs.prepare_release) }}) is met. This job will run on ubuntu-latest runner. The job `prepare-release-notes` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting only applies to the job `prepare-release-notes`. This job references release environment. The job `prepare-release-notes` has 5 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines 2 input parameters for the action: `ref` is set to `master` and `show-progress` is set to `False`. The 2nd step is named `Set up JDK`. This step runs action `actions/setup-java` tagged as v4. The step defines 2 input parameters for the action: `java-version` is set to `${{ env.JAVA_VERSION }}` and `distribution` is set to `${{ env.JAVA_DISTRIBUTION }}`. The 3rd step is named `Configure git`. This step runs a script: `git config --global --add safe.directory ${{github.workspace}}\ngit config --global user.email \"ci@lists.prestodb.io\"\ngit config --global user.name \"prestodb-ci\"\ngit config pull.rebase false\n`. The 4th step is named `Add git upstream`. This step runs a script: `git remote add upstream ${{ github.server_url }}/${{ github.repository }}.git\ngit fetch upstream --tags\ngit remote -v\n`. The 5th step is named `Create release notes pull request`. This step runs a script: `echo \"In case this job failed, please delete the release notes branch(e.g. release-notes-0.292) in repository ${{ github.repository }}, and re-run the job\"\n./src/release/release-notes.sh ${{ github.repository_owner }} ${{ secrets.PRESTODB_CI_TOKEN }}\n`. ","nb_triggers":1,"triggers":["workflow_dispatch"],"nb_jobs":2,"nb_actions":4,"actions":["actions/checkout","actions/checkout","actions/setup-java","actions/setup-java"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/setup-java"},{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/setup-java"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":13,"cyclomatic_complexity":1}
{"id":49998,"repository_id":6848860,"mainLanguage":"JavaScript","file_name":"check_duplicate_prs.yml","file_content":"#/\n# @license Apache-2.0\n#\n# Copyright (c) 2025 The Stdlib Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#/\n\n# Workflow name:\nname: check_duplicate_prs\n\n# Workflow triggers:\non:\n  # Run the workflow daily at 3 AM UTC:\n  schedule:\n    - cron: '0 3 * * *'\n\n  # Allow the workflow to be manually run:\n  workflow_dispatch:\n    inputs:\n      debug:\n        description: 'Enable debug output'\n        required: false\n        default: 'false'\n        type: choice\n        options:\n          - 'true'\n          - 'false'\n\n# Global permissions:\npermissions:\n  # Allow read-only access to the repository contents:\n  contents: read\n\n# Workflow jobs:\njobs:\n\n  # Define a job for checking duplicate PRs...\n  check_duplicates:\n\n    # Define a display name:\n    name: 'Check Duplicate PRs'\n\n    # Ensure the job does not run on forks:\n    if: github.repository == 'stdlib-js/stdlib'\n\n    # Define the type of virtual host machine:\n    runs-on: ubuntu-latest\n\n    # Define the sequence of job steps...\n    steps:\n      # Checkout the repository:\n      - name: 'Checkout repository'\n        # Pin action to full length commit SHA\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n        with:\n          # Ensure we have access to the scripts directory:\n          sparse-checkout: |\n            .github/workflows/scripts\n          sparse-checkout-cone-mode: false\n        timeout-minutes: 10\n\n      # Check for duplicate PRs:\n      - name: 'Check for duplicate PRs'\n        env:\n          GITHUB_TOKEN: ${{ secrets.STDLIB_BOT_PAT_REPO_WRITE }}\n          DEBUG: ${{ inputs.debug || 'false' }}\n        run: |\n          . \"$GITHUB_WORKSPACE/.github/workflows/scripts/check_duplicate_prs\"\n        timeout-minutes: 15\n","repository_owner":"stdlib-js","repository_name":"stdlib","tokens_count":563,"workflow":"#/\n# @license Apache-2.0\n#\n# Copyright (c) 2025 The Stdlib Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#/\n\n# Workflow name:\nname: check_duplicate_prs\n\n# Workflow triggers:\non:\n  # Run the workflow daily at 3 AM UTC:\n  schedule:\n  - cron: 0 3 * * *\n\n  # Allow the workflow to be manually run:\n  workflow_dispatch:\n    inputs:\n      debug:\n        description: Enable debug output\n        required: false\n        default: 'false'\n        type: choice\n        options:\n        - 'true'\n        - 'false'\n\n# Global permissions:\npermissions:\n  # Allow read-only access to the repository contents:\n  contents: read\n\n# Workflow jobs:\njobs:\n\n  # Define a job for checking duplicate PRs...\n  check_duplicates:\n\n    # Define a display name:\n    name: Check Duplicate PRs\n\n    # Ensure the job does not run on forks:\n    if: github.repository == 'stdlib-js/stdlib'\n\n    # Define the type of virtual host machine:\n    runs-on: ubuntu-latest\n\n    # Define the sequence of job steps...\n    steps:\n      # Checkout the repository:\n    - name: Checkout repository\n        # Pin action to full length commit SHA\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683   # v4.2.2\n      with:\n          # Ensure we have access to the scripts directory:\n        sparse-checkout: |\n          .github/workflows/scripts\n        sparse-checkout-cone-mode: false\n      timeout-minutes: 10\n\n      # Check for duplicate PRs:\n    - name: Check for duplicate PRs\n      env:\n        GITHUB_TOKEN: ${{ secrets.STDLIB_BOT_PAT_REPO_WRITE }}\n        DEBUG: ${{ inputs.debug || 'false' }}\n      run: |\n        . \"$GITHUB_WORKSPACE/.github/workflows/scripts/check_duplicate_prs\"\n      timeout-minutes: 15\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `check_duplicate_prs` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 03:00 am. 2) someone manually triggers the workflow. This workflow receives an input: debug-this input represents enable debug output, it is optional, its default value is false, the data type is choice and it has options including true and false. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Check Duplicate PRs` and its job id is `check_duplicates`. ","prompt_level2":"Generate a GitHub Workflow named `check_duplicate_prs` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 03:00 am. 2) someone manually triggers the workflow. This workflow receives an input: debug-this input represents enable debug output, it is optional, its default value is false, the data type is choice and it has options including true and false. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Check Duplicate PRs` and its job id is `check_duplicates`. The job `check_duplicates` has 2 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Check for duplicate PRs`. ","prompt_level3":"Generate a GitHub Workflow named `check_duplicate_prs` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 03:00 am. 2) someone manually triggers the workflow. This workflow receives an input: debug-this input represents enable debug output, it is optional, its default value is false, the data type is choice and it has options including true and false. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Check Duplicate PRs` and its job id is `check_duplicates`. This job will run only if the condition(github.repository == 'stdlib-js/stdlib') is met. This job will run on ubuntu-latest runner. The job `check_duplicates` has 2 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is 11bd71901bbe5b1630ceea73d27597364c9af683. The step defines 2 input parameters for the action: `sparse-checkout` is set to `.github/workflows/scripts\n` and `sparse-checkout-cone-mode` is set to `False`. The maximum number of minutes to run the step is 10. The 2nd step is named `Check for duplicate PRs`. The step sets 2 environment variables to use: `GITHUB_TOKEN` is set to `${{ secrets.STDLIB_BOT_PAT_REPO_WRITE }}` and `DEBUG` is set to `${{ inputs.debug || 'false' }}`. This step runs a script: `. \"$GITHUB_WORKSPACE/.github/workflows/scripts/check_duplicate_prs\"\n`. The maximum number of minutes to run the step is 15. ","nb_triggers":2,"triggers":["schedule","workflow_dispatch"],"nb_jobs":1,"nb_actions":1,"actions":["actions/checkout"],"actions_details":[{"version":"11bd71901bbe5b1630ceea73d27597364c9af683","name":"actions/checkout"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":2,"cyclomatic_complexity":1}
{"id":30644,"repository_id":94530930,"mainLanguage":"Python","file_name":"start_ec2_runner.yml","file_content":"name: Start EC2 Runner\n\non:\n  workflow_call:\n    inputs:\n      base-ami-id:\n        description: 'Base AMI ID for the EC2 runner'\n        required: true\n        type: string\n      ec2-instance-type:\n        description: 'Instance type for the EC2 runner'\n        required: true\n        type: string\n    secrets:\n      GH_PERSONAL_ACCESS_TOKEN:\n        required: true\n      MARQO_WORKFLOW_TESTS_SUBNET_ID:\n        required: true\n      MARQO_WORKFLOW_TESTS_SECURITY_GROUP_ID:\n        required: true\n    outputs:\n      label:\n        description: \"EC2 Runner Label\"\n        value: ${{ jobs.Start-Runner.outputs.label }}\n      ec2-instance-id:\n        description: \"EC2 Instance ID\"\n        value: ${{ jobs.Start-Runner.outputs.ec2-instance-id }}\n\njobs:\n  Start-Runner:\n    name: Start EC2 runner\n    runs-on: ubuntu-latest\n    outputs:\n      label: ${{ steps.start-ec2-runner.outputs.label }}\n      ec2-instance-id: ${{ steps.start-ec2-runner.outputs.ec2-instance-id }}\n    steps:\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-region: us-east-1\n          role-to-assume: arn:aws:iam::424082663841:role/GhRunnerManagerRole-Marqo\n\n      - name: Start EC2 runner\n        id: start-ec2-runner\n        uses: machulav/ec2-github-runner@v2\n        with:\n          mode: start\n          github-token: ${{ secrets.GH_PERSONAL_ACCESS_TOKEN }}\n          ec2-image-id: ${{ inputs.base-ami-id }}\n          ec2-instance-type: ${{ inputs.ec2-instance-type }}\n          subnet-id: ${{ secrets.MARQO_WORKFLOW_TESTS_SUBNET_ID }}\n          security-group-id: ${{ secrets.MARQO_WORKFLOW_TESTS_SECURITY_GROUP_ID }}\n          aws-resource-tags: >\n            [\n              {\"Key\": \"Name\", \"Value\": \"marqo-github-runner-${{ github.run_id }}\"},\n              {\"Key\": \"GitHubRepo\", \"Value\": \"${{ github.repository }}\"},\n              {\"Key\": \"WorkflowName\", \"Value\": \"${{ github.workflow }}\"},\n              {\"Key\": \"WorkflowRunId\", \"Value\": \"${{ github.run_id }}\"},\n              {\"Key\": \"WorkflowURL\", \"Value\": \"${{ github.event.repository.html_url }}/actions/runs/${{ github.run_id }}\"},\n              {\"Key\": \"PoloRole\", \"Value\": \"testing\"}\n            ]\n\npermissions:\n  contents: read\n  id-token: write","repository_owner":"marqo-ai","repository_name":"marqo","tokens_count":575,"workflow":"name: Start EC2 Runner\n\non:\n  workflow_call:\n    inputs:\n      base-ami-id:\n        description: Base AMI ID for the EC2 runner\n        required: true\n        type: string\n      ec2-instance-type:\n        description: Instance type for the EC2 runner\n        required: true\n        type: string\n    secrets:\n      GH_PERSONAL_ACCESS_TOKEN:\n        required: true\n      MARQO_WORKFLOW_TESTS_SUBNET_ID:\n        required: true\n      MARQO_WORKFLOW_TESTS_SECURITY_GROUP_ID:\n        required: true\n    outputs:\n      label:\n        description: EC2 Runner Label\n        value: ${{ jobs.Start-Runner.outputs.label }}\n      ec2-instance-id:\n        description: EC2 Instance ID\n        value: ${{ jobs.Start-Runner.outputs.ec2-instance-id }}\n\njobs:\n  Start-Runner:\n    name: Start EC2 runner\n    runs-on: ubuntu-latest\n    outputs:\n      label: ${{ steps.start-ec2-runner.outputs.label }}\n      ec2-instance-id: ${{ steps.start-ec2-runner.outputs.ec2-instance-id }}\n    steps:\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v4\n      with:\n        aws-region: us-east-1\n        role-to-assume: arn:aws:iam::424082663841:role/GhRunnerManagerRole-Marqo\n\n    - name: Start EC2 runner\n      id: start-ec2-runner\n      uses: machulav/ec2-github-runner@v2\n      with:\n        mode: start\n        github-token: ${{ secrets.GH_PERSONAL_ACCESS_TOKEN }}\n        ec2-image-id: ${{ inputs.base-ami-id }}\n        ec2-instance-type: ${{ inputs.ec2-instance-type }}\n        subnet-id: ${{ secrets.MARQO_WORKFLOW_TESTS_SUBNET_ID }}\n        security-group-id: ${{ secrets.MARQO_WORKFLOW_TESTS_SECURITY_GROUP_ID }}\n        aws-resource-tags: >\n          [\n            {\"Key\": \"Name\", \"Value\": \"marqo-github-runner-${{ github.run_id }}\"},\n            {\"Key\": \"GitHubRepo\", \"Value\": \"${{ github.repository }}\"},\n            {\"Key\": \"WorkflowName\", \"Value\": \"${{ github.workflow }}\"},\n            {\"Key\": \"WorkflowRunId\", \"Value\": \"${{ github.run_id }}\"},\n            {\"Key\": \"WorkflowURL\", \"Value\": \"${{ github.event.repository.html_url\n          }}/actions/runs/${{ github.run_id }}\"},\n            {\"Key\": \"PoloRole\", \"Value\": \"testing\"}\n          ]\n\npermissions:\n  contents: read\n  id-token: write\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Start EC2 Runner` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 2 inputs: base-ami-id-this input represents base ami id for the ec2 runner, it must be supplied and the data type is string; ec2-instance-type-this input represents instance type for the ec2 runner, it must be supplied and the data type is string. This workflow has 2 outputs: label-it represents ec2 runner label and its value is ${{ jobs.Start-Runner.outputs.label }}; ec2-instance-id-it represents ec2 instance id and its value is ${{ jobs.Start-Runner.outputs.ec2-instance-id }}. It receives 3 secrets: GH_PERSONAL_ACCESS_TOKEN-it must be supplied; MARQO_WORKFLOW_TESTS_SUBNET_ID-it must be supplied; MARQO_WORKFLOW_TESTS_SECURITY_GROUP_ID-it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Start EC2 runner` and its job id is `Start-Runner`. ","prompt_level2":"Generate a GitHub Workflow named `Start EC2 Runner` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 2 inputs: base-ami-id-this input represents base ami id for the ec2 runner, it must be supplied and the data type is string; ec2-instance-type-this input represents instance type for the ec2 runner, it must be supplied and the data type is string. This workflow has 2 outputs: label-it represents ec2 runner label and its value is ${{ jobs.Start-Runner.outputs.label }}; ec2-instance-id-it represents ec2 instance id and its value is ${{ jobs.Start-Runner.outputs.ec2-instance-id }}. It receives 3 secrets: GH_PERSONAL_ACCESS_TOKEN-it must be supplied; MARQO_WORKFLOW_TESTS_SUBNET_ID-it must be supplied; MARQO_WORKFLOW_TESTS_SECURITY_GROUP_ID-it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Start EC2 runner` and its job id is `Start-Runner`. The job `Start-Runner` has 2 steps. The 1st step is named `Configure AWS credentials`. The 2nd step is named `Start EC2 runner` and its id is `start-ec2-runner`. ","prompt_level3":"Generate a GitHub Workflow named `Start EC2 Runner` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 2 inputs: base-ami-id-this input represents base ami id for the ec2 runner, it must be supplied and the data type is string; ec2-instance-type-this input represents instance type for the ec2 runner, it must be supplied and the data type is string. This workflow has 2 outputs: label-it represents ec2 runner label and its value is ${{ jobs.Start-Runner.outputs.label }}; ec2-instance-id-it represents ec2 instance id and its value is ${{ jobs.Start-Runner.outputs.ec2-instance-id }}. It receives 3 secrets: GH_PERSONAL_ACCESS_TOKEN-it must be supplied; MARQO_WORKFLOW_TESTS_SUBNET_ID-it must be supplied; MARQO_WORKFLOW_TESTS_SECURITY_GROUP_ID-it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Start EC2 runner` and its job id is `Start-Runner`. This job will run on ubuntu-latest runner. The job `Start-Runner` has 2 steps. The 1st step is named `Configure AWS credentials`. This step runs action `aws-actions/configure-aws-credentials` tagged as v4. The step defines 2 input parameters for the action: `aws-region` is set to `us-east-1` and `role-to-assume` is set to `arn:aws:iam::424082663841:role/GhRunnerManagerRole-Marqo`. The 2nd step is named `Start EC2 runner` and its id is `start-ec2-runner`. This step runs action `machulav/ec2-github-runner` tagged as v2. The step defines 7 input parameters for the action: `mode` is set to `start`, `github-token` is set to `${{ secrets.GH_PERSONAL_ACCESS_TOKEN }}`, `ec2-image-id` is set to `${{ inputs.base-ami-id }}`, `ec2-instance-type` is set to `${{ inputs.ec2-instance-type }}`, `subnet-id` is set to `${{ secrets.MARQO_WORKFLOW_TESTS_SUBNET_ID }}`, `security-group-id` is set to `${{ secrets.MARQO_WORKFLOW_TESTS_SECURITY_GROUP_ID }}` and `aws-resource-tags` is set to `[\n  {\"Key\": \"Name\", \"Value\": \"marqo-github-runner-${{ github.run_id }}\"},\n  {\"Key\": \"GitHubRepo\", \"Value\": \"${{ github.repository }}\"},\n  {\"Key\": \"WorkflowName\", \"Value\": \"${{ github.workflow }}\"},\n  {\"Key\": \"WorkflowRunId\", \"Value\": \"${{ github.run_id }}\"},\n  {\"Key\": \"WorkflowURL\", \"Value\": \"${{ github.event.repository.html_url\n}}/actions/runs/${{ github.run_id }}\"},\n  {\"Key\": \"PoloRole\", \"Value\": \"testing\"}\n]\n`. This job has 2 outputs: `label` is defined as ${{ steps.start-ec2-runner.outputs.label }} and `ec2-instance-id` is defined as ${{ steps.start-ec2-runner.outputs.ec2-instance-id }}. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":2,"actions":["aws-actions/configure-aws-credentials","machulav/ec2-github-runner"],"actions_details":[{"version":"v4","name":"aws-actions/configure-aws-credentials"},{"version":"v2","name":"machulav/ec2-github-runner"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":2,"cyclomatic_complexity":1}
{"id":10043,"repository_id":94708621,"mainLanguage":"Python","file_name":"publish.yml","file_content":"# publish.yml\n\nname: \"Publish\"\n\non:\n  release:\n    types: [\"published\"]\n\njobs:\n  pypi:\n    name: \"Build and publish release\"\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv \n        uses: astral-sh/setup-uv@v3\n        with:\n          enable-cache: true\n          cache-dependency-glob: uv.lock\n\n      - name: Run UV Sync\n        run: |\n          uv sync\n\n      - name: Build\n        run: uv build\n\n      - name: Publish\n        run: uv publish -t ${{ secrets.THE_PYPI_TOKEN }}\n\n  build_docker_amd:\n    name: \"Build and Publish for AMD\"\n    runs-on: ubuntu-latest\n    needs: pypi\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          version: latest\n          driver-opts: |\n            image=moby/buildkit:master\n\n      - name: Login to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Get version from tag\n        id: get_version\n        run: echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT\n\n      - name: Build and Publish Docker Images\n        env:\n          VERSION: ${{ steps.get_version.outputs.VERSION }}\n        run: |\n          cd ..\n          # Build for AMD64\n          docker buildx create --use --name single-arch-builder\n          docker buildx build --platform linux/amd64 \\\n            -f Upsonic/Dockerfile \\\n            --push \\\n            --load \\\n            -t upsonic/server:$VERSION-amd64 \\\n            -t upsonic/server:latest-amd64 \\\n            .\n          docker push upsonic/server:$VERSION-amd64\n          docker push upsonic/server:latest-amd64\n\n  build_docker_arm:\n    name: \"Build and Publish for ARM\"\n    runs-on: ubuntu-24.04-arm\n    needs: pypi\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          version: latest\n          driver-opts: |\n            image=moby/buildkit:master\n\n      - name: Login to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Get version from tag\n        id: get_version\n        run: echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT\n\n      - name: Build and Publish Docker Images for ARM\n        env:\n          VERSION: ${{ steps.get_version.outputs.VERSION }}\n        run: |\n          cd ..\n          # Build for ARM64\n          docker buildx create --use --name single-arch-builder\n          docker buildx build --platform linux/arm64 \\\n            -f Upsonic/Dockerfile \\\n            --push \\\n            --load \\\n            -t upsonic/server:$VERSION-arm64 \\\n            -t upsonic/server:latest-arm64 \\\n            .\n          docker push upsonic/server:$VERSION-arm64\n          docker push upsonic/server:latest-arm64\n\n  create_manifest:\n    name: \"Create Multi-Architecture Manifest\"\n    needs: [build_docker_amd, build_docker_arm]\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Login to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Get version from tag\n        id: get_version\n        run: echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT\n\n      - name: Create and Push Manifest\n        env:\n          VERSION: ${{ steps.get_version.outputs.VERSION }}\n          DOCKER_CLI_EXPERIMENTAL: enabled\n          DOCKER_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n          DOCKER_PASSWORD: ${{ secrets.DOCKERHUB_TOKEN }}\n        run: |\n          mkdir -p ~/.docker\n          \n          # Create proper config with auth\n          echo \"{\n            \\\"experimental\\\": \\\"enabled\\\",\n            \\\"auths\\\": {\n              \\\"https://index.docker.io/v1/\\\": {\n                \\\"auth\\\": \\\"$(echo -n ${DOCKER_USERNAME}:${DOCKER_PASSWORD} | base64)\\\"\n              }\n            }\n          }\" > ~/.docker/config.json\n          \n          # Ensure we're logged in via docker login command as well\n          echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin\n          \n          # Pull the images first to ensure we have the correct manifests locally\n          docker pull upsonic/server:$VERSION-amd64\n          docker pull upsonic/server:$VERSION-arm64\n          docker pull upsonic/server:latest-amd64\n          docker pull upsonic/server:latest-arm64\n          \n          # Remove existing manifests if they exist\n          docker manifest rm upsonic/server:$VERSION || true\n          docker manifest rm upsonic/server:latest || true\n          \n          # Create and push the version manifest\n          docker manifest create upsonic/server:$VERSION \\\n            upsonic/server:$VERSION-amd64 \\\n            upsonic/server:$VERSION-arm64\n\n          # Create and push the latest manifest\n          docker manifest create upsonic/server:latest \\\n            upsonic/server:latest-amd64 \\\n            upsonic/server:latest-arm64\n\n          # Annotate the version manifest\n          docker manifest annotate upsonic/server:$VERSION \\\n            upsonic/server:$VERSION-amd64 --arch amd64 --os linux\n          docker manifest annotate upsonic/server:$VERSION \\\n            upsonic/server:$VERSION-arm64 --arch arm64 --os linux\n\n          # Annotate the latest manifest\n          docker manifest annotate upsonic/server:latest \\\n            upsonic/server:latest-amd64 --arch amd64 --os linux\n          docker manifest annotate upsonic/server:latest \\\n            upsonic/server:latest-arm64 --arch arm64 --os linux\n\n          # Inspect before pushing to verify\n          docker manifest inspect upsonic/server:$VERSION\n          docker manifest inspect upsonic/server:latest\n\n          # Push the manifests with retries\n          for manifest in \"$VERSION\" \"latest\"; do\n            for i in 1 2 3; do\n              if docker manifest push --purge upsonic/server:$manifest; then\n                echo \"Successfully pushed manifest for $manifest\"\n                break\n              fi\n              echo \"Push attempt $i failed for $manifest, retrying...\"\n              # Re-login before retry\n              echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin\n              sleep 5\n              if [ $i -eq 3 ]; then\n                echo \"Failed to push manifest for $manifest after 3 attempts\"\n                exit 1\n              fi\n            done\n          done\n","repository_owner":"Upsonic","repository_name":"Upsonic","tokens_count":1601,"workflow":"# publish.yml\n\nname: Publish\n\non:\n  release:\n    types: [published]\n\njobs:\n  pypi:\n    name: Build and publish release\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Install uv\n      uses: astral-sh/setup-uv@v3\n      with:\n        enable-cache: true\n        cache-dependency-glob: uv.lock\n\n    - name: Run UV Sync\n      run: |\n        uv sync\n\n    - name: Build\n      run: uv build\n\n    - name: Publish\n      run: uv publish -t ${{ secrets.THE_PYPI_TOKEN }}\n\n  build_docker_amd:\n    name: Build and Publish for AMD\n    runs-on: ubuntu-latest\n    needs: pypi\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v3\n      with:\n        version: latest\n        driver-opts: |\n          image=moby/buildkit:master\n\n    - name: Login to Docker Hub\n      uses: docker/login-action@v3\n      with:\n        username: ${{ secrets.DOCKERHUB_USERNAME }}\n        password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n    - name: Get version from tag\n      id: get_version\n      run: echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT\n\n    - name: Build and Publish Docker Images\n      env:\n        VERSION: ${{ steps.get_version.outputs.VERSION }}\n      run: |\n        cd ..\n        # Build for AMD64\n        docker buildx create --use --name single-arch-builder\n        docker buildx build --platform linux/amd64 \\\n          -f Upsonic/Dockerfile \\\n          --push \\\n          --load \\\n          -t upsonic/server:$VERSION-amd64 \\\n          -t upsonic/server:latest-amd64 \\\n          .\n        docker push upsonic/server:$VERSION-amd64\n        docker push upsonic/server:latest-amd64\n\n  build_docker_arm:\n    name: Build and Publish for ARM\n    runs-on: ubuntu-24.04-arm\n    needs: pypi\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v3\n      with:\n        version: latest\n        driver-opts: |\n          image=moby/buildkit:master\n\n    - name: Login to Docker Hub\n      uses: docker/login-action@v3\n      with:\n        username: ${{ secrets.DOCKERHUB_USERNAME }}\n        password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n    - name: Get version from tag\n      id: get_version\n      run: echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT\n\n    - name: Build and Publish Docker Images for ARM\n      env:\n        VERSION: ${{ steps.get_version.outputs.VERSION }}\n      run: |\n        cd ..\n        # Build for ARM64\n        docker buildx create --use --name single-arch-builder\n        docker buildx build --platform linux/arm64 \\\n          -f Upsonic/Dockerfile \\\n          --push \\\n          --load \\\n          -t upsonic/server:$VERSION-arm64 \\\n          -t upsonic/server:latest-arm64 \\\n          .\n        docker push upsonic/server:$VERSION-arm64\n        docker push upsonic/server:latest-arm64\n\n  create_manifest:\n    name: Create Multi-Architecture Manifest\n    needs: [build_docker_amd, build_docker_arm]\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Login to Docker Hub\n      uses: docker/login-action@v3\n      with:\n        username: ${{ secrets.DOCKERHUB_USERNAME }}\n        password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n    - name: Get version from tag\n      id: get_version\n      run: echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT\n\n    - name: Create and Push Manifest\n      env:\n        VERSION: ${{ steps.get_version.outputs.VERSION }}\n        DOCKER_CLI_EXPERIMENTAL: enabled\n        DOCKER_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n        DOCKER_PASSWORD: ${{ secrets.DOCKERHUB_TOKEN }}\n      run: |\n        mkdir -p ~/.docker\n\n        # Create proper config with auth\n        echo \"{\n          \\\"experimental\\\": \\\"enabled\\\",\n          \\\"auths\\\": {\n            \\\"https://index.docker.io/v1/\\\": {\n              \\\"auth\\\": \\\"$(echo -n ${DOCKER_USERNAME}:${DOCKER_PASSWORD} | base64)\\\"\n            }\n          }\n        }\" > ~/.docker/config.json\n\n        # Ensure we're logged in via docker login command as well\n        echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin\n\n        # Pull the images first to ensure we have the correct manifests locally\n        docker pull upsonic/server:$VERSION-amd64\n        docker pull upsonic/server:$VERSION-arm64\n        docker pull upsonic/server:latest-amd64\n        docker pull upsonic/server:latest-arm64\n\n        # Remove existing manifests if they exist\n        docker manifest rm upsonic/server:$VERSION || true\n        docker manifest rm upsonic/server:latest || true\n\n        # Create and push the version manifest\n        docker manifest create upsonic/server:$VERSION \\\n          upsonic/server:$VERSION-amd64 \\\n          upsonic/server:$VERSION-arm64\n\n        # Create and push the latest manifest\n        docker manifest create upsonic/server:latest \\\n          upsonic/server:latest-amd64 \\\n          upsonic/server:latest-arm64\n\n        # Annotate the version manifest\n        docker manifest annotate upsonic/server:$VERSION \\\n          upsonic/server:$VERSION-amd64 --arch amd64 --os linux\n        docker manifest annotate upsonic/server:$VERSION \\\n          upsonic/server:$VERSION-arm64 --arch arm64 --os linux\n\n        # Annotate the latest manifest\n        docker manifest annotate upsonic/server:latest \\\n          upsonic/server:latest-amd64 --arch amd64 --os linux\n        docker manifest annotate upsonic/server:latest \\\n          upsonic/server:latest-arm64 --arch arm64 --os linux\n\n        # Inspect before pushing to verify\n        docker manifest inspect upsonic/server:$VERSION\n        docker manifest inspect upsonic/server:latest\n\n        # Push the manifests with retries\n        for manifest in \"$VERSION\" \"latest\"; do\n          for i in 1 2 3; do\n            if docker manifest push --purge upsonic/server:$manifest; then\n              echo \"Successfully pushed manifest for $manifest\"\n              break\n            fi\n            echo \"Push attempt $i failed for $manifest, retrying...\"\n            # Re-login before retry\n            echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin\n            sleep 5\n            if [ $i -eq 3 ]; then\n              echo \"Failed to push manifest for $manifest after 3 attempts\"\n              exit 1\n            fi\n          done\n        done\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Publish` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: a release, pre-release, or draft of a release is published. The workflow has 4 jobs. The 1st job is named `Build and publish release` and its job id is `pypi`. The 2nd job is named `Build and Publish for AMD` and its job id is `build_docker_amd`. The 3rd job is named `Build and Publish for ARM` and its job id is `build_docker_arm`. The 4th job is named `Create Multi-Architecture Manifest` and its job id is `create_manifest`. ","prompt_level2":"Generate a GitHub Workflow named `Publish` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: a release, pre-release, or draft of a release is published. The workflow has 4 jobs. The 1st job is named `Build and publish release` and its job id is `pypi`. The job `pypi` has 5 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Install uv`. The 3rd step is named `Run UV Sync`. The 4th step is named `Build`. The 5th step is named `Publish`. The 2nd job is named `Build and Publish for AMD` and its job id is `build_docker_amd`. The job `build_docker_amd` has 5 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up Docker Buildx`. The 3rd step is named `Login to Docker Hub`. The 4th step is named `Get version from tag` and its id is `get_version`. The 5th step is named `Build and Publish Docker Images`. The 3rd job is named `Build and Publish for ARM` and its job id is `build_docker_arm`. The job `build_docker_arm` has 5 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up Docker Buildx`. The 3rd step is named `Login to Docker Hub`. The 4th step is named `Get version from tag` and its id is `get_version`. The 5th step is named `Build and Publish Docker Images for ARM`. The 4th job is named `Create Multi-Architecture Manifest` and its job id is `create_manifest`. The job `create_manifest` has 3 steps. The 1st step is named `Login to Docker Hub`. The 2nd step is named `Get version from tag` and its id is `get_version`. The 3rd step is named `Create and Push Manifest`. ","prompt_level3":"Generate a GitHub Workflow named `Publish` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: a release, pre-release, or draft of a release is published. The workflow has 4 jobs. The 1st job is named `Build and publish release` and its job id is `pypi`. This job will run on ubuntu-latest runner. The job `pypi` has 5 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Install uv`. This step runs action `astral-sh/setup-uv` tagged as v3. The step defines 2 input parameters for the action: `enable-cache` is set to `True` and `cache-dependency-glob` is set to `uv.lock`. The 3rd step is named `Run UV Sync`. This step runs a script: `uv sync\n`. The 4th step is named `Build`. This step runs a script: `uv build`. The 5th step is named `Publish`. This step runs a script: `uv publish -t ${{ secrets.THE_PYPI_TOKEN }}`. The 2nd job is named `Build and Publish for AMD` and its job id is `build_docker_amd`. Before this job runs, `pypi` must complete successfully. This job will run on ubuntu-latest runner. The job `build_docker_amd` has 5 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Set up Docker Buildx`. This step runs action `docker/setup-buildx-action` tagged as v3. The step defines 2 input parameters for the action: `version` is set to `latest` and `driver-opts` is set to `image=moby/buildkit:master\n`. The 3rd step is named `Login to Docker Hub`. This step runs action `docker/login-action` tagged as v3. The step defines 2 input parameters for the action: `username` is set to `${{ secrets.DOCKERHUB_USERNAME }}` and `password` is set to `${{ secrets.DOCKERHUB_TOKEN }}`. The 4th step is named `Get version from tag` and its id is `get_version`. This step runs a script: `echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT`. The 5th step is named `Build and Publish Docker Images`. The step sets an environment variable to use: `VERSION` is set to `${{ steps.get_version.outputs.VERSION }}`. This step runs a script: `cd ..\n# Build for AMD64\ndocker buildx create --use --name single-arch-builder\ndocker buildx build --platform linux/amd64 \\\n  -f Upsonic/Dockerfile \\\n  --push \\\n  --load \\\n  -t upsonic/server:$VERSION-amd64 \\\n  -t upsonic/server:latest-amd64 \\\n  .\ndocker push upsonic/server:$VERSION-amd64\ndocker push upsonic/server:latest-amd64\n`. The 3rd job is named `Build and Publish for ARM` and its job id is `build_docker_arm`. Before this job runs, `pypi` must complete successfully. This job will run on ubuntu-24.04-arm runner. The job `build_docker_arm` has 5 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Set up Docker Buildx`. This step runs action `docker/setup-buildx-action` tagged as v3. The step defines 2 input parameters for the action: `version` is set to `latest` and `driver-opts` is set to `image=moby/buildkit:master\n`. The 3rd step is named `Login to Docker Hub`. This step runs action `docker/login-action` tagged as v3. The step defines 2 input parameters for the action: `username` is set to `${{ secrets.DOCKERHUB_USERNAME }}` and `password` is set to `${{ secrets.DOCKERHUB_TOKEN }}`. The 4th step is named `Get version from tag` and its id is `get_version`. This step runs a script: `echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT`. The 5th step is named `Build and Publish Docker Images for ARM`. The step sets an environment variable to use: `VERSION` is set to `${{ steps.get_version.outputs.VERSION }}`. This step runs a script: `cd ..\n# Build for ARM64\ndocker buildx create --use --name single-arch-builder\ndocker buildx build --platform linux/arm64 \\\n  -f Upsonic/Dockerfile \\\n  --push \\\n  --load \\\n  -t upsonic/server:$VERSION-arm64 \\\n  -t upsonic/server:latest-arm64 \\\n  .\ndocker push upsonic/server:$VERSION-arm64\ndocker push upsonic/server:latest-arm64\n`. The 4th job is named `Create Multi-Architecture Manifest` and its job id is `create_manifest`. Before this job runs, `build_docker_amd` and `build_docker_arm` must complete successfully. This job will run on ubuntu-latest runner. The job `create_manifest` has 3 steps. The 1st step is named `Login to Docker Hub`. This step runs action `docker/login-action` tagged as v3. The step defines 2 input parameters for the action: `username` is set to `${{ secrets.DOCKERHUB_USERNAME }}` and `password` is set to `${{ secrets.DOCKERHUB_TOKEN }}`. The 2nd step is named `Get version from tag` and its id is `get_version`. This step runs a script: `echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT`. The 3rd step is named `Create and Push Manifest`. The step sets 4 environment variables to use: `VERSION` is set to `${{ steps.get_version.outputs.VERSION }}`, `DOCKER_CLI_EXPERIMENTAL` is set to `enabled`, `DOCKER_USERNAME` is set to `${{ secrets.DOCKERHUB_USERNAME }}` and `DOCKER_PASSWORD` is set to `${{ secrets.DOCKERHUB_TOKEN }}`. This step runs a script: `mkdir -p ~/.docker\n\n# Create proper config with auth\necho \"{\n  \\\"experimental\\\": \\\"enabled\\\",\n  \\\"auths\\\": {\n    \\\"https://index.docker.io/v1/\\\": {\n      \\\"auth\\\": \\\"$(echo -n ${DOCKER_USERNAME}:${DOCKER_PASSWORD} | base64)\\\"\n    }\n  }\n}\" > ~/.docker/config.json\n\n# Ensure we're logged in via docker login command as well\necho $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin\n\n# Pull the images first to ensure we have the correct manifests locally\ndocker pull upsonic/server:$VERSION-amd64\ndocker pull upsonic/server:$VERSION-arm64\ndocker pull upsonic/server:latest-amd64\ndocker pull upsonic/server:latest-arm64\n\n# Remove existing manifests if they exist\ndocker manifest rm upsonic/server:$VERSION || true\ndocker manifest rm upsonic/server:latest || true\n\n# Create and push the version manifest\ndocker manifest create upsonic/server:$VERSION \\\n  upsonic/server:$VERSION-amd64 \\\n  upsonic/server:$VERSION-arm64\n\n# Create and push the latest manifest\ndocker manifest create upsonic/server:latest \\\n  upsonic/server:latest-amd64 \\\n  upsonic/server:latest-arm64\n\n# Annotate the version manifest\ndocker manifest annotate upsonic/server:$VERSION \\\n  upsonic/server:$VERSION-amd64 --arch amd64 --os linux\ndocker manifest annotate upsonic/server:$VERSION \\\n  upsonic/server:$VERSION-arm64 --arch arm64 --os linux\n\n# Annotate the latest manifest\ndocker manifest annotate upsonic/server:latest \\\n  upsonic/server:latest-amd64 --arch amd64 --os linux\ndocker manifest annotate upsonic/server:latest \\\n  upsonic/server:latest-arm64 --arch arm64 --os linux\n\n# Inspect before pushing to verify\ndocker manifest inspect upsonic/server:$VERSION\ndocker manifest inspect upsonic/server:latest\n\n# Push the manifests with retries\nfor manifest in \"$VERSION\" \"latest\"; do\n  for i in 1 2 3; do\n    if docker manifest push --purge upsonic/server:$manifest; then\n      echo \"Successfully pushed manifest for $manifest\"\n      break\n    fi\n    echo \"Push attempt $i failed for $manifest, retrying...\"\n    # Re-login before retry\n    echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin\n    sleep 5\n    if [ $i -eq 3 ]; then\n      echo \"Failed to push manifest for $manifest after 3 attempts\"\n      exit 1\n    fi\n  done\ndone\n`. ","nb_triggers":1,"triggers":["release"],"nb_jobs":4,"nb_actions":9,"actions":["actions/checkout","actions/checkout","actions/checkout","astral-sh/setup-uv","docker/login-action","docker/login-action","docker/login-action","docker/setup-buildx-action","docker/setup-buildx-action"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v3","name":"astral-sh/setup-uv"},{"version":"v4","name":"actions/checkout"},{"version":"v3","name":"docker/setup-buildx-action"},{"version":"v3","name":"docker/login-action"},{"version":"v4","name":"actions/checkout"},{"version":"v3","name":"docker/setup-buildx-action"},{"version":"v3","name":"docker/login-action"},{"version":"v3","name":"docker/login-action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":18,"cyclomatic_complexity":2}
{"id":1909,"repository_id":16148273,"mainLanguage":"Go","file_name":"test-latest-releases.yml","file_content":"name: \"Check: Check release on package managers\"\nrun-name: \"Check: Check release on package managers [${{ github.ref_name }}]\"\n\non:\n  workflow_dispatch:\n    inputs:\n      major-version:\n        description: Major version to retrieve\n        required: true\n        type: choice\n        options:\n          - '8'\n          - '7'\n      version:\n        description: Version of CLI to check if it is present\n        type: string\n        required: true\n      claw-url:\n        description: Location of CLAW\n        type: string\n        required: true\n        default: https://packages.cloudfoundry.org\n\ndefaults:\n  run:\n    shell: bash\n\njobs:\n  test-homebrew:\n    name: Test Homebrew Repository\n    runs-on: macos-latest\n    env:\n      CLAW_URL: ${{ inputs.claw-url }}\n      VERSION_BUILD: ${{ inputs.version }}\n      VERSION_MAJOR: ${{ inputs.major-version }}\n    steps:\n\n      - name: Install CF CLI via Homebrew\n        run: |\n          set -evx\n          \n          brew install cloudfoundry/tap/cf-cli@${VERSION_MAJOR}\n          installed_cf_version=$(cf${VERSION_MAJOR} version)\n          \n          cf_location=$(which cf)\n          \n          echo $cf_location\n          echo $installed_cf_version\n          echo ${VERSION_BUILD}\n          \n          codesign --verify $cf_location || echo ---\n          \n          cf -v | grep \"${VERSION_BUILD}\"\n\n  test-deb:\n    name: Test Debian Repository\n    strategy:\n      matrix:\n        os: [ubuntu-22.04, ubuntu-latest]\n    runs-on: ${{ matrix.os }}\n    env:\n      CLAW_URL: ${{ inputs.claw-url }}\n      VERSION_BUILD: ${{ inputs.version }}\n      VERSION_MAJOR: ${{ inputs.major-version }}\n    steps:\n\n      - name: Install CF CLI via apt\n        run: |\n          set -o pipefail -e\n          \n          sudo apt update\n          sudo apt install -y wget gnupg\n          \n          wget -q -O - ${CLAW_URL}/debian/cli.cloudfoundry.org.key | sudo apt-key add -\n          echo \"deb ${CLAW_URL}/debian stable main\" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list\n          \n          sudo apt update\n          sudo apt install -y cf${VERSION_MAJOR}-cli\n          \n          which cf\n          \n          set -x\n          \n          cf  -v\n          cf${VERSION_MAJOR} -v\n          \n          cf -v | grep \"${VERSION_BUILD}\"\n\n\n  test-rpm-repo:\n    name: Test RPM Repository\n    runs-on: ubuntu-latest\n    container:\n      image: fedora\n    env:\n      CLAW_URL: ${{ inputs.claw-url }}\n      VERSION_BUILD: ${{ inputs.version }}\n      VERSION_MAJOR: ${{ inputs.major-version }}\n    steps:\n\n      - name: Configure Custom CF Repository\n        run: |\n          curl -sL -o /etc/yum.repos.d/cloudfoundry-cli.repo  \\\n          ${CLAW_URL}/fedora/cloudfoundry-cli.repo\n\n      - name: Install cf cli package\n        run: dnf install -y cf${VERSION_MAJOR}-cli\n\n      - name: Print CF CLI Versions\n        run: |\n          cf -v\n          cf${VERSION_MAJOR} -v\n\n      - name: Test Version Match\n        run: cf -v | grep -q \"${VERSION_BUILD}\"\n\n  test-windows:\n    name: Test Windows Chocolatey Package\n    runs-on: windows-2019\n    defaults:\n      run:\n        shell: pwsh\n    env:\n      VERSION_BUILD: ${{ inputs.version }}\n      VERSION_MAJOR: ${{ inputs.major-version }}\n    steps:\n\n      - name: Install cf cli package\n        run: choco install cloudfoundry-cli --version $env:VERSION_BUILD\n\n      - name: Print Chocolatey CF CLI Versions\n        run: |\n          cd 'C:/ProgramData/chocolatey/lib/cloudfoundry-cli/tools'\n          ./cf -v\n          Invoke-Expression \"./cf$env:VERSION_MAJOR -v\"\n\n      - name: Test Chocolatey Version Match\n        run: |\n          cd 'C:/ProgramData/chocolatey/lib/cloudfoundry-cli/tools'\n          $found = (./cf -v | Select-String \"$env:VERSION_BUILD\")\n          if ($null -eq $found) {\n            Write-Error \"CF CLI version $env:VERSION_BUILD was not found\" -ErrorAction Stop\n          }\n\n\n# vim: set sw=2 ts=2 sts=2 et tw=78 foldlevel=2 fdm=indent nospell:\n","repository_owner":"cloudfoundry","repository_name":"cli","tokens_count":999,"workflow":"name: 'Check: Check release on package managers'\nrun-name: 'Check: Check release on package managers [${{ github.ref_name }}]'\n\non:\n  workflow_dispatch:\n    inputs:\n      major-version:\n        description: Major version to retrieve\n        required: true\n        type: choice\n        options:\n        - '8'\n        - '7'\n      version:\n        description: Version of CLI to check if it is present\n        type: string\n        required: true\n      claw-url:\n        description: Location of CLAW\n        type: string\n        required: true\n        default: https://packages.cloudfoundry.org\n\ndefaults:\n  run:\n    shell: bash\n\njobs:\n  test-homebrew:\n    name: Test Homebrew Repository\n    runs-on: macos-latest\n    env:\n      CLAW_URL: ${{ inputs.claw-url }}\n      VERSION_BUILD: ${{ inputs.version }}\n      VERSION_MAJOR: ${{ inputs.major-version }}\n    steps:\n\n    - name: Install CF CLI via Homebrew\n      run: |\n        set -evx\n\n        brew install cloudfoundry/tap/cf-cli@${VERSION_MAJOR}\n        installed_cf_version=$(cf${VERSION_MAJOR} version)\n\n        cf_location=$(which cf)\n\n        echo $cf_location\n        echo $installed_cf_version\n        echo ${VERSION_BUILD}\n\n        codesign --verify $cf_location || echo ---\n\n        cf -v | grep \"${VERSION_BUILD}\"\n\n  test-deb:\n    name: Test Debian Repository\n    strategy:\n      matrix:\n        os: [ubuntu-22.04, ubuntu-latest]\n    runs-on: ${{ matrix.os }}\n    env:\n      CLAW_URL: ${{ inputs.claw-url }}\n      VERSION_BUILD: ${{ inputs.version }}\n      VERSION_MAJOR: ${{ inputs.major-version }}\n    steps:\n\n    - name: Install CF CLI via apt\n      run: |\n        set -o pipefail -e\n\n        sudo apt update\n        sudo apt install -y wget gnupg\n\n        wget -q -O - ${CLAW_URL}/debian/cli.cloudfoundry.org.key | sudo apt-key add -\n        echo \"deb ${CLAW_URL}/debian stable main\" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list\n\n        sudo apt update\n        sudo apt install -y cf${VERSION_MAJOR}-cli\n\n        which cf\n\n        set -x\n\n        cf  -v\n        cf${VERSION_MAJOR} -v\n\n        cf -v | grep \"${VERSION_BUILD}\"\n\n\n  test-rpm-repo:\n    name: Test RPM Repository\n    runs-on: ubuntu-latest\n    container:\n      image: fedora\n    env:\n      CLAW_URL: ${{ inputs.claw-url }}\n      VERSION_BUILD: ${{ inputs.version }}\n      VERSION_MAJOR: ${{ inputs.major-version }}\n    steps:\n\n    - name: Configure Custom CF Repository\n      run: |\n        curl -sL -o /etc/yum.repos.d/cloudfoundry-cli.repo  \\\n        ${CLAW_URL}/fedora/cloudfoundry-cli.repo\n\n    - name: Install cf cli package\n      run: dnf install -y cf${VERSION_MAJOR}-cli\n\n    - name: Print CF CLI Versions\n      run: |\n        cf -v\n        cf${VERSION_MAJOR} -v\n\n    - name: Test Version Match\n      run: cf -v | grep -q \"${VERSION_BUILD}\"\n\n  test-windows:\n    name: Test Windows Chocolatey Package\n    runs-on: windows-2019\n    defaults:\n      run:\n        shell: pwsh\n    env:\n      VERSION_BUILD: ${{ inputs.version }}\n      VERSION_MAJOR: ${{ inputs.major-version }}\n    steps:\n\n    - name: Install cf cli package\n      run: choco install cloudfoundry-cli --version $env:VERSION_BUILD\n\n    - name: Print Chocolatey CF CLI Versions\n      run: |\n        cd 'C:/ProgramData/chocolatey/lib/cloudfoundry-cli/tools'\n        ./cf -v\n        Invoke-Expression \"./cf$env:VERSION_MAJOR -v\"\n\n    - name: Test Chocolatey Version Match\n      run: |\n        cd 'C:/ProgramData/chocolatey/lib/cloudfoundry-cli/tools'\n        $found = (./cf -v | Select-String \"$env:VERSION_BUILD\")\n        if ($null -eq $found) {\n          Write-Error \"CF CLI version $env:VERSION_BUILD was not found\" -ErrorAction Stop\n        }\n\n\n# vim: set sw=2 ts=2 sts=2 et tw=78 foldlevel=2 fdm=indent nospell:\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Check: Check release on package managers` for a GitHub repository whose primary programming language is Go. The name for workflow runs is set to `Check: Check release on package managers [${{ github.ref_name }}]`. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 3 inputs: major-version-this input represents major version to retrieve, it must be supplied, the data type is choice and it has options including 8 and 7; version-this input represents version of cli to check if it is present, the data type is string and it must be supplied; claw-url-this input represents location of claw, the data type is string, it must be supplied and its default value is https://packages.cloudfoundry.org. For all run steps in the workflow, default shell is set to bash. The workflow has 4 jobs. The 1st job is named `Test Homebrew Repository` and its job id is `test-homebrew`. The 2nd job is named `Test Debian Repository` and its job id is `test-deb`. The 3rd job is named `Test RPM Repository` and its job id is `test-rpm-repo`. The 4th job is named `Test Windows Chocolatey Package` and its job id is `test-windows`. ","prompt_level2":"Generate a GitHub Workflow named `Check: Check release on package managers` for a GitHub repository whose primary programming language is Go. The name for workflow runs is set to `Check: Check release on package managers [${{ github.ref_name }}]`. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 3 inputs: major-version-this input represents major version to retrieve, it must be supplied, the data type is choice and it has options including 8 and 7; version-this input represents version of cli to check if it is present, the data type is string and it must be supplied; claw-url-this input represents location of claw, the data type is string, it must be supplied and its default value is https://packages.cloudfoundry.org. For all run steps in the workflow, default shell is set to bash. The workflow has 4 jobs. The 1st job is named `Test Homebrew Repository` and its job id is `test-homebrew`. The job `test-homebrew` has one step. The 1st step is named `Install CF CLI via Homebrew`. The 2nd job is named `Test Debian Repository` and its job id is `test-deb`. The job `test-deb` has one step. The 1st step is named `Install CF CLI via apt`. The 3rd job is named `Test RPM Repository` and its job id is `test-rpm-repo`. The job `test-rpm-repo` has 4 steps. The 1st step is named `Configure Custom CF Repository`. The 2nd step is named `Install cf cli package`. The 3rd step is named `Print CF CLI Versions`. The 4th step is named `Test Version Match`. The 4th job is named `Test Windows Chocolatey Package` and its job id is `test-windows`. The job `test-windows` has 3 steps. The 1st step is named `Install cf cli package`. The 2nd step is named `Print Chocolatey CF CLI Versions`. The 3rd step is named `Test Chocolatey Version Match`. ","prompt_level3":"Generate a GitHub Workflow named `Check: Check release on package managers` for a GitHub repository whose primary programming language is Go. The name for workflow runs is set to `Check: Check release on package managers [${{ github.ref_name }}]`. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 3 inputs: major-version-this input represents major version to retrieve, it must be supplied, the data type is choice and it has options including 8 and 7; version-this input represents version of cli to check if it is present, the data type is string and it must be supplied; claw-url-this input represents location of claw, the data type is string, it must be supplied and its default value is https://packages.cloudfoundry.org. For all run steps in the workflow, default shell is set to bash. The workflow has 4 jobs. The 1st job is named `Test Homebrew Repository` and its job id is `test-homebrew`. This job will run on macos-latest runner. The job sets 3 environment variables to use: `CLAW_URL` is set to `${{ inputs.claw-url }}`, `VERSION_BUILD` is set to `${{ inputs.version }}` and `VERSION_MAJOR` is set to `${{ inputs.major-version }}`. The job `test-homebrew` has one step. The 1st step is named `Install CF CLI via Homebrew`. This step runs a script: `set -evx\n\nbrew install cloudfoundry/tap/cf-cli@${VERSION_MAJOR}\ninstalled_cf_version=$(cf${VERSION_MAJOR} version)\n\ncf_location=$(which cf)\n\necho $cf_location\necho $installed_cf_version\necho ${VERSION_BUILD}\n\ncodesign --verify $cf_location || echo ---\n\ncf -v | grep \"${VERSION_BUILD}\"\n`. The 2nd job is named `Test Debian Repository` and its job id is `test-deb`. This job will run on ${{ matrix.os }} runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `os` has 2 values: ubuntu-22.04 and ubuntu-latest. The job sets 3 environment variables to use: `CLAW_URL` is set to `${{ inputs.claw-url }}`, `VERSION_BUILD` is set to `${{ inputs.version }}` and `VERSION_MAJOR` is set to `${{ inputs.major-version }}`. The job `test-deb` has one step. The 1st step is named `Install CF CLI via apt`. This step runs a script: `set -o pipefail -e\n\nsudo apt update\nsudo apt install -y wget gnupg\n\nwget -q -O - ${CLAW_URL}/debian/cli.cloudfoundry.org.key | sudo apt-key add -\necho \"deb ${CLAW_URL}/debian stable main\" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list\n\nsudo apt update\nsudo apt install -y cf${VERSION_MAJOR}-cli\n\nwhich cf\n\nset -x\n\ncf  -v\ncf${VERSION_MAJOR} -v\n\ncf -v | grep \"${VERSION_BUILD}\"\n`. The 3rd job is named `Test RPM Repository` and its job id is `test-rpm-repo`. This job will run on ubuntu-latest runner. The job creates a Docker container that uses `fedora` image. The job sets 3 environment variables to use: `CLAW_URL` is set to `${{ inputs.claw-url }}`, `VERSION_BUILD` is set to `${{ inputs.version }}` and `VERSION_MAJOR` is set to `${{ inputs.major-version }}`. The job `test-rpm-repo` has 4 steps. The 1st step is named `Configure Custom CF Repository`. This step runs a script: `curl -sL -o /etc/yum.repos.d/cloudfoundry-cli.repo  \\\n${CLAW_URL}/fedora/cloudfoundry-cli.repo\n`. The 2nd step is named `Install cf cli package`. This step runs a script: `dnf install -y cf${VERSION_MAJOR}-cli`. The 3rd step is named `Print CF CLI Versions`. This step runs a script: `cf -v\ncf${VERSION_MAJOR} -v\n`. The 4th step is named `Test Version Match`. This step runs a script: `cf -v | grep -q \"${VERSION_BUILD}\"`. The 4th job is named `Test Windows Chocolatey Package` and its job id is `test-windows`. This job will run on windows-2019 runner. The job sets 2 environment variables to use: `VERSION_BUILD` is set to `${{ inputs.version }}` and `VERSION_MAJOR` is set to `${{ inputs.major-version }}`. For all run steps in the job, default shell is set to pwsh. The job `test-windows` has 3 steps. The 1st step is named `Install cf cli package`. This step runs a script: `choco install cloudfoundry-cli --version $env:VERSION_BUILD`. The 2nd step is named `Print Chocolatey CF CLI Versions`. This step runs a script: `cd 'C:/ProgramData/chocolatey/lib/cloudfoundry-cli/tools'\n./cf -v\nInvoke-Expression \"./cf$env:VERSION_MAJOR -v\"\n`. The 3rd step is named `Test Chocolatey Version Match`. This step runs a script: `cd 'C:/ProgramData/chocolatey/lib/cloudfoundry-cli/tools'\n$found = (./cf -v | Select-String \"$env:VERSION_BUILD\")\nif ($null -eq $found) {\n  Write-Error \"CF CLI version $env:VERSION_BUILD was not found\" -ErrorAction Stop\n}\n`. ","nb_triggers":1,"triggers":["workflow_dispatch"],"nb_jobs":4,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":9,"cyclomatic_complexity":4}
{"id":17188,"repository_id":4097618,"mainLanguage":"TypeScript","file_name":"release-comment-issues.yml","file_content":"name: 'Automation: Notify issues for release'\non:\n  release:\n    types:\n      - published\n  workflow_dispatch:\n    inputs:\n      version:\n        description: Which version to notify issues for\n        required: false\n\n# This workflow is triggered when a release is published\njobs:\n  release-comment-issues:\n    runs-on: ubuntu-24.04\n    name: 'Notify issues'\n    steps:\n      - name: Get version\n        id: get_version\n        env:\n          INPUTS_VERSION: ${{ github.event.inputs.version }}\n          RELEASE_TAG_NAME: ${{ github.event.release.tag_name }}\n        run: echo \"version=${INPUTS_VERSION:-$RELEASE_TAG_NAME}\" >> \"$GITHUB_OUTPUT\"\n\n      - name: Comment on linked issues that are mentioned in release\n        if: |\n          steps.get_version.outputs.version != ''\n          && !contains(steps.get_version.outputs.version, '-beta.')\n          && !contains(steps.get_version.outputs.version, '-alpha.')\n          && !contains(steps.get_version.outputs.version, '-rc.')\n\n        uses: getsentry/release-comment-issues-gh-action@v1\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          version: ${{ steps.get_version.outputs.version }}\n","repository_owner":"getsentry","repository_name":"sentry-javascript","tokens_count":257,"workflow":"name: 'Automation: Notify issues for release'\non:\n  release:\n    types:\n    - published\n  workflow_dispatch:\n    inputs:\n      version:\n        description: Which version to notify issues for\n        required: false\n\n# This workflow is triggered when a release is published\njobs:\n  release-comment-issues:\n    runs-on: ubuntu-24.04\n    name: Notify issues\n    steps:\n    - name: Get version\n      id: get_version\n      env:\n        INPUTS_VERSION: ${{ github.event.inputs.version }}\n        RELEASE_TAG_NAME: ${{ github.event.release.tag_name }}\n      run: echo \"version=${INPUTS_VERSION:-$RELEASE_TAG_NAME}\" >> \n        \"$GITHUB_OUTPUT\"\n\n    - name: Comment on linked issues that are mentioned in release\n      if: |\n        steps.get_version.outputs.version != ''\n        && !contains(steps.get_version.outputs.version, '-beta.')\n        && !contains(steps.get_version.outputs.version, '-alpha.')\n        && !contains(steps.get_version.outputs.version, '-rc.')\n\n      uses: getsentry/release-comment-issues-gh-action@v1\n      with:\n        github_token: ${{ secrets.GITHUB_TOKEN }}\n        version: ${{ steps.get_version.outputs.version }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Automation: Notify issues for release` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) someone manually triggers the workflow. This workflow receives an input: version-this input represents which version to notify issues for and it is optional. The workflow has one job. The 1st job is named `Notify issues` and its job id is `release-comment-issues`. ","prompt_level2":"Generate a GitHub Workflow named `Automation: Notify issues for release` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) someone manually triggers the workflow. This workflow receives an input: version-this input represents which version to notify issues for and it is optional. The workflow has one job. The 1st job is named `Notify issues` and its job id is `release-comment-issues`. The job `release-comment-issues` has 2 steps. The 1st step is named `Get version` and its id is `get_version`. The 2nd step is named `Comment on linked issues that are mentioned in release`. ","prompt_level3":"Generate a GitHub Workflow named `Automation: Notify issues for release` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) someone manually triggers the workflow. This workflow receives an input: version-this input represents which version to notify issues for and it is optional. The workflow has one job. The 1st job is named `Notify issues` and its job id is `release-comment-issues`. This job will run on ubuntu-24.04 runner. The job `release-comment-issues` has 2 steps. The 1st step is named `Get version` and its id is `get_version`. The step sets 2 environment variables to use: `INPUTS_VERSION` is set to `${{ github.event.inputs.version }}` and `RELEASE_TAG_NAME` is set to `${{ github.event.release.tag_name }}`. This step runs a script: `echo \"version=${INPUTS_VERSION:-$RELEASE_TAG_NAME}\" >> \"$GITHUB_OUTPUT\"`. The 2nd step is named `Comment on linked issues that are mentioned in release`. This step will run only if the condition(steps.get_version.outputs.version != ''\n&& !contains(steps.get_version.outputs.version, '-beta.')\n&& !contains(steps.get_version.outputs.version, '-alpha.')\n&& !contains(steps.get_version.outputs.version, '-rc.')\n) is met. This step runs action `getsentry/release-comment-issues-gh-action` tagged as v1. The step defines 2 input parameters for the action: `github_token` is set to `${{ secrets.GITHUB_TOKEN }}` and `version` is set to `${{ steps.get_version.outputs.version }}`. ","nb_triggers":2,"triggers":["release","workflow_dispatch"],"nb_jobs":1,"nb_actions":1,"actions":["getsentry/release-comment-issues-gh-action"],"actions_details":[{"version":"v1","name":"getsentry/release-comment-issues-gh-action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":2,"cyclomatic_complexity":1}
{"id":45370,"repository_id":94556628,"mainLanguage":"Python","file_name":"airflow-distributions-tests.yml","file_content":"# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n---\nname: Non-core Distribution tests\non:  # yamllint disable-line rule:truthy\n  workflow_call:\n    inputs:\n      # Static inputs defined to choose which distribution to test to run\n      distribution-name:\n        description: \"The name of the distribution to test\"\n        required: true\n        type: string\n      distribution-cmd-format:\n        description: \"The type of distribution to test\"  # eg prepare-task-sdk-distributions\n        required: true\n        type: string\n      test-type:\n        description: \"distribution test type\"  # eg task-sdk-tests\n        required: true\n        type: string\n      # Environment inputs\n      runs-on-as-json-default:\n        description: \"The array of labels (in json form) determining default runner used for the build.\"\n        required: true\n        type: string\n      default-python-version:\n        description: \"Which version of python should be used by default\"\n        required: true\n        type: string\n      python-versions:\n        description: \"JSON-formatted array of Python versions to build images from\"\n        required: true\n        type: string\n      use-uv:\n        description: \"Whether to use uv to build the image (true/false)\"\n        required: true\n        type: string\n      canary-run:\n        description: \"Whether this is a canary run (true/false)\"\n        required: true\n        type: string\npermissions:\n  contents: read\njobs:\n  distributions-tests:\n    timeout-minutes: 80\n    name: ${{ inputs.distribution-name }}:P${{ matrix.python-version }} tests\n    runs-on: ${{ fromJSON(inputs.runs-on-as-json-default) }}\n    strategy:\n      fail-fast: false\n      matrix:\n        python-version: \"${{fromJSON(inputs.python-versions)}}\"\n    env:\n      GITHUB_REPOSITORY: ${{ github.repository }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      GITHUB_USERNAME: ${{ github.actor }}\n      INCLUDE_NOT_READY_PROVIDERS: \"true\"\n      PYTHON_MAJOR_MINOR_VERSION: \"${{ inputs.default-python-version }}\"\n      VERBOSE: \"true\"\n    steps:\n      - name: \"Cleanup repo\"\n        shell: bash\n        run: docker run -v \"${GITHUB_WORKSPACE}:/workspace\" -u 0:0 bash -c \"rm -rf /workspace/*\"\n      - name: \"Checkout ${{ github.ref }} ( ${{ github.sha }} )\"\n        uses: actions/checkout@v4\n        with:\n          persist-credentials: false\n      - name: \"Prepare breeze & CI image: ${{ matrix.python-version }}\"\n        uses: ./.github/actions/prepare_breeze_and_image\n        with:\n          platform: \"linux/amd64\"\n          python: ${{ matrix.python-version }}\n          use-uv: ${{ inputs.use-uv }}\n      - name: \"Cleanup dist files\"\n        run: rm -fv ./dist/*\n      # Conditional steps based on the distribution name\n      - name: \"Prepare Airflow ${{inputs.distribution-name}}: wheel\"\n        env:\n          DISTRIBUTION_TYPE: \"${{ inputs.distribution-cmd-format }}\"\n        run: >\n          breeze release-management \"${DISTRIBUTION_TYPE}\" --distribution-format wheel\n      - name: \"Verify wheel packages with twine\"\n        run: |\n          uv tool uninstall twine || true\n          uv tool install twine && twine check dist/*.whl\n      - name: >\n          Run unit tests for Airflow ${{inputs.distribution-name}}:Python ${{ matrix.python-version }}\n        env:\n          PYTHON_VERSION: \"${{ matrix.python-version }}\"\n          TEST_TYPE: \"${{ inputs.test-type }}\"\n        run: >\n          breeze testing \"${TEST_TYPE}\" --python \"${PYTHON_VERSION}\"\n","repository_owner":"apache","repository_name":"airflow","tokens_count":966,"workflow":"name: Non-core Distribution tests\non:  # yamllint disable-line rule:truthy\n  workflow_call:\n    inputs:\n      # Static inputs defined to choose which distribution to test to run\n      distribution-name:\n        description: The name of the distribution to test\n        required: true\n        type: string\n      distribution-cmd-format:\n        description: The type of distribution to test    # eg prepare-task-sdk-distributions\n        required: true\n        type: string\n      test-type:\n        description: distribution test type    # eg task-sdk-tests\n        required: true\n        type: string\n      # Environment inputs\n      runs-on-as-json-default:\n        description: The array of labels (in json form) determining default \n          runner used for the build.\n        required: true\n        type: string\n      default-python-version:\n        description: Which version of python should be used by default\n        required: true\n        type: string\n      python-versions:\n        description: JSON-formatted array of Python versions to build images \n          from\n        required: true\n        type: string\n      use-uv:\n        description: Whether to use uv to build the image (true/false)\n        required: true\n        type: string\n      canary-run:\n        description: Whether this is a canary run (true/false)\n        required: true\n        type: string\npermissions:\n  contents: read\njobs:\n  distributions-tests:\n    timeout-minutes: 80\n    name: ${{ inputs.distribution-name }}:P${{ matrix.python-version }} tests\n    runs-on: ${{ fromJSON(inputs.runs-on-as-json-default) }}\n    strategy:\n      fail-fast: false\n      matrix:\n        python-version: ${{fromJSON(inputs.python-versions)}}\n    env:\n      GITHUB_REPOSITORY: ${{ github.repository }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      GITHUB_USERNAME: ${{ github.actor }}\n      INCLUDE_NOT_READY_PROVIDERS: 'true'\n      PYTHON_MAJOR_MINOR_VERSION: ${{ inputs.default-python-version }}\n      VERBOSE: 'true'\n    steps:\n    - name: Cleanup repo\n      shell: bash\n      run: docker run -v \"${GITHUB_WORKSPACE}:/workspace\" -u 0:0 bash -c \"rm -rf\n        /workspace/*\"\n    - name: Checkout ${{ github.ref }} ( ${{ github.sha }} )\n      uses: actions/checkout@v4\n      with:\n        persist-credentials: false\n    - name: 'Prepare breeze & CI image: ${{ matrix.python-version }}'\n      uses: ./.github/actions/prepare_breeze_and_image\n      with:\n        platform: linux/amd64\n        python: ${{ matrix.python-version }}\n        use-uv: ${{ inputs.use-uv }}\n    - name: Cleanup dist files\n      run: rm -fv ./dist/*\n      # Conditional steps based on the distribution name\n    - name: 'Prepare Airflow ${{inputs.distribution-name}}: wheel'\n      env:\n        DISTRIBUTION_TYPE: ${{ inputs.distribution-cmd-format }}\n      run: >\n        breeze release-management \"${DISTRIBUTION_TYPE}\" --distribution-format wheel\n    - name: Verify wheel packages with twine\n      run: |\n        uv tool uninstall twine || true\n        uv tool install twine && twine check dist/*.whl\n    - name: >\n        Run unit tests for Airflow ${{inputs.distribution-name}}:Python ${{ matrix.python-version\n        }}\n      env:\n        PYTHON_VERSION: ${{ matrix.python-version }}\n        TEST_TYPE: ${{ inputs.test-type }}\n      run: >\n        breeze testing \"${TEST_TYPE}\" --python \"${PYTHON_VERSION}\"\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Non-core Distribution tests` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 8 inputs: distribution-name-this input represents the name of the distribution to test, it must be supplied and the data type is string; distribution-cmd-format-this input represents the type of distribution to test, it must be supplied and the data type is string; test-type-this input represents distribution test type, it must be supplied and the data type is string; runs-on-as-json-default-this input represents the array of labels (in json form) determining default runner used for the build., it must be supplied and the data type is string; default-python-version-this input represents which version of python should be used by default, it must be supplied and the data type is string; python-versions-this input represents json-formatted array of python versions to build images from, it must be supplied and the data type is string; use-uv-this input represents whether to use uv to build the image (true/false), it must be supplied and the data type is string; canary-run-this input represents whether this is a canary run (true/false), it must be supplied and the data type is string. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `${{ inputs.distribution-name }}:P${{ matrix.python-version }} tests` and its job id is `distributions-tests`. ","prompt_level2":"Generate a GitHub Workflow named `Non-core Distribution tests` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 8 inputs: distribution-name-this input represents the name of the distribution to test, it must be supplied and the data type is string; distribution-cmd-format-this input represents the type of distribution to test, it must be supplied and the data type is string; test-type-this input represents distribution test type, it must be supplied and the data type is string; runs-on-as-json-default-this input represents the array of labels (in json form) determining default runner used for the build., it must be supplied and the data type is string; default-python-version-this input represents which version of python should be used by default, it must be supplied and the data type is string; python-versions-this input represents json-formatted array of python versions to build images from, it must be supplied and the data type is string; use-uv-this input represents whether to use uv to build the image (true/false), it must be supplied and the data type is string; canary-run-this input represents whether this is a canary run (true/false), it must be supplied and the data type is string. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `${{ inputs.distribution-name }}:P${{ matrix.python-version }} tests` and its job id is `distributions-tests`. The job `distributions-tests` has 7 steps. The 1st step is named `Cleanup repo`. The 2nd step is named `Checkout repository`. The 3rd step is named `Prepare breeze & CI image: ${{ matrix.python-version }}`. The 4th step is named `Cleanup dist files`. The 5th step is named `Prepare Airflow ${{inputs.distribution-name}}: wheel`. The 6th step is named `Verify wheel packages with twine`. The 7th step is named `Run unit tests for Airflow ${{inputs.distribution-name}}:Python ${{ matrix.python-version }}\n`. ","prompt_level3":"Generate a GitHub Workflow named `Non-core Distribution tests` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 8 inputs: distribution-name-this input represents the name of the distribution to test, it must be supplied and the data type is string; distribution-cmd-format-this input represents the type of distribution to test, it must be supplied and the data type is string; test-type-this input represents distribution test type, it must be supplied and the data type is string; runs-on-as-json-default-this input represents the array of labels (in json form) determining default runner used for the build., it must be supplied and the data type is string; default-python-version-this input represents which version of python should be used by default, it must be supplied and the data type is string; python-versions-this input represents json-formatted array of python versions to build images from, it must be supplied and the data type is string; use-uv-this input represents whether to use uv to build the image (true/false), it must be supplied and the data type is string; canary-run-this input represents whether this is a canary run (true/false), it must be supplied and the data type is string. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `${{ inputs.distribution-name }}:P${{ matrix.python-version }} tests` and its job id is `distributions-tests`. This job will run on ${{ fromJSON(inputs.runs-on-as-json-default) }} runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `python-version` has 37 values: $, {, {, f, r, o, m, J, S, O, N, (, i, n, p, u, t, s, ., p, y, t, h, o, n, -, v, e, r, s, i, o, n, s, ), } and }. The job sets 6 environment variables to use: `GITHUB_REPOSITORY` is set to `${{ github.repository }}`, `GITHUB_TOKEN` is set to `${{ secrets.GITHUB_TOKEN }}`, `GITHUB_USERNAME` is set to `${{ github.actor }}`, `INCLUDE_NOT_READY_PROVIDERS` is set to `true`, `PYTHON_MAJOR_MINOR_VERSION` is set to `${{ inputs.default-python-version }}` and `VERBOSE` is set to `true`. The maximum number of minutes to run the job is 80. The job `distributions-tests` has 7 steps. The 1st step is named `Cleanup repo`. This step uses bash to run a script: `docker run -v \"${GITHUB_WORKSPACE}:/workspace\" -u 0:0 bash -c \"rm -rf /workspace/*\"`. The 2nd step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `persist-credentials` is set to `False`. The 3rd step is named `Prepare breeze & CI image: ${{ matrix.python-version }}`. This step runs action `./.github/actions/prepare_breeze_and_image`.The step defines 3 input parameters for the action: `platform` is set to `linux/amd64`, `python` is set to `${{ matrix.python-version }}` and `use-uv` is set to `${{ inputs.use-uv }}`. The 4th step is named `Cleanup dist files`. This step runs a script: `rm -fv ./dist/*`. The 5th step is named `Prepare Airflow ${{inputs.distribution-name}}: wheel`. The step sets an environment variable to use: `DISTRIBUTION_TYPE` is set to `${{ inputs.distribution-cmd-format }}`. This step runs a script: `breeze release-management \"${DISTRIBUTION_TYPE}\" --distribution-format wheel\n`. The 6th step is named `Verify wheel packages with twine`. This step runs a script: `uv tool uninstall twine || true\nuv tool install twine && twine check dist/*.whl\n`. The 7th step is named `Run unit tests for Airflow ${{inputs.distribution-name}}:Python ${{ matrix.python-version }}\n`. The step sets 2 environment variables to use: `PYTHON_VERSION` is set to `${{ matrix.python-version }}` and `TEST_TYPE` is set to `${{ inputs.test-type }}`. This step runs a script: `breeze testing \"${TEST_TYPE}\" --python \"${PYTHON_VERSION}\"\n`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":2,"actions":["./.github/actions/prepare_breeze_and_image","actions/checkout"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":null,"name":"./.github/actions/prepare_breeze_and_image"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":7,"cyclomatic_complexity":1}
{"id":61973,"repository_id":3907043,"mainLanguage":"C++","file_name":"reusable.yml","file_content":"name: Reusable build workflow\n\npermissions: read-all\n\non:\n  workflow_call:\n    inputs:\n      os_version:\n        required: true\n        type: string\n      qt_version:\n        required: true\n        type: string\n      shared:\n        required: false\n        default: \"ON\"\n        type: string\n      zlib_const:\n        required: false\n        default: \"OFF\"\n        type: string\n      runs_on:\n        required: true\n        type: string\n      run_tests:\n        required: false\n        default: true\n        type: boolean\n      cross_extract:\n        required: false\n        default: false\n        type: boolean\n    secrets:\n        GH_TOKEN:\n            required: false\n\nenv:\n  # Customize the CMake build type here (Release, Debug, RelWithDebInfo, etc.)\n  # All aqt options: https://ddalcino.github.io/aqt-list-server/\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    runs-on:  ${{ inputs.runs_on }}\n    name: Build-${{ inputs.runs_on }}-Qt-${{ inputs.qt_version }}-shared-${{ inputs.shared }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Install Qt6\n        if: \"startsWith(inputs.qt_version, '6.')\"\n        uses: jurplel/install-qt-action@v3\n        with:\n          version: ${{ inputs.qt_version }}\n          cache: 'true'\n          cache-key-prefix: ${{ runner.os }}-Qt-Cache-${{ inputs.qt_version }}\n          dir: ${{ github.workspace }}/Qt\n          modules: 'qt5compat'\n\n      - name: Install Qt5\n        if: \"startsWith(inputs.qt_version, '5.')\"\n        uses: jurplel/install-qt-action@v3\n        with:\n          version: ${{ inputs.qt_version }}\n          cache: 'true'\n          cache-key-prefix: ${{ runner.os }}-Qt-Cache-${{ inputs.qt_version }}\n          dir: ${{ github.workspace }}/Qt\n\n      - name: Install libraries (Linux Only)\n        if: contains(inputs.runs_on, 'ubuntu')\n        run: |\n          sudo apt-get update &&\n          sudo apt-get install -y --no-install-recommends \\\n          zlib1g-dev libbz2-dev\n\n      - name: Configure CMake\n        run: cmake -DCMAKE_BUILD_TYPE=\"${{env.BUILD_TYPE}}\" -DBUILD_SHARED_LIBS=${{ inputs.shared }} -DQUAZIP_ENABLE_TESTS=ON -DZLIB_CONST=${{ inputs.zlib_const }} -B \"${{github.workspace}}/build\"\n\n      - name: Build\n        run: cmake --build ${{github.workspace}}/build --config ${{env.BUILD_TYPE}}\n\n      - name: Run tests\n        if: inputs.run_tests && !inputs.cross_extract\n        working-directory: ${{github.workspace}}/build\n        env:\n          TEST_CR_COMPRESS: \"true\"\n          #TEST_ZIP_UNZIP_LARGE: true\n        run: ctest --verbose\n\n      - name: Upload cp.zip to GitHub Actions Storage\n        if: inputs.run_tests && !inputs.cross_extract\n        uses: actions/upload-artifact@v4\n        with:\n          retention-days: 1\n          overwrite: true\n          name: \"${{ inputs.runs_on }}_qt${{ inputs.qt_version }}_shared${{ inputs.shared }}_cp\"\n          path: build/quazip/cp.zip\n\n      - name: Download bundle containing cp.zip\n        if: inputs.cross_extract\n        uses: actions/download-artifact@v4\n        with:\n          path: build/quazip\n          merge-multiple: false\n\n      - name: Run extract tests\n        if: inputs.cross_extract\n        working-directory: ${{github.workspace}}/build\n        env:\n          TEST_CR_DECOMPRESS: \"true\"\n        run: ctest --verbose\n\n\n","repository_owner":"stachenov","repository_name":"quazip","tokens_count":832,"workflow":"name: Reusable build workflow\n\npermissions: read-all\n\non:\n  workflow_call:\n    inputs:\n      os_version:\n        required: true\n        type: string\n      qt_version:\n        required: true\n        type: string\n      shared:\n        required: false\n        default: ON\n        type: string\n      zlib_const:\n        required: false\n        default: OFF\n        type: string\n      runs_on:\n        required: true\n        type: string\n      run_tests:\n        required: false\n        default: true\n        type: boolean\n      cross_extract:\n        required: false\n        default: false\n        type: boolean\n    secrets:\n      GH_TOKEN:\n        required: false\n\nenv:\n  # Customize the CMake build type here (Release, Debug, RelWithDebInfo, etc.)\n  # All aqt options: https://ddalcino.github.io/aqt-list-server/\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    runs-on: ${{ inputs.runs_on }}\n    name: Build-${{ inputs.runs_on }}-Qt-${{ inputs.qt_version }}-shared-${{ \n      inputs.shared }}\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v4\n\n    - name: Install Qt6\n      if: startsWith(inputs.qt_version, '6.')\n      uses: jurplel/install-qt-action@v3\n      with:\n        version: ${{ inputs.qt_version }}\n        cache: 'true'\n        cache-key-prefix: ${{ runner.os }}-Qt-Cache-${{ inputs.qt_version }}\n        dir: ${{ github.workspace }}/Qt\n        modules: qt5compat\n\n    - name: Install Qt5\n      if: startsWith(inputs.qt_version, '5.')\n      uses: jurplel/install-qt-action@v3\n      with:\n        version: ${{ inputs.qt_version }}\n        cache: 'true'\n        cache-key-prefix: ${{ runner.os }}-Qt-Cache-${{ inputs.qt_version }}\n        dir: ${{ github.workspace }}/Qt\n\n    - name: Install libraries (Linux Only)\n      if: contains(inputs.runs_on, 'ubuntu')\n      run: |\n        sudo apt-get update &&\n        sudo apt-get install -y --no-install-recommends \\\n        zlib1g-dev libbz2-dev\n\n    - name: Configure CMake\n      run: cmake -DCMAKE_BUILD_TYPE=\"${{env.BUILD_TYPE}}\" \n        -DBUILD_SHARED_LIBS=${{ inputs.shared }} -DQUAZIP_ENABLE_TESTS=ON \n        -DZLIB_CONST=${{ inputs.zlib_const }} -B \"${{github.workspace}}/build\"\n\n    - name: Build\n      run: cmake --build ${{github.workspace}}/build --config \n        ${{env.BUILD_TYPE}}\n\n    - name: Run tests\n      if: inputs.run_tests && !inputs.cross_extract\n      working-directory: ${{github.workspace}}/build\n      env:\n        TEST_CR_COMPRESS: 'true'\n          #TEST_ZIP_UNZIP_LARGE: true\n      run: ctest --verbose\n\n    - name: Upload cp.zip to GitHub Actions Storage\n      if: inputs.run_tests && !inputs.cross_extract\n      uses: actions/upload-artifact@v4\n      with:\n        retention-days: 1\n        overwrite: true\n        name: ${{ inputs.runs_on }}_qt${{ inputs.qt_version }}_shared${{ \n          inputs.shared }}_cp\n        path: build/quazip/cp.zip\n\n    - name: Download bundle containing cp.zip\n      if: inputs.cross_extract\n      uses: actions/download-artifact@v4\n      with:\n        path: build/quazip\n        merge-multiple: false\n\n    - name: Run extract tests\n      if: inputs.cross_extract\n      working-directory: ${{github.workspace}}/build\n      env:\n        TEST_CR_DECOMPRESS: 'true'\n      run: ctest --verbose\n\n\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Reusable build workflow` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 7 inputs: os_version-it must be supplied and the data type is string; qt_version-it must be supplied and the data type is string; shared-it is optional, its default value is True and the data type is string; zlib_const-it is optional, its default value is False and the data type is string; runs_on-it must be supplied and the data type is string; run_tests-it is optional, its default value is True and the data type is boolean; cross_extract-it is optional, its default value is False and the data type is boolean. It receives a secret: GH_TOKEN-it is optional. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow sets an environment variable to use: `BUILD_TYPE` is set to `Release`. The workflow has one job. The 1st job is named `Build-${{ inputs.runs_on }}-Qt-${{ inputs.qt_version }}-shared-${{ inputs.shared }}` and its job id is `build`. ","prompt_level2":"Generate a GitHub Workflow named `Reusable build workflow` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 7 inputs: os_version-it must be supplied and the data type is string; qt_version-it must be supplied and the data type is string; shared-it is optional, its default value is True and the data type is string; zlib_const-it is optional, its default value is False and the data type is string; runs_on-it must be supplied and the data type is string; run_tests-it is optional, its default value is True and the data type is boolean; cross_extract-it is optional, its default value is False and the data type is boolean. It receives a secret: GH_TOKEN-it is optional. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow sets an environment variable to use: `BUILD_TYPE` is set to `Release`. The workflow has one job. The 1st job is named `Build-${{ inputs.runs_on }}-Qt-${{ inputs.qt_version }}-shared-${{ inputs.shared }}` and its job id is `build`. The job `build` has 10 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Install Qt6`. The 3rd step is named `Install Qt5`. The 4th step is named `Install libraries (Linux Only)`. The 5th step is named `Configure CMake`. The 6th step is named `Build`. The 7th step is named `Run tests`. The 8th step is named `Upload cp.zip to GitHub Actions Storage`. The 9th step is named `Download bundle containing cp.zip`. The 10th step is named `Run extract tests`. ","prompt_level3":"Generate a GitHub Workflow named `Reusable build workflow` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 7 inputs: os_version-it must be supplied and the data type is string; qt_version-it must be supplied and the data type is string; shared-it is optional, its default value is True and the data type is string; zlib_const-it is optional, its default value is False and the data type is string; runs_on-it must be supplied and the data type is string; run_tests-it is optional, its default value is True and the data type is boolean; cross_extract-it is optional, its default value is False and the data type is boolean. It receives a secret: GH_TOKEN-it is optional. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow sets an environment variable to use: `BUILD_TYPE` is set to `Release`. The workflow has one job. The 1st job is named `Build-${{ inputs.runs_on }}-Qt-${{ inputs.qt_version }}-shared-${{ inputs.shared }}` and its job id is `build`. This job will run on ${{ inputs.runs_on }} runner. The job `build` has 10 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Install Qt6`. This step will run only if the condition(startsWith(inputs.qt_version, '6.')) is met. This step runs action `jurplel/install-qt-action` tagged as v3. The step defines 5 input parameters for the action: `version` is set to `${{ inputs.qt_version }}`, `cache` is set to `true`, `cache-key-prefix` is set to `${{ runner.os }}-Qt-Cache-${{ inputs.qt_version }}`, `dir` is set to `${{ github.workspace }}/Qt` and `modules` is set to `qt5compat`. The 3rd step is named `Install Qt5`. This step will run only if the condition(startsWith(inputs.qt_version, '5.')) is met. This step runs action `jurplel/install-qt-action` tagged as v3. The step defines 4 input parameters for the action: `version` is set to `${{ inputs.qt_version }}`, `cache` is set to `true`, `cache-key-prefix` is set to `${{ runner.os }}-Qt-Cache-${{ inputs.qt_version }}` and `dir` is set to `${{ github.workspace }}/Qt`. The 4th step is named `Install libraries (Linux Only)`. This step will run only if the condition(contains(inputs.runs_on, 'ubuntu')) is met. This step runs a script: `sudo apt-get update &&\nsudo apt-get install -y --no-install-recommends \\\nzlib1g-dev libbz2-dev\n`. The 5th step is named `Configure CMake`. This step runs a script: `cmake -DCMAKE_BUILD_TYPE=\"${{env.BUILD_TYPE}}\" -DBUILD_SHARED_LIBS=${{ inputs.shared }} -DQUAZIP_ENABLE_TESTS=ON -DZLIB_CONST=${{ inputs.zlib_const }} -B \"${{github.workspace}}/build\"`. The 6th step is named `Build`. This step runs a script: `cmake --build ${{github.workspace}}/build --config ${{env.BUILD_TYPE}}`. The 7th step is named `Run tests`. This step will run only if the condition(inputs.run_tests && !inputs.cross_extract) is met. The step sets an environment variable to use: `TEST_CR_COMPRESS` is set to `true`. This step runs a script: `ctest --verbose`. The 8th step is named `Upload cp.zip to GitHub Actions Storage`. This step will run only if the condition(inputs.run_tests && !inputs.cross_extract) is met. This step runs action `actions/upload-artifact` tagged as v4. The step defines 4 input parameters for the action: `retention-days` is set to `1`, `overwrite` is set to `True`, `name` is set to `${{ inputs.runs_on }}_qt${{ inputs.qt_version }}_shared${{ inputs.shared }}_cp` and `path` is set to `build/quazip/cp.zip`. The 9th step is named `Download bundle containing cp.zip`. This step will run only if the condition(inputs.cross_extract) is met. This step runs action `actions/download-artifact` tagged as v4. The step defines 2 input parameters for the action: `path` is set to `build/quazip` and `merge-multiple` is set to `False`. The 10th step is named `Run extract tests`. This step will run only if the condition(inputs.cross_extract) is met. The step sets an environment variable to use: `TEST_CR_DECOMPRESS` is set to `true`. This step runs a script: `ctest --verbose`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":5,"actions":["actions/checkout","actions/download-artifact","actions/upload-artifact","jurplel/install-qt-action","jurplel/install-qt-action"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v3","name":"jurplel/install-qt-action"},{"version":"v3","name":"jurplel/install-qt-action"},{"version":"v4","name":"actions/upload-artifact"},{"version":"v4","name":"actions/download-artifact"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":10,"cyclomatic_complexity":1}
{"id":49417,"repository_id":46291537,"mainLanguage":"C++","file_name":"release-pipeline.yml","file_content":"# Copyright 2025, Intel Corporation\n# SPDX-License-Identifier: BSD-3-Clause\n\nname: Release Pipeline\n\npermissions: read-all\n\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: 'ISPC Version'\n        required: true\n        type: string\n        default: 'v1.26.0'\n\njobs:\n  aarch64:\n    runs-on: ubuntu-22.04-arm\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@eef61447b9ff4aafe5dcd4e0bbf5d482be7e7871 # v4.2.1\n        with:\n          ref: ${{ github.event.inputs.version }}\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@b5ca514318bd6ebac0fb2aedd5d36ec1b5c232a2 # v3.10.0\n\n      - name: Build Docker image\n        working-directory: docker/${{ github.event.inputs.version }}/ubuntu18.04\n        run: |\n          docker build --no-cache \\\n            --build-arg XE_DEPS=OFF \\\n            --build-arg LTO=ON \\\n            -t ispc-release .\n\n      - name: Extract tarball from container\n        run: |\n          CONTAINER_ID=$(docker create ispc-release)\n          docker cp \"$CONTAINER_ID\":/usr/local/src/ ./\n\n      - name: Upload artifact\n        uses: actions/upload-artifact@65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08 # v4.6.0\n        with:\n          name: ispc_aarch64\n          path: src/ispc-*.tar.gz\n\n  x86_64:\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@eef61447b9ff4aafe5dcd4e0bbf5d482be7e7871 # v4.2.1\n        with:\n          ref: ${{ github.event.inputs.version }}\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@b5ca514318bd6ebac0fb2aedd5d36ec1b5c232a2 # v3.10.0\n\n      - name: Build Docker image\n        working-directory: docker/${{ github.event.inputs.version }}/ubuntu18.04\n        run: |\n          docker build --no-cache \\\n            --build-arg LTO=ON \\\n            -t ispc-release .\n\n      - name: Extract tarball from container\n        run: |\n          CONTAINER_ID=$(docker create ispc-release)\n          docker cp \"$CONTAINER_ID\":/usr/local/src/ ./\n\n      - name: Upload artifact\n        uses: actions/upload-artifact@65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08 # v4.6.0\n        with:\n          name: ispc_x86_64\n          path: src/ispc-*.tar.gz\n","repository_owner":"ispc","repository_name":"ispc","tokens_count":744,"workflow":"# Copyright 2025, Intel Corporation\n# SPDX-License-Identifier: BSD-3-Clause\n\nname: Release Pipeline\n\npermissions: read-all\n\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: ISPC Version\n        required: true\n        type: string\n        default: v1.26.0\n\njobs:\n  aarch64:\n    runs-on: ubuntu-22.04-arm\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@eef61447b9ff4aafe5dcd4e0bbf5d482be7e7871   # v4.2.1\n      with:\n        ref: ${{ github.event.inputs.version }}\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@b5ca514318bd6ebac0fb2aedd5d36ec1b5c232a2   # v3.10.0\n\n    - name: Build Docker image\n      working-directory: docker/${{ github.event.inputs.version }}/ubuntu18.04\n      run: |\n        docker build --no-cache \\\n          --build-arg XE_DEPS=OFF \\\n          --build-arg LTO=ON \\\n          -t ispc-release .\n\n    - name: Extract tarball from container\n      run: |\n        CONTAINER_ID=$(docker create ispc-release)\n        docker cp \"$CONTAINER_ID\":/usr/local/src/ ./\n\n    - name: Upload artifact\n      uses: actions/upload-artifact@65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08   # v4.6.0\n      with:\n        name: ispc_aarch64\n        path: src/ispc-*.tar.gz\n\n  x86_64:\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@eef61447b9ff4aafe5dcd4e0bbf5d482be7e7871   # v4.2.1\n      with:\n        ref: ${{ github.event.inputs.version }}\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@b5ca514318bd6ebac0fb2aedd5d36ec1b5c232a2   # v3.10.0\n\n    - name: Build Docker image\n      working-directory: docker/${{ github.event.inputs.version }}/ubuntu18.04\n      run: |\n        docker build --no-cache \\\n          --build-arg LTO=ON \\\n          -t ispc-release .\n\n    - name: Extract tarball from container\n      run: |\n        CONTAINER_ID=$(docker create ispc-release)\n        docker cp \"$CONTAINER_ID\":/usr/local/src/ ./\n\n    - name: Upload artifact\n      uses: actions/upload-artifact@65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08   # v4.6.0\n      with:\n        name: ispc_x86_64\n        path: src/ispc-*.tar.gz\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Release Pipeline` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives an input: version-this input represents ispc version, it must be supplied, the data type is string and its default value is v1.26.0. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow has 2 jobs. The job id of the 1st job is `aarch64`. The job id of the 2nd job is `x86_64`. ","prompt_level2":"Generate a GitHub Workflow named `Release Pipeline` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives an input: version-this input represents ispc version, it must be supplied, the data type is string and its default value is v1.26.0. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow has 2 jobs. The job id of the 1st job is `aarch64`. The job `aarch64` has 5 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up Docker Buildx`. The 3rd step is named `Build Docker image`. The 4th step is named `Extract tarball from container`. The 5th step is named `Upload artifact`. The job id of the 2nd job is `x86_64`. The job `x86_64` has 5 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up Docker Buildx`. The 3rd step is named `Build Docker image`. The 4th step is named `Extract tarball from container`. The 5th step is named `Upload artifact`. ","prompt_level3":"Generate a GitHub Workflow named `Release Pipeline` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives an input: version-this input represents ispc version, it must be supplied, the data type is string and its default value is v1.26.0. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow has 2 jobs. The job id of the 1st job is `aarch64`. This job will run on ubuntu-22.04-arm runner. The job `aarch64` has 5 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is eef61447b9ff4aafe5dcd4e0bbf5d482be7e7871. The step defines an input parameter for the action: `ref` is set to `${{ github.event.inputs.version }}`. The 2nd step is named `Set up Docker Buildx`. This step runs action `docker/setup-buildx-action` whose commit is b5ca514318bd6ebac0fb2aedd5d36ec1b5c232a2. The 3rd step is named `Build Docker image`. This step runs a script: `docker build --no-cache \\\n  --build-arg XE_DEPS=OFF \\\n  --build-arg LTO=ON \\\n  -t ispc-release .\n`. The 4th step is named `Extract tarball from container`. This step runs a script: `CONTAINER_ID=$(docker create ispc-release)\ndocker cp \"$CONTAINER_ID\":/usr/local/src/ ./\n`. The 5th step is named `Upload artifact`. This step runs action `actions/upload-artifact` whose commit is 65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08. The step defines 2 input parameters for the action: `name` is set to `ispc_aarch64` and `path` is set to `src/ispc-*.tar.gz`. The job id of the 2nd job is `x86_64`. This job will run on ubuntu-22.04 runner. The job `x86_64` has 5 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is eef61447b9ff4aafe5dcd4e0bbf5d482be7e7871. The step defines an input parameter for the action: `ref` is set to `${{ github.event.inputs.version }}`. The 2nd step is named `Set up Docker Buildx`. This step runs action `docker/setup-buildx-action` whose commit is b5ca514318bd6ebac0fb2aedd5d36ec1b5c232a2. The 3rd step is named `Build Docker image`. This step runs a script: `docker build --no-cache \\\n  --build-arg LTO=ON \\\n  -t ispc-release .\n`. The 4th step is named `Extract tarball from container`. This step runs a script: `CONTAINER_ID=$(docker create ispc-release)\ndocker cp \"$CONTAINER_ID\":/usr/local/src/ ./\n`. The 5th step is named `Upload artifact`. This step runs action `actions/upload-artifact` whose commit is 65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08. The step defines 2 input parameters for the action: `name` is set to `ispc_x86_64` and `path` is set to `src/ispc-*.tar.gz`. ","nb_triggers":1,"triggers":["workflow_dispatch"],"nb_jobs":2,"nb_actions":6,"actions":["actions/checkout","actions/checkout","actions/upload-artifact","actions/upload-artifact","docker/setup-buildx-action","docker/setup-buildx-action"],"actions_details":[{"version":"eef61447b9ff4aafe5dcd4e0bbf5d482be7e7871","name":"actions/checkout"},{"version":"b5ca514318bd6ebac0fb2aedd5d36ec1b5c232a2","name":"docker/setup-buildx-action"},{"version":"65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08","name":"actions/upload-artifact"},{"version":"eef61447b9ff4aafe5dcd4e0bbf5d482be7e7871","name":"actions/checkout"},{"version":"b5ca514318bd6ebac0fb2aedd5d36ec1b5c232a2","name":"docker/setup-buildx-action"},{"version":"65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08","name":"actions/upload-artifact"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":10,"cyclomatic_complexity":2}
{"id":13029,"repository_id":39151079,"mainLanguage":"Python","file_name":"integration-test-fast-services.yml","file_content":"---\nname: Integration Tests (Fast CI)\non:\n  workflow_call:\n    inputs:\n      os:\n        description: OS\n        type: string\n        required: true\n      python-version:\n        description: Python version\n        type: string\n        required: true\n      test_environment:\n        description: The test environment\n        type: string\n        required: true\n      enable_tmate:\n        description: Enable tmate session for debugging\n        type: string\n        required: false\n        default: never\n      tmate_timeout:\n        description: Timeout for tmate session (minutes)\n        type: number\n        required: false\n        default: 30\n  workflow_dispatch:\n    inputs:\n      os:\n        description: OS\n        type: choice\n        options: [ubuntu-latest, macos-13, windows-latest]\n        required: false\n        default: ubuntu-latest\n      python-version:\n        description: Python version\n        type: choice\n        options: ['3.9', '3.10', '3.11', '3.12']\n        required: false\n        default: '3.11'\n      test_environment:\n        description: The test environment\n        type: choice\n        options:\n          # Default ZenML deployments\n          - default\n          - default-docker-orchestrator\n          - default-airflow-orchestrator\n          # Local ZenML server deployments\n          - local-server\n          - local-server-docker-orchestrator\n          - local-server-airflow-orchestrator\n          # Local ZenML docker-compose server deployments\n          - docker-server-mysql\n          - docker-server-mariadb\n          - docker-server-docker-orchestrator-mysql\n          - docker-server-docker-orchestrator-mariadb\n          - docker-server-airflow-orchestrator-mysql\n          - docker-server-airflow-orchestrator-mariadb\n          - github-actions-server-docker-orchestrator\n        required: false\n        default: default\n      enable_tmate:\n        description: Enable tmate session for debugging\n        type: choice\n        options: [no, on-failure, always, before-tests]\n        required: false\n        default: 'no'\n      tmate_timeout:\n        description: Timeout for tmate session (minutes)\n        type: number\n        required: false\n        default: 30\njobs:\n  integration-tests-fast:\n    name: integration-tests-fast\n    runs-on: ${{ inputs.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        shard: [1, 2, 3, 4, 5, 6]\n    env:\n      ZENML_DEBUG: 1\n      ZENML_ANALYTICS_OPT_IN: false\n      PYTHONIOENCODING: utf-8\n      UV_HTTP_TIMEOUT: 600\n      # on MAC OS, we need to set this environment variable\n      # to fix problems with the fork() calls (see this thread\n      # for more information: http://sealiesoftware.com/blog/archive/2017/6/5/Objective-C_and_fork_in_macOS_1013.html)\n      OBJC_DISABLE_INITIALIZE_FORK_SAFETY: 'YES'\n      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_US_EAST_1_ENV_ACCESS_KEY_ID }}\n      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_US_EAST_1_ENV_SECRET_ACCESS_KEY }}\n      AWS_US_EAST_1_SERVER_URL: ${{ secrets.AWS_US_EAST_1_SERVER_URL }}\n      AWS_US_EAST_1_SERVER_USERNAME: ${{ secrets.AWS_US_EAST_1_SERVER_USERNAME }}\n      AWS_US_EAST_1_SERVER_PASSWORD: ${{ secrets.AWS_US_EAST_1_SERVER_PASSWORD }}\n      GCP_US_EAST4_SERVER_URL: ${{ secrets.GCP_US_EAST4_SERVER_URL }}\n      GCP_US_EAST4_SERVER_USERNAME: ${{ secrets.GCP_US_EAST4_SERVER_USERNAME }}\n      GCP_US_EAST4_SERVER_PASSWORD: ${{ secrets.GCP_US_EAST4_SERVER_PASSWORD }}\n    if: ${{ ! startsWith(github.event.head_commit.message, 'GitBook:') }}\n    defaults:\n      run:\n        shell: bash\n    steps:\n      - uses: actions/checkout@v4.2.2\n      - name: Restore uv cache\n        uses: actions/cache@v4\n        with:\n          path: ~/.cache/uv\n          key: |\n            uv-${{ runner.os }}-${{ inputs.python-version }}-${{ hashFiles('src/zenml/integrations/*/__init__.py') }}\n          restore-keys: |\n            uv-${{ runner.os }}-${{ inputs.python-version }}-${{ hashFiles('src/zenml/integrations/*/__init__.py') }}\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v1\n        with:\n          role-to-assume: ${{ secrets.AWS_US_EAST_1_ENV_ROLE_ARN }}\n          aws-region: us-east-1\n        if: contains(inputs.test_environment, 'aws')\n      - name: Configure GCP credentials\n        uses: google-github-actions/auth@v2\n        with:\n          credentials_json: ${{ secrets.GCP_US_EAST4_ENV_CREDENTIALS }}\n        if: contains(inputs.test_environment, 'gcp')\n      - name: Set up gcloud SDK\n        uses: google-github-actions/setup-gcloud@v1\n        with:\n          install_components: gke-gcloud-auth-plugin\n        if: contains(inputs.test_environment, 'gcp')\n      - name: Login to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n        if: github.event.pull_request.head.repo.fork == false && (contains(inputs.test_environment,\n          'docker') || contains(inputs.test_environment, 'kubeflow') || contains(inputs.test_environment,\n          'airflow') || contains(inputs.test_environment, 'kubernetes'))\n      - name: Setup environment\n        uses: ./.github/actions/setup_environment\n        with:\n          python-version: ${{ inputs.python-version }}\n          os: ${{ inputs.os }}\n      - name: Install docker-compose for non-default environments\n        if: inputs.test_environment != 'default'\n        run: |\n          pip install uv\n          # see https://github.com/docker/docker-py/issues/3256 for why we need to pin requests\n          # docker-compose is deprecated and doesn't work with newer versions of docker\n          uv pip install --system \"pyyaml==5.3.1\" \"requests<2.32.0\" \"docker==6.1.3\" docker-compose\n      - name: Install Linux System Dependencies\n        if: (inputs.os == 'ubuntu-latest' || inputs.os == 'arc-runner-set')\n        run: sudo apt install graphviz\n      - name: Install MacOS System Dependencies\n        if: runner.os=='macOS'\n        run: brew install graphviz\n      - name: Install Windows System Dependencies\n        if: runner.os=='Windows'\n        run: choco install graphviz\n      - name: Unbreak python in github actions\n        if: runner.os=='macOS'\n        # github actions overwrites brew's python. Force it to reassert itself, by\n        # running in a separate step.\n        # Workaround GitHub Actions Python issues\n        # see https://github.com/Homebrew/homebrew-core/issues/165793#issuecomment-1989441193\n        run: |\n          find /usr/local/bin -lname '*/Library/Frameworks/Python.framework/*' -delete\n          sudo rm -rf /Library/Frameworks/Python.framework/\n          brew install --force python3 && brew unlink python3 && brew unlink python3 && brew link --overwrite python3\n      - name: Install Docker and Colima on MacOS\n        if: runner.os=='macOS'\n        run: |\n          export HOMEBREW_NO_INSTALLED_DEPENDENTS_CHECK=1\n          brew update\n          brew install docker colima\n          brew reinstall --force qemu\n\n          # We need to mount the /private/tmp/zenml-test/ folder because\n          # this folder is also mounted in the Docker containers that are\n          # started by local ZenML orchestrators.\n          colima start --mount /private/tmp/zenml-test/:w\n\n          # This is required for the Docker Python SDK to work\n          sudo ln -sf $HOME/.colima/default/docker.sock /var/run/docker.sock\n      - name: Install kubectl on Linux\n        run: |\n          curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n          sudo install -o root -g 0 -m 0755 kubectl /usr/local/bin/kubectl\n        if: (inputs.os == 'ubuntu-latest' || inputs.os == 'arc-runner-set')\n      - name: Install kubectl on MacOS\n        run: |\n          curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/amd64/kubectl\"\n          sudo install -o root -g 0 -m 0755 kubectl /usr/local/bin/kubectl\n        if: runner.os=='macOS'\n      - name: Install K3D\n        run: |\n          curl -s https://raw.githubusercontent.com/rancher/k3d/main/install.sh | bash\n        if: runner.os!='Windows' && contains(inputs.test_environment, 'kubeflow')\n      - name: Login to Amazon ECR\n        id: login-ecr\n        run: |\n          aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 715803424590.dkr.ecr.us-east-1.amazonaws.com\n        if: contains(inputs.test_environment, 'aws')\n      - name: Login to Amazon EKS\n        id: login-eks\n        run: |\n          aws eks --region us-east-1 update-kubeconfig --name zenml-ci-cluster --alias zenml-ci-aws-us-east-1\n        if: contains(inputs.test_environment, 'aws')\n      - name: Login to Google ECR\n        run: |\n          gcloud auth configure-docker --project zenml-ci\n        if: contains(inputs.test_environment, 'gcp')\n      - name: Login to Google GKE\n        uses: google-github-actions/get-gke-credentials@v2\n        with:\n          cluster_name: zenml-ci-cluster\n          location: us-east4\n          project_id: zenml-ci\n        if: contains(inputs.test_environment, 'gcp')\n      - name: Setup tmate session before tests\n        if: ${{ inputs.enable_tmate == 'before-tests' }}\n        uses: mxschmitt/action-tmate@v3.17\n        timeout-minutes: ${{ inputs.tmate_timeout }}\n      - name: Sharded Integration Tests (Ubuntu) - Fast CI\n        # Ubuntu integration tests run as 6 shards\n        if: runner.os != 'macOS' && runner.os != 'Windows'\n        run: |\n          bash scripts/test-coverage-xml.sh integration ${{ inputs.test_environment }} 6 ${{ matrix.shard }}\n      - name: Setup tmate session after tests\n        if: ${{ inputs.enable_tmate == 'always' || (inputs.enable_tmate == 'on-failure' && failure()) }}\n        uses: mxschmitt/action-tmate@v3.17\n        timeout-minutes: ${{ inputs.tmate_timeout }}\n      - name: Verify Python Env unaffected\n        run: |-\n          zenml integration list\n          uv pip list\n          uv pip check || true\n    services:\n      mysql:\n        image: mysql:5.7\n        env:\n          MYSQL_ROOT_PASSWORD: zenml\n          MYSQL_DATABASE: zenml\n        ports:\n          - 3306:3306\n        options: >-\n          --health-cmd=\"mysqladmin ping\"\n          --health-interval=10s\n          --health-timeout=5s\n          --health-retries=3\n      zenml-server:\n        image: ghcr.io/${{ github.repository_owner }}/zenml-server-github-actions:${{\n          github.sha }}\n        credentials:\n          username: ${{ github.actor }}\n          password: ${{ secrets.github_token }}\n        env:\n          ZENML_STORE_URL: mysql://root:zenml@mysql:3306/zenml\n          ZENML_SERVER_DEPLOYMENT_TYPE: docker\n          ZENML_SERVER_AUTO_ACTIVATE: 'True'\n          ZENML_SERVER_AUTO_CREATE_DEFAULT_USER: 'True'\n        ports:\n          - 8080:8080\n        options: >-\n          --health-cmd=\"curl -f http://127.0.0.1:8080/health\"\n          --health-interval=10s\n          --health-timeout=5s\n          --health-retries=3\n","repository_owner":"zenml-io","repository_name":"zenml","tokens_count":2833,"workflow":"name: Integration Tests (Fast CI)\non:\n  workflow_call:\n    inputs:\n      os:\n        description: OS\n        type: string\n        required: true\n      python-version:\n        description: Python version\n        type: string\n        required: true\n      test_environment:\n        description: The test environment\n        type: string\n        required: true\n      enable_tmate:\n        description: Enable tmate session for debugging\n        type: string\n        required: false\n        default: never\n      tmate_timeout:\n        description: Timeout for tmate session (minutes)\n        type: number\n        required: false\n        default: 30\n  workflow_dispatch:\n    inputs:\n      os:\n        description: OS\n        type: choice\n        options: [ubuntu-latest, macos-13, windows-latest]\n        required: false\n        default: ubuntu-latest\n      python-version:\n        description: Python version\n        type: choice\n        options: ['3.9', '3.10', '3.11', '3.12']\n        required: false\n        default: '3.11'\n      test_environment:\n        description: The test environment\n        type: choice\n        options:\n          # Default ZenML deployments\n        - default\n        - default-docker-orchestrator\n        - default-airflow-orchestrator\n          # Local ZenML server deployments\n        - local-server\n        - local-server-docker-orchestrator\n        - local-server-airflow-orchestrator\n          # Local ZenML docker-compose server deployments\n        - docker-server-mysql\n        - docker-server-mariadb\n        - docker-server-docker-orchestrator-mysql\n        - docker-server-docker-orchestrator-mariadb\n        - docker-server-airflow-orchestrator-mysql\n        - docker-server-airflow-orchestrator-mariadb\n        - github-actions-server-docker-orchestrator\n        required: false\n        default: default\n      enable_tmate:\n        description: Enable tmate session for debugging\n        type: choice\n        options: [no, on-failure, always, before-tests]\n        required: false\n        default: no\n      tmate_timeout:\n        description: Timeout for tmate session (minutes)\n        type: number\n        required: false\n        default: 30\njobs:\n  integration-tests-fast:\n    name: integration-tests-fast\n    runs-on: ${{ inputs.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        shard: [1, 2, 3, 4, 5, 6]\n    env:\n      ZENML_DEBUG: 1\n      ZENML_ANALYTICS_OPT_IN: false\n      PYTHONIOENCODING: utf-8\n      UV_HTTP_TIMEOUT: 600\n      # on MAC OS, we need to set this environment variable\n      # to fix problems with the fork() calls (see this thread\n      # for more information: http://sealiesoftware.com/blog/archive/2017/6/5/Objective-C_and_fork_in_macOS_1013.html)\n      OBJC_DISABLE_INITIALIZE_FORK_SAFETY: YES\n      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_US_EAST_1_ENV_ACCESS_KEY_ID }}\n      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_US_EAST_1_ENV_SECRET_ACCESS_KEY }}\n      AWS_US_EAST_1_SERVER_URL: ${{ secrets.AWS_US_EAST_1_SERVER_URL }}\n      AWS_US_EAST_1_SERVER_USERNAME: ${{ secrets.AWS_US_EAST_1_SERVER_USERNAME \n        }}\n      AWS_US_EAST_1_SERVER_PASSWORD: ${{ secrets.AWS_US_EAST_1_SERVER_PASSWORD \n        }}\n      GCP_US_EAST4_SERVER_URL: ${{ secrets.GCP_US_EAST4_SERVER_URL }}\n      GCP_US_EAST4_SERVER_USERNAME: ${{ secrets.GCP_US_EAST4_SERVER_USERNAME }}\n      GCP_US_EAST4_SERVER_PASSWORD: ${{ secrets.GCP_US_EAST4_SERVER_PASSWORD }}\n    if: ${{ ! startsWith(github.event.head_commit.message, 'GitBook:') }}\n    defaults:\n      run:\n        shell: bash\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4.2.2\n    - name: Restore uv cache\n      uses: actions/cache@v4\n      with:\n        path: ~/.cache/uv\n        key: |\n          uv-${{ runner.os }}-${{ inputs.python-version }}-${{ hashFiles('src/zenml/integrations/*/__init__.py') }}\n        restore-keys: |\n          uv-${{ runner.os }}-${{ inputs.python-version }}-${{ hashFiles('src/zenml/integrations/*/__init__.py') }}\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v1\n      with:\n        role-to-assume: ${{ secrets.AWS_US_EAST_1_ENV_ROLE_ARN }}\n        aws-region: us-east-1\n      if: contains(inputs.test_environment, 'aws')\n    - name: Configure GCP credentials\n      uses: google-github-actions/auth@v2\n      with:\n        credentials_json: ${{ secrets.GCP_US_EAST4_ENV_CREDENTIALS }}\n      if: contains(inputs.test_environment, 'gcp')\n    - name: Set up gcloud SDK\n      uses: google-github-actions/setup-gcloud@v1\n      with:\n        install_components: gke-gcloud-auth-plugin\n      if: contains(inputs.test_environment, 'gcp')\n    - name: Login to Docker Hub\n      uses: docker/login-action@v3\n      with:\n        username: ${{ secrets.DOCKERHUB_USERNAME }}\n        password: ${{ secrets.DOCKERHUB_TOKEN }}\n      if: github.event.pull_request.head.repo.fork == false && \n        (contains(inputs.test_environment, 'docker') || \n        contains(inputs.test_environment, 'kubeflow') || \n        contains(inputs.test_environment, 'airflow') || \n        contains(inputs.test_environment, 'kubernetes'))\n    - name: Setup environment\n      uses: ./.github/actions/setup_environment\n      with:\n        python-version: ${{ inputs.python-version }}\n        os: ${{ inputs.os }}\n    - name: Install docker-compose for non-default environments\n      if: inputs.test_environment != 'default'\n      run: |\n        pip install uv\n        # see https://github.com/docker/docker-py/issues/3256 for why we need to pin requests\n        # docker-compose is deprecated and doesn't work with newer versions of docker\n        uv pip install --system \"pyyaml==5.3.1\" \"requests<2.32.0\" \"docker==6.1.3\" docker-compose\n    - name: Install Linux System Dependencies\n      if: (inputs.os == 'ubuntu-latest' || inputs.os == 'arc-runner-set')\n      run: sudo apt install graphviz\n    - name: Install MacOS System Dependencies\n      if: runner.os=='macOS'\n      run: brew install graphviz\n    - name: Install Windows System Dependencies\n      if: runner.os=='Windows'\n      run: choco install graphviz\n    - name: Unbreak python in github actions\n      if: runner.os=='macOS'\n        # github actions overwrites brew's python. Force it to reassert itself, by\n        # running in a separate step.\n        # Workaround GitHub Actions Python issues\n        # see https://github.com/Homebrew/homebrew-core/issues/165793#issuecomment-1989441193\n      run: |\n        find /usr/local/bin -lname '*/Library/Frameworks/Python.framework/*' -delete\n        sudo rm -rf /Library/Frameworks/Python.framework/\n        brew install --force python3 && brew unlink python3 && brew unlink python3 && brew link --overwrite python3\n    - name: Install Docker and Colima on MacOS\n      if: runner.os=='macOS'\n      run: |\n        export HOMEBREW_NO_INSTALLED_DEPENDENTS_CHECK=1\n        brew update\n        brew install docker colima\n        brew reinstall --force qemu\n\n        # We need to mount the /private/tmp/zenml-test/ folder because\n        # this folder is also mounted in the Docker containers that are\n        # started by local ZenML orchestrators.\n        colima start --mount /private/tmp/zenml-test/:w\n\n        # This is required for the Docker Python SDK to work\n        sudo ln -sf $HOME/.colima/default/docker.sock /var/run/docker.sock\n    - name: Install kubectl on Linux\n      run: |\n        curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n        sudo install -o root -g 0 -m 0755 kubectl /usr/local/bin/kubectl\n      if: (inputs.os == 'ubuntu-latest' || inputs.os == 'arc-runner-set')\n    - name: Install kubectl on MacOS\n      run: |\n        curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/amd64/kubectl\"\n        sudo install -o root -g 0 -m 0755 kubectl /usr/local/bin/kubectl\n      if: runner.os=='macOS'\n    - name: Install K3D\n      run: |\n        curl -s https://raw.githubusercontent.com/rancher/k3d/main/install.sh | bash\n      if: runner.os!='Windows' && contains(inputs.test_environment, 'kubeflow')\n    - name: Login to Amazon ECR\n      id: login-ecr\n      run: |\n        aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 715803424590.dkr.ecr.us-east-1.amazonaws.com\n      if: contains(inputs.test_environment, 'aws')\n    - name: Login to Amazon EKS\n      id: login-eks\n      run: |\n        aws eks --region us-east-1 update-kubeconfig --name zenml-ci-cluster --alias zenml-ci-aws-us-east-1\n      if: contains(inputs.test_environment, 'aws')\n    - name: Login to Google ECR\n      run: |\n        gcloud auth configure-docker --project zenml-ci\n      if: contains(inputs.test_environment, 'gcp')\n    - name: Login to Google GKE\n      uses: google-github-actions/get-gke-credentials@v2\n      with:\n        cluster_name: zenml-ci-cluster\n        location: us-east4\n        project_id: zenml-ci\n      if: contains(inputs.test_environment, 'gcp')\n    - name: Setup tmate session before tests\n      if: ${{ inputs.enable_tmate == 'before-tests' }}\n      uses: mxschmitt/action-tmate@v3.17\n      timeout-minutes: ${{ inputs.tmate_timeout }}\n    - name: Sharded Integration Tests (Ubuntu) - Fast CI\n        # Ubuntu integration tests run as 6 shards\n      if: runner.os != 'macOS' && runner.os != 'Windows'\n      run: |\n        bash scripts/test-coverage-xml.sh integration ${{ inputs.test_environment }} 6 ${{ matrix.shard }}\n    - name: Setup tmate session after tests\n      if: ${{ inputs.enable_tmate == 'always' || (inputs.enable_tmate == \n        'on-failure' && failure()) }}\n      uses: mxschmitt/action-tmate@v3.17\n      timeout-minutes: ${{ inputs.tmate_timeout }}\n    - name: Verify Python Env unaffected\n      run: |-\n        zenml integration list\n        uv pip list\n        uv pip check || true\n    services:\n      mysql:\n        image: mysql:5.7\n        env:\n          MYSQL_ROOT_PASSWORD: zenml\n          MYSQL_DATABASE: zenml\n        ports:\n        - 3306:3306\n        options: >-\n          --health-cmd=\"mysqladmin ping\"\n          --health-interval=10s\n          --health-timeout=5s\n          --health-retries=3\n      zenml-server:\n        image: ghcr.io/${{ github.repository_owner \n          }}/zenml-server-github-actions:${{ github.sha }}\n        credentials:\n          username: ${{ github.actor }}\n          password: ${{ secrets.github_token }}\n        env:\n          ZENML_STORE_URL: mysql://root:zenml@mysql:3306/zenml\n          ZENML_SERVER_DEPLOYMENT_TYPE: docker\n          ZENML_SERVER_AUTO_ACTIVATE: 'True'\n          ZENML_SERVER_AUTO_CREATE_DEFAULT_USER: 'True'\n        ports:\n        - 8080:8080\n        options: >-\n          --health-cmd=\"curl -f http://127.0.0.1:8080/health\"\n          --health-interval=10s\n          --health-timeout=5s\n          --health-retries=3\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Integration Tests (Fast CI)` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) this workflow is called by another workflow. This workflow receives 5 inputs: os-this input represents os, the data type is string and it must be supplied; python-version-this input represents python version, the data type is string and it must be supplied; test_environment-this input represents the test environment, the data type is string and it must be supplied; enable_tmate-this input represents enable tmate session for debugging, the data type is string, it is optional and its default value is never; tmate_timeout-this input represents timeout for tmate session (minutes), the data type is number, it is optional and its default value is 30. 2) someone manually triggers the workflow. This workflow receives 5 inputs: os-this input represents os, the data type is choice, it has options including ubuntu-latest, macos-13 and windows-latest, it is optional and its default value is ubuntu-latest; python-version-this input represents python version, the data type is choice, it has options including 3.9, 3.10, 3.11 and 3.12, it is optional and its default value is 3.11; test_environment-this input represents the test environment, the data type is choice, it has options including default, default-docker-orchestrator, default-airflow-orchestrator, local-server, local-server-docker-orchestrator, local-server-airflow-orchestrator, docker-server-mysql, docker-server-mariadb, docker-server-docker-orchestrator-mysql, docker-server-docker-orchestrator-mariadb, docker-server-airflow-orchestrator-mysql, docker-server-airflow-orchestrator-mariadb and github-actions-server-docker-orchestrator, it is optional and its default value is default; enable_tmate-this input represents enable tmate session for debugging, the data type is choice, it has options including False, on-failure, always and before-tests, it is optional and its default value is False; tmate_timeout-this input represents timeout for tmate session (minutes), the data type is number, it is optional and its default value is 30. The workflow has one job. The 1st job is named `integration-tests-fast` and its job id is `integration-tests-fast`. ","prompt_level2":"Generate a GitHub Workflow named `Integration Tests (Fast CI)` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) this workflow is called by another workflow. This workflow receives 5 inputs: os-this input represents os, the data type is string and it must be supplied; python-version-this input represents python version, the data type is string and it must be supplied; test_environment-this input represents the test environment, the data type is string and it must be supplied; enable_tmate-this input represents enable tmate session for debugging, the data type is string, it is optional and its default value is never; tmate_timeout-this input represents timeout for tmate session (minutes), the data type is number, it is optional and its default value is 30. 2) someone manually triggers the workflow. This workflow receives 5 inputs: os-this input represents os, the data type is choice, it has options including ubuntu-latest, macos-13 and windows-latest, it is optional and its default value is ubuntu-latest; python-version-this input represents python version, the data type is choice, it has options including 3.9, 3.10, 3.11 and 3.12, it is optional and its default value is 3.11; test_environment-this input represents the test environment, the data type is choice, it has options including default, default-docker-orchestrator, default-airflow-orchestrator, local-server, local-server-docker-orchestrator, local-server-airflow-orchestrator, docker-server-mysql, docker-server-mariadb, docker-server-docker-orchestrator-mysql, docker-server-docker-orchestrator-mariadb, docker-server-airflow-orchestrator-mysql, docker-server-airflow-orchestrator-mariadb and github-actions-server-docker-orchestrator, it is optional and its default value is default; enable_tmate-this input represents enable tmate session for debugging, the data type is choice, it has options including False, on-failure, always and before-tests, it is optional and its default value is False; tmate_timeout-this input represents timeout for tmate session (minutes), the data type is number, it is optional and its default value is 30. The workflow has one job. The 1st job is named `integration-tests-fast` and its job id is `integration-tests-fast`. The job `integration-tests-fast` has 24 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Restore uv cache`. The 3rd step is named `Configure AWS credentials`. The 4th step is named `Configure GCP credentials`. The 5th step is named `Set up gcloud SDK`. The 6th step is named `Login to Docker Hub`. The 7th step is named `Setup environment`. The 8th step is named `Install docker-compose for non-default environments`. The 9th step is named `Install Linux System Dependencies`. The 10th step is named `Install MacOS System Dependencies`. The 11th step is named `Install Windows System Dependencies`. The 12th step is named `Unbreak python in github actions`. The 13th step is named `Install Docker and Colima on MacOS`. The 14th step is named `Install kubectl on Linux`. The 15th step is named `Install kubectl on MacOS`. The 16th step is named `Install K3D`. The 17th step is named `Login to Amazon ECR` and its id is `login-ecr`. The 18th step is named `Login to Amazon EKS` and its id is `login-eks`. The 19th step is named `Login to Google ECR`. The 20th step is named `Login to Google GKE`. The 21st step is named `Setup tmate session before tests`. The 22nd step is named `Sharded Integration Tests (Ubuntu) - Fast CI`. The 23rd step is named `Setup tmate session after tests`. The 24th step is named `Verify Python Env unaffected`. ","prompt_level3":"Generate a GitHub Workflow named `Integration Tests (Fast CI)` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) this workflow is called by another workflow. This workflow receives 5 inputs: os-this input represents os, the data type is string and it must be supplied; python-version-this input represents python version, the data type is string and it must be supplied; test_environment-this input represents the test environment, the data type is string and it must be supplied; enable_tmate-this input represents enable tmate session for debugging, the data type is string, it is optional and its default value is never; tmate_timeout-this input represents timeout for tmate session (minutes), the data type is number, it is optional and its default value is 30. 2) someone manually triggers the workflow. This workflow receives 5 inputs: os-this input represents os, the data type is choice, it has options including ubuntu-latest, macos-13 and windows-latest, it is optional and its default value is ubuntu-latest; python-version-this input represents python version, the data type is choice, it has options including 3.9, 3.10, 3.11 and 3.12, it is optional and its default value is 3.11; test_environment-this input represents the test environment, the data type is choice, it has options including default, default-docker-orchestrator, default-airflow-orchestrator, local-server, local-server-docker-orchestrator, local-server-airflow-orchestrator, docker-server-mysql, docker-server-mariadb, docker-server-docker-orchestrator-mysql, docker-server-docker-orchestrator-mariadb, docker-server-airflow-orchestrator-mysql, docker-server-airflow-orchestrator-mariadb and github-actions-server-docker-orchestrator, it is optional and its default value is default; enable_tmate-this input represents enable tmate session for debugging, the data type is choice, it has options including False, on-failure, always and before-tests, it is optional and its default value is False; tmate_timeout-this input represents timeout for tmate session (minutes), the data type is number, it is optional and its default value is 30. The workflow has one job. The 1st job is named `integration-tests-fast` and its job id is `integration-tests-fast`. This job will run only if the condition(${{ ! startsWith(github.event.head_commit.message, 'GitBook:') }}) is met. This job will run on ${{ inputs.os }} runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `shard` has 6 values: 1, 2, 3, 4, 5 and 6. The job defines a service called mysql which will be created using the Docker image `mysql:5.7`. The service container sets 2 environment variables to use: `MYSQL_ROOT_PASSWORD` is set to `zenml` and `MYSQL_DATABASE` is set to `zenml`. For communication, the port 3306 on the Docker host is mapped to port 3306 on the service container. It configures additional Docker container resource options: --health-cmd=\"mysqladmin ping\" --health-interval=10s --health-timeout=5s --health-retries=3. The job defines a service called zenml-server which will be created using the Docker image `ghcr.io/${{ github.repository_owner }}/zenml-server-github-actions:${{ github.sha }}`. The authentication credentials required to access the Docker image registry for zenml-server are that `username` is ${{ github.actor }} and `password` is ${{ secrets.github_token }}. The service container sets 4 environment variables to use: `ZENML_STORE_URL` is set to `mysql://root:zenml@mysql:3306/zenml`, `ZENML_SERVER_DEPLOYMENT_TYPE` is set to `docker`, `ZENML_SERVER_AUTO_ACTIVATE` is set to `True` and `ZENML_SERVER_AUTO_CREATE_DEFAULT_USER` is set to `True`. For communication, the port 8080 on the Docker host is mapped to port 8080 on the service container. It configures additional Docker container resource options: --health-cmd=\"curl -f http://127.0.0.1:8080/health\" --health-interval=10s --health-timeout=5s --health-retries=3. The job sets 13 environment variables to use: `ZENML_DEBUG` is set to `1`, `ZENML_ANALYTICS_OPT_IN` is set to `False`, `PYTHONIOENCODING` is set to `utf-8`, `UV_HTTP_TIMEOUT` is set to `600`, `OBJC_DISABLE_INITIALIZE_FORK_SAFETY` is set to `True`, `AWS_ACCESS_KEY_ID` is set to `${{ secrets.AWS_US_EAST_1_ENV_ACCESS_KEY_ID }}`, `AWS_SECRET_ACCESS_KEY` is set to `${{ secrets.AWS_US_EAST_1_ENV_SECRET_ACCESS_KEY }}`, `AWS_US_EAST_1_SERVER_URL` is set to `${{ secrets.AWS_US_EAST_1_SERVER_URL }}`, `AWS_US_EAST_1_SERVER_USERNAME` is set to `${{ secrets.AWS_US_EAST_1_SERVER_USERNAME }}`, `AWS_US_EAST_1_SERVER_PASSWORD` is set to `${{ secrets.AWS_US_EAST_1_SERVER_PASSWORD }}`, `GCP_US_EAST4_SERVER_URL` is set to `${{ secrets.GCP_US_EAST4_SERVER_URL }}`, `GCP_US_EAST4_SERVER_USERNAME` is set to `${{ secrets.GCP_US_EAST4_SERVER_USERNAME }}` and `GCP_US_EAST4_SERVER_PASSWORD` is set to `${{ secrets.GCP_US_EAST4_SERVER_PASSWORD }}`. For all run steps in the job, default shell is set to bash. The job `integration-tests-fast` has 24 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4.2.2. The 2nd step is named `Restore uv cache`. This step runs action `actions/cache` tagged as v4. The step defines 3 input parameters for the action: `path` is set to `~/.cache/uv`, `key` is set to `uv-${{ runner.os }}-${{ inputs.python-version }}-${{ hashFiles('src/zenml/integrations/*/__init__.py') }}\n` and `restore-keys` is set to `uv-${{ runner.os }}-${{ inputs.python-version }}-${{ hashFiles('src/zenml/integrations/*/__init__.py') }}\n`. The 3rd step is named `Configure AWS credentials`. This step will run only if the condition(contains(inputs.test_environment, 'aws')) is met. This step runs action `aws-actions/configure-aws-credentials` tagged as v1. The step defines 2 input parameters for the action: `role-to-assume` is set to `${{ secrets.AWS_US_EAST_1_ENV_ROLE_ARN }}` and `aws-region` is set to `us-east-1`. The 4th step is named `Configure GCP credentials`. This step will run only if the condition(contains(inputs.test_environment, 'gcp')) is met. This step runs action `google-github-actions/auth` tagged as v2. The step defines an input parameter for the action: `credentials_json` is set to `${{ secrets.GCP_US_EAST4_ENV_CREDENTIALS }}`. The 5th step is named `Set up gcloud SDK`. This step will run only if the condition(contains(inputs.test_environment, 'gcp')) is met. This step runs action `google-github-actions/setup-gcloud` tagged as v1. The step defines an input parameter for the action: `install_components` is set to `gke-gcloud-auth-plugin`. The 6th step is named `Login to Docker Hub`. This step will run only if the condition(github.event.pull_request.head.repo.fork == false && (contains(inputs.test_environment, 'docker') || contains(inputs.test_environment, 'kubeflow') || contains(inputs.test_environment, 'airflow') || contains(inputs.test_environment, 'kubernetes'))) is met. This step runs action `docker/login-action` tagged as v3. The step defines 2 input parameters for the action: `username` is set to `${{ secrets.DOCKERHUB_USERNAME }}` and `password` is set to `${{ secrets.DOCKERHUB_TOKEN }}`. The 7th step is named `Setup environment`. This step runs action `./.github/actions/setup_environment`.The step defines 2 input parameters for the action: `python-version` is set to `${{ inputs.python-version }}` and `os` is set to `${{ inputs.os }}`. The 8th step is named `Install docker-compose for non-default environments`. This step will run only if the condition(inputs.test_environment != 'default') is met. This step runs a script: `pip install uv\n# see https://github.com/docker/docker-py/issues/3256 for why we need to pin requests\n# docker-compose is deprecated and doesn't work with newer versions of docker\nuv pip install --system \"pyyaml==5.3.1\" \"requests<2.32.0\" \"docker==6.1.3\" docker-compose\n`. The 9th step is named `Install Linux System Dependencies`. This step will run only if the condition((inputs.os == 'ubuntu-latest' || inputs.os == 'arc-runner-set')) is met. This step runs a script: `sudo apt install graphviz`. The 10th step is named `Install MacOS System Dependencies`. This step will run only if the condition(runner.os=='macOS') is met. This step runs a script: `brew install graphviz`. The 11th step is named `Install Windows System Dependencies`. This step will run only if the condition(runner.os=='Windows') is met. This step runs a script: `choco install graphviz`. The 12th step is named `Unbreak python in github actions`. This step will run only if the condition(runner.os=='macOS') is met. This step runs a script: `find /usr/local/bin -lname '*/Library/Frameworks/Python.framework/*' -delete\nsudo rm -rf /Library/Frameworks/Python.framework/\nbrew install --force python3 && brew unlink python3 && brew unlink python3 && brew link --overwrite python3\n`. The 13th step is named `Install Docker and Colima on MacOS`. This step will run only if the condition(runner.os=='macOS') is met. This step runs a script: `export HOMEBREW_NO_INSTALLED_DEPENDENTS_CHECK=1\nbrew update\nbrew install docker colima\nbrew reinstall --force qemu\n\n# We need to mount the /private/tmp/zenml-test/ folder because\n# this folder is also mounted in the Docker containers that are\n# started by local ZenML orchestrators.\ncolima start --mount /private/tmp/zenml-test/:w\n\n# This is required for the Docker Python SDK to work\nsudo ln -sf $HOME/.colima/default/docker.sock /var/run/docker.sock\n`. The 14th step is named `Install kubectl on Linux`. This step will run only if the condition((inputs.os == 'ubuntu-latest' || inputs.os == 'arc-runner-set')) is met. This step runs a script: `curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nsudo install -o root -g 0 -m 0755 kubectl /usr/local/bin/kubectl\n`. The 15th step is named `Install kubectl on MacOS`. This step will run only if the condition(runner.os=='macOS') is met. This step runs a script: `curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/amd64/kubectl\"\nsudo install -o root -g 0 -m 0755 kubectl /usr/local/bin/kubectl\n`. The 16th step is named `Install K3D`. This step will run only if the condition(runner.os!='Windows' && contains(inputs.test_environment, 'kubeflow')) is met. This step runs a script: `curl -s https://raw.githubusercontent.com/rancher/k3d/main/install.sh | bash\n`. The 17th step is named `Login to Amazon ECR` and its id is `login-ecr`. This step will run only if the condition(contains(inputs.test_environment, 'aws')) is met. This step runs a script: `aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 715803424590.dkr.ecr.us-east-1.amazonaws.com\n`. The 18th step is named `Login to Amazon EKS` and its id is `login-eks`. This step will run only if the condition(contains(inputs.test_environment, 'aws')) is met. This step runs a script: `aws eks --region us-east-1 update-kubeconfig --name zenml-ci-cluster --alias zenml-ci-aws-us-east-1\n`. The 19th step is named `Login to Google ECR`. This step will run only if the condition(contains(inputs.test_environment, 'gcp')) is met. This step runs a script: `gcloud auth configure-docker --project zenml-ci\n`. The 20th step is named `Login to Google GKE`. This step will run only if the condition(contains(inputs.test_environment, 'gcp')) is met. This step runs action `google-github-actions/get-gke-credentials` tagged as v2. The step defines 3 input parameters for the action: `cluster_name` is set to `zenml-ci-cluster`, `location` is set to `us-east4` and `project_id` is set to `zenml-ci`. The 21st step is named `Setup tmate session before tests`. This step will run only if the condition(${{ inputs.enable_tmate == 'before-tests' }}) is met. This step runs action `mxschmitt/action-tmate` tagged as v3.17. The maximum number of minutes to run the step is ${{ inputs.tmate_timeout }}. The 22nd step is named `Sharded Integration Tests (Ubuntu) - Fast CI`. This step will run only if the condition(runner.os != 'macOS' && runner.os != 'Windows') is met. This step runs a script: `bash scripts/test-coverage-xml.sh integration ${{ inputs.test_environment }} 6 ${{ matrix.shard }}\n`. The 23rd step is named `Setup tmate session after tests`. This step will run only if the condition(${{ inputs.enable_tmate == 'always' || (inputs.enable_tmate == 'on-failure' && failure()) }}) is met. This step runs action `mxschmitt/action-tmate` tagged as v3.17. The maximum number of minutes to run the step is ${{ inputs.tmate_timeout }}. The 24th step is named `Verify Python Env unaffected`. This step runs a script: `zenml integration list\nuv pip list\nuv pip check || true`. ","nb_triggers":2,"triggers":["workflow_call","workflow_dispatch"],"nb_jobs":1,"nb_actions":10,"actions":["./.github/actions/setup_environment","actions/cache","actions/checkout","aws-actions/configure-aws-credentials","docker/login-action","google-github-actions/auth","google-github-actions/get-gke-credentials","google-github-actions/setup-gcloud","mxschmitt/action-tmate","mxschmitt/action-tmate"],"actions_details":[{"version":"v4.2.2","name":"actions/checkout"},{"version":"v4","name":"actions/cache"},{"version":"v1","name":"aws-actions/configure-aws-credentials"},{"version":"v2","name":"google-github-actions/auth"},{"version":"v1","name":"google-github-actions/setup-gcloud"},{"version":"v3","name":"docker/login-action"},{"version":null,"name":"./.github/actions/setup_environment"},{"version":"v2","name":"google-github-actions/get-gke-credentials"},{"version":"v3.17","name":"mxschmitt/action-tmate"},{"version":"v3.17","name":"mxschmitt/action-tmate"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":24,"cyclomatic_complexity":1}
{"id":48157,"repository_id":95025688,"mainLanguage":"Fortran","file_name":"ci.yml","file_content":"name: Regression Suite\nrun-name : ${{ github.event_name == 'push' && 'CI' || github.event.label.name }} (${{ github.event_name }})\n\non:\n  push:\n    branches: [ master, develop ]\n# See https://stackoverflow.com/a/78444521 and \n# https://github.com/orgs/community/discussions/26874#discussioncomment-3253755\n# as well as official (but buried) documentation :\n# https://docs.github.com/en/actions/writing-workflows/choosing-when-your-workflow-runs/events-that-trigger-workflows#pull-request-events-for-forked-repositories-2\n  pull_request:\n    types:    [ labeled ]\n\n# https://docs.github.com/en/actions/sharing-automations/reusing-workflows#supported-keywords-for-jobs-that-call-a-reusable-workflow\n# Also https://stackoverflow.com/a/74959635\n# TL;DR - For public repositories the safest approach will be to use the default read permissions, but at the cost\n# of not being able to modify the labels. That will need to be a separate [trusted] workflow that runs from the base repo\n# permissions :\n#   contents : read\n#   pull-requests : write\n  \n# Write our tests out this way for easier legibility\n# testsSet    :\n#   - key : value\n#     key : value\n#     tests :\n#       - value\n#       - value\n#   - < next test >\n# https://stackoverflow.com/a/68940067\njobs:\n  buildtests:\n    if : ${{ github.event.label.name == 'compile-tests' || github.event.label.name == 'all-tests' || github.event_name == 'push' }}\n    strategy:\n      max-parallel: 4\n      fail-fast: false\n      matrix:\n      \n        testSet  :\n          - host : derecho\n            hpc-workflows_path : .ci/hpc-workflows\n            archive : /glade/work/aislas/github/runners/wrf/derecho/logs/\n            account : NMMM0012\n            name : \"Make Compilation Tests\"\n            id   : make-tests\n            fileroot : wrf_compilation_tests-make\n            args : -j='{\"node_select\":{\"-l \":{\"select\":1}}}'\n            pool  : 8\n            tpool : 1\n            mkdirs : true\n            tests :\n              - make-gnu-serial\n              - make-gnu-sm\n              - make-gnu-dm\n              - make-gnu-dm+sm\n              - make-intel-classic-serial\n              - make-intel-classic-sm\n              - make-intel-classic-dm\n              - make-intel-classic-dm+sm\n              - make-intel-llvm-serial\n              - make-intel-llvm-sm\n              - make-intel-llvm-dm\n              - make-intel-llvm-dm+sm\n              - make-pgi-serial\n              - make-pgi-sm\n              - make-pgi-dm\n              - make-pgi-dm+sm\n              # add new compilation tests here\n\n    uses : ./.github/workflows/test_workflow.yml\n    with :\n      # This should be the only hard-coded value, we don't use ${{ github.event.label.name }}\n      # to avoid 'all-tests' to be used in this workflow\n      label    : compile-tests\n\n      # Everything below this should remain the same and comes from the testSet matrix\n      hpc-workflows_path : ${{ matrix.testSet.hpc-workflows_path }}\n      archive  : ${{ matrix.testSet.archive }}\n      name     : ${{ matrix.testSet.name }}\n      id       : ${{ matrix.testSet.id }}\n      host     : ${{ matrix.testSet.host }}\n      fileroot : ${{ matrix.testSet.fileroot }}\n      account  : ${{ matrix.testSet.account }}\n      tests    : ${{ toJson( matrix.testSet.tests ) }}\n      mkdirs   : ${{ matrix.testSet.mkdirs }}\n      args     : ${{ matrix.testSet.args }}\n      pool     : ${{ matrix.testSet.pool }}\n      tpool    : ${{ matrix.testSet.tpool }}\n    # I am leaving this here for posterity if this is to be replicated in private repositories for testing\n    permissions:\n      contents: read\n      pull-requests: write\n    name : Test ${{ matrix.testSet.name }} on ${{ matrix.testSet.host }}\n\n  # In the event that 'all-tests' is used, this final job will be the one to remove\n  # the label from the PR\n  removeAllLabel :\n    if : ${{ !cancelled() && github.event.label.name == 'all-tests' }}\n    name : Remove 'all-tests' label\n    runs-on: ubuntu-latest\n    needs : [ buildtests ] # Put tests here to make this wait for the tests to complete\n    steps: \n      - name : Remove '${{ github.event.label.name }}' label\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n        run: |\n          curl \\\n            -X DELETE \\\n            -H \"Accept: application/vnd.github.v3+json\" \\\n            -H 'Authorization: token ${{ github.token }}' \\\n            https://api.github.com/repos/${GITHUB_REPOSITORY}/issues/${PR_NUMBER}/labels/${{ github.event.label.name }}\n","repository_owner":"wrf-model","repository_name":"WRF","tokens_count":1149,"workflow":"name: Regression Suite\nrun-name: ${{ github.event_name == 'push' && 'CI' || github.event.label.name }} \n  (${{ github.event_name }})\n\non:\n  push:\n    branches: [master, develop]\n# See https://stackoverflow.com/a/78444521 and \n# https://github.com/orgs/community/discussions/26874#discussioncomment-3253755\n# as well as official (but buried) documentation :\n# https://docs.github.com/en/actions/writing-workflows/choosing-when-your-workflow-runs/events-that-trigger-workflows#pull-request-events-for-forked-repositories-2\n  pull_request:\n    types: [labeled]\n\n# https://docs.github.com/en/actions/sharing-automations/reusing-workflows#supported-keywords-for-jobs-that-call-a-reusable-workflow\n# Also https://stackoverflow.com/a/74959635\n# TL;DR - For public repositories the safest approach will be to use the default read permissions, but at the cost\n# of not being able to modify the labels. That will need to be a separate [trusted] workflow that runs from the base repo\n# permissions :\n#   contents : read\n#   pull-requests : write\n# Write our tests out this way for easier legibility\n# testsSet    :\n#   - key : value\n#     key : value\n#     tests :\n#       - value\n#       - value\n#   - < next test >\n# https://stackoverflow.com/a/68940067\njobs:\n  buildtests:\n    if: ${{ github.event.label.name == 'compile-tests' || \n      github.event.label.name == 'all-tests' || github.event_name == 'push' }}\n    strategy:\n      max-parallel: 4\n      fail-fast: false\n      matrix:\n        testSet:\n        - host: derecho\n          hpc-workflows_path: .ci/hpc-workflows\n          archive: /glade/work/aislas/github/runners/wrf/derecho/logs/\n          account: NMMM0012\n          name: Make Compilation Tests\n          id: make-tests\n          fileroot: wrf_compilation_tests-make\n          args: -j='{\"node_select\":{\"-l \":{\"select\":1}}}'\n          pool: 8\n          tpool: 1\n          mkdirs: true\n          tests:\n          - make-gnu-serial\n          - make-gnu-sm\n          - make-gnu-dm\n          - make-gnu-dm+sm\n          - make-intel-classic-serial\n          - make-intel-classic-sm\n          - make-intel-classic-dm\n          - make-intel-classic-dm+sm\n          - make-intel-llvm-serial\n          - make-intel-llvm-sm\n          - make-intel-llvm-dm\n          - make-intel-llvm-dm+sm\n          - make-pgi-serial\n          - make-pgi-sm\n          - make-pgi-dm\n          - make-pgi-dm+sm\n              # add new compilation tests here\n\n    uses: ./.github/workflows/test_workflow.yml\n    with:\n      # This should be the only hard-coded value, we don't use ${{ github.event.label.name }}\n      # to avoid 'all-tests' to be used in this workflow\n      label: compile-tests\n\n      # Everything below this should remain the same and comes from the testSet matrix\n      hpc-workflows_path: ${{ matrix.testSet.hpc-workflows_path }}\n      archive: ${{ matrix.testSet.archive }}\n      name: ${{ matrix.testSet.name }}\n      id: ${{ matrix.testSet.id }}\n      host: ${{ matrix.testSet.host }}\n      fileroot: ${{ matrix.testSet.fileroot }}\n      account: ${{ matrix.testSet.account }}\n      tests: ${{ toJson( matrix.testSet.tests ) }}\n      mkdirs: ${{ matrix.testSet.mkdirs }}\n      args: ${{ matrix.testSet.args }}\n      pool: ${{ matrix.testSet.pool }}\n      tpool: ${{ matrix.testSet.tpool }}\n    # I am leaving this here for posterity if this is to be replicated in private repositories for testing\n    permissions:\n      contents: read\n      pull-requests: write\n    name: Test ${{ matrix.testSet.name }} on ${{ matrix.testSet.host }}\n\n  # In the event that 'all-tests' is used, this final job will be the one to remove\n  # the label from the PR\n  removeAllLabel:\n    if: ${{ !cancelled() && github.event.label.name == 'all-tests' }}\n    name: Remove 'all-tests' label\n    runs-on: ubuntu-latest\n    needs: [buildtests]    # Put tests here to make this wait for the tests to complete\n    steps:\n    - name: Remove '${{ github.event.label.name }}' label\n      env:\n        PR_NUMBER: ${{ github.event.number }}\n      run: |\n        curl \\\n          -X DELETE \\\n          -H \"Accept: application/vnd.github.v3+json\" \\\n          -H 'Authorization: token ${{ github.token }}' \\\n          https://api.github.com/repos/${GITHUB_REPOSITORY}/issues/${PR_NUMBER}/labels/${{ github.event.label.name }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Regression Suite` for a GitHub repository whose primary programming language is Fortran. The name for workflow runs is set to `${{ github.event_name == 'push' && 'CI' || github.event.label.name }} (${{ github.event_name }})`. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master or a branch named develop. 2) a label is added to a pull request. The workflow has 2 jobs. The 1st job is named `Test ${{ matrix.testSet.name }} on ${{ matrix.testSet.host }}` and its job id is `buildtests`. The 2nd job is named `Remove 'all-tests' label` and its job id is `removeAllLabel`. ","prompt_level2":"Generate a GitHub Workflow named `Regression Suite` for a GitHub repository whose primary programming language is Fortran. The name for workflow runs is set to `${{ github.event_name == 'push' && 'CI' || github.event.label.name }} (${{ github.event_name }})`. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master or a branch named develop. 2) a label is added to a pull request. The workflow has 2 jobs. The 1st job is named `Test ${{ matrix.testSet.name }} on ${{ matrix.testSet.host }}` and its job id is `buildtests`. The 2nd job is named `Remove 'all-tests' label` and its job id is `removeAllLabel`. The job `removeAllLabel` has one step. The 1st step is named `Remove '${{ github.event.label.name }}' label`. ","prompt_level3":"Generate a GitHub Workflow named `Regression Suite` for a GitHub repository whose primary programming language is Fortran. The name for workflow runs is set to `${{ github.event_name == 'push' && 'CI' || github.event.label.name }} (${{ github.event_name }})`. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master or a branch named develop. 2) a label is added to a pull request. The workflow has 2 jobs. The 1st job is named `Test ${{ matrix.testSet.name }} on ${{ matrix.testSet.host }}` and its job id is `buildtests`. This job will run only if the condition(${{ github.event.label.name == 'compile-tests' || github.event.label.name == 'all-tests' || github.event_name == 'push' }}) is met. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `testSet` has one value: {'host': 'derecho', 'hpc-workflows_path': '.ci/hpc-workflows', 'archive': '/glade/work/aislas/github/runners/wrf/derecho/logs/', 'account': 'NMMM0012', 'name': 'Make Compilation Tests', 'id': 'make-tests', 'fileroot': 'wrf_compilation_tests-make', 'args': '-j=\\'{\"node_select\":{\"-l \":{\"select\":1}}}\\'', 'pool': 8, 'tpool': 1, 'mkdirs': True, 'tests': ['make-gnu-serial', 'make-gnu-sm', 'make-gnu-dm', 'make-gnu-dm+sm', 'make-intel-classic-serial', 'make-intel-classic-sm', 'make-intel-classic-dm', 'make-intel-classic-dm+sm', 'make-intel-llvm-serial', 'make-intel-llvm-sm', 'make-intel-llvm-dm', 'make-intel-llvm-dm+sm', 'make-pgi-serial', 'make-pgi-sm', 'make-pgi-dm', 'make-pgi-dm+sm']}. The maximum number of job runs in parallel is set to 4. The job `buildtests` modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `pull-requests` scope. This permission setting only applies to the job `buildtests`. This job will call a reusable workflow located at `./.github/workflows/test_workflow.yml`. The job will pass 13 inputs to the called workflow: the input `label` is `compile-tests`, the input `hpc-workflows_path` is `${{ matrix.testSet.hpc-workflows_path }}`, the input `archive` is `${{ matrix.testSet.archive }}`, the input `name` is `${{ matrix.testSet.name }}`, the input `id` is `${{ matrix.testSet.id }}`, the input `host` is `${{ matrix.testSet.host }}`, the input `fileroot` is `${{ matrix.testSet.fileroot }}`, the input `account` is `${{ matrix.testSet.account }}`, the input `tests` is `${{ toJson( matrix.testSet.tests ) }}`, the input `mkdirs` is `${{ matrix.testSet.mkdirs }}`, the input `args` is `${{ matrix.testSet.args }}`, the input `pool` is `${{ matrix.testSet.pool }}` and the input `tpool` is `${{ matrix.testSet.tpool }}`. The 2nd job is named `Remove 'all-tests' label` and its job id is `removeAllLabel`. Before this job runs, `buildtests` must complete successfully. This job will run only if the condition(${{ !cancelled() && github.event.label.name == 'all-tests' }}) is met. This job will run on ubuntu-latest runner. The job `removeAllLabel` has one step. The 1st step is named `Remove '${{ github.event.label.name }}' label`. The step sets an environment variable to use: `PR_NUMBER` is set to `${{ github.event.number }}`. This step runs a script: `curl \\\n  -X DELETE \\\n  -H \"Accept: application/vnd.github.v3+json\" \\\n  -H 'Authorization: token ${{ github.token }}' \\\n  https://api.github.com/repos/${GITHUB_REPOSITORY}/issues/${PR_NUMBER}/labels/${{ github.event.label.name }}\n`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":2,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["./.github/workflows/test_workflow.yml"],"nb_steps":1,"cyclomatic_complexity":1}
{"id":14216,"repository_id":95196261,"mainLanguage":"Elixir","file_name":"on_push.yml","file_content":"# Push\n#\n# This is the pipeline that will run for every pushed commit, except for main and next.\n#\n# The pipeline does the following.\n# 1. Compile the source code for all environments (dev, test, prod)\n# 2. Run the linter on the source code.\n\nname: Push\nrun-name: Push on `${{ github.ref_name }}`\non:\n  push:\n    branches-ignore:\n      - 'main'\n      - 'next'\n      - 'base'\n\njobs:\n  compile:\n    strategy:\n      matrix:\n        target: [dev, test, prod]\n    uses: ./.github/workflows/compile.yaml\n    with:\n      mix-env: ${{ matrix.target }}\n      elixir-version: \"1.17\"\n      otp-version: \"27.1\"\n\n  lint:\n    needs: compile\n    uses: ./.github/workflows/lint.yaml\n    with:\n      mix-env: \"dev\"\n      elixir-version: \"1.17\"\n      otp-version: \"27.1\"\n","repository_owner":"anoma","repository_name":"anoma","tokens_count":221,"workflow":"# Push\n#\n# This is the pipeline that will run for every pushed commit, except for main and next.\n#\n# The pipeline does the following.\n# 1. Compile the source code for all environments (dev, test, prod)\n# 2. Run the linter on the source code.\n\nname: Push\nrun-name: Push on `${{ github.ref_name }}`\non:\n  push:\n    branches-ignore:\n    - main\n    - next\n    - base\n\njobs:\n  compile:\n    strategy:\n      matrix:\n        target: [dev, test, prod]\n    uses: ./.github/workflows/compile.yaml\n    with:\n      mix-env: ${{ matrix.target }}\n      elixir-version: '1.17'\n      otp-version: '27.1'\n\n  lint:\n    needs: compile\n    uses: ./.github/workflows/lint.yaml\n    with:\n      mix-env: dev\n      elixir-version: '1.17'\n      otp-version: '27.1'\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Push` for a GitHub repository whose primary programming language is Elixir. The name for workflow runs is set to `Push on `${{ github.ref_name }}``. This workflow will be triggered by an event: The workflow would run whenever there is a push event unless the push event is to: a branch named main, a branch named next or a branch named base. The workflow has 2 jobs. The job id of the 1st job is `compile`. The job id of the 2nd job is `lint`. ","prompt_level2":"Generate a GitHub Workflow named `Push` for a GitHub repository whose primary programming language is Elixir. The name for workflow runs is set to `Push on `${{ github.ref_name }}``. This workflow will be triggered by an event: The workflow would run whenever there is a push event unless the push event is to: a branch named main, a branch named next or a branch named base. The workflow has 2 jobs. The job id of the 1st job is `compile`. The job id of the 2nd job is `lint`. ","prompt_level3":"Generate a GitHub Workflow named `Push` for a GitHub repository whose primary programming language is Elixir. The name for workflow runs is set to `Push on `${{ github.ref_name }}``. This workflow will be triggered by an event: The workflow would run whenever there is a push event unless the push event is to: a branch named main, a branch named next or a branch named base. The workflow has 2 jobs. The job id of the 1st job is `compile`. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `target` has 3 values: dev, test and prod. This job will call a reusable workflow located at `./.github/workflows/compile.yaml`. The job will pass 3 inputs to the called workflow: the input `mix-env` is `${{ matrix.target }}`, the input `elixir-version` is `1.17` and the input `otp-version` is `27.1`. The job id of the 2nd job is `lint`. Before this job runs, `compile` must complete successfully. This job will call a reusable workflow located at `./.github/workflows/lint.yaml`. The job will pass 3 inputs to the called workflow: the input `mix-env` is `dev`, the input `elixir-version` is `1.17` and the input `otp-version` is `27.1`. ","nb_triggers":1,"triggers":["push"],"nb_jobs":2,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":2,"reusable_workflows":["./.github/workflows/compile.yaml","./.github/workflows/lint.yaml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":20671,"repository_id":95182954,"mainLanguage":"C++","file_name":"test-windows.yml","file_content":"name: test Workflow\n\non:\n  workflow_call:\n    inputs:\n      run_platform:\n        required: false\n        type: string\n        default: amd64\njobs:\n  test:\n    runs-on: ${{ inputs.run_platform }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - uses: actions/setup-python@v5\n        with:\n            python-version: '3.11.0'\n\n      - name: set up MSVC\n        uses: ilammy/msvc-dev-cmd@v1.4.1\n        with:\n          sdk: '10.0.22621.0'\n\n      - name: Add msbuild to PATH\n        uses: microsoft/setup-msbuild@v1.1.3\n\n      - name: Install dependencies for build\n        shell: bash\n        run: |\n          pip install pyinstaller jinja2 setuptools==74.1.2 pyyaml sphinx sphinx_rtd_theme sphinx-design myst-parser build linkify-it-py wheel\n\n      - name: start test\n        shell: bash\n        run: |\n          ./test.bat","repository_owner":"AimRT","repository_name":"AimRT","tokens_count":245,"workflow":"name: test Workflow\n\non:\n  workflow_call:\n    inputs:\n      run_platform:\n        required: false\n        type: string\n        default: amd64\njobs:\n  test:\n    runs-on: ${{ inputs.run_platform }}\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v4\n\n    - name: Setup Python 3.11.0\n      uses: actions/setup-python@v5\n      with:\n        python-version: 3.11.0\n\n    - name: set up MSVC\n      uses: ilammy/msvc-dev-cmd@v1.4.1\n      with:\n        sdk: 10.0.22621.0\n\n    - name: Add msbuild to PATH\n      uses: microsoft/setup-msbuild@v1.1.3\n\n    - name: Install dependencies for build\n      shell: bash\n      run: |\n        pip install pyinstaller jinja2 setuptools==74.1.2 pyyaml sphinx sphinx_rtd_theme sphinx-design myst-parser build linkify-it-py wheel\n\n    - name: start test\n      shell: bash\n      run: |-\n        ./test.bat\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `test Workflow` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives an input: run_platform-it is optional, the data type is string and its default value is amd64. The workflow has one job. The job id of the 1st job is `test`. ","prompt_level2":"Generate a GitHub Workflow named `test Workflow` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives an input: run_platform-it is optional, the data type is string and its default value is amd64. The workflow has one job. The job id of the 1st job is `test`. The job `test` has 6 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Setup Python 3.11.0`. The 3rd step is named `set up MSVC`. The 4th step is named `Add msbuild to PATH`. The 5th step is named `Install dependencies for build`. The 6th step is named `start test`. ","prompt_level3":"Generate a GitHub Workflow named `test Workflow` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives an input: run_platform-it is optional, the data type is string and its default value is amd64. The workflow has one job. The job id of the 1st job is `test`. This job will run on ${{ inputs.run_platform }} runner. The job `test` has 6 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Setup Python 3.11.0`. This step runs action `actions/setup-python` tagged as v5. The step defines an input parameter for the action: `python-version` is set to `3.11.0`. The 3rd step is named `set up MSVC`. This step runs action `ilammy/msvc-dev-cmd` tagged as v1.4.1. The step defines an input parameter for the action: `sdk` is set to `10.0.22621.0`. The 4th step is named `Add msbuild to PATH`. This step runs action `microsoft/setup-msbuild` tagged as v1.1.3. The 5th step is named `Install dependencies for build`. This step uses bash to run a script: `pip install pyinstaller jinja2 setuptools==74.1.2 pyyaml sphinx sphinx_rtd_theme sphinx-design myst-parser build linkify-it-py wheel\n`. The 6th step is named `start test`. This step uses bash to run a script: `./test.bat`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":4,"actions":["actions/checkout","actions/setup-python","ilammy/msvc-dev-cmd","microsoft/setup-msbuild"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v5","name":"actions/setup-python"},{"version":"v1.4.1","name":"ilammy/msvc-dev-cmd"},{"version":"v1.1.3","name":"microsoft/setup-msbuild"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":6,"cyclomatic_complexity":1}
{"id":21109,"repository_id":18239562,"mainLanguage":"Go","file_name":"job-test-in-lima.yml","file_content":"# Currently, Lima job test only for EL, though in the future it could be used to also test FreeBSD or other linux-es\nname: job-test-in-lima\n\non:\n  workflow_call:\n    inputs:\n      timeout:\n        required: true\n        type: number\n      runner:\n        required: true\n        type: string\n      target:\n        required: true\n        type: string\n      guest:\n        required: true\n        type: string\n\njobs:\n  test:\n    name: \"${{ inputs.guest }} ${{ inputs.target }}\"\n    timeout-minutes: ${{ inputs.timeout }}\n    runs-on: \"${{ inputs.runner }}\"\n    env:\n      TARGET: ${{ inputs.target }}\n    steps:\n      - name: \"Init: checkout\"\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683  # v4.2.2\n        with:\n          fetch-depth: 1\n\n      - name: \"Init: lima\"\n        uses: lima-vm/lima-actions/setup@be564a1408f84557d067b099a475652288074b2e  # v1.0.0\n        id: lima-actions-setup\n\n      - name: \"Init: Cache\"\n        uses: actions/cache@5a3ec84eff668545956fd18022155c47e93e2684  # v4.2.3\n        with:\n          path: ~/.cache/lima\n          key: lima-${{ steps.lima-actions-setup.outputs.version }}\n\n      - name: \"Init: start the guest VM\"\n        run: |\n          set -eux\n          # containerd=none is set because the built-in containerd support conflicts with Docker\n          limactl start \\\n            --name=default \\\n            --cpus=4 \\\n            --memory=12 \\\n            --containerd=none \\\n            --set '.mounts=null | .portForwards=[{\"guestSocket\":\"/var/run/docker.sock\",\"hostSocket\":\"{{.Dir}}/sock/docker.sock\"}]' \\\n            template://${{ inputs.guest }}\n\n      # FIXME: the tests should be directly executed in the VM without nesting Docker inside it\n      # https://github.com/containerd/nerdctl/issues/3858\n      - name: \"Init: install dockerd in the guest VM\"\n        run: |\n          set -eux\n          lima sudo mkdir -p /etc/systemd/system/docker.socket.d\n          cat <<-EOF | lima sudo tee /etc/systemd/system/docker.socket.d/override.conf\n          [Socket]\n          SocketUser=$(whoami)\n          EOF\n          lima sudo dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo\n          lima sudo dnf -q -y install docker-ce --nobest\n          lima sudo systemctl enable --now docker\n\n      - name: \"Init: configure the host to use dockerd in the guest VM\"\n        run: |\n          set -eux\n          sudo systemctl disable --now docker.service docker.socket\n          export DOCKER_HOST=\"unix://$(limactl ls --format '{{.Dir}}/sock/docker.sock' default)\"\n          echo \"DOCKER_HOST=${DOCKER_HOST}\" >>$GITHUB_ENV\n          docker info\n          docker version\n\n      - name: \"Init: expose GitHub Runtime variables for gha\"\n        uses: crazy-max/ghaction-github-runtime@3cb05d89e1f492524af3d41a1c98c83bc3025124  # v3.1.0\n\n      - name: \"Init: prepare integration tests\"\n        run: |\n          set -eux\n\n          sudo losetup -Dv\n          sudo losetup -lv\n\n          [ \"$TARGET\" = \"rootless\" ] && TARGET=test-integration-rootless || TARGET=test-integration\n          docker buildx create --name with-gha --use\n          docker buildx build \\\n            --output=type=docker \\\n            --cache-from type=gha,scope=test-integration-dependencies-amd64 \\\n            -t test-integration --target \"${TARGET}\" \\\n            .\n\n      - name: \"Run integration tests\"\n        # Presumably, something is broken with the way docker exposes /dev to the container, as it appears to only\n        # randomly work. Mounting /dev does workaround the issue.\n        # This might be due to the old kernel shipped with Alma (4.18), or something else between centos/docker.\n        run: |\n          set -eux\n          if [ \"$TARGET\" = \"rootless\" ]; then\n            echo \"rootless\"\n            docker run -t -v /dev:/dev --rm --privileged test-integration /test-integration-rootless.sh ./hack/test-integration.sh -test.only-flaky=false\n          else\n            echo \"rootful\"\n            docker run -t -v /dev:/dev --rm --privileged test-integration ./hack/test-integration.sh -test.only-flaky=false\n          fi\n      - name: \"Run: integration tests (flaky)\"\n        run: |\n          set -eux\n          if [ \"$TARGET\" = \"rootless\" ]; then\n            echo \"rootless\"\n            docker run -t -v /dev:/dev --rm --privileged test-integration /test-integration-rootless.sh ./hack/test-integration.sh -test.only-flaky=true\n          else\n            echo \"rootful\"\n            docker run -t -v /dev:/dev --rm --privileged test-integration ./hack/test-integration.sh -test.only-flaky=true\n          fi\n","repository_owner":"containerd","repository_name":"nerdctl","tokens_count":1262,"workflow":"# Currently, Lima job test only for EL, though in the future it could be used to also test FreeBSD or other linux-es\nname: job-test-in-lima\n\non:\n  workflow_call:\n    inputs:\n      timeout:\n        required: true\n        type: number\n      runner:\n        required: true\n        type: string\n      target:\n        required: true\n        type: string\n      guest:\n        required: true\n        type: string\n\njobs:\n  test:\n    name: ${{ inputs.guest }} ${{ inputs.target }}\n    timeout-minutes: ${{ inputs.timeout }}\n    runs-on: ${{ inputs.runner }}\n    env:\n      TARGET: ${{ inputs.target }}\n    steps:\n    - name: 'Init: checkout'\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683    # v4.2.2\n      with:\n        fetch-depth: 1\n\n    - name: 'Init: lima'\n      uses: lima-vm/lima-actions/setup@be564a1408f84557d067b099a475652288074b2e    # v1.0.0\n      id: lima-actions-setup\n\n    - name: 'Init: Cache'\n      uses: actions/cache@5a3ec84eff668545956fd18022155c47e93e2684    # v4.2.3\n      with:\n        path: ~/.cache/lima\n        key: lima-${{ steps.lima-actions-setup.outputs.version }}\n\n    - name: 'Init: start the guest VM'\n      run: |\n        set -eux\n        # containerd=none is set because the built-in containerd support conflicts with Docker\n        limactl start \\\n          --name=default \\\n          --cpus=4 \\\n          --memory=12 \\\n          --containerd=none \\\n          --set '.mounts=null | .portForwards=[{\"guestSocket\":\"/var/run/docker.sock\",\"hostSocket\":\"{{.Dir}}/sock/docker.sock\"}]' \\\n          template://${{ inputs.guest }}\n\n      # FIXME: the tests should be directly executed in the VM without nesting Docker inside it\n      # https://github.com/containerd/nerdctl/issues/3858\n    - name: 'Init: install dockerd in the guest VM'\n      run: |\n        set -eux\n        lima sudo mkdir -p /etc/systemd/system/docker.socket.d\n        cat <<-EOF | lima sudo tee /etc/systemd/system/docker.socket.d/override.conf\n        [Socket]\n        SocketUser=$(whoami)\n        EOF\n        lima sudo dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo\n        lima sudo dnf -q -y install docker-ce --nobest\n        lima sudo systemctl enable --now docker\n\n    - name: 'Init: configure the host to use dockerd in the guest VM'\n      run: |\n        set -eux\n        sudo systemctl disable --now docker.service docker.socket\n        export DOCKER_HOST=\"unix://$(limactl ls --format '{{.Dir}}/sock/docker.sock' default)\"\n        echo \"DOCKER_HOST=${DOCKER_HOST}\" >>$GITHUB_ENV\n        docker info\n        docker version\n\n    - name: 'Init: expose GitHub Runtime variables for gha'\n      uses: \n        crazy-max/ghaction-github-runtime@3cb05d89e1f492524af3d41a1c98c83bc3025124        # v3.1.0\n\n    - name: 'Init: prepare integration tests'\n      run: |\n        set -eux\n\n        sudo losetup -Dv\n        sudo losetup -lv\n\n        [ \"$TARGET\" = \"rootless\" ] && TARGET=test-integration-rootless || TARGET=test-integration\n        docker buildx create --name with-gha --use\n        docker buildx build \\\n          --output=type=docker \\\n          --cache-from type=gha,scope=test-integration-dependencies-amd64 \\\n          -t test-integration --target \"${TARGET}\" \\\n          .\n\n    - name: Run integration tests\n        # Presumably, something is broken with the way docker exposes /dev to the container, as it appears to only\n        # randomly work. Mounting /dev does workaround the issue.\n        # This might be due to the old kernel shipped with Alma (4.18), or something else between centos/docker.\n      run: |\n        set -eux\n        if [ \"$TARGET\" = \"rootless\" ]; then\n          echo \"rootless\"\n          docker run -t -v /dev:/dev --rm --privileged test-integration /test-integration-rootless.sh ./hack/test-integration.sh -test.only-flaky=false\n        else\n          echo \"rootful\"\n          docker run -t -v /dev:/dev --rm --privileged test-integration ./hack/test-integration.sh -test.only-flaky=false\n        fi\n    - name: 'Run: integration tests (flaky)'\n      run: |\n        set -eux\n        if [ \"$TARGET\" = \"rootless\" ]; then\n          echo \"rootless\"\n          docker run -t -v /dev:/dev --rm --privileged test-integration /test-integration-rootless.sh ./hack/test-integration.sh -test.only-flaky=true\n        else\n          echo \"rootful\"\n          docker run -t -v /dev:/dev --rm --privileged test-integration ./hack/test-integration.sh -test.only-flaky=true\n        fi\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `job-test-in-lima` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 4 inputs: timeout-it must be supplied and the data type is number; runner-it must be supplied and the data type is string; target-it must be supplied and the data type is string; guest-it must be supplied and the data type is string. The workflow has one job. The 1st job is named `${{ inputs.guest }} ${{ inputs.target }}` and its job id is `test`. ","prompt_level2":"Generate a GitHub Workflow named `job-test-in-lima` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 4 inputs: timeout-it must be supplied and the data type is number; runner-it must be supplied and the data type is string; target-it must be supplied and the data type is string; guest-it must be supplied and the data type is string. The workflow has one job. The 1st job is named `${{ inputs.guest }} ${{ inputs.target }}` and its job id is `test`. The job `test` has 10 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Init: lima` and its id is `lima-actions-setup`. The 3rd step is named `Init: Cache`. The 4th step is named `Init: start the guest VM`. The 5th step is named `Init: install dockerd in the guest VM`. The 6th step is named `Init: configure the host to use dockerd in the guest VM`. The 7th step is named `Init: expose GitHub Runtime variables for gha`. The 8th step is named `Init: prepare integration tests`. The 9th step is named `Run integration tests`. The 10th step is named `Run: integration tests (flaky)`. ","prompt_level3":"Generate a GitHub Workflow named `job-test-in-lima` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 4 inputs: timeout-it must be supplied and the data type is number; runner-it must be supplied and the data type is string; target-it must be supplied and the data type is string; guest-it must be supplied and the data type is string. The workflow has one job. The 1st job is named `${{ inputs.guest }} ${{ inputs.target }}` and its job id is `test`. This job will run on ${{ inputs.runner }} runner. The job sets an environment variable to use: `TARGET` is set to `${{ inputs.target }}`. The maximum number of minutes to run the job is ${{ inputs.timeout }}. The job `test` has 10 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is 11bd71901bbe5b1630ceea73d27597364c9af683. The step defines an input parameter for the action: `fetch-depth` is set to `1`. The 2nd step is named `Init: lima` and its id is `lima-actions-setup`. This step runs action `lima-vm/lima-actions/setup` whose commit is be564a1408f84557d067b099a475652288074b2e. The 3rd step is named `Init: Cache`. This step runs action `actions/cache` whose commit is 5a3ec84eff668545956fd18022155c47e93e2684. The step defines 2 input parameters for the action: `path` is set to `~/.cache/lima` and `key` is set to `lima-${{ steps.lima-actions-setup.outputs.version }}`. The 4th step is named `Init: start the guest VM`. This step runs a script: `set -eux\n# containerd=none is set because the built-in containerd support conflicts with Docker\nlimactl start \\\n  --name=default \\\n  --cpus=4 \\\n  --memory=12 \\\n  --containerd=none \\\n  --set '.mounts=null | .portForwards=[{\"guestSocket\":\"/var/run/docker.sock\",\"hostSocket\":\"{{.Dir}}/sock/docker.sock\"}]' \\\n  template://${{ inputs.guest }}\n`. The 5th step is named `Init: install dockerd in the guest VM`. This step runs a script: `set -eux\nlima sudo mkdir -p /etc/systemd/system/docker.socket.d\ncat <<-EOF | lima sudo tee /etc/systemd/system/docker.socket.d/override.conf\n[Socket]\nSocketUser=$(whoami)\nEOF\nlima sudo dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo\nlima sudo dnf -q -y install docker-ce --nobest\nlima sudo systemctl enable --now docker\n`. The 6th step is named `Init: configure the host to use dockerd in the guest VM`. This step runs a script: `set -eux\nsudo systemctl disable --now docker.service docker.socket\nexport DOCKER_HOST=\"unix://$(limactl ls --format '{{.Dir}}/sock/docker.sock' default)\"\necho \"DOCKER_HOST=${DOCKER_HOST}\" >>$GITHUB_ENV\ndocker info\ndocker version\n`. The 7th step is named `Init: expose GitHub Runtime variables for gha`. This step runs action `crazy-max/ghaction-github-runtime` whose commit is 3cb05d89e1f492524af3d41a1c98c83bc3025124. The 8th step is named `Init: prepare integration tests`. This step runs a script: `set -eux\n\nsudo losetup -Dv\nsudo losetup -lv\n\n[ \"$TARGET\" = \"rootless\" ] && TARGET=test-integration-rootless || TARGET=test-integration\ndocker buildx create --name with-gha --use\ndocker buildx build \\\n  --output=type=docker \\\n  --cache-from type=gha,scope=test-integration-dependencies-amd64 \\\n  -t test-integration --target \"${TARGET}\" \\\n  .\n`. The 9th step is named `Run integration tests`. This step runs a script: `set -eux\nif [ \"$TARGET\" = \"rootless\" ]; then\n  echo \"rootless\"\n  docker run -t -v /dev:/dev --rm --privileged test-integration /test-integration-rootless.sh ./hack/test-integration.sh -test.only-flaky=false\nelse\n  echo \"rootful\"\n  docker run -t -v /dev:/dev --rm --privileged test-integration ./hack/test-integration.sh -test.only-flaky=false\nfi\n`. The 10th step is named `Run: integration tests (flaky)`. This step runs a script: `set -eux\nif [ \"$TARGET\" = \"rootless\" ]; then\n  echo \"rootless\"\n  docker run -t -v /dev:/dev --rm --privileged test-integration /test-integration-rootless.sh ./hack/test-integration.sh -test.only-flaky=true\nelse\n  echo \"rootful\"\n  docker run -t -v /dev:/dev --rm --privileged test-integration ./hack/test-integration.sh -test.only-flaky=true\nfi\n`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":4,"actions":["actions/cache","actions/checkout","crazy-max/ghaction-github-runtime","lima-vm/lima-actions/setup"],"actions_details":[{"version":"11bd71901bbe5b1630ceea73d27597364c9af683","name":"actions/checkout"},{"version":"be564a1408f84557d067b099a475652288074b2e","name":"lima-vm/lima-actions/setup"},{"version":"5a3ec84eff668545956fd18022155c47e93e2684","name":"actions/cache"},{"version":"3cb05d89e1f492524af3d41a1c98c83bc3025124","name":"crazy-max/ghaction-github-runtime"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":10,"cyclomatic_complexity":1}
{"id":21173,"repository_id":89260929,"mainLanguage":"C++","file_name":"flatpak.yml","file_content":"name: Flatpak\n\non:\n  push:\n    # We don't do anything with these artifacts on releases. They go to Flathub\n    tags-ignore:\n      - \"*\"\n    paths:\n      # File types\n      - \"**.cpp\"\n      - \"**.h\"\n      - \"**.java\"\n\n      # Build files\n      - \"flatpak/\"\n\n      # Directories\n      - \"buildconfig/\"\n      - \"cmake/\"\n      - \"launcher/\"\n      - \"libraries/\"\n      - \"program_info/\"\n      - \"tests/\"\n\n      # Files\n      - \"CMakeLists.txt\"\n      - \"COPYING.md\"\n\n      # Workflows\n      - \".github/workflows/flatpak.yml\"\n  pull_request:\n    paths:\n      # File types\n      - \"**.cpp\"\n      - \"**.h\"\n\n      # Build files\n      - \"flatpak/\"\n\n      # Directories\n      - \"buildconfig/\"\n      - \"cmake/\"\n      - \"launcher/\"\n      - \"libraries/\"\n      - \"program_info/\"\n      - \"tests/\"\n\n      # Files\n      - \"CMakeLists.txt\"\n      - \"COPYING.md\"\n\n      # Workflows\n      - \".github/workflows/flatpak.yml\"\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\njobs:\n  build:\n    name: Build (${{ matrix.arch }})\n\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - os: ubuntu-22.04\n            arch: x86_64\n\n          - os: ubuntu-22.04-arm\n            arch: aarch64\n\n    runs-on: ${{ matrix.os }}\n\n    container:\n      image: ghcr.io/flathub-infra/flatpak-github-actions:kde-6.8\n      options: --privileged\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        with:\n          submodules: true\n\n      - name: Set short version\n        shell: bash\n        run: |\n          echo \"VERSION=${GITHUB_SHA::7}\" >> \"$GITHUB_ENV\"\n\n      - name: Build Flatpak\n        uses: flatpak/flatpak-github-actions/flatpak-builder@v6\n        with:\n          bundle: PrismLauncher-${{ runner.os }}-${{ env.VERSION }}-Flatpak.flatpak\n          manifest-path: flatpak/org.prismlauncher.PrismLauncher.yml\n          arch: ${{ matrix.arch }}\n","repository_owner":"prismlauncher","repository_name":"prismlauncher","tokens_count":521,"workflow":"name: Flatpak\n\non:\n  push:\n    # We don't do anything with these artifacts on releases. They go to Flathub\n    tags-ignore:\n    - '*'\n    paths:\n      # File types\n    - '**.cpp'\n    - '**.h'\n    - '**.java'\n\n      # Build files\n    - flatpak/\n\n      # Directories\n    - buildconfig/\n    - cmake/\n    - launcher/\n    - libraries/\n    - program_info/\n    - tests/\n\n      # Files\n    - CMakeLists.txt\n    - COPYING.md\n\n      # Workflows\n    - .github/workflows/flatpak.yml\n  pull_request:\n    paths:\n      # File types\n    - '**.cpp'\n    - '**.h'\n\n      # Build files\n    - flatpak/\n\n      # Directories\n    - buildconfig/\n    - cmake/\n    - launcher/\n    - libraries/\n    - program_info/\n    - tests/\n\n      # Files\n    - CMakeLists.txt\n    - COPYING.md\n\n      # Workflows\n    - .github/workflows/flatpak.yml\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\njobs:\n  build:\n    name: Build (${{ matrix.arch }})\n\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n        - os: ubuntu-22.04\n          arch: x86_64\n\n        - os: ubuntu-22.04-arm\n          arch: aarch64\n\n    runs-on: ${{ matrix.os }}\n\n    container:\n      image: ghcr.io/flathub-infra/flatpak-github-actions:kde-6.8\n      options: --privileged\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      with:\n        submodules: true\n\n    - name: Set short version\n      shell: bash\n      run: |\n        echo \"VERSION=${GITHUB_SHA::7}\" >> \"$GITHUB_ENV\"\n\n    - name: Build Flatpak\n      uses: flatpak/flatpak-github-actions/flatpak-builder@v6\n      with:\n        bundle: PrismLauncher-${{ runner.os }}-${{ env.VERSION \n          }}-Flatpak.flatpak\n        manifest-path: flatpak/org.prismlauncher.PrismLauncher.yml\n        arch: ${{ matrix.arch }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Flatpak` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event unless the push event is to: a tag whose name matches *. Only if at least one path of push event matches a pattern in the paths filter(**.cpp, **.h, **.java, flatpak/, buildconfig/, cmake/, launcher/, libraries/, program_info/, tests/, CMakeLists.txt, COPYING.md or .github/workflows/flatpak.yml), the workflow runs. 2) Only if at least one path of pull_request event matches a pattern in the paths filter(**.cpp, **.h, flatpak/, buildconfig/, cmake/, launcher/, libraries/, program_info/, tests/, CMakeLists.txt, COPYING.md or .github/workflows/flatpak.yml), the workflow runs. 3) someone manually triggers the workflow. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Build (${{ matrix.arch }})` and its job id is `build`. ","prompt_level2":"Generate a GitHub Workflow named `Flatpak` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event unless the push event is to: a tag whose name matches *. Only if at least one path of push event matches a pattern in the paths filter(**.cpp, **.h, **.java, flatpak/, buildconfig/, cmake/, launcher/, libraries/, program_info/, tests/, CMakeLists.txt, COPYING.md or .github/workflows/flatpak.yml), the workflow runs. 2) Only if at least one path of pull_request event matches a pattern in the paths filter(**.cpp, **.h, flatpak/, buildconfig/, cmake/, launcher/, libraries/, program_info/, tests/, CMakeLists.txt, COPYING.md or .github/workflows/flatpak.yml), the workflow runs. 3) someone manually triggers the workflow. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Build (${{ matrix.arch }})` and its job id is `build`. The job `build` has 3 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set short version`. The 3rd step is named `Build Flatpak`. ","prompt_level3":"Generate a GitHub Workflow named `Flatpak` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event unless the push event is to: a tag whose name matches *. Only if at least one path of push event matches a pattern in the paths filter(**.cpp, **.h, **.java, flatpak/, buildconfig/, cmake/, launcher/, libraries/, program_info/, tests/, CMakeLists.txt, COPYING.md or .github/workflows/flatpak.yml), the workflow runs. 2) Only if at least one path of pull_request event matches a pattern in the paths filter(**.cpp, **.h, flatpak/, buildconfig/, cmake/, launcher/, libraries/, program_info/, tests/, CMakeLists.txt, COPYING.md or .github/workflows/flatpak.yml), the workflow runs. 3) someone manually triggers the workflow. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Build (${{ matrix.arch }})` and its job id is `build`. This job will run on ${{ matrix.os }} runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. For each object in the [{'os': 'ubuntu-22.04', 'arch': 'x86_64'}, {'os': 'ubuntu-22.04-arm', 'arch': 'aarch64'}] list, the key:value pairs in the object will be added to each of the matrix combinations if none of the key:value pairs overwrite any of the original matrix values. If the object cannot be added to any of the matrix combinations, a new matrix combination will be created instead. The job creates a Docker container that uses `ghcr.io/flathub-infra/flatpak-github-actions:kde-6.8` image. It configures additional container resource options: --privileged. The job `build` has 3 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `submodules` is set to `True`. The 2nd step is named `Set short version`. This step uses bash to run a script: `echo \"VERSION=${GITHUB_SHA::7}\" >> \"$GITHUB_ENV\"\n`. The 3rd step is named `Build Flatpak`. This step runs action `flatpak/flatpak-github-actions/flatpak-builder` tagged as v6. The step defines 3 input parameters for the action: `bundle` is set to `PrismLauncher-${{ runner.os }}-${{ env.VERSION }}-Flatpak.flatpak`, `manifest-path` is set to `flatpak/org.prismlauncher.PrismLauncher.yml` and `arch` is set to `${{ matrix.arch }}`. ","nb_triggers":3,"triggers":["pull_request","push","workflow_dispatch"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","flatpak/flatpak-github-actions/flatpak-builder"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v6","name":"flatpak/flatpak-github-actions/flatpak-builder"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":3,"cyclomatic_complexity":1}
{"id":14577,"repository_id":3976726,"mainLanguage":"C++","file_name":"manual-release.yml","file_content":"# This one was created to make it work whil\n\nname: manual-release\n\non:\n  workflow_dispatch:\n    inputs:\n      release:\n        description: \"release\"\n        required: true\n        default: \"latest\"\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  ccache: ccache\n  RELEASE: ${{ github.event.inputs.release }}\n\njobs:\n  manual-nightly:\n    runs-on: ubuntu-24.04\n    if: github.repository == 'openframeworks/openFrameworks' && github.ref == 'refs/heads/master'\n    strategy:\n      matrix:\n        cfg:\n          - { target: linux64, libs: 64gcc6 }\n    steps:\n      - name: Install libunwind\n        run: sudo apt-get install libunwind-dev\n      - name: Cache Packages\n        uses: awalsh128/cache-apt-pkgs-action@latest\n        with:\n          packages: aptitude aptitude-common libboost-iostreams1.83.0 libcwidget4 libsigc++-2.0-0v5 libxapian30 fonts-wine{a} libasound2-plugins{a} libcapi20-3t64{a} libosmesa6{a} libpcsclite1{a} libspeexdsp1{a} libwine{a} libxkbregistry0{a} libz-mingw-w64{a} wine{a} wine64 make curl libjack-jackd2-0 libjack-jackd2-dev freeglut3-dev libasound2-dev libxmu-dev libxxf86vm-dev g++ libgl1-mesa-dev libglu1-mesa-dev libraw1394-dev libudev-dev libdrm-dev libglew-dev libopenal-dev libsndfile1-dev libfreeimage-dev libcairo2-dev libfreetype6-dev libssl-dev libpulse-dev libusb-1.0-0-dev libgtk2.0-dev libopencv-dev libassimp-dev librtaudio-dev gdb libglfw3-dev liburiparser-dev libcurl4-openssl-dev libpugixml-dev libgconf-2-4 libgtk2.0-0 libpoco-dev libxcursor-dev libxi-dev libxinerama-dev libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev gstreamer1.0-libav gstreamer1.0-pulseaudio gstreamer1.0-x gstreamer1.0-plugins-bad gstreamer1.0-alsa gstreamer1.0-plugins-base gstreamer1.0-plugins-good\n          # libunwind-dev wget2\n          version: 1.0\n\n      - uses: actions/checkout@v4\n      - name: ccache\n        uses: hendrikmuhs/ccache-action@v1.2.14\n        with:\n          key: ${{ matrix.cfg.target }}\n      - name: update submodules\n        run: ./scripts/dev/init_submodules.sh\n      - name: Install dependencies\n        run: ./scripts/ci/${{matrix.cfg.target}}/install.sh;\n      - name: Download libs\n        run: ./scripts/linux/download_libs.sh -a ${{matrix.cfg.libs}};\n      - name: Create Package\n        run: scripts/ci/package_builds.sh ${{ github.event.inputs.release }};\n        id: createpackage\n      - name: List output directory\n        run: ls -lah out/\n      # - name: Test Artefact zip\n      #   run: |\n      #     tar -cjf out/manual-mega_artefact.tar.bz2 -C out $(echo ${{ steps.createpackage.outputs.FILES_OUT }} | tr ' ' '\\n' | sed 's|^out/||')\n      # - name: Upload binaries as Artefact\n      #   uses: actions/upload-artifact@v4\n      #   with:\n      #     name: openFrameworks-all-artefact-${{ env.TARGET }}-${{ matrix.bundle }}\n      #     path: out/manual-mega_artefact.tar.bz2\n      #     retention-days: 1\n      - name: Update Release\n        uses: IsaacShelton/update-existing-release@v1.3.4\n        if: github.repository == 'openframeworks/openFrameworks' && github.ref == 'refs/heads/master'\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          tag: ${{ github.event.inputs.release }}\n          release: ${{ github.event.inputs.release }}\n          prerelease: false\n          replace: true\n          files: ${{ steps.createpackage.outputs.FILES_OUT }}\n","repository_owner":"openframeworks","repository_name":"openframeworks","tokens_count":1006,"workflow":"# This one was created to make it work whil\n\nname: manual-release\n\non:\n  workflow_dispatch:\n    inputs:\n      release:\n        description: release\n        required: true\n        default: latest\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  ccache: ccache\n  RELEASE: ${{ github.event.inputs.release }}\n\njobs:\n  manual-nightly:\n    runs-on: ubuntu-24.04\n    if: github.repository == 'openframeworks/openFrameworks' && github.ref == \n      'refs/heads/master'\n    strategy:\n      matrix:\n        cfg:\n        - {target: linux64, libs: 64gcc6}\n    steps:\n    - name: Install libunwind\n      run: sudo apt-get install libunwind-dev\n    - name: Cache Packages\n      uses: awalsh128/cache-apt-pkgs-action@latest\n      with:\n        packages: aptitude aptitude-common libboost-iostreams1.83.0 libcwidget4 \n          libsigc++-2.0-0v5 libxapian30 fonts-wine{a} libasound2-plugins{a} \n          libcapi20-3t64{a} libosmesa6{a} libpcsclite1{a} libspeexdsp1{a} \n          libwine{a} libxkbregistry0{a} libz-mingw-w64{a} wine{a} wine64 make \n          curl libjack-jackd2-0 libjack-jackd2-dev freeglut3-dev libasound2-dev \n          libxmu-dev libxxf86vm-dev g++ libgl1-mesa-dev libglu1-mesa-dev \n          libraw1394-dev libudev-dev libdrm-dev libglew-dev libopenal-dev \n          libsndfile1-dev libfreeimage-dev libcairo2-dev libfreetype6-dev \n          libssl-dev libpulse-dev libusb-1.0-0-dev libgtk2.0-dev libopencv-dev \n          libassimp-dev librtaudio-dev gdb libglfw3-dev liburiparser-dev \n          libcurl4-openssl-dev libpugixml-dev libgconf-2-4 libgtk2.0-0 \n          libpoco-dev libxcursor-dev libxi-dev libxinerama-dev \n          libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev \n          gstreamer1.0-libav gstreamer1.0-pulseaudio gstreamer1.0-x \n          gstreamer1.0-plugins-bad gstreamer1.0-alsa gstreamer1.0-plugins-base \n          gstreamer1.0-plugins-good\n          # libunwind-dev wget2\n        version: 1.0\n\n    - name: Checkout repository\n      uses: actions/checkout@v4\n    - name: ccache\n      uses: hendrikmuhs/ccache-action@v1.2.14\n      with:\n        key: ${{ matrix.cfg.target }}\n    - name: update submodules\n      run: ./scripts/dev/init_submodules.sh\n    - name: Install dependencies\n      run: ./scripts/ci/${{matrix.cfg.target}}/install.sh;\n    - name: Download libs\n      run: ./scripts/linux/download_libs.sh -a ${{matrix.cfg.libs}};\n    - name: Create Package\n      run: scripts/ci/package_builds.sh ${{ github.event.inputs.release }};\n      id: createpackage\n    - name: List output directory\n      run: ls -lah out/\n      # - name: Test Artefact zip\n      #   run: |\n      #     tar -cjf out/manual-mega_artefact.tar.bz2 -C out $(echo ${{ steps.createpackage.outputs.FILES_OUT }} | tr ' ' '\\n' | sed 's|^out/||')\n      # - name: Upload binaries as Artefact\n      #   uses: actions/upload-artifact@v4\n      #   with:\n      #     name: openFrameworks-all-artefact-${{ env.TARGET }}-${{ matrix.bundle }}\n      #     path: out/manual-mega_artefact.tar.bz2\n      #     retention-days: 1\n    - name: Update Release\n      uses: IsaacShelton/update-existing-release@v1.3.4\n      if: github.repository == 'openframeworks/openFrameworks' && github.ref == \n        'refs/heads/master'\n      with:\n        token: ${{ secrets.GITHUB_TOKEN }}\n        tag: ${{ github.event.inputs.release }}\n        release: ${{ github.event.inputs.release }}\n        prerelease: false\n        replace: true\n        files: ${{ steps.createpackage.outputs.FILES_OUT }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `manual-release` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives an input: release-this input represents release, it must be supplied and its default value is latest. The workflow sets 2 environment variables to use: `ccache` is set to `ccache` and `RELEASE` is set to `${{ github.event.inputs.release }}`. Only a single workflow using the ${{ github.workflow }}-${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `manual-nightly`. ","prompt_level2":"Generate a GitHub Workflow named `manual-release` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives an input: release-this input represents release, it must be supplied and its default value is latest. The workflow sets 2 environment variables to use: `ccache` is set to `ccache` and `RELEASE` is set to `${{ github.event.inputs.release }}`. Only a single workflow using the ${{ github.workflow }}-${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `manual-nightly`. The job `manual-nightly` has 10 steps. The 1st step is named `Install libunwind`. The 2nd step is named `Cache Packages`. The 3rd step is named `Checkout repository`. The 4th step is named `ccache`. The 5th step is named `update submodules`. The 6th step is named `Install dependencies`. The 7th step is named `Download libs`. The 8th step is named `Create Package` and its id is `createpackage`. The 9th step is named `List output directory`. The 10th step is named `Update Release`. ","prompt_level3":"Generate a GitHub Workflow named `manual-release` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives an input: release-this input represents release, it must be supplied and its default value is latest. The workflow sets 2 environment variables to use: `ccache` is set to `ccache` and `RELEASE` is set to `${{ github.event.inputs.release }}`. Only a single workflow using the ${{ github.workflow }}-${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `manual-nightly`. This job will run only if the condition(github.repository == 'openframeworks/openFrameworks' && github.ref == 'refs/heads/master') is met. This job will run on ubuntu-24.04 runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `cfg` has one value: {'target': 'linux64', 'libs': '64gcc6'}. The job `manual-nightly` has 10 steps. The 1st step is named `Install libunwind`. This step runs a script: `sudo apt-get install libunwind-dev`. The 2nd step is named `Cache Packages`. This step runs action `awalsh128/cache-apt-pkgs-action` tagged as latest. The step defines 2 input parameters for the action: `packages` is set to `aptitude aptitude-common libboost-iostreams1.83.0 libcwidget4 libsigc++-2.0-0v5 libxapian30 fonts-wine{a} libasound2-plugins{a} libcapi20-3t64{a} libosmesa6{a} libpcsclite1{a} libspeexdsp1{a} libwine{a} libxkbregistry0{a} libz-mingw-w64{a} wine{a} wine64 make curl libjack-jackd2-0 libjack-jackd2-dev freeglut3-dev libasound2-dev libxmu-dev libxxf86vm-dev g++ libgl1-mesa-dev libglu1-mesa-dev libraw1394-dev libudev-dev libdrm-dev libglew-dev libopenal-dev libsndfile1-dev libfreeimage-dev libcairo2-dev libfreetype6-dev libssl-dev libpulse-dev libusb-1.0-0-dev libgtk2.0-dev libopencv-dev libassimp-dev librtaudio-dev gdb libglfw3-dev liburiparser-dev libcurl4-openssl-dev libpugixml-dev libgconf-2-4 libgtk2.0-0 libpoco-dev libxcursor-dev libxi-dev libxinerama-dev libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev gstreamer1.0-libav gstreamer1.0-pulseaudio gstreamer1.0-x gstreamer1.0-plugins-bad gstreamer1.0-alsa gstreamer1.0-plugins-base gstreamer1.0-plugins-good` and `version` is set to `1.0`. The 3rd step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 4th step is named `ccache`. This step runs action `hendrikmuhs/ccache-action` tagged as v1.2.14. The step defines an input parameter for the action: `key` is set to `${{ matrix.cfg.target }}`. The 5th step is named `update submodules`. This step runs a script: `./scripts/dev/init_submodules.sh`. The 6th step is named `Install dependencies`. This step runs a script: `./scripts/ci/${{matrix.cfg.target}}/install.sh;`. The 7th step is named `Download libs`. This step runs a script: `./scripts/linux/download_libs.sh -a ${{matrix.cfg.libs}};`. The 8th step is named `Create Package` and its id is `createpackage`. This step runs a script: `scripts/ci/package_builds.sh ${{ github.event.inputs.release }};`. The 9th step is named `List output directory`. This step runs a script: `ls -lah out/`. The 10th step is named `Update Release`. This step will run only if the condition(github.repository == 'openframeworks/openFrameworks' && github.ref == 'refs/heads/master') is met. This step runs action `IsaacShelton/update-existing-release` tagged as v1.3.4. The step defines 6 input parameters for the action: `token` is set to `${{ secrets.GITHUB_TOKEN }}`, `tag` is set to `${{ github.event.inputs.release }}`, `release` is set to `${{ github.event.inputs.release }}`, `prerelease` is set to `False`, `replace` is set to `True` and `files` is set to `${{ steps.createpackage.outputs.FILES_OUT }}`. ","nb_triggers":1,"triggers":["workflow_dispatch"],"nb_jobs":1,"nb_actions":4,"actions":["IsaacShelton/update-existing-release","actions/checkout","awalsh128/cache-apt-pkgs-action","hendrikmuhs/ccache-action"],"actions_details":[{"version":"latest","name":"awalsh128/cache-apt-pkgs-action"},{"version":"v4","name":"actions/checkout"},{"version":"v1.2.14","name":"hendrikmuhs/ccache-action"},{"version":"v1.3.4","name":"IsaacShelton/update-existing-release"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":10,"cyclomatic_complexity":1}
{"id":55941,"repository_id":35707461,"mainLanguage":"C++","file_name":"ci.yml","file_content":"name: Integration Tests\non:\n  workflow_dispatch:\n  pull_request:\n    branches-ignore: ['llvm-**']\n  merge_group:\n    branches: [main, 'dev-**']\n    types: [checks_requested]\n  push:\n    branches: [main]\nconcurrency:\n  group: ${{ github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\npermissions: read-all\nenv:\n  TRITON_BUILD_WITH_CCACHE: \"true\"\n  TRITON_BUILD_WITH_CLANG_LLD: \"TRUE\"\n  TRITON_USE_ASSERT_ENABLED_LLVM: \"TRUE\"\n  TRITON_DISABLE_LINE_INFO: 1\n  PROTON_SKIP_PC_SAMPLING_TEST: 1\n  PYTHON: \"python3\"\n  CCACHE_COMPRESS: \"true\"\n\njobs:\n\n  runner-preparation:\n    uses: ./.github/workflows/runner-preparation.yml\n\n  pre-commit:\n    uses: ./.github/workflows/pre-commit.yml\n\n  integration-tests-nvidia:\n    needs: runner-preparation\n    if: needs.runner-preparation.outputs.matrix-NVIDIA != ''\n    uses: ./.github/workflows/integration-tests-nvidia.yml\n    with:\n      matrix: ${{ needs.runner-preparation.outputs.matrix-NVIDIA }}\n\n  integration-tests-amd:\n    needs: runner-preparation\n    if: needs.runner-preparation.outputs.matrix-AMD != ''\n    uses: ./.github/workflows/integration-tests-amd.yml\n    with:\n      matrix: ${{ needs.runner-preparation.outputs.matrix-AMD }}\n\n  build-macos:\n    needs: runner-preparation\n    if: needs.runner-preparation.outputs.matrix-MACOS != ''\n    uses: ./.github/workflows/build-macos.yml\n    with:\n      matrix: ${{ needs.runner-preparation.outputs.matrix-MACOS }}\n","repository_owner":"openai","repository_name":"triton","tokens_count":378,"workflow":"name: Integration Tests\non:\n  workflow_dispatch:\n  pull_request:\n    branches-ignore: [llvm-**]\n  merge_group:\n    branches: [main, dev-**]\n    types: [checks_requested]\n  push:\n    branches: [main]\nconcurrency:\n  group: ${{ github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\npermissions: read-all\nenv:\n  TRITON_BUILD_WITH_CCACHE: 'true'\n  TRITON_BUILD_WITH_CLANG_LLD: 'TRUE'\n  TRITON_USE_ASSERT_ENABLED_LLVM: 'TRUE'\n  TRITON_DISABLE_LINE_INFO: 1\n  PROTON_SKIP_PC_SAMPLING_TEST: 1\n  PYTHON: python3\n  CCACHE_COMPRESS: 'true'\n\njobs:\n\n  runner-preparation:\n    uses: ./.github/workflows/runner-preparation.yml\n\n  pre-commit:\n    uses: ./.github/workflows/pre-commit.yml\n\n  integration-tests-nvidia:\n    needs: runner-preparation\n    if: needs.runner-preparation.outputs.matrix-NVIDIA != ''\n    uses: ./.github/workflows/integration-tests-nvidia.yml\n    with:\n      matrix: ${{ needs.runner-preparation.outputs.matrix-NVIDIA }}\n\n  integration-tests-amd:\n    needs: runner-preparation\n    if: needs.runner-preparation.outputs.matrix-AMD != ''\n    uses: ./.github/workflows/integration-tests-amd.yml\n    with:\n      matrix: ${{ needs.runner-preparation.outputs.matrix-AMD }}\n\n  build-macos:\n    needs: runner-preparation\n    if: needs.runner-preparation.outputs.matrix-MACOS != ''\n    uses: ./.github/workflows/build-macos.yml\n    with:\n      matrix: ${{ needs.runner-preparation.outputs.matrix-MACOS }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Integration Tests` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) The workflow would run whenever there is a pull_request event unless the pull request is targeting: a branch whose name matches llvm-**. 3) status checks are requested for a merge group. 4) The workflow would run whenever there is a push event to: a branch named main. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow sets 7 environment variables to use: `TRITON_BUILD_WITH_CCACHE` is set to `true`, `TRITON_BUILD_WITH_CLANG_LLD` is set to `TRUE`, `TRITON_USE_ASSERT_ENABLED_LLVM` is set to `TRUE`, `TRITON_DISABLE_LINE_INFO` is set to `1`, `PROTON_SKIP_PC_SAMPLING_TEST` is set to `1`, `PYTHON` is set to `python3` and `CCACHE_COMPRESS` is set to `true`. Only a single workflow using the ${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has 5 jobs. The job id of the 1st job is `runner-preparation`. The job id of the 2nd job is `pre-commit`. The job id of the 3rd job is `integration-tests-nvidia`. The job id of the 4th job is `integration-tests-amd`. The job id of the 5th job is `build-macos`. ","prompt_level2":"Generate a GitHub Workflow named `Integration Tests` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) The workflow would run whenever there is a pull_request event unless the pull request is targeting: a branch whose name matches llvm-**. 3) status checks are requested for a merge group. 4) The workflow would run whenever there is a push event to: a branch named main. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow sets 7 environment variables to use: `TRITON_BUILD_WITH_CCACHE` is set to `true`, `TRITON_BUILD_WITH_CLANG_LLD` is set to `TRUE`, `TRITON_USE_ASSERT_ENABLED_LLVM` is set to `TRUE`, `TRITON_DISABLE_LINE_INFO` is set to `1`, `PROTON_SKIP_PC_SAMPLING_TEST` is set to `1`, `PYTHON` is set to `python3` and `CCACHE_COMPRESS` is set to `true`. Only a single workflow using the ${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has 5 jobs. The job id of the 1st job is `runner-preparation`. The job id of the 2nd job is `pre-commit`. The job id of the 3rd job is `integration-tests-nvidia`. The job id of the 4th job is `integration-tests-amd`. The job id of the 5th job is `build-macos`. ","prompt_level3":"Generate a GitHub Workflow named `Integration Tests` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) The workflow would run whenever there is a pull_request event unless the pull request is targeting: a branch whose name matches llvm-**. 3) status checks are requested for a merge group. 4) The workflow would run whenever there is a push event to: a branch named main. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow sets 7 environment variables to use: `TRITON_BUILD_WITH_CCACHE` is set to `true`, `TRITON_BUILD_WITH_CLANG_LLD` is set to `TRUE`, `TRITON_USE_ASSERT_ENABLED_LLVM` is set to `TRUE`, `TRITON_DISABLE_LINE_INFO` is set to `1`, `PROTON_SKIP_PC_SAMPLING_TEST` is set to `1`, `PYTHON` is set to `python3` and `CCACHE_COMPRESS` is set to `true`. Only a single workflow using the ${{ github.ref }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has 5 jobs. The job id of the 1st job is `runner-preparation`. This job will call a reusable workflow located at `./.github/workflows/runner-preparation.yml`. The job id of the 2nd job is `pre-commit`. This job will call a reusable workflow located at `./.github/workflows/pre-commit.yml`. The job id of the 3rd job is `integration-tests-nvidia`. Before this job runs, `runner-preparation` must complete successfully. This job will run only if the condition(needs.runner-preparation.outputs.matrix-NVIDIA != '') is met. This job will call a reusable workflow located at `./.github/workflows/integration-tests-nvidia.yml`. The job will pass an input to the called workflow: the input `matrix` is `${{ needs.runner-preparation.outputs.matrix-NVIDIA }}`. The job id of the 4th job is `integration-tests-amd`. Before this job runs, `runner-preparation` must complete successfully. This job will run only if the condition(needs.runner-preparation.outputs.matrix-AMD != '') is met. This job will call a reusable workflow located at `./.github/workflows/integration-tests-amd.yml`. The job will pass an input to the called workflow: the input `matrix` is `${{ needs.runner-preparation.outputs.matrix-AMD }}`. The job id of the 5th job is `build-macos`. Before this job runs, `runner-preparation` must complete successfully. This job will run only if the condition(needs.runner-preparation.outputs.matrix-MACOS != '') is met. This job will call a reusable workflow located at `./.github/workflows/build-macos.yml`. The job will pass an input to the called workflow: the input `matrix` is `${{ needs.runner-preparation.outputs.matrix-MACOS }}`. ","nb_triggers":4,"triggers":["merge_group","pull_request","push","workflow_dispatch"],"nb_jobs":5,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":5,"reusable_workflows":["./.github/workflows/build-macos.yml","./.github/workflows/integration-tests-amd.yml","./.github/workflows/integration-tests-nvidia.yml","./.github/workflows/pre-commit.yml","./.github/workflows/runner-preparation.yml"],"nb_steps":0,"cyclomatic_complexity":4}
{"id":6944,"repository_id":71303086,"mainLanguage":"Python","file_name":"build-docs.yml","file_content":"# Copyright (c) 2024-2025, NVIDIA CORPORATION & AFFILIATES. ALL RIGHTS RESERVED.\n#\n# SPDX-License-Identifier: Apache-2.0\n\nname: \"CI: Build and update docs\"\n\non:\n  workflow_call:\n    inputs:\n      build-ctk-ver:\n        type: string\n        required: true\n      component:\n        description: \"Component(s) to build docs for\"\n        required: false\n        default: \"all\"\n        type: string\n        # below are the acceptable options:\n        #   - cuda-core\n        #   - cuda-bindings\n        #   - cuda-python\n        #   - all\n      git-tag:\n        description: \"Target git tag to build docs for\"\n        required: false\n        default: \"\"\n        type: string\n      run-id:\n        description: \"The GHA run ID that generated validated artifacts\"\n        required: false\n        default: ${{ github.run_id }}\n        type: string\n      is-release:\n        description: \"Are we building release docs?\"\n        required: false\n        default: false\n        type: boolean\n\njobs:\n  build:\n    name: Build docs\n    # The build stage could fail but we want the CI to keep moving.\n    if: ${{ github.repository_owner == 'nvidia' && !cancelled() }}\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        shell: bash -el {0}\n    steps:\n      - name: Checkout ${{ github.event.repository.name }}\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n          ref: ${{ inputs.git-tag }}\n\n      # TODO: cache conda env to speed up the workflow once conda-incubator/setup-miniconda#267\n      # is resolved\n\n      - name: Set up miniforge\n        uses: conda-incubator/setup-miniconda@v3\n        with:\n          activate-environment: cuda-python-docs\n          environment-file: ./cuda_python/docs/environment-docs.yml\n          miniforge-version: latest\n          conda-remove-defaults: \"true\"\n          python-version: 3.12\n\n      - name: Check conda env\n        run: |\n          conda info\n          conda list\n          conda config --show-sources\n          conda config --show\n\n      # WAR: Building the doc currently requires CTK installed (NVIDIA/cuda-python#326,327)\n      - name: Set up mini CTK\n        uses: ./.github/actions/fetch_ctk\n        with:\n          host-platform: linux-64\n          cuda-version: ${{ inputs.build-ctk-ver }}\n\n      - name: Set environment variables\n        run: |\n          PYTHON_VERSION_FORMATTED=\"312\"  # see above\n          REPO_DIR=$(pwd)\n\n          if [[ ${{ inputs.is-release }} == \"true\" ]]; then\n            FILE_HASH=\"*\"\n            COMMIT_HASH=\"${{ inputs.git-tag }}\"\n          else\n            FILE_HASH=\"${{ github.sha }}\"\n            COMMIT_HASH=\"${{ github.sha }}\"\n          fi\n\n          # make outputs from the previous job as env vars\n          CUDA_CORE_ARTIFACT_BASENAME=\"cuda-core-python${PYTHON_VERSION_FORMATTED}-linux-64\"\n          echo \"COMMIT_HASH=${COMMIT_HASH}\" >> $GITHUB_ENV\n          echo \"CUDA_CORE_ARTIFACT_BASENAME=${CUDA_CORE_ARTIFACT_BASENAME}\" >> $GITHUB_ENV\n          echo \"CUDA_CORE_ARTIFACT_NAME=${CUDA_CORE_ARTIFACT_BASENAME}-${FILE_HASH}\" >> $GITHUB_ENV\n          echo \"CUDA_CORE_ARTIFACTS_DIR=$(realpath \"$REPO_DIR/cuda_core/dist\")\" >> $GITHUB_ENV\n          CUDA_BINDINGS_ARTIFACT_BASENAME=\"cuda-bindings-python${PYTHON_VERSION_FORMATTED}-cuda${{ inputs.build-ctk-ver }}-linux-64\"\n          echo \"CUDA_BINDINGS_ARTIFACT_BASENAME=${CUDA_BINDINGS_ARTIFACT_BASENAME}\" >> $GITHUB_ENV\n          echo \"CUDA_BINDINGS_ARTIFACT_NAME=${CUDA_BINDINGS_ARTIFACT_BASENAME}-${FILE_HASH}\" >> $GITHUB_ENV\n          echo \"CUDA_BINDINGS_ARTIFACTS_DIR=$(realpath \"$REPO_DIR/cuda_bindings/dist\")\" >> $GITHUB_ENV\n\n      - name: Download cuda-python build artifacts\n        uses: actions/download-artifact@v4\n        with:\n          name: cuda-python-wheel\n          path: .\n          run-id: ${{ inputs.run-id }}\n          github-token: ${{ github.token }}\n\n      - name: Display structure of downloaded cuda-python artifacts\n        run: |\n          pwd\n          ls -lahR .\n\n      - name: Download cuda.bindings build artifacts\n        if: ${{ !inputs.is-release }}\n        uses: actions/download-artifact@v4\n        with:\n          name: ${{ env.CUDA_BINDINGS_ARTIFACT_NAME }}\n          path: ${{ env.CUDA_BINDINGS_ARTIFACTS_DIR }}\n\n      - name: Download cuda.bindings build artifacts\n        if: ${{ inputs.is-release }}\n        uses: actions/download-artifact@v4\n        with:\n          pattern: ${{ env.CUDA_BINDINGS_ARTIFACT_NAME }}\n          merge-multiple: true\n          path: ${{ env.CUDA_BINDINGS_ARTIFACTS_DIR }}\n          run-id: ${{ inputs.run-id }}\n          github-token: ${{ github.token }}\n\n      - name: Display structure of downloaded cuda.bindings artifacts\n        run: |\n          pwd\n          ls -lahR $CUDA_BINDINGS_ARTIFACTS_DIR\n\n      - name: Download cuda.core build artifacts\n        if: ${{ !inputs.is-release }}\n        uses: actions/download-artifact@v4\n        with:\n          name: ${{ env.CUDA_CORE_ARTIFACT_NAME }}\n          path: ${{ env.CUDA_CORE_ARTIFACTS_DIR }}\n\n      - name: Download cuda.core build artifacts\n        if: ${{ inputs.is-release }}\n        uses: actions/download-artifact@v4\n        with:\n          pattern: ${{ env.CUDA_CORE_ARTIFACT_NAME }}\n          merge-multiple: true\n          path: ${{ env.CUDA_CORE_ARTIFACTS_DIR }}\n          run-id: ${{ inputs.run-id }}\n          github-token: ${{ github.token }}\n\n      - name: Display structure of downloaded cuda.core build artifacts\n        run: |\n          pwd\n          ls -lahR $CUDA_CORE_ARTIFACTS_DIR\n\n      - name: Install all packages\n        run: |\n          pushd \"${CUDA_BINDINGS_ARTIFACTS_DIR}\"\n          pip install *.whl\n          popd\n\n          pushd \"${CUDA_CORE_ARTIFACTS_DIR}\"\n          pip install *.whl\n          popd\n\n          pip install cuda_python*.whl\n\n      # This step sets the PR_NUMBER/BUILD_LATEST/BUILD_PREVIEW env vars.\n      - name: Get PR number\n        if: ${{ !inputs.is-release }}\n        uses: ./.github/actions/get_pr_number\n\n      - name: Set up artifact directories\n        run: |\n          mkdir -p artifacts/docs\n          # create an empty folder for removal use\n          mkdir -p artifacts/empty_docs\n\n      - name: Build all docs\n        if: ${{ inputs.component == 'all' }}\n        run: |\n          pushd cuda_python/docs/\n          if [[ \"${{ inputs.is-release }}\" == \"false\" ]]; then\n            ./build_all_docs.sh latest-only\n          else\n            ./build_all_docs.sh\n            # At release time, we don't want to update the latest docs\n            rm -rf build/html/latest\n          fi\n          ls -l build\n          popd\n          mv cuda_python/docs/build/html/* artifacts/docs/\n\n      - name: Build component docs\n        if: ${{ inputs.component != 'all' }}\n        run: |\n          COMPONENT=$(echo \"${{ inputs.component }}\" | tr '-' '_')\n          pushd ${COMPONENT}/docs/\n          if [[ \"${{ inputs.is-release }}\" == \"false\" ]]; then\n            ./build_docs.sh latest-only\n          else\n            ./build_docs.sh\n            # At release time, we don't want to update the latest docs\n            rm -rf build/html/latest\n          fi\n          ls -l build\n          popd\n          if [[ \"${{ inputs.component }}\" != \"cuda-python\" ]]; then\n            TARGET=\"${{ inputs.component }}\"\n            mkdir -p artifacts/docs/${TARGET}\n          else\n            TARGET=\"\"\n          fi\n          mv ${COMPONENT}/docs/build/html/* artifacts/docs/${TARGET}\n\n      # TODO: Consider removing this step?\n      - name: Upload doc artifacts\n        uses: actions/upload-pages-artifact@v3\n        with:\n          path: artifacts/\n          retention-days: 3\n\n      - name: Deploy or clean up doc preview\n        if: ${{ !inputs.is-release }}\n        uses: ./.github/actions/doc_preview\n        with:\n          source-folder: ${{ (github.ref_name != 'main' && 'artifacts/docs') ||\n                              'artifacts/empty_docs' }}\n          pr-number: ${{ env.PR_NUMBER }}\n\n      - name: Deploy doc update\n        if: ${{ github.ref_name == 'main' || inputs.is-release }}\n        uses: JamesIves/github-pages-deploy-action@v4\n        with:\n          git-config-name: cuda-python-bot\n          git-config-email: cuda-python-bot@users.noreply.github.com\n          folder: artifacts/docs/\n          target-folder: docs/\n          commit-message: \"Deploy ${{ (inputs.is-release && 'release') || 'latest' }} docs: ${{ env.COMMIT_HASH }}\"\n          clean: false\n","repository_owner":"nvidia","repository_name":"cuda-python","tokens_count":2048,"workflow":"# Copyright (c) 2024-2025, NVIDIA CORPORATION & AFFILIATES. ALL RIGHTS RESERVED.\n#\n# SPDX-License-Identifier: Apache-2.0\n\nname: 'CI: Build and update docs'\n\non:\n  workflow_call:\n    inputs:\n      build-ctk-ver:\n        type: string\n        required: true\n      component:\n        description: Component(s) to build docs for\n        required: false\n        default: all\n        type: string\n        # below are the acceptable options:\n        #   - cuda-core\n        #   - cuda-bindings\n        #   - cuda-python\n        #   - all\n      git-tag:\n        description: Target git tag to build docs for\n        required: false\n        default: ''\n        type: string\n      run-id:\n        description: The GHA run ID that generated validated artifacts\n        required: false\n        default: ${{ github.run_id }}\n        type: string\n      is-release:\n        description: Are we building release docs?\n        required: false\n        default: false\n        type: boolean\n\njobs:\n  build:\n    name: Build docs\n    # The build stage could fail but we want the CI to keep moving.\n    if: ${{ github.repository_owner == 'nvidia' && !cancelled() }}\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        shell: bash -el {0}\n    steps:\n    - name: Checkout ${{ github.event.repository.name }}\n      uses: actions/checkout@v4\n      with:\n        fetch-depth: 0\n        ref: ${{ inputs.git-tag }}\n\n      # TODO: cache conda env to speed up the workflow once conda-incubator/setup-miniconda#267\n      # is resolved\n\n    - name: Set up miniforge\n      uses: conda-incubator/setup-miniconda@v3\n      with:\n        activate-environment: cuda-python-docs\n        environment-file: ./cuda_python/docs/environment-docs.yml\n        miniforge-version: latest\n        conda-remove-defaults: 'true'\n        python-version: 3.12\n\n    - name: Check conda env\n      run: |\n        conda info\n        conda list\n        conda config --show-sources\n        conda config --show\n\n      # WAR: Building the doc currently requires CTK installed (NVIDIA/cuda-python#326,327)\n    - name: Set up mini CTK\n      uses: ./.github/actions/fetch_ctk\n      with:\n        host-platform: linux-64\n        cuda-version: ${{ inputs.build-ctk-ver }}\n\n    - name: Set environment variables\n      run: |\n        PYTHON_VERSION_FORMATTED=\"312\"  # see above\n        REPO_DIR=$(pwd)\n\n        if [[ ${{ inputs.is-release }} == \"true\" ]]; then\n          FILE_HASH=\"*\"\n          COMMIT_HASH=\"${{ inputs.git-tag }}\"\n        else\n          FILE_HASH=\"${{ github.sha }}\"\n          COMMIT_HASH=\"${{ github.sha }}\"\n        fi\n\n        # make outputs from the previous job as env vars\n        CUDA_CORE_ARTIFACT_BASENAME=\"cuda-core-python${PYTHON_VERSION_FORMATTED}-linux-64\"\n        echo \"COMMIT_HASH=${COMMIT_HASH}\" >> $GITHUB_ENV\n        echo \"CUDA_CORE_ARTIFACT_BASENAME=${CUDA_CORE_ARTIFACT_BASENAME}\" >> $GITHUB_ENV\n        echo \"CUDA_CORE_ARTIFACT_NAME=${CUDA_CORE_ARTIFACT_BASENAME}-${FILE_HASH}\" >> $GITHUB_ENV\n        echo \"CUDA_CORE_ARTIFACTS_DIR=$(realpath \"$REPO_DIR/cuda_core/dist\")\" >> $GITHUB_ENV\n        CUDA_BINDINGS_ARTIFACT_BASENAME=\"cuda-bindings-python${PYTHON_VERSION_FORMATTED}-cuda${{ inputs.build-ctk-ver }}-linux-64\"\n        echo \"CUDA_BINDINGS_ARTIFACT_BASENAME=${CUDA_BINDINGS_ARTIFACT_BASENAME}\" >> $GITHUB_ENV\n        echo \"CUDA_BINDINGS_ARTIFACT_NAME=${CUDA_BINDINGS_ARTIFACT_BASENAME}-${FILE_HASH}\" >> $GITHUB_ENV\n        echo \"CUDA_BINDINGS_ARTIFACTS_DIR=$(realpath \"$REPO_DIR/cuda_bindings/dist\")\" >> $GITHUB_ENV\n\n    - name: Download cuda-python build artifacts\n      uses: actions/download-artifact@v4\n      with:\n        name: cuda-python-wheel\n        path: .\n        run-id: ${{ inputs.run-id }}\n        github-token: ${{ github.token }}\n\n    - name: Display structure of downloaded cuda-python artifacts\n      run: |\n        pwd\n        ls -lahR .\n\n    - name: Download cuda.bindings build artifacts\n      if: ${{ !inputs.is-release }}\n      uses: actions/download-artifact@v4\n      with:\n        name: ${{ env.CUDA_BINDINGS_ARTIFACT_NAME }}\n        path: ${{ env.CUDA_BINDINGS_ARTIFACTS_DIR }}\n\n    - name: Download cuda.bindings build artifacts\n      if: ${{ inputs.is-release }}\n      uses: actions/download-artifact@v4\n      with:\n        pattern: ${{ env.CUDA_BINDINGS_ARTIFACT_NAME }}\n        merge-multiple: true\n        path: ${{ env.CUDA_BINDINGS_ARTIFACTS_DIR }}\n        run-id: ${{ inputs.run-id }}\n        github-token: ${{ github.token }}\n\n    - name: Display structure of downloaded cuda.bindings artifacts\n      run: |\n        pwd\n        ls -lahR $CUDA_BINDINGS_ARTIFACTS_DIR\n\n    - name: Download cuda.core build artifacts\n      if: ${{ !inputs.is-release }}\n      uses: actions/download-artifact@v4\n      with:\n        name: ${{ env.CUDA_CORE_ARTIFACT_NAME }}\n        path: ${{ env.CUDA_CORE_ARTIFACTS_DIR }}\n\n    - name: Download cuda.core build artifacts\n      if: ${{ inputs.is-release }}\n      uses: actions/download-artifact@v4\n      with:\n        pattern: ${{ env.CUDA_CORE_ARTIFACT_NAME }}\n        merge-multiple: true\n        path: ${{ env.CUDA_CORE_ARTIFACTS_DIR }}\n        run-id: ${{ inputs.run-id }}\n        github-token: ${{ github.token }}\n\n    - name: Display structure of downloaded cuda.core build artifacts\n      run: |\n        pwd\n        ls -lahR $CUDA_CORE_ARTIFACTS_DIR\n\n    - name: Install all packages\n      run: |\n        pushd \"${CUDA_BINDINGS_ARTIFACTS_DIR}\"\n        pip install *.whl\n        popd\n\n        pushd \"${CUDA_CORE_ARTIFACTS_DIR}\"\n        pip install *.whl\n        popd\n\n        pip install cuda_python*.whl\n\n      # This step sets the PR_NUMBER/BUILD_LATEST/BUILD_PREVIEW env vars.\n    - name: Get PR number\n      if: ${{ !inputs.is-release }}\n      uses: ./.github/actions/get_pr_number\n\n    - name: Set up artifact directories\n      run: |\n        mkdir -p artifacts/docs\n        # create an empty folder for removal use\n        mkdir -p artifacts/empty_docs\n\n    - name: Build all docs\n      if: ${{ inputs.component == 'all' }}\n      run: |\n        pushd cuda_python/docs/\n        if [[ \"${{ inputs.is-release }}\" == \"false\" ]]; then\n          ./build_all_docs.sh latest-only\n        else\n          ./build_all_docs.sh\n          # At release time, we don't want to update the latest docs\n          rm -rf build/html/latest\n        fi\n        ls -l build\n        popd\n        mv cuda_python/docs/build/html/* artifacts/docs/\n\n    - name: Build component docs\n      if: ${{ inputs.component != 'all' }}\n      run: |\n        COMPONENT=$(echo \"${{ inputs.component }}\" | tr '-' '_')\n        pushd ${COMPONENT}/docs/\n        if [[ \"${{ inputs.is-release }}\" == \"false\" ]]; then\n          ./build_docs.sh latest-only\n        else\n          ./build_docs.sh\n          # At release time, we don't want to update the latest docs\n          rm -rf build/html/latest\n        fi\n        ls -l build\n        popd\n        if [[ \"${{ inputs.component }}\" != \"cuda-python\" ]]; then\n          TARGET=\"${{ inputs.component }}\"\n          mkdir -p artifacts/docs/${TARGET}\n        else\n          TARGET=\"\"\n        fi\n        mv ${COMPONENT}/docs/build/html/* artifacts/docs/${TARGET}\n\n      # TODO: Consider removing this step?\n    - name: Upload doc artifacts\n      uses: actions/upload-pages-artifact@v3\n      with:\n        path: artifacts/\n        retention-days: 3\n\n    - name: Deploy or clean up doc preview\n      if: ${{ !inputs.is-release }}\n      uses: ./.github/actions/doc_preview\n      with:\n        source-folder: ${{ (github.ref_name != 'main' && 'artifacts/docs') || \n          'artifacts/empty_docs' }}\n        pr-number: ${{ env.PR_NUMBER }}\n\n    - name: Deploy doc update\n      if: ${{ github.ref_name == 'main' || inputs.is-release }}\n      uses: JamesIves/github-pages-deploy-action@v4\n      with:\n        git-config-name: cuda-python-bot\n        git-config-email: cuda-python-bot@users.noreply.github.com\n        folder: artifacts/docs/\n        target-folder: docs/\n        commit-message: \"Deploy ${{ (inputs.is-release && 'release') || 'latest' }}\n          docs: ${{ env.COMMIT_HASH }}\"\n        clean: false\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `CI: Build and update docs` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 5 inputs: build-ctk-ver-the data type is string and it must be supplied; component-this input represents component(s) to build docs for, it is optional, its default value is all and the data type is string; git-tag-this input represents target git tag to build docs for, it is optional, its default value is  and the data type is string; run-id-this input represents the gha run id that generated validated artifacts, it is optional, its default value is ${{ github.run_id }} and the data type is string; is-release-this input represents are we building release docs?, it is optional, its default value is False and the data type is boolean. The workflow has one job. The 1st job is named `Build docs` and its job id is `build`. ","prompt_level2":"Generate a GitHub Workflow named `CI: Build and update docs` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 5 inputs: build-ctk-ver-the data type is string and it must be supplied; component-this input represents component(s) to build docs for, it is optional, its default value is all and the data type is string; git-tag-this input represents target git tag to build docs for, it is optional, its default value is  and the data type is string; run-id-this input represents the gha run id that generated validated artifacts, it is optional, its default value is ${{ github.run_id }} and the data type is string; is-release-this input represents are we building release docs?, it is optional, its default value is False and the data type is boolean. The workflow has one job. The 1st job is named `Build docs` and its job id is `build`. The job `build` has 21 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up miniforge`. The 3rd step is named `Check conda env`. The 4th step is named `Set up mini CTK`. The 5th step is named `Set environment variables`. The 6th step is named `Download cuda-python build artifacts`. The 7th step is named `Display structure of downloaded cuda-python artifacts`. The 8th step is named `Download cuda.bindings build artifacts`. The 9th step is named `Download cuda.bindings build artifacts`. The 10th step is named `Display structure of downloaded cuda.bindings artifacts`. The 11th step is named `Download cuda.core build artifacts`. The 12th step is named `Download cuda.core build artifacts`. The 13th step is named `Display structure of downloaded cuda.core build artifacts`. The 14th step is named `Install all packages`. The 15th step is named `Get PR number`. The 16th step is named `Set up artifact directories`. The 17th step is named `Build all docs`. The 18th step is named `Build component docs`. The 19th step is named `Upload doc artifacts`. The 20th step is named `Deploy or clean up doc preview`. The 21st step is named `Deploy doc update`. ","prompt_level3":"Generate a GitHub Workflow named `CI: Build and update docs` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 5 inputs: build-ctk-ver-the data type is string and it must be supplied; component-this input represents component(s) to build docs for, it is optional, its default value is all and the data type is string; git-tag-this input represents target git tag to build docs for, it is optional, its default value is  and the data type is string; run-id-this input represents the gha run id that generated validated artifacts, it is optional, its default value is ${{ github.run_id }} and the data type is string; is-release-this input represents are we building release docs?, it is optional, its default value is False and the data type is boolean. The workflow has one job. The 1st job is named `Build docs` and its job id is `build`. This job will run only if the condition(${{ github.repository_owner == 'nvidia' && !cancelled() }}) is met. This job will run on ubuntu-latest runner. For all run steps in the job, default shell is set to bash -el {0}. The job `build` has 21 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines 2 input parameters for the action: `fetch-depth` is set to `0` and `ref` is set to `${{ inputs.git-tag }}`. The 2nd step is named `Set up miniforge`. This step runs action `conda-incubator/setup-miniconda` tagged as v3. The step defines 5 input parameters for the action: `activate-environment` is set to `cuda-python-docs`, `environment-file` is set to `./cuda_python/docs/environment-docs.yml`, `miniforge-version` is set to `latest`, `conda-remove-defaults` is set to `true` and `python-version` is set to `3.12`. The 3rd step is named `Check conda env`. This step runs a script: `conda info\nconda list\nconda config --show-sources\nconda config --show\n`. The 4th step is named `Set up mini CTK`. This step runs action `./.github/actions/fetch_ctk`.The step defines 2 input parameters for the action: `host-platform` is set to `linux-64` and `cuda-version` is set to `${{ inputs.build-ctk-ver }}`. The 5th step is named `Set environment variables`. This step runs a script: `PYTHON_VERSION_FORMATTED=\"312\"  # see above\nREPO_DIR=$(pwd)\n\nif [[ ${{ inputs.is-release }} == \"true\" ]]; then\n  FILE_HASH=\"*\"\n  COMMIT_HASH=\"${{ inputs.git-tag }}\"\nelse\n  FILE_HASH=\"${{ github.sha }}\"\n  COMMIT_HASH=\"${{ github.sha }}\"\nfi\n\n# make outputs from the previous job as env vars\nCUDA_CORE_ARTIFACT_BASENAME=\"cuda-core-python${PYTHON_VERSION_FORMATTED}-linux-64\"\necho \"COMMIT_HASH=${COMMIT_HASH}\" >> $GITHUB_ENV\necho \"CUDA_CORE_ARTIFACT_BASENAME=${CUDA_CORE_ARTIFACT_BASENAME}\" >> $GITHUB_ENV\necho \"CUDA_CORE_ARTIFACT_NAME=${CUDA_CORE_ARTIFACT_BASENAME}-${FILE_HASH}\" >> $GITHUB_ENV\necho \"CUDA_CORE_ARTIFACTS_DIR=$(realpath \"$REPO_DIR/cuda_core/dist\")\" >> $GITHUB_ENV\nCUDA_BINDINGS_ARTIFACT_BASENAME=\"cuda-bindings-python${PYTHON_VERSION_FORMATTED}-cuda${{ inputs.build-ctk-ver }}-linux-64\"\necho \"CUDA_BINDINGS_ARTIFACT_BASENAME=${CUDA_BINDINGS_ARTIFACT_BASENAME}\" >> $GITHUB_ENV\necho \"CUDA_BINDINGS_ARTIFACT_NAME=${CUDA_BINDINGS_ARTIFACT_BASENAME}-${FILE_HASH}\" >> $GITHUB_ENV\necho \"CUDA_BINDINGS_ARTIFACTS_DIR=$(realpath \"$REPO_DIR/cuda_bindings/dist\")\" >> $GITHUB_ENV\n`. The 6th step is named `Download cuda-python build artifacts`. This step runs action `actions/download-artifact` tagged as v4. The step defines 4 input parameters for the action: `name` is set to `cuda-python-wheel`, `path` is set to `.`, `run-id` is set to `${{ inputs.run-id }}` and `github-token` is set to `${{ github.token }}`. The 7th step is named `Display structure of downloaded cuda-python artifacts`. This step runs a script: `pwd\nls -lahR .\n`. The 8th step is named `Download cuda.bindings build artifacts`. This step will run only if the condition(${{ !inputs.is-release }}) is met. This step runs action `actions/download-artifact` tagged as v4. The step defines 2 input parameters for the action: `name` is set to `${{ env.CUDA_BINDINGS_ARTIFACT_NAME }}` and `path` is set to `${{ env.CUDA_BINDINGS_ARTIFACTS_DIR }}`. The 9th step is named `Download cuda.bindings build artifacts`. This step will run only if the condition(${{ inputs.is-release }}) is met. This step runs action `actions/download-artifact` tagged as v4. The step defines 5 input parameters for the action: `pattern` is set to `${{ env.CUDA_BINDINGS_ARTIFACT_NAME }}`, `merge-multiple` is set to `True`, `path` is set to `${{ env.CUDA_BINDINGS_ARTIFACTS_DIR }}`, `run-id` is set to `${{ inputs.run-id }}` and `github-token` is set to `${{ github.token }}`. The 10th step is named `Display structure of downloaded cuda.bindings artifacts`. This step runs a script: `pwd\nls -lahR $CUDA_BINDINGS_ARTIFACTS_DIR\n`. The 11th step is named `Download cuda.core build artifacts`. This step will run only if the condition(${{ !inputs.is-release }}) is met. This step runs action `actions/download-artifact` tagged as v4. The step defines 2 input parameters for the action: `name` is set to `${{ env.CUDA_CORE_ARTIFACT_NAME }}` and `path` is set to `${{ env.CUDA_CORE_ARTIFACTS_DIR }}`. The 12th step is named `Download cuda.core build artifacts`. This step will run only if the condition(${{ inputs.is-release }}) is met. This step runs action `actions/download-artifact` tagged as v4. The step defines 5 input parameters for the action: `pattern` is set to `${{ env.CUDA_CORE_ARTIFACT_NAME }}`, `merge-multiple` is set to `True`, `path` is set to `${{ env.CUDA_CORE_ARTIFACTS_DIR }}`, `run-id` is set to `${{ inputs.run-id }}` and `github-token` is set to `${{ github.token }}`. The 13th step is named `Display structure of downloaded cuda.core build artifacts`. This step runs a script: `pwd\nls -lahR $CUDA_CORE_ARTIFACTS_DIR\n`. The 14th step is named `Install all packages`. This step runs a script: `pushd \"${CUDA_BINDINGS_ARTIFACTS_DIR}\"\npip install *.whl\npopd\n\npushd \"${CUDA_CORE_ARTIFACTS_DIR}\"\npip install *.whl\npopd\n\npip install cuda_python*.whl\n`. The 15th step is named `Get PR number`. This step will run only if the condition(${{ !inputs.is-release }}) is met. This step runs action `./.github/actions/get_pr_number`.The 16th step is named `Set up artifact directories`. This step runs a script: `mkdir -p artifacts/docs\n# create an empty folder for removal use\nmkdir -p artifacts/empty_docs\n`. The 17th step is named `Build all docs`. This step will run only if the condition(${{ inputs.component == 'all' }}) is met. This step runs a script: `pushd cuda_python/docs/\nif [[ \"${{ inputs.is-release }}\" == \"false\" ]]; then\n  ./build_all_docs.sh latest-only\nelse\n  ./build_all_docs.sh\n  # At release time, we don't want to update the latest docs\n  rm -rf build/html/latest\nfi\nls -l build\npopd\nmv cuda_python/docs/build/html/* artifacts/docs/\n`. The 18th step is named `Build component docs`. This step will run only if the condition(${{ inputs.component != 'all' }}) is met. This step runs a script: `COMPONENT=$(echo \"${{ inputs.component }}\" | tr '-' '_')\npushd ${COMPONENT}/docs/\nif [[ \"${{ inputs.is-release }}\" == \"false\" ]]; then\n  ./build_docs.sh latest-only\nelse\n  ./build_docs.sh\n  # At release time, we don't want to update the latest docs\n  rm -rf build/html/latest\nfi\nls -l build\npopd\nif [[ \"${{ inputs.component }}\" != \"cuda-python\" ]]; then\n  TARGET=\"${{ inputs.component }}\"\n  mkdir -p artifacts/docs/${TARGET}\nelse\n  TARGET=\"\"\nfi\nmv ${COMPONENT}/docs/build/html/* artifacts/docs/${TARGET}\n`. The 19th step is named `Upload doc artifacts`. This step runs action `actions/upload-pages-artifact` tagged as v3. The step defines 2 input parameters for the action: `path` is set to `artifacts/` and `retention-days` is set to `3`. The 20th step is named `Deploy or clean up doc preview`. This step will run only if the condition(${{ !inputs.is-release }}) is met. This step runs action `./.github/actions/doc_preview`.The step defines 2 input parameters for the action: `source-folder` is set to `${{ (github.ref_name != 'main' && 'artifacts/docs') || 'artifacts/empty_docs' }}` and `pr-number` is set to `${{ env.PR_NUMBER }}`. The 21st step is named `Deploy doc update`. This step will run only if the condition(${{ github.ref_name == 'main' || inputs.is-release }}) is met. This step runs action `JamesIves/github-pages-deploy-action` tagged as v4. The step defines 6 input parameters for the action: `git-config-name` is set to `cuda-python-bot`, `git-config-email` is set to `cuda-python-bot@users.noreply.github.com`, `folder` is set to `artifacts/docs/`, `target-folder` is set to `docs/`, `commit-message` is set to `Deploy ${{ (inputs.is-release && 'release') || 'latest' }} docs: ${{ env.COMMIT_HASH }}` and `clean` is set to `False`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":12,"actions":["./.github/actions/doc_preview","./.github/actions/fetch_ctk","./.github/actions/get_pr_number","JamesIves/github-pages-deploy-action","actions/checkout","actions/download-artifact","actions/download-artifact","actions/download-artifact","actions/download-artifact","actions/download-artifact","actions/upload-pages-artifact","conda-incubator/setup-miniconda"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v3","name":"conda-incubator/setup-miniconda"},{"version":null,"name":"./.github/actions/fetch_ctk"},{"version":"v4","name":"actions/download-artifact"},{"version":"v4","name":"actions/download-artifact"},{"version":"v4","name":"actions/download-artifact"},{"version":"v4","name":"actions/download-artifact"},{"version":"v4","name":"actions/download-artifact"},{"version":null,"name":"./.github/actions/get_pr_number"},{"version":"v3","name":"actions/upload-pages-artifact"},{"version":null,"name":"./.github/actions/doc_preview"},{"version":"v4","name":"JamesIves/github-pages-deploy-action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":21,"cyclomatic_complexity":1}
{"id":62013,"repository_id":18255702,"mainLanguage":"Go","file_name":"ci-performance-gate.yml","file_content":"# This workflow runs performance tests to ensure we do not introduce performance\n# regressions. This runs for every PR, as well as on every merge to the master\n# branch.\n#\n# The Pulumi CLI binaries used in this workflow are built without race detection\n# or coverage instrumentation to ensure that the performance tests are not\n# affected by these flags.\n\nname: Performance Gate\n\npermissions:\n  contents: read\n\non:\n  workflow_call:\n    inputs:\n      ref:\n        required: true\n        description: \"GitHub ref to use\"\n        type: string\n      version:\n        required: true\n        description: \"Version to produce\"\n        type: string\n      test-version-sets:\n        required: false\n        default: minimum current\n        description: Version sets on which to run integration tests\n        type: string\n      performance-test-platforms:\n        required: false\n        default: ubuntu-22.04\n        description: Platforms on which to run performance tests, as a space delimited list\n        type: string\n      fail-fast:\n        required: false\n        default: false\n        description: \"Fail all workflows whenever one of them fails\"\n        type: boolean\n      test-retries:\n        required: false\n        default: 0\n        description: \"Retry tests n times if there are failures\"\n        type: number\n    secrets:\n      PULUMI_PROD_ACCESS_TOKEN:\n        required: false\n        description: \"Pulumi access token, required to run tests against the service\"\n      AZURE_TENANT_ID:\n        required: false\n        description: \"Azure tenant ID, required to run tests against Azure\"\n      AZURE_CLIENT_ID:\n        required: false\n        description: \"Azure client ID, required to run tests against Azure\"\n      AZURE_CLIENT_SECRET:\n        required: false\n        description: \"Azure clients secret, needs to be rotated before 2025-12-21 (see the pulumi-test user in Azure portal)\"\n      AZURE_STORAGE_SAS_TOKEN:\n        required: false\n        description: \"Azure storage SAS token, required to run tests against Azure\"\n      GCP_SERVICE_ACCOUNT:\n        required: false\n        description: \"GCP service account, required to run tests against GCP\"\n\njobs:\n  matrix:\n    runs-on: ubuntu-22.04\n    strategy:\n      fail-fast: ${{ inputs.fail-fast }}\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.ref }}\n      - name: build matrix\n        id: matrix\n        env:\n          TEST_VERSION_SETS: ${{ inputs.test-version-sets }}\n          INPUT_PERFORMANCE_TEST_PLATFORMS: ${{ inputs.performance-test-platforms }}\n        run: |\n          echo \"::group::Test matrix variables\"\n          readarray -td' ' VERSION_SETS_TO_TEST < <(echo -n \"$TEST_VERSION_SETS\"); declare -p VERSION_SETS_TO_TEST;\n          readarray -td' ' PERFORMANCE_TEST_PLATFORMS < <(echo -n \"$INPUT_PERFORMANCE_TEST_PLATFORMS\"); declare -p PERFORMANCE_TEST_PLATFORMS;\n          BUILD_TARGETS='[\n              { \"os\": \"linux\",   \"arch\": \"amd64\", \"build-platform\": \"ubuntu-22.04\" },\n              { \"os\": \"windows\", \"arch\": \"amd64\", \"build-platform\": \"ubuntu-22.04\" },\n              { \"os\": \"darwin\",  \"arch\": \"arm64\", \"build-platform\": \"ubuntu-22.04\" }\n          ]'\n\n          PERFORMANCE_TEST_MATRIX=$(\n            ./scripts/get-job-matrix.py \\\n            -vvv \\\n            generate-matrix \\\n            --kind performance-test \\\n            --platform \"${PERFORMANCE_TEST_PLATFORMS[@]}\" \\\n            --version-set \"${VERSION_SETS_TO_TEST[@]}\"\n          )\n          echo \"::endgroup::\"\n\n          echo \"::group::Version set variable\"\n          VERSION_SET=$(./scripts/get-job-matrix.py \\\n            generate-version-set \\\n            --version-set current\n          )\n          echo \"::endgroup::\"\n\n          echo \"::group::Performance test matrix\"\n          echo \"$PERFORMANCE_TEST_MATRIX\" | yq -P '.'\n          echo \"::endgroup::\"\n          echo \"::group::Version set\"\n          echo \"$VERSION_SET\" | yq -P '.'\n          echo \"::endgroup::\"\n\n          echo \"::group::Set outputs\"\n          ./.github/scripts/set-output performance-test-matrix \"${PERFORMANCE_TEST_MATRIX}\"\n          ./.github/scripts/set-output version-set \"${VERSION_SET}\"\n          ./.github/scripts/set-output build-targets \"${BUILD_TARGETS}\"\n          echo \"::endgroup::\"\n    outputs:\n      performance-test-matrix: \"${{ fromJson(steps.matrix.outputs.performance-test-matrix) }}\"\n      version-set: \"${{ fromJson(steps.matrix.outputs.version-set) }}\"\n      build-targets: \"${{ fromJson(steps.matrix.outputs.build-targets) }}\"\n\n  build-binaries:\n    name: build binaries\n    needs: [matrix]\n    strategy:\n      fail-fast: ${{ inputs.fail-fast }}\n      matrix:\n        target: ${{ fromJson(needs.matrix.outputs.build-targets) }}\n    uses: ./.github/workflows/ci-build-binaries.yml\n    with:\n      ref: ${{ inputs.ref }}\n      version: ${{ inputs.version }}\n      os: ${{ matrix.target.os }}\n      arch: ${{ matrix.target.arch }}\n      build-platform: ${{ matrix.target.build-platform }}\n      version-set: ${{ needs.matrix.outputs.version-set }}\n      # For performance tests, we do not want coverage or race detection enabled.\n      enable-coverage: false\n      enable-race-detection: false\n      # Suffix the artifacts so they do not clash with those of the main build.\n      artifact-suffix: '-perf'\n    secrets: inherit\n\n  performance-test:\n    # By putting a variable in the name, we remove GitHub's auto-generated matrix parameters from\n    # appearing in the rendered title of the job name.\n    name: Performance Test${{ matrix.platform && '' }}\n    needs: [matrix, build-binaries]\n    strategy:\n      fail-fast: ${{ inputs.fail-fast }}\n      matrix: ${{ fromJson(needs.matrix.outputs.performance-test-matrix) }}\n    uses: ./.github/workflows/ci-run-test.yml\n    with:\n      ref: ${{ inputs.ref }}\n      version: ${{ inputs.version }}\n      platform: ${{ matrix.platform }}\n      test-name: ${{ matrix.test-suite.name || matrix.test-suite.command }} on ${{ matrix.platform }}/${{ matrix.version-set.name }}\n      test-command: ${{ matrix.test-suite.command }}\n      is-performance-test: true\n      enable-coverage: false\n      test-retries: ${{ inputs.test-retries }}\n      version-set: ${{ toJson(matrix.version-set) }}\n    secrets: inherit\n","repository_owner":"pulumi","repository_name":"pulumi","tokens_count":1429,"workflow":"# This workflow runs performance tests to ensure we do not introduce performance\n# regressions. This runs for every PR, as well as on every merge to the master\n# branch.\n#\n# The Pulumi CLI binaries used in this workflow are built without race detection\n# or coverage instrumentation to ensure that the performance tests are not\n# affected by these flags.\n\nname: Performance Gate\n\npermissions:\n  contents: read\n\non:\n  workflow_call:\n    inputs:\n      ref:\n        required: true\n        description: GitHub ref to use\n        type: string\n      version:\n        required: true\n        description: Version to produce\n        type: string\n      test-version-sets:\n        required: false\n        default: minimum current\n        description: Version sets on which to run integration tests\n        type: string\n      performance-test-platforms:\n        required: false\n        default: ubuntu-22.04\n        description: Platforms on which to run performance tests, as a space \n          delimited list\n        type: string\n      fail-fast:\n        required: false\n        default: false\n        description: Fail all workflows whenever one of them fails\n        type: boolean\n      test-retries:\n        required: false\n        default: 0\n        description: Retry tests n times if there are failures\n        type: number\n    secrets:\n      PULUMI_PROD_ACCESS_TOKEN:\n        required: false\n        description: Pulumi access token, required to run tests against the \n          service\n      AZURE_TENANT_ID:\n        required: false\n        description: Azure tenant ID, required to run tests against Azure\n      AZURE_CLIENT_ID:\n        required: false\n        description: Azure client ID, required to run tests against Azure\n      AZURE_CLIENT_SECRET:\n        required: false\n        description: Azure clients secret, needs to be rotated before 2025-12-21\n          (see the pulumi-test user in Azure portal)\n      AZURE_STORAGE_SAS_TOKEN:\n        required: false\n        description: Azure storage SAS token, required to run tests against \n          Azure\n      GCP_SERVICE_ACCOUNT:\n        required: false\n        description: GCP service account, required to run tests against GCP\n\njobs:\n  matrix:\n    runs-on: ubuntu-22.04\n    strategy:\n      fail-fast: ${{ inputs.fail-fast }}\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      with:\n        ref: ${{ inputs.ref }}\n    - name: build matrix\n      id: matrix\n      env:\n        TEST_VERSION_SETS: ${{ inputs.test-version-sets }}\n        INPUT_PERFORMANCE_TEST_PLATFORMS: ${{ inputs.performance-test-platforms \n          }}\n      run: |\n        echo \"::group::Test matrix variables\"\n        readarray -td' ' VERSION_SETS_TO_TEST < <(echo -n \"$TEST_VERSION_SETS\"); declare -p VERSION_SETS_TO_TEST;\n        readarray -td' ' PERFORMANCE_TEST_PLATFORMS < <(echo -n \"$INPUT_PERFORMANCE_TEST_PLATFORMS\"); declare -p PERFORMANCE_TEST_PLATFORMS;\n        BUILD_TARGETS='[\n            { \"os\": \"linux\",   \"arch\": \"amd64\", \"build-platform\": \"ubuntu-22.04\" },\n            { \"os\": \"windows\", \"arch\": \"amd64\", \"build-platform\": \"ubuntu-22.04\" },\n            { \"os\": \"darwin\",  \"arch\": \"arm64\", \"build-platform\": \"ubuntu-22.04\" }\n        ]'\n\n        PERFORMANCE_TEST_MATRIX=$(\n          ./scripts/get-job-matrix.py \\\n          -vvv \\\n          generate-matrix \\\n          --kind performance-test \\\n          --platform \"${PERFORMANCE_TEST_PLATFORMS[@]}\" \\\n          --version-set \"${VERSION_SETS_TO_TEST[@]}\"\n        )\n        echo \"::endgroup::\"\n\n        echo \"::group::Version set variable\"\n        VERSION_SET=$(./scripts/get-job-matrix.py \\\n          generate-version-set \\\n          --version-set current\n        )\n        echo \"::endgroup::\"\n\n        echo \"::group::Performance test matrix\"\n        echo \"$PERFORMANCE_TEST_MATRIX\" | yq -P '.'\n        echo \"::endgroup::\"\n        echo \"::group::Version set\"\n        echo \"$VERSION_SET\" | yq -P '.'\n        echo \"::endgroup::\"\n\n        echo \"::group::Set outputs\"\n        ./.github/scripts/set-output performance-test-matrix \"${PERFORMANCE_TEST_MATRIX}\"\n        ./.github/scripts/set-output version-set \"${VERSION_SET}\"\n        ./.github/scripts/set-output build-targets \"${BUILD_TARGETS}\"\n        echo \"::endgroup::\"\n    outputs:\n      performance-test-matrix: ${{ \n        fromJson(steps.matrix.outputs.performance-test-matrix) }}\n      version-set: ${{ fromJson(steps.matrix.outputs.version-set) }}\n      build-targets: ${{ fromJson(steps.matrix.outputs.build-targets) }}\n\n  build-binaries:\n    name: build binaries\n    needs: [matrix]\n    strategy:\n      fail-fast: ${{ inputs.fail-fast }}\n      matrix:\n        target: ${{ fromJson(needs.matrix.outputs.build-targets) }}\n    uses: ./.github/workflows/ci-build-binaries.yml\n    with:\n      ref: ${{ inputs.ref }}\n      version: ${{ inputs.version }}\n      os: ${{ matrix.target.os }}\n      arch: ${{ matrix.target.arch }}\n      build-platform: ${{ matrix.target.build-platform }}\n      version-set: ${{ needs.matrix.outputs.version-set }}\n      # For performance tests, we do not want coverage or race detection enabled.\n      enable-coverage: false\n      enable-race-detection: false\n      # Suffix the artifacts so they do not clash with those of the main build.\n      artifact-suffix: -perf\n    secrets: inherit\n\n  performance-test:\n    # By putting a variable in the name, we remove GitHub's auto-generated matrix parameters from\n    # appearing in the rendered title of the job name.\n    name: Performance Test${{ matrix.platform && '' }}\n    needs: [matrix, build-binaries]\n    strategy:\n      fail-fast: ${{ inputs.fail-fast }}\n      matrix: ${{ fromJson(needs.matrix.outputs.performance-test-matrix) }}\n    uses: ./.github/workflows/ci-run-test.yml\n    with:\n      ref: ${{ inputs.ref }}\n      version: ${{ inputs.version }}\n      platform: ${{ matrix.platform }}\n      test-name: ${{ matrix.test-suite.name || matrix.test-suite.command }} on \n        ${{ matrix.platform }}/${{ matrix.version-set.name }}\n      test-command: ${{ matrix.test-suite.command }}\n      is-performance-test: true\n      enable-coverage: false\n      test-retries: ${{ inputs.test-retries }}\n      version-set: ${{ toJson(matrix.version-set) }}\n    secrets: inherit\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Performance Gate` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 6 inputs: ref-it must be supplied, this input represents github ref to use and the data type is string; version-it must be supplied, this input represents version to produce and the data type is string; test-version-sets-it is optional, its default value is minimum current, this input represents version sets on which to run integration tests and the data type is string; performance-test-platforms-it is optional, its default value is ubuntu-22.04, this input represents platforms on which to run performance tests, as a space delimited list and the data type is string; fail-fast-it is optional, its default value is False, this input represents fail all workflows whenever one of them fails and the data type is boolean; test-retries-it is optional, its default value is 0, this input represents retry tests n times if there are failures and the data type is number. It receives 6 secrets: PULUMI_PROD_ACCESS_TOKEN-it is optional and it represents pulumi access token, required to run tests against the service; AZURE_TENANT_ID-it is optional and it represents azure tenant id, required to run tests against azure; AZURE_CLIENT_ID-it is optional and it represents azure client id, required to run tests against azure; AZURE_CLIENT_SECRET-it is optional and it represents azure clients secret, needs to be rotated before 2025-12-21 (see the pulumi-test user in azure portal); AZURE_STORAGE_SAS_TOKEN-it is optional and it represents azure storage sas token, required to run tests against azure; GCP_SERVICE_ACCOUNT-it is optional and it represents gcp service account, required to run tests against gcp. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 3 jobs. The job id of the 1st job is `matrix`. The 2nd job is named `build binaries` and its job id is `build-binaries`. The 3rd job is named `Performance Test${{ matrix.platform && '' }}` and its job id is `performance-test`. ","prompt_level2":"Generate a GitHub Workflow named `Performance Gate` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 6 inputs: ref-it must be supplied, this input represents github ref to use and the data type is string; version-it must be supplied, this input represents version to produce and the data type is string; test-version-sets-it is optional, its default value is minimum current, this input represents version sets on which to run integration tests and the data type is string; performance-test-platforms-it is optional, its default value is ubuntu-22.04, this input represents platforms on which to run performance tests, as a space delimited list and the data type is string; fail-fast-it is optional, its default value is False, this input represents fail all workflows whenever one of them fails and the data type is boolean; test-retries-it is optional, its default value is 0, this input represents retry tests n times if there are failures and the data type is number. It receives 6 secrets: PULUMI_PROD_ACCESS_TOKEN-it is optional and it represents pulumi access token, required to run tests against the service; AZURE_TENANT_ID-it is optional and it represents azure tenant id, required to run tests against azure; AZURE_CLIENT_ID-it is optional and it represents azure client id, required to run tests against azure; AZURE_CLIENT_SECRET-it is optional and it represents azure clients secret, needs to be rotated before 2025-12-21 (see the pulumi-test user in azure portal); AZURE_STORAGE_SAS_TOKEN-it is optional and it represents azure storage sas token, required to run tests against azure; GCP_SERVICE_ACCOUNT-it is optional and it represents gcp service account, required to run tests against gcp. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 3 jobs. The job id of the 1st job is `matrix`. The job `matrix` has 2 steps. The 1st step is named `Checkout repository`. The 2nd step is named `build matrix` and its id is `matrix`. The 2nd job is named `build binaries` and its job id is `build-binaries`. The 3rd job is named `Performance Test${{ matrix.platform && '' }}` and its job id is `performance-test`. ","prompt_level3":"Generate a GitHub Workflow named `Performance Gate` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 6 inputs: ref-it must be supplied, this input represents github ref to use and the data type is string; version-it must be supplied, this input represents version to produce and the data type is string; test-version-sets-it is optional, its default value is minimum current, this input represents version sets on which to run integration tests and the data type is string; performance-test-platforms-it is optional, its default value is ubuntu-22.04, this input represents platforms on which to run performance tests, as a space delimited list and the data type is string; fail-fast-it is optional, its default value is False, this input represents fail all workflows whenever one of them fails and the data type is boolean; test-retries-it is optional, its default value is 0, this input represents retry tests n times if there are failures and the data type is number. It receives 6 secrets: PULUMI_PROD_ACCESS_TOKEN-it is optional and it represents pulumi access token, required to run tests against the service; AZURE_TENANT_ID-it is optional and it represents azure tenant id, required to run tests against azure; AZURE_CLIENT_ID-it is optional and it represents azure client id, required to run tests against azure; AZURE_CLIENT_SECRET-it is optional and it represents azure clients secret, needs to be rotated before 2025-12-21 (see the pulumi-test user in azure portal); AZURE_STORAGE_SAS_TOKEN-it is optional and it represents azure storage sas token, required to run tests against azure; GCP_SERVICE_ACCOUNT-it is optional and it represents gcp service account, required to run tests against gcp. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 3 jobs. The job id of the 1st job is `matrix`. This job will run on ubuntu-22.04 runner. If any job run in the matrix fails, all in-progress and queued jobs in the matrix will be canceled. The job `matrix` has 2 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `ref` is set to `${{ inputs.ref }}`. The 2nd step is named `build matrix` and its id is `matrix`. The step sets 2 environment variables to use: `TEST_VERSION_SETS` is set to `${{ inputs.test-version-sets }}` and `INPUT_PERFORMANCE_TEST_PLATFORMS` is set to `${{ inputs.performance-test-platforms }}`. This step runs a script: `echo \"::group::Test matrix variables\"\nreadarray -td' ' VERSION_SETS_TO_TEST < <(echo -n \"$TEST_VERSION_SETS\"); declare -p VERSION_SETS_TO_TEST;\nreadarray -td' ' PERFORMANCE_TEST_PLATFORMS < <(echo -n \"$INPUT_PERFORMANCE_TEST_PLATFORMS\"); declare -p PERFORMANCE_TEST_PLATFORMS;\nBUILD_TARGETS='[\n    { \"os\": \"linux\",   \"arch\": \"amd64\", \"build-platform\": \"ubuntu-22.04\" },\n    { \"os\": \"windows\", \"arch\": \"amd64\", \"build-platform\": \"ubuntu-22.04\" },\n    { \"os\": \"darwin\",  \"arch\": \"arm64\", \"build-platform\": \"ubuntu-22.04\" }\n]'\n\nPERFORMANCE_TEST_MATRIX=$(\n  ./scripts/get-job-matrix.py \\\n  -vvv \\\n  generate-matrix \\\n  --kind performance-test \\\n  --platform \"${PERFORMANCE_TEST_PLATFORMS[@]}\" \\\n  --version-set \"${VERSION_SETS_TO_TEST[@]}\"\n)\necho \"::endgroup::\"\n\necho \"::group::Version set variable\"\nVERSION_SET=$(./scripts/get-job-matrix.py \\\n  generate-version-set \\\n  --version-set current\n)\necho \"::endgroup::\"\n\necho \"::group::Performance test matrix\"\necho \"$PERFORMANCE_TEST_MATRIX\" | yq -P '.'\necho \"::endgroup::\"\necho \"::group::Version set\"\necho \"$VERSION_SET\" | yq -P '.'\necho \"::endgroup::\"\n\necho \"::group::Set outputs\"\n./.github/scripts/set-output performance-test-matrix \"${PERFORMANCE_TEST_MATRIX}\"\n./.github/scripts/set-output version-set \"${VERSION_SET}\"\n./.github/scripts/set-output build-targets \"${BUILD_TARGETS}\"\necho \"::endgroup::\"\n`. This job has 3 outputs: `performance-test-matrix` is defined as ${{ fromJson(steps.matrix.outputs.performance-test-matrix) }}, `version-set` is defined as ${{ fromJson(steps.matrix.outputs.version-set) }} and `build-targets` is defined as ${{ fromJson(steps.matrix.outputs.build-targets) }}. The 2nd job is named `build binaries` and its job id is `build-binaries`. Before this job runs, `matrix` must complete successfully. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `target` has 51 values: $, {, {,  , f, r, o, m, J, s, o, n, (, n, e, e, d, s, ., m, a, t, r, i, x, ., o, u, t, p, u, t, s, ., b, u, i, l, d, -, t, a, r, g, e, t, s, ),  , } and }. If any job run in the matrix fails, all in-progress and queued jobs in the matrix will be canceled. This job will call a reusable workflow located at `./.github/workflows/ci-build-binaries.yml`. The job will pass 9 inputs to the called workflow: the input `ref` is `${{ inputs.ref }}`, the input `version` is `${{ inputs.version }}`, the input `os` is `${{ matrix.target.os }}`, the input `arch` is `${{ matrix.target.arch }}`, the input `build-platform` is `${{ matrix.target.build-platform }}`, the input `version-set` is `${{ needs.matrix.outputs.version-set }}`, the input `enable-coverage` is `False`, the input `enable-race-detection` is `False` and the input `artifact-suffix` is `-perf`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. The 3rd job is named `Performance Test${{ matrix.platform && '' }}` and its job id is `performance-test`. Before this job runs, `matrix` and `build-binaries` must complete successfully. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The matrix is ${{ fromJson(needs.matrix.outputs.performance-test-matrix) }}. If any job run in the matrix fails, all in-progress and queued jobs in the matrix will be canceled. This job will call a reusable workflow located at `./.github/workflows/ci-run-test.yml`. The job will pass 9 inputs to the called workflow: the input `ref` is `${{ inputs.ref }}`, the input `version` is `${{ inputs.version }}`, the input `platform` is `${{ matrix.platform }}`, the input `test-name` is `${{ matrix.test-suite.name || matrix.test-suite.command }} on ${{ matrix.platform }}/${{ matrix.version-set.name }}`, the input `test-command` is `${{ matrix.test-suite.command }}`, the input `is-performance-test` is `True`, the input `enable-coverage` is `False`, the input `test-retries` is `${{ inputs.test-retries }}` and the input `version-set` is `${{ toJson(matrix.version-set) }}`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":3,"nb_actions":1,"actions":["actions/checkout"],"actions_details":[{"version":"v4","name":"actions/checkout"}],"nb_reusable_workflows":2,"reusable_workflows":["./.github/workflows/ci-build-binaries.yml","./.github/workflows/ci-run-test.yml"],"nb_steps":2,"cyclomatic_complexity":2}
{"id":15175,"repository_id":69178598,"mainLanguage":"Rust","file_name":"benchmarks.yml","file_content":"name: Benchmarks (CodSpeed)\n\non:\n  push:\n    branches:\n      - dev\n  pull_request:\n  workflow_dispatch:\n\njobs:\n  benchmarks:\n    name: Run benchmarks\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Setup rust toolchain, cache and cargo-codspeed binary\n        uses: moonrepo/setup-rust@v1\n        with:\n          channel: stable\n          cache-target: release\n          bins: cargo-codspeed\n\n      - name: Build the benchmark target(s)\n        run: cargo codspeed build --features serde\n\n      - name: Run the benchmarks\n        uses: CodSpeedHQ/action@v3\n        with:\n          run: cargo codspeed run\n","repository_owner":"pubgrub-rs","repository_name":"pubgrub","tokens_count":163,"workflow":"name: Benchmarks (CodSpeed)\n\non:\n  push:\n    branches:\n    - dev\n  pull_request:\n  workflow_dispatch:\n\njobs:\n  benchmarks:\n    name: Run benchmarks\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n    - name: Setup rust toolchain, cache and cargo-codspeed binary\n      uses: moonrepo/setup-rust@v1\n      with:\n        channel: stable\n        cache-target: release\n        bins: cargo-codspeed\n\n    - name: Build the benchmark target(s)\n      run: cargo codspeed build --features serde\n\n    - name: Run the benchmarks\n      uses: CodSpeedHQ/action@v3\n      with:\n        run: cargo codspeed run\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Benchmarks (CodSpeed)` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named dev. 2) there is activity relating to a pull request. 3) someone manually triggers the workflow. The workflow has one job. The 1st job is named `Run benchmarks` and its job id is `benchmarks`. ","prompt_level2":"Generate a GitHub Workflow named `Benchmarks (CodSpeed)` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named dev. 2) there is activity relating to a pull request. 3) someone manually triggers the workflow. The workflow has one job. The 1st job is named `Run benchmarks` and its job id is `benchmarks`. The job `benchmarks` has 4 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Setup rust toolchain, cache and cargo-codspeed binary`. The 3rd step is named `Build the benchmark target(s)`. The 4th step is named `Run the benchmarks`. ","prompt_level3":"Generate a GitHub Workflow named `Benchmarks (CodSpeed)` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named dev. 2) there is activity relating to a pull request. 3) someone manually triggers the workflow. The workflow has one job. The 1st job is named `Run benchmarks` and its job id is `benchmarks`. This job will run on ubuntu-latest runner. The job `benchmarks` has 4 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Setup rust toolchain, cache and cargo-codspeed binary`. This step runs action `moonrepo/setup-rust` tagged as v1. The step defines 3 input parameters for the action: `channel` is set to `stable`, `cache-target` is set to `release` and `bins` is set to `cargo-codspeed`. The 3rd step is named `Build the benchmark target(s)`. This step runs a script: `cargo codspeed build --features serde`. The 4th step is named `Run the benchmarks`. This step runs action `CodSpeedHQ/action` tagged as v3. The step defines an input parameter for the action: `run` is set to `cargo codspeed run`. ","nb_triggers":3,"triggers":["pull_request","push","workflow_dispatch"],"nb_jobs":1,"nb_actions":3,"actions":["CodSpeedHQ/action","actions/checkout","moonrepo/setup-rust"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v1","name":"moonrepo/setup-rust"},{"version":"v3","name":"CodSpeedHQ/action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":4,"cyclomatic_complexity":1}
{"id":48531,"repository_id":69491913,"mainLanguage":"Rust","file_name":"treadmill-ci.yml","file_content":"# Licensed under the Apache License, Version 2.0 or the MIT License.\n# SPDX-License-Identifier: Apache-2.0 OR MIT\n# Copyright Tock Contributors 2024.\n\n# This workflow contains all Treadmill-based hardware CI jobs.\n#\n# Treadmill is a distributed hardware testbed developed within the Tock OS\n# project. For more information on Treadmill, have a look at its documentation\n# [1] or repository [2].\n#\n# This workflow is based on the Treadmill GitHub Actions integration guide [3].\n# In addition, it features the ability to run multiple Treadmill jobs and\n# test-execute stages through GitHub Action's job matrices, and uses a GitHub\n# environment to allow deployments with access to secrets for select PRs.\n#\n# [1]: https://book.treadmill.ci/\n# [2]: https://github.com/treadmill-tb/treadmill\n# [3]: https://book.treadmill.ci/user-guide/github-actions-integration.html\n\nname: treadmill-ci\n\nenv:\n  TERM: xterm # Makes tput work in actions output\n\n# Controls when the action will run. Triggers the workflow on pull request and\n# merge group checks:\n#\n# KEEP IN SYNC WITH `environment:` ATTRIBUTE BELOW:\non:\n  push:\n    branches:\n      - master\n      # Add any additional branches you want to include\n      # - dev/test_ci_branch\n\n  # Pull requests from forks will not have access to the required GitHub API\n  # secrets below, even if they are using an appropriate deployment environment\n  # and the workflow runs have been approved according to this environment's\n  # rules. We don't know whether this is a bug on GitHub's end or deliberate.\n  #\n  # Either way, for now we disable this workflow to run on PRs until we have\n  # an API proxy that securely performs these GitHub API calls (adding runners\n  # and starting Treadmill jobs with those runner registration tokens), which\n  # allows this workflow to run without access to repository secrets.\n  #\n  # However, because GitHub's merge queues don't allow to differentiate required\n  # checks for *entering* the merge queue from those that are required to *pass*\n  # it, we also can't disable this trigger entirely. Instead, we use a selector\n  # to avoid running any actual checks on this trigger, while still technically\n  # succeeding for PRs.\n  pull_request:\n\n  merge_group: # Run CI for the GitHub merge queue\n\n  # Manually dispatch for a specific branch (will require approval\n  # through the treadmill-ci-merged environment:\n  workflow_dispatch:\n    inputs:\n      tock-kernel-ref:\n        description: 'Ref (revision/branch/tag) of the upstream Tock repo to test'\n        required: true\n        default: 'master'\n      libtock-c-ref:\n        description: 'Ref (revision/branch/tag) of the upstream libtock-c repo to test'\n        required: true\n        default: 'master'\n      tests-json:\n        description: 'tests-json value passed to HWCI workflow (if empty, output from hwci-determine-tests step is used)'\n        required: false\n\npermissions:\n  contents: read\n\njobs:\n  hwci-determine-tests:\n    runs-on: ubuntu-latest\n\n    # Don't run on a pull request, as explained above.\n    if: github.event_name != 'pull_request'\n\n    outputs:\n      hwci-tests-json: ${{ steps.determine-tests.outputs.hwci-tests-json }}\n\n    steps:\n      - name: Checkout the tock/tock repository\n        uses: actions/checkout@v4\n        with:\n          # Checkout the repository at the commit that triggered the workflow\n          repository: tock/tock\n          ref: ${{ github.sha }}\n          path: tock-tock\n\n      - name: Checkout the tock-hardware-ci repository\n        uses: actions/checkout@v4\n        with:\n          repository: tock/tock-hardware-ci\n          # Change this in accordance with the two other `tock-hardware-ci` refs\n          # referenced below in the reusable workflow's parameters:\n          ref: 'main'\n          path: tock-hardware-ci\n\n      - name: Analyze changes to determine relevant tests\n        id: determine-tests\n        run: |\n          # Ensure Python dependencies are installed\n          python3 -m pip install --user --upgrade pip\n\n          # Run the select_tests.py script\n          python3 tock-hardware-ci/hwci/select_tests.py \\\n            --repo-path tock-tock \\\n            --hwci-path tock-hardware-ci/hwci \\\n            --output selected_tests.json\n\n          echo \"Selected HWCI tests:\"\n          cat selected_tests.json\n\n          # Output the tests JSON\n          hwci_tests_json=$(cat selected_tests.json | jq -c '.')\n          echo \"hwci-tests-json=${hwci_tests_json}\" >> \"$GITHUB_OUTPUT\"\n\n  hwci-treadmill-dispatch:\n    needs: [hwci-determine-tests]\n\n    # This checks whether there is at least one test to run, see\n    # https://github.com/orgs/community/discussions/27125#discussioncomment-3254720\n    #\n    # Don't run on a pull request, as explained above.\n    if: github.event_name != 'pull_request' && (fromJSON(needs.hwci-determine-tests.outputs.hwci-tests-json)[0] != null || github.event_name == 'workflow_dispatch')\n\n    # The main tock-hardware-ci workflow is imported from another repository. It\n    # can be reused across multiple Tock repositories such as the kernel,\n    # libtock-c, and libtock-rs.\n    uses: tock/tock-hardware-ci/.github/workflows/treadmill-ci.yml@main\n\n    with:\n      # Only run on a specific repository, as others will not have the right\n      # environments set up and secrets configured. Forks may want to change\n      # this parameter.\n      repository-filter: 'tock/tock'\n\n      # Provide access to the required Treadmill secrets by running in the\n      # appropriate environment (depending on the `on:` triggers above)\n      job-environment: ${{ (github.event_name == 'pull_request' || github.event_name == 'workflow_dispatch') && 'treadmill-ci' || 'treadmill-ci-merged' }}\n\n      # Reference for tock-hardware-ci repo, change if you want a specific test\n      # suite. In this case, you should also update the branch reference in the\n      # \"uses\" line above.\n      tock-hardware-ci-ref: 'main'\n\n      # Test the tock kernel revision that triggered this workflow:\n      tock-kernel-ref: ${{ github.event_name == 'workflow_dispatch' && inputs.tock-kernel-ref || github.sha }}\n\n      # Use the latest upstream libtock-c library:\n      libtock-c-ref: ${{ github.event_name == 'workflow_dispatch' && inputs.libtock-c-ref || 'master' }}\n\n      # Pass the selected tests:\n      tests-json: ${{ (github.event_name == 'workflow_dispatch' && inputs.tests-json != '') && inputs.tests-json || needs.hwci-determine-tests.outputs.hwci-tests-json }}\n\n    secrets: inherit\n\n  # We cannot depend on *all* test-execute jobs of hwci-treadmill-dispatch as\n  # required checks for pull requests and merge queues. Thus, we run another\n  # single dummy step here that waits for all the hwci-treadmill-dispatch jobs\n  # to complete and report success.\n  #\n  # We also use this to report a \"dummy\" success value for the \"pull_request\"\n  # trigger, as explained in the comment of the \"on:\" parameters above.\n  hwci-report-success:\n    needs: [hwci-determine-tests, hwci-treadmill-dispatch]\n\n    if: always()\n\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Fail if any of the 'hwci-treadmill-dispatch' jobs failed\n        if: github.event_name != 'pull_request' && contains(needs.*.result, 'failure')\n        run: exit 1\n","repository_owner":"tock","repository_name":"tock","tokens_count":1744,"workflow":"# Licensed under the Apache License, Version 2.0 or the MIT License.\n# SPDX-License-Identifier: Apache-2.0 OR MIT\n# Copyright Tock Contributors 2024.\n\n# This workflow contains all Treadmill-based hardware CI jobs.\n#\n# Treadmill is a distributed hardware testbed developed within the Tock OS\n# project. For more information on Treadmill, have a look at its documentation\n# [1] or repository [2].\n#\n# This workflow is based on the Treadmill GitHub Actions integration guide [3].\n# In addition, it features the ability to run multiple Treadmill jobs and\n# test-execute stages through GitHub Action's job matrices, and uses a GitHub\n# environment to allow deployments with access to secrets for select PRs.\n#\n# [1]: https://book.treadmill.ci/\n# [2]: https://github.com/treadmill-tb/treadmill\n# [3]: https://book.treadmill.ci/user-guide/github-actions-integration.html\n\nname: treadmill-ci\n\nenv:\n  TERM: xterm # Makes tput work in actions output\n\n# Controls when the action will run. Triggers the workflow on pull request and\n# merge group checks:\n#\n# KEEP IN SYNC WITH `environment:` ATTRIBUTE BELOW:\non:\n  push:\n    branches:\n    - master\n      # Add any additional branches you want to include\n      # - dev/test_ci_branch\n\n  # Pull requests from forks will not have access to the required GitHub API\n  # secrets below, even if they are using an appropriate deployment environment\n  # and the workflow runs have been approved according to this environment's\n  # rules. We don't know whether this is a bug on GitHub's end or deliberate.\n  #\n  # Either way, for now we disable this workflow to run on PRs until we have\n  # an API proxy that securely performs these GitHub API calls (adding runners\n  # and starting Treadmill jobs with those runner registration tokens), which\n  # allows this workflow to run without access to repository secrets.\n  #\n  # However, because GitHub's merge queues don't allow to differentiate required\n  # checks for *entering* the merge queue from those that are required to *pass*\n  # it, we also can't disable this trigger entirely. Instead, we use a selector\n  # to avoid running any actual checks on this trigger, while still technically\n  # succeeding for PRs.\n  pull_request:\n\n  merge_group: # Run CI for the GitHub merge queue\n\n  # Manually dispatch for a specific branch (will require approval\n  # through the treadmill-ci-merged environment:\n  workflow_dispatch:\n    inputs:\n      tock-kernel-ref:\n        description: Ref (revision/branch/tag) of the upstream Tock repo to test\n        required: true\n        default: master\n      libtock-c-ref:\n        description: Ref (revision/branch/tag) of the upstream libtock-c repo to\n          test\n        required: true\n        default: master\n      tests-json:\n        description: tests-json value passed to HWCI workflow (if empty, output \n          from hwci-determine-tests step is used)\n        required: false\n\npermissions:\n  contents: read\n\njobs:\n  hwci-determine-tests:\n    runs-on: ubuntu-latest\n\n    # Don't run on a pull request, as explained above.\n    if: github.event_name != 'pull_request'\n\n    outputs:\n      hwci-tests-json: ${{ steps.determine-tests.outputs.hwci-tests-json }}\n\n    steps:\n    - name: Checkout the tock/tock repository\n      uses: actions/checkout@v4\n      with:\n          # Checkout the repository at the commit that triggered the workflow\n        repository: tock/tock\n        ref: ${{ github.sha }}\n        path: tock-tock\n\n    - name: Checkout the tock-hardware-ci repository\n      uses: actions/checkout@v4\n      with:\n        repository: tock/tock-hardware-ci\n          # Change this in accordance with the two other `tock-hardware-ci` refs\n          # referenced below in the reusable workflow's parameters:\n        ref: main\n        path: tock-hardware-ci\n\n    - name: Analyze changes to determine relevant tests\n      id: determine-tests\n      run: |\n        # Ensure Python dependencies are installed\n        python3 -m pip install --user --upgrade pip\n\n        # Run the select_tests.py script\n        python3 tock-hardware-ci/hwci/select_tests.py \\\n          --repo-path tock-tock \\\n          --hwci-path tock-hardware-ci/hwci \\\n          --output selected_tests.json\n\n        echo \"Selected HWCI tests:\"\n        cat selected_tests.json\n\n        # Output the tests JSON\n        hwci_tests_json=$(cat selected_tests.json | jq -c '.')\n        echo \"hwci-tests-json=${hwci_tests_json}\" >> \"$GITHUB_OUTPUT\"\n\n  hwci-treadmill-dispatch:\n    needs: [hwci-determine-tests]\n\n    # This checks whether there is at least one test to run, see\n    # https://github.com/orgs/community/discussions/27125#discussioncomment-3254720\n    #\n    # Don't run on a pull request, as explained above.\n    if: github.event_name != 'pull_request' && \n      (fromJSON(needs.hwci-determine-tests.outputs.hwci-tests-json)[0] != null \n      || github.event_name == 'workflow_dispatch')\n\n    # The main tock-hardware-ci workflow is imported from another repository. It\n    # can be reused across multiple Tock repositories such as the kernel,\n    # libtock-c, and libtock-rs.\n    uses: tock/tock-hardware-ci/.github/workflows/treadmill-ci.yml@main\n\n    with:\n      # Only run on a specific repository, as others will not have the right\n      # environments set up and secrets configured. Forks may want to change\n      # this parameter.\n      repository-filter: tock/tock\n\n      # Provide access to the required Treadmill secrets by running in the\n      # appropriate environment (depending on the `on:` triggers above)\n      job-environment: ${{ (github.event_name == 'pull_request' || \n        github.event_name == 'workflow_dispatch') && 'treadmill-ci' || \n        'treadmill-ci-merged' }}\n\n      # Reference for tock-hardware-ci repo, change if you want a specific test\n      # suite. In this case, you should also update the branch reference in the\n      # \"uses\" line above.\n      tock-hardware-ci-ref: main\n\n      # Test the tock kernel revision that triggered this workflow:\n      tock-kernel-ref: ${{ github.event_name == 'workflow_dispatch' && \n        inputs.tock-kernel-ref || github.sha }}\n\n      # Use the latest upstream libtock-c library:\n      libtock-c-ref: ${{ github.event_name == 'workflow_dispatch' && \n        inputs.libtock-c-ref || 'master' }}\n\n      # Pass the selected tests:\n      tests-json: ${{ (github.event_name == 'workflow_dispatch' && \n        inputs.tests-json != '') && inputs.tests-json || \n        needs.hwci-determine-tests.outputs.hwci-tests-json }}\n\n    secrets: inherit\n\n  # We cannot depend on *all* test-execute jobs of hwci-treadmill-dispatch as\n  # required checks for pull requests and merge queues. Thus, we run another\n  # single dummy step here that waits for all the hwci-treadmill-dispatch jobs\n  # to complete and report success.\n  #\n  # We also use this to report a \"dummy\" success value for the \"pull_request\"\n  # trigger, as explained in the comment of the \"on:\" parameters above.\n  hwci-report-success:\n    needs: [hwci-determine-tests, hwci-treadmill-dispatch]\n\n    if: always()\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Fail if any of the 'hwci-treadmill-dispatch' jobs failed\n      if: github.event_name != 'pull_request' && contains(needs.*.result, \n        'failure')\n      run: exit 1\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `treadmill-ci` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master. 2) there is activity relating to a pull request. 3) there is activity relating to a merge group in a merge queue. 4) someone manually triggers the workflow. This workflow receives 3 inputs: tock-kernel-ref-this input represents ref (revision/branch/tag) of the upstream tock repo to test, it must be supplied and its default value is master; libtock-c-ref-this input represents ref (revision/branch/tag) of the upstream libtock-c repo to test, it must be supplied and its default value is master; tests-json-this input represents tests-json value passed to hwci workflow (if empty, output from hwci-determine-tests step is used) and it is optional. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow sets an environment variable to use: `TERM` is set to `xterm`. The workflow has 3 jobs. The job id of the 1st job is `hwci-determine-tests`. The job id of the 2nd job is `hwci-treadmill-dispatch`. The job id of the 3rd job is `hwci-report-success`. ","prompt_level2":"Generate a GitHub Workflow named `treadmill-ci` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master. 2) there is activity relating to a pull request. 3) there is activity relating to a merge group in a merge queue. 4) someone manually triggers the workflow. This workflow receives 3 inputs: tock-kernel-ref-this input represents ref (revision/branch/tag) of the upstream tock repo to test, it must be supplied and its default value is master; libtock-c-ref-this input represents ref (revision/branch/tag) of the upstream libtock-c repo to test, it must be supplied and its default value is master; tests-json-this input represents tests-json value passed to hwci workflow (if empty, output from hwci-determine-tests step is used) and it is optional. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow sets an environment variable to use: `TERM` is set to `xterm`. The workflow has 3 jobs. The job id of the 1st job is `hwci-determine-tests`. The job `hwci-determine-tests` has 3 steps. The 1st step is named `Checkout tock/tock`. The 2nd step is named `Checkout tock/tock-hardware-ci`. The 3rd step is named `Analyze changes to determine relevant tests` and its id is `determine-tests`. The job id of the 2nd job is `hwci-treadmill-dispatch`. The job id of the 3rd job is `hwci-report-success`. The job `hwci-report-success` has one step. The 1st step is named `Fail if any of the 'hwci-treadmill-dispatch' jobs failed`. ","prompt_level3":"Generate a GitHub Workflow named `treadmill-ci` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master. 2) there is activity relating to a pull request. 3) there is activity relating to a merge group in a merge queue. 4) someone manually triggers the workflow. This workflow receives 3 inputs: tock-kernel-ref-this input represents ref (revision/branch/tag) of the upstream tock repo to test, it must be supplied and its default value is master; libtock-c-ref-this input represents ref (revision/branch/tag) of the upstream libtock-c repo to test, it must be supplied and its default value is master; tests-json-this input represents tests-json value passed to hwci workflow (if empty, output from hwci-determine-tests step is used) and it is optional. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow sets an environment variable to use: `TERM` is set to `xterm`. The workflow has 3 jobs. The job id of the 1st job is `hwci-determine-tests`. This job will run only if the condition(github.event_name != 'pull_request') is met. This job will run on ubuntu-latest runner. The job `hwci-determine-tests` has 3 steps. The 1st step is named `Checkout tock/tock`. This step runs action `actions/checkout` tagged as v4. The step defines 3 input parameters for the action: `repository` is set to `tock/tock`, `ref` is set to `${{ github.sha }}` and `path` is set to `tock-tock`. The 2nd step is named `Checkout tock/tock-hardware-ci`. This step runs action `actions/checkout` tagged as v4. The step defines 3 input parameters for the action: `repository` is set to `tock/tock-hardware-ci`, `ref` is set to `main` and `path` is set to `tock-hardware-ci`. The 3rd step is named `Analyze changes to determine relevant tests` and its id is `determine-tests`. This step runs a script: `# Ensure Python dependencies are installed\npython3 -m pip install --user --upgrade pip\n\n# Run the select_tests.py script\npython3 tock-hardware-ci/hwci/select_tests.py \\\n  --repo-path tock-tock \\\n  --hwci-path tock-hardware-ci/hwci \\\n  --output selected_tests.json\n\necho \"Selected HWCI tests:\"\ncat selected_tests.json\n\n# Output the tests JSON\nhwci_tests_json=$(cat selected_tests.json | jq -c '.')\necho \"hwci-tests-json=${hwci_tests_json}\" >> \"$GITHUB_OUTPUT\"\n`. This job has an output: `hwci-tests-json` is defined as ${{ steps.determine-tests.outputs.hwci-tests-json }}. The job id of the 2nd job is `hwci-treadmill-dispatch`. Before this job runs, `hwci-determine-tests` must complete successfully. This job will run only if the condition(github.event_name != 'pull_request' && (fromJSON(needs.hwci-determine-tests.outputs.hwci-tests-json)[0] != null || github.event_name == 'workflow_dispatch')) is met. This job will call a reusable workflow located at `tock/tock-hardware-ci/.github/workflows/treadmill-ci.yml@main`. The job will pass 6 inputs to the called workflow: the input `repository-filter` is `tock/tock`, the input `job-environment` is `${{ (github.event_name == 'pull_request' || github.event_name == 'workflow_dispatch') && 'treadmill-ci' || 'treadmill-ci-merged' }}`, the input `tock-hardware-ci-ref` is `main`, the input `tock-kernel-ref` is `${{ github.event_name == 'workflow_dispatch' && inputs.tock-kernel-ref || github.sha }}`, the input `libtock-c-ref` is `${{ github.event_name == 'workflow_dispatch' && inputs.libtock-c-ref || 'master' }}` and the input `tests-json` is `${{ (github.event_name == 'workflow_dispatch' && inputs.tests-json != '') && inputs.tests-json || needs.hwci-determine-tests.outputs.hwci-tests-json }}`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. The job id of the 3rd job is `hwci-report-success`. Before this job runs, `hwci-determine-tests` and `hwci-treadmill-dispatch` must complete successfully. This job will run only if the condition(always()) is met. This job will run on ubuntu-latest runner. The job `hwci-report-success` has one step. The 1st step is named `Fail if any of the 'hwci-treadmill-dispatch' jobs failed`. This step will run only if the condition(github.event_name != 'pull_request' && contains(needs.*.result, 'failure')) is met. This step runs a script: `exit 1`. ","nb_triggers":4,"triggers":["merge_group","pull_request","push","workflow_dispatch"],"nb_jobs":3,"nb_actions":2,"actions":["actions/checkout","actions/checkout"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/checkout"}],"nb_reusable_workflows":1,"reusable_workflows":["tock/tock-hardware-ci/.github/workflows/treadmill-ci.yml"],"nb_steps":4,"cyclomatic_complexity":2}
{"id":21111,"repository_id":18239562,"mainLanguage":"Go","file_name":"workflow-tigron.yml","file_content":"name: tigron\n\non:\n  push:\n    branches:\n      - main\n      - 'release/**'\n  pull_request:\n    paths: 'mod/tigron/**'\n\nenv:\n  GO_VERSION: \"1.24\"\n  GOTOOLCHAIN: local\n\njobs:\n  lint:\n    timeout-minutes: 15\n    name: \"${{ matrix.goos }} ${{ matrix.runner }} | go ${{ matrix.canary }}\"\n    runs-on: ${{ matrix.runner }}\n    defaults:\n      run:\n        shell: bash\n    strategy:\n      matrix:\n        include:\n          - runner: ubuntu-24.04\n          - runner: macos-15\n          - runner: windows-2022\n          - runner: ubuntu-24.04\n            goos: freebsd\n          - runner: ubuntu-24.04\n            canary: go-canary\n    steps:\n      - name: \"Checkout project\"\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683  # v4.2.2\n        with:\n          fetch-depth: 100\n      - if: ${{ matrix.canary }}\n        name: \"Init (canary): retrieve GO_VERSION\"\n        run: |\n          latest_go=\"$(. ./hack/provisioning/version/fetch.sh; go::canary::for::go-setup)\"\n          printf \"GO_VERSION=%s\\n\" \"$latest_go\" >> \"$GITHUB_ENV\"\n          [ \"$latest_go\" != \"\" ] || \\\n            echo \"::warning title=No canary go::There is currently no canary go version to test. Steps will not run.\"\n      - if: ${{ env.GO_VERSION != '' }}\n        name: \"Install go\"\n        uses: actions/setup-go@0aaccfd150d50ccaeb58ebd88d36e91967a5f35b  # v5.4.0\n        with:\n          go-version: ${{ env.GO_VERSION }}\n          check-latest: true\n      - if: ${{ env.GO_VERSION != '' }}\n        name: \"Install tools\"\n        run: |\n          cd mod/tigron\n          echo \"::group:: make install-dev-tools\"\n          make install-dev-tools\n          if [ \"$RUNNER_OS\" == macOS ]; then\n            brew install yamllint shellcheck\n          fi\n          echo \"::endgroup::\"\n      - if: ${{ env.GO_VERSION != '' && env.RUNNER_OS == 'Linux' && matrix.goos == '' }}\n        name: \"lint\"\n        env:\n          NO_COLOR: true\n        run: |\n          echo \"::group:: lint\"\n          cd mod/tigron\n          export LINT_COMMIT_RANGE=\"$(jq -r '.after + \"..HEAD\"' ${GITHUB_EVENT_PATH})\"\n          make lint\n          echo \"::endgroup::\"\n      - if: ${{ env.GO_VERSION != '' }}\n        name: \"test-unit\"\n        run: |\n          echo \"::group:: unit test\"\n          cd mod/tigron\n          make test-unit\n          echo \"::endgroup::\"\n      - if: ${{ env.GO_VERSION != '' }}\n        name: \"test-unit-race\"\n        run: |\n          echo \"::group:: race test\"\n          cd mod/tigron\n          make test-unit-race\n          echo \"::endgroup::\"\n      - if: ${{ env.GO_VERSION != '' }}\n        name: \"test-unit-bench\"\n        run: |\n          echo \"::group:: bench\"\n          cd mod/tigron\n          make test-unit-bench\n          echo \"::endgroup::\"\n","repository_owner":"containerd","repository_name":"nerdctl","tokens_count":794,"workflow":"name: tigron\n\non:\n  push:\n    branches:\n    - main\n    - release/**\n  pull_request:\n    paths: mod/tigron/**\n\nenv:\n  GO_VERSION: '1.24'\n  GOTOOLCHAIN: local\n\njobs:\n  lint:\n    timeout-minutes: 15\n    name: ${{ matrix.goos }} ${{ matrix.runner }} | go ${{ matrix.canary }}\n    runs-on: ${{ matrix.runner }}\n    defaults:\n      run:\n        shell: bash\n    strategy:\n      matrix:\n        include:\n        - runner: ubuntu-24.04\n        - runner: macos-15\n        - runner: windows-2022\n        - runner: ubuntu-24.04\n          goos: freebsd\n        - runner: ubuntu-24.04\n          canary: go-canary\n    steps:\n    - name: Checkout project\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683    # v4.2.2\n      with:\n        fetch-depth: 100\n    - if: ${{ matrix.canary }}\n      name: 'Init (canary): retrieve GO_VERSION'\n      run: |\n        latest_go=\"$(. ./hack/provisioning/version/fetch.sh; go::canary::for::go-setup)\"\n        printf \"GO_VERSION=%s\\n\" \"$latest_go\" >> \"$GITHUB_ENV\"\n        [ \"$latest_go\" != \"\" ] || \\\n          echo \"::warning title=No canary go::There is currently no canary go version to test. Steps will not run.\"\n    - if: ${{ env.GO_VERSION != '' }}\n      name: Install go\n      uses: actions/setup-go@0aaccfd150d50ccaeb58ebd88d36e91967a5f35b    # v5.4.0\n      with:\n        go-version: ${{ env.GO_VERSION }}\n        check-latest: true\n    - if: ${{ env.GO_VERSION != '' }}\n      name: Install tools\n      run: |\n        cd mod/tigron\n        echo \"::group:: make install-dev-tools\"\n        make install-dev-tools\n        if [ \"$RUNNER_OS\" == macOS ]; then\n          brew install yamllint shellcheck\n        fi\n        echo \"::endgroup::\"\n    - if: ${{ env.GO_VERSION != '' && env.RUNNER_OS == 'Linux' && matrix.goos ==\n        '' }}\n      name: lint\n      env:\n        NO_COLOR: true\n      run: |\n        echo \"::group:: lint\"\n        cd mod/tigron\n        export LINT_COMMIT_RANGE=\"$(jq -r '.after + \"..HEAD\"' ${GITHUB_EVENT_PATH})\"\n        make lint\n        echo \"::endgroup::\"\n    - if: ${{ env.GO_VERSION != '' }}\n      name: test-unit\n      run: |\n        echo \"::group:: unit test\"\n        cd mod/tigron\n        make test-unit\n        echo \"::endgroup::\"\n    - if: ${{ env.GO_VERSION != '' }}\n      name: test-unit-race\n      run: |\n        echo \"::group:: race test\"\n        cd mod/tigron\n        make test-unit-race\n        echo \"::endgroup::\"\n    - if: ${{ env.GO_VERSION != '' }}\n      name: test-unit-bench\n      run: |\n        echo \"::group:: bench\"\n        cd mod/tigron\n        make test-unit-bench\n        echo \"::endgroup::\"\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `tigron` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main or a branch whose name matches release/**. 2) Only if at least one path of pull_request event matches a pattern in the paths filter(m, o, d, /, t, i, g, r, o, n, /, * or *), the workflow runs. The workflow sets 2 environment variables to use: `GO_VERSION` is set to `1.24` and `GOTOOLCHAIN` is set to `local`. The workflow has one job. The 1st job is named `${{ matrix.goos }} ${{ matrix.runner }} | go ${{ matrix.canary }}` and its job id is `lint`. ","prompt_level2":"Generate a GitHub Workflow named `tigron` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main or a branch whose name matches release/**. 2) Only if at least one path of pull_request event matches a pattern in the paths filter(m, o, d, /, t, i, g, r, o, n, /, * or *), the workflow runs. The workflow sets 2 environment variables to use: `GO_VERSION` is set to `1.24` and `GOTOOLCHAIN` is set to `local`. The workflow has one job. The 1st job is named `${{ matrix.goos }} ${{ matrix.runner }} | go ${{ matrix.canary }}` and its job id is `lint`. The job `lint` has 8 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Init (canary): retrieve GO_VERSION`. The 3rd step is named `Install go`. The 4th step is named `Install tools`. The 5th step is named `lint`. The 6th step is named `test-unit`. The 7th step is named `test-unit-race`. The 8th step is named `test-unit-bench`. ","prompt_level3":"Generate a GitHub Workflow named `tigron` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main or a branch whose name matches release/**. 2) Only if at least one path of pull_request event matches a pattern in the paths filter(m, o, d, /, t, i, g, r, o, n, /, * or *), the workflow runs. The workflow sets 2 environment variables to use: `GO_VERSION` is set to `1.24` and `GOTOOLCHAIN` is set to `local`. The workflow has one job. The 1st job is named `${{ matrix.goos }} ${{ matrix.runner }} | go ${{ matrix.canary }}` and its job id is `lint`. This job will run on ${{ matrix.runner }} runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. For each object in the [{'runner': 'ubuntu-24.04'}, {'runner': 'macos-15'}, {'runner': 'windows-2022'}, {'runner': 'ubuntu-24.04', 'goos': 'freebsd'}, {'runner': 'ubuntu-24.04', 'canary': 'go-canary'}] list, the key:value pairs in the object will be added to each of the matrix combinations if none of the key:value pairs overwrite any of the original matrix values. If the object cannot be added to any of the matrix combinations, a new matrix combination will be created instead. For all run steps in the job, default shell is set to bash. The maximum number of minutes to run the job is 15. The job `lint` has 8 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is 11bd71901bbe5b1630ceea73d27597364c9af683. The step defines an input parameter for the action: `fetch-depth` is set to `100`. The 2nd step is named `Init (canary): retrieve GO_VERSION`. This step will run only if the condition(${{ matrix.canary }}) is met. This step runs a script: `latest_go=\"$(. ./hack/provisioning/version/fetch.sh; go::canary::for::go-setup)\"\nprintf \"GO_VERSION=%s\\n\" \"$latest_go\" >> \"$GITHUB_ENV\"\n[ \"$latest_go\" != \"\" ] || \\\n  echo \"::warning title=No canary go::There is currently no canary go version to test. Steps will not run.\"\n`. The 3rd step is named `Install go`. This step will run only if the condition(${{ env.GO_VERSION != '' }}) is met. This step runs action `actions/setup-go` whose commit is 0aaccfd150d50ccaeb58ebd88d36e91967a5f35b. The step defines 2 input parameters for the action: `go-version` is set to `${{ env.GO_VERSION }}` and `check-latest` is set to `True`. The 4th step is named `Install tools`. This step will run only if the condition(${{ env.GO_VERSION != '' }}) is met. This step runs a script: `cd mod/tigron\necho \"::group:: make install-dev-tools\"\nmake install-dev-tools\nif [ \"$RUNNER_OS\" == macOS ]; then\n  brew install yamllint shellcheck\nfi\necho \"::endgroup::\"\n`. The 5th step is named `lint`. This step will run only if the condition(${{ env.GO_VERSION != '' && env.RUNNER_OS == 'Linux' && matrix.goos == '' }}) is met. The step sets an environment variable to use: `NO_COLOR` is set to `True`. This step runs a script: `echo \"::group:: lint\"\ncd mod/tigron\nexport LINT_COMMIT_RANGE=\"$(jq -r '.after + \"..HEAD\"' ${GITHUB_EVENT_PATH})\"\nmake lint\necho \"::endgroup::\"\n`. The 6th step is named `test-unit`. This step will run only if the condition(${{ env.GO_VERSION != '' }}) is met. This step runs a script: `echo \"::group:: unit test\"\ncd mod/tigron\nmake test-unit\necho \"::endgroup::\"\n`. The 7th step is named `test-unit-race`. This step will run only if the condition(${{ env.GO_VERSION != '' }}) is met. This step runs a script: `echo \"::group:: race test\"\ncd mod/tigron\nmake test-unit-race\necho \"::endgroup::\"\n`. The 8th step is named `test-unit-bench`. This step will run only if the condition(${{ env.GO_VERSION != '' }}) is met. This step runs a script: `echo \"::group:: bench\"\ncd mod/tigron\nmake test-unit-bench\necho \"::endgroup::\"\n`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","actions/setup-go"],"actions_details":[{"version":"11bd71901bbe5b1630ceea73d27597364c9af683","name":"actions/checkout"},{"version":"0aaccfd150d50ccaeb58ebd88d36e91967a5f35b","name":"actions/setup-go"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":8,"cyclomatic_complexity":1}
{"id":18631,"repository_id":95237737,"mainLanguage":"PHP","file_name":"release.yml","file_content":"name:  Main\nrun-name:  Version Deployment\n\non:\n  push:\n    tags:\n      - '*.*.*'\n\nenv:\n  DOCKER_REGISTRY: ghcr.io\n  DOCKER_IMAGE_NAME: ${{ github.repository }}\n  DOCKERHUB_REPOSITORY: ${{ secrets.DOCKERHUB_USERNAME }}/marreta\n\njobs:\n  docker-build:\n    name:  Build and Push\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n    \n    steps:\n      - name:  Checkout code\n        uses: actions/checkout@v4\n\n      - name:  Extract version from tag\n        id: get_version\n        run: echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT\n\n      - name:  Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      - name:  Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          platforms: linux/amd64,linux/arm64,linux/arm/v7\n\n      - name:  Extract Docker metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: |\n            ${{ env.DOCKER_REGISTRY }}/${{ env.DOCKER_IMAGE_NAME }}\n            ${{ env.DOCKERHUB_REPOSITORY }}\n          tags: |\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            type=sha\n\n      - name:  Log in to GitHub Registry\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.DOCKER_REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name:  Log in to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name:  Build and Push\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          platforms: linux/amd64,linux/arm64,linux/arm/v7\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n  publish-release:\n    name:  Publish Release\n    runs-on: ubuntu-latest\n    needs: docker-build\n    permissions:\n      contents: write\n    \n    steps:\n      - name:  Checkout code\n        uses: actions/checkout@v4\n\n      - name:  Extract version from tag\n        id: get_version\n        run: echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT\n\n      - name:  Create Release\n        uses: softprops/action-gh-release@v1\n        with:\n          name: \" Release v${{ steps.get_version.outputs.VERSION }}\"\n          tag_name: ${{ steps.get_version.outputs.VERSION }}\n          generate_release_notes: true\n          draft: false\n          prerelease: false","repository_owner":"manualdousuario","repository_name":"marreta","tokens_count":710,"workflow":"name:  Main\nrun-name:  Version Deployment\n\non:\n  push:\n    tags:\n    - '*.*.*'\n\nenv:\n  DOCKER_REGISTRY: ghcr.io\n  DOCKER_IMAGE_NAME: ${{ github.repository }}\n  DOCKERHUB_REPOSITORY: ${{ secrets.DOCKERHUB_USERNAME }}/marreta\n\njobs:\n  docker-build:\n    name:  Build and Push\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n    - name:  Checkout code\n      uses: actions/checkout@v4\n\n    - name:  Extract version from tag\n      id: get_version\n      run: echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT\n\n    - name:  Set up QEMU\n      uses: docker/setup-qemu-action@v3\n\n    - name:  Set up Docker Buildx\n      uses: docker/setup-buildx-action@v3\n      with:\n        platforms: linux/amd64,linux/arm64,linux/arm/v7\n\n    - name:  Extract Docker metadata\n      id: meta\n      uses: docker/metadata-action@v5\n      with:\n        images: |\n          ${{ env.DOCKER_REGISTRY }}/${{ env.DOCKER_IMAGE_NAME }}\n          ${{ env.DOCKERHUB_REPOSITORY }}\n        tags: |\n          type=semver,pattern={{version}}\n          type=semver,pattern={{major}}.{{minor}}\n          type=sha\n\n    - name:  Log in to GitHub Registry\n      uses: docker/login-action@v3\n      with:\n        registry: ${{ env.DOCKER_REGISTRY }}\n        username: ${{ github.actor }}\n        password: ${{ secrets.GITHUB_TOKEN }}\n\n    - name:  Log in to Docker Hub\n      uses: docker/login-action@v3\n      with:\n        username: ${{ secrets.DOCKERHUB_USERNAME }}\n        password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n    - name:  Build and Push\n      uses: docker/build-push-action@v5\n      with:\n        context: .\n        platforms: linux/amd64,linux/arm64,linux/arm/v7\n        push: true\n        tags: ${{ steps.meta.outputs.tags }}\n        labels: ${{ steps.meta.outputs.labels }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n\n  publish-release:\n    name:  Publish Release\n    runs-on: ubuntu-latest\n    needs: docker-build\n    permissions:\n      contents: write\n\n    steps:\n    - name:  Checkout code\n      uses: actions/checkout@v4\n\n    - name:  Extract version from tag\n      id: get_version\n      run: echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT\n\n    - name:  Create Release\n      uses: softprops/action-gh-release@v1\n      with:\n        name:  Release v${{ steps.get_version.outputs.VERSION }}\n        tag_name: ${{ steps.get_version.outputs.VERSION }}\n        generate_release_notes: true\n        draft: false\n        prerelease: false\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named ` Main` for a GitHub repository whose primary programming language is PHP. The name for workflow runs is set to ` Version Deployment`. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a tag whose name matches *.*.*. The workflow sets 3 environment variables to use: `DOCKER_REGISTRY` is set to `ghcr.io`, `DOCKER_IMAGE_NAME` is set to `${{ github.repository }}` and `DOCKERHUB_REPOSITORY` is set to `${{ secrets.DOCKERHUB_USERNAME }}/marreta`. The workflow has 2 jobs. The 1st job is named ` Build and Push` and its job id is `docker-build`. The 2nd job is named ` Publish Release` and its job id is `publish-release`. ","prompt_level2":"Generate a GitHub Workflow named ` Main` for a GitHub repository whose primary programming language is PHP. The name for workflow runs is set to ` Version Deployment`. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a tag whose name matches *.*.*. The workflow sets 3 environment variables to use: `DOCKER_REGISTRY` is set to `ghcr.io`, `DOCKER_IMAGE_NAME` is set to `${{ github.repository }}` and `DOCKERHUB_REPOSITORY` is set to `${{ secrets.DOCKERHUB_USERNAME }}/marreta`. The workflow has 2 jobs. The 1st job is named ` Build and Push` and its job id is `docker-build`. The job `docker-build` has 8 steps. The 1st step is named `Checkout repository`. The 2nd step is named ` Extract version from tag` and its id is `get_version`. The 3rd step is named ` Set up QEMU`. The 4th step is named ` Set up Docker Buildx`. The 5th step is named ` Extract Docker metadata` and its id is `meta`. The 6th step is named ` Log in to GitHub Registry`. The 7th step is named ` Log in to Docker Hub`. The 8th step is named ` Build and Push`. The 2nd job is named ` Publish Release` and its job id is `publish-release`. The job `publish-release` has 3 steps. The 1st step is named `Checkout repository`. The 2nd step is named ` Extract version from tag` and its id is `get_version`. The 3rd step is named ` Create Release`. ","prompt_level3":"Generate a GitHub Workflow named ` Main` for a GitHub repository whose primary programming language is PHP. The name for workflow runs is set to ` Version Deployment`. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a tag whose name matches *.*.*. The workflow sets 3 environment variables to use: `DOCKER_REGISTRY` is set to `ghcr.io`, `DOCKER_IMAGE_NAME` is set to `${{ github.repository }}` and `DOCKERHUB_REPOSITORY` is set to `${{ secrets.DOCKERHUB_USERNAME }}/marreta`. The workflow has 2 jobs. The 1st job is named ` Build and Push` and its job id is `docker-build`. This job will run on ubuntu-latest runner. The job `docker-build` modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `packages` scope. This permission setting only applies to the job `docker-build`. The job `docker-build` has 8 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named ` Extract version from tag` and its id is `get_version`. This step runs a script: `echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT`. The 3rd step is named ` Set up QEMU`. This step runs action `docker/setup-qemu-action` tagged as v3. The 4th step is named ` Set up Docker Buildx`. This step runs action `docker/setup-buildx-action` tagged as v3. The step defines an input parameter for the action: `platforms` is set to `linux/amd64,linux/arm64,linux/arm/v7`. The 5th step is named ` Extract Docker metadata` and its id is `meta`. This step runs action `docker/metadata-action` tagged as v5. The step defines 2 input parameters for the action: `images` is set to `${{ env.DOCKER_REGISTRY }}/${{ env.DOCKER_IMAGE_NAME }}\n${{ env.DOCKERHUB_REPOSITORY }}\n` and `tags` is set to `type=semver,pattern={{version}}\ntype=semver,pattern={{major}}.{{minor}}\ntype=sha\n`. The 6th step is named ` Log in to GitHub Registry`. This step runs action `docker/login-action` tagged as v3. The step defines 3 input parameters for the action: `registry` is set to `${{ env.DOCKER_REGISTRY }}`, `username` is set to `${{ github.actor }}` and `password` is set to `${{ secrets.GITHUB_TOKEN }}`. The 7th step is named ` Log in to Docker Hub`. This step runs action `docker/login-action` tagged as v3. The step defines 2 input parameters for the action: `username` is set to `${{ secrets.DOCKERHUB_USERNAME }}` and `password` is set to `${{ secrets.DOCKERHUB_TOKEN }}`. The 8th step is named ` Build and Push`. This step runs action `docker/build-push-action` tagged as v5. The step defines 7 input parameters for the action: `context` is set to `.`, `platforms` is set to `linux/amd64,linux/arm64,linux/arm/v7`, `push` is set to `True`, `tags` is set to `${{ steps.meta.outputs.tags }}`, `labels` is set to `${{ steps.meta.outputs.labels }}`, `cache-from` is set to `type=gha` and `cache-to` is set to `type=gha,mode=max`. The 2nd job is named ` Publish Release` and its job id is `publish-release`. Before this job runs, `docker-build` must complete successfully. This job will run on ubuntu-latest runner. The job `publish-release` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting only applies to the job `publish-release`. The job `publish-release` has 3 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named ` Extract version from tag` and its id is `get_version`. This step runs a script: `echo \"VERSION=${GITHUB_REF#refs/tags/}\" >> $GITHUB_OUTPUT`. The 3rd step is named ` Create Release`. This step runs action `softprops/action-gh-release` tagged as v1. The step defines 5 input parameters for the action: `name` is set to ` Release v${{ steps.get_version.outputs.VERSION }}`, `tag_name` is set to `${{ steps.get_version.outputs.VERSION }}`, `generate_release_notes` is set to `True`, `draft` is set to `False` and `prerelease` is set to `False`. ","nb_triggers":1,"triggers":["push"],"nb_jobs":2,"nb_actions":9,"actions":["actions/checkout","actions/checkout","docker/build-push-action","docker/login-action","docker/login-action","docker/metadata-action","docker/setup-buildx-action","docker/setup-qemu-action","softprops/action-gh-release"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v3","name":"docker/setup-qemu-action"},{"version":"v3","name":"docker/setup-buildx-action"},{"version":"v5","name":"docker/metadata-action"},{"version":"v3","name":"docker/login-action"},{"version":"v3","name":"docker/login-action"},{"version":"v5","name":"docker/build-push-action"},{"version":"v4","name":"actions/checkout"},{"version":"v1","name":"softprops/action-gh-release"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":11,"cyclomatic_complexity":1}
{"id":17796,"repository_id":1050286,"mainLanguage":"Java","file_name":"unassign-issues.yml","file_content":"name: Unassign stale issue assignments\n\non:\n  schedule:\n    - cron: 4 12 * * *\n  workflow_dispatch:\n\njobs:\n  unassign_issues:\n    if: github.repository == 'JabRef/jabref'\n    runs-on: ubuntu-latest\n    permissions:\n      issues: write\n    outputs:\n      unassigned_issues: ${{ steps.unassign.outputs.unassigned_issues || '[]' }}\n    steps:\n      - name: Unassign stale assignments\n        id: unassign\n        uses: takanome-dev/assign-issue-action@edge\n        with:\n          github_token: '${{ secrets.GITHUB_TOKEN }}'\n          reminder_comment: |\n              ###  Assignment Reminder\n\n              Hi @{{ handle }}, this is a friendly reminder about your assignment to this issue.\n\n              > [!WARNING]\n              > This issue will be **automatically unassigned** in **{{ days_remaining }} days** if there's no activity.\n\n              <details open>\n              <summary>How to keep your assignment</summary>\n\n              \\\n              If you are working on it, you can prevent automatic unassignment by:\n\n              - Submitting a draft PR with your progress\n              - Asking for the **{{{ pin_label }}}** label if you need more time\n              </details>\n\n              We appreciate your contribution and are here to help if needed!\n          days_until_unassign: 21\n          unassigned_comment: |\n            ###  Assignment Update\n\n            Hi @{{ handle }}, due to inactivity, you have been unassigned from this issue.\n\n            <details>\n            <summary>Next steps</summary>\n\n            \\\n            **If you still want to work on this:**\n            - Submit a pull request showing your current state. You will be automatically assigned again.\n            - Ask a maintainer to assign you again.\n            </details>\n      - name: Print unassigned issues\n        run: >\n          echo \"Unassigned issues: ${{ steps.unassign.outputs.unassigned_issues }}\"\n\n  move_unassigned_issues:\n    needs: unassign_issues\n    if: ${{ needs.unassign_issues.outputs.unassigned_issues != '[]' }}\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        issue_number: ${{ fromJson(needs.unassign_issues.outputs.unassigned_issues) }}\n    steps:\n      - name: Move issue to \"Free to take\" in \"Good First Issues\"\n        uses: m7kvqbe1/github-action-move-issues/@add-issue-parameter\n        with:\n          github-token: ${{ secrets.GH_TOKEN_ACTION_MOVE_ISSUE }}\n          project-url: \"https://github.com/orgs/JabRef/projects/5\"\n          target-labels: \" Assigned\"\n          target-column: \"Free to take\"\n          ignored-columns: \"\"\n          default-column: \"Free to take\"\n          issue-number: ${{ matrix.issue_number }}\n          skip-if-not-in-project: true\n      - name: Move issue to \"Free to take\" in \"Candidates for University Projects\"\n        uses: m7kvqbe1/github-action-move-issues/@add-issue-parameter\n        with:\n          github-token: ${{ secrets.GH_TOKEN_ACTION_MOVE_ISSUE }}\n          project-url: \"https://github.com/orgs/JabRef/projects/3\"\n          target-labels: \" Assigned\"\n          target-column: \"Free to take\"\n          ignored-columns: \"\"\n          default-column: \"Free to take\"\n          issue-number: ${{ matrix.issue_number }}\n          skip-if-not-in-project: true\n","repository_owner":"jabref","repository_name":"jabref","tokens_count":732,"workflow":"name: Unassign stale issue assignments\n\non:\n  schedule:\n  - cron: 4 12 * * *\n  workflow_dispatch:\n\njobs:\n  unassign_issues:\n    if: github.repository == 'JabRef/jabref'\n    runs-on: ubuntu-latest\n    permissions:\n      issues: write\n    outputs:\n      unassigned_issues: ${{ steps.unassign.outputs.unassigned_issues || '[]' }}\n    steps:\n    - name: Unassign stale assignments\n      id: unassign\n      uses: takanome-dev/assign-issue-action@edge\n      with:\n        github_token: ${{ secrets.GITHUB_TOKEN }}\n        reminder_comment: |\n          ###  Assignment Reminder\n\n          Hi @{{ handle }}, this is a friendly reminder about your assignment to this issue.\n\n          > [!WARNING]\n          > This issue will be **automatically unassigned** in **{{ days_remaining }} days** if there's no activity.\n\n          <details open>\n          <summary>How to keep your assignment</summary>\n\n          \\\n          If you are working on it, you can prevent automatic unassignment by:\n\n          - Submitting a draft PR with your progress\n          - Asking for the **{{{ pin_label }}}** label if you need more time\n          </details>\n\n          We appreciate your contribution and are here to help if needed!\n        days_until_unassign: 21\n        unassigned_comment: |\n          ###  Assignment Update\n\n          Hi @{{ handle }}, due to inactivity, you have been unassigned from this issue.\n\n          <details>\n          <summary>Next steps</summary>\n\n          \\\n          **If you still want to work on this:**\n          - Submit a pull request showing your current state. You will be automatically assigned again.\n          - Ask a maintainer to assign you again.\n          </details>\n    - name: Print unassigned issues\n      run: >\n        echo \"Unassigned issues: ${{ steps.unassign.outputs.unassigned_issues }}\"\n\n  move_unassigned_issues:\n    needs: unassign_issues\n    if: ${{ needs.unassign_issues.outputs.unassigned_issues != '[]' }}\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        issue_number: ${{ \n          fromJson(needs.unassign_issues.outputs.unassigned_issues) }}\n    steps:\n    - name: Move issue to \"Free to take\" in \"Good First Issues\"\n      uses: m7kvqbe1/github-action-move-issues/@add-issue-parameter\n      with:\n        github-token: ${{ secrets.GH_TOKEN_ACTION_MOVE_ISSUE }}\n        project-url: https://github.com/orgs/JabRef/projects/5\n        target-labels:  Assigned\n        target-column: Free to take\n        ignored-columns: ''\n        default-column: Free to take\n        issue-number: ${{ matrix.issue_number }}\n        skip-if-not-in-project: true\n    - name: Move issue to \"Free to take\" in \"Candidates for University Projects\"\n      uses: m7kvqbe1/github-action-move-issues/@add-issue-parameter\n      with:\n        github-token: ${{ secrets.GH_TOKEN_ACTION_MOVE_ISSUE }}\n        project-url: https://github.com/orgs/JabRef/projects/3\n        target-labels:  Assigned\n        target-column: Free to take\n        ignored-columns: ''\n        default-column: Free to take\n        issue-number: ${{ matrix.issue_number }}\n        skip-if-not-in-project: true\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Unassign stale issue assignments` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 12:04 pm. 2) someone manually triggers the workflow. The workflow has 2 jobs. The job id of the 1st job is `unassign_issues`. The job id of the 2nd job is `move_unassigned_issues`. ","prompt_level2":"Generate a GitHub Workflow named `Unassign stale issue assignments` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 12:04 pm. 2) someone manually triggers the workflow. The workflow has 2 jobs. The job id of the 1st job is `unassign_issues`. The job `unassign_issues` has 2 steps. The 1st step is named `Unassign stale assignments` and its id is `unassign`. The 2nd step is named `Print unassigned issues`. The job id of the 2nd job is `move_unassigned_issues`. The job `move_unassigned_issues` has 2 steps. The 1st step is named `Move issue to \"Free to take\" in \"Good First Issues\"`. The 2nd step is named `Move issue to \"Free to take\" in \"Candidates for University Projects\"`. ","prompt_level3":"Generate a GitHub Workflow named `Unassign stale issue assignments` for a GitHub repository whose primary programming language is Java. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 12:04 pm. 2) someone manually triggers the workflow. The workflow has 2 jobs. The job id of the 1st job is `unassign_issues`. This job will run only if the condition(github.repository == 'JabRef/jabref') is met. This job will run on ubuntu-latest runner. The job `unassign_issues` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `issues` scope. This permission setting only applies to the job `unassign_issues`. The job `unassign_issues` has 2 steps. The 1st step is named `Unassign stale assignments` and its id is `unassign`. This step runs action `takanome-dev/assign-issue-action` from the edge branch. The step defines 4 input parameters for the action: `github_token` is set to `${{ secrets.GITHUB_TOKEN }}`, `reminder_comment` is set to `###  Assignment Reminder\n\nHi @{{ handle }}, this is a friendly reminder about your assignment to this issue.\n\n> [!WARNING]\n> This issue will be **automatically unassigned** in **{{ days_remaining }} days** if there's no activity.\n\n<details open>\n<summary>How to keep your assignment</summary>\n\n\\\nIf you are working on it, you can prevent automatic unassignment by:\n\n- Submitting a draft PR with your progress\n- Asking for the **{{{ pin_label }}}** label if you need more time\n</details>\n\nWe appreciate your contribution and are here to help if needed!\n`, `days_until_unassign` is set to `21` and `unassigned_comment` is set to `###  Assignment Update\n\nHi @{{ handle }}, due to inactivity, you have been unassigned from this issue.\n\n<details>\n<summary>Next steps</summary>\n\n\\\n**If you still want to work on this:**\n- Submit a pull request showing your current state. You will be automatically assigned again.\n- Ask a maintainer to assign you again.\n</details>\n`. The 2nd step is named `Print unassigned issues`. This step runs a script: `echo \"Unassigned issues: ${{ steps.unassign.outputs.unassigned_issues }}\"\n`. This job has an output: `unassigned_issues` is defined as ${{ steps.unassign.outputs.unassigned_issues || '[]' }}. The job id of the 2nd job is `move_unassigned_issues`. Before this job runs, `unassign_issues` must complete successfully. This job will run only if the condition(${{ needs.unassign_issues.outputs.unassigned_issues != '[]' }}) is met. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `issue_number` has 64 values: $, {, {,  , f, r, o, m, J, s, o, n, (, n, e, e, d, s, ., u, n, a, s, s, i, g, n, _, i, s, s, u, e, s, ., o, u, t, p, u, t, s, ., u, n, a, s, s, i, g, n, e, d, _, i, s, s, u, e, s, ),  , } and }. The job `move_unassigned_issues` has 2 steps. The 1st step is named `Move issue to \"Free to take\" in \"Good First Issues\"`. This step runs action `m7kvqbe1/github-action-move-issues/` from the add-issue-parameter branch. The step defines 8 input parameters for the action: `github-token` is set to `${{ secrets.GH_TOKEN_ACTION_MOVE_ISSUE }}`, `project-url` is set to `https://github.com/orgs/JabRef/projects/5`, `target-labels` is set to ` Assigned`, `target-column` is set to `Free to take`, `ignored-columns` is set to ``, `default-column` is set to `Free to take`, `issue-number` is set to `${{ matrix.issue_number }}` and `skip-if-not-in-project` is set to `True`. The 2nd step is named `Move issue to \"Free to take\" in \"Candidates for University Projects\"`. This step runs action `m7kvqbe1/github-action-move-issues/` from the add-issue-parameter branch. The step defines 8 input parameters for the action: `github-token` is set to `${{ secrets.GH_TOKEN_ACTION_MOVE_ISSUE }}`, `project-url` is set to `https://github.com/orgs/JabRef/projects/3`, `target-labels` is set to ` Assigned`, `target-column` is set to `Free to take`, `ignored-columns` is set to ``, `default-column` is set to `Free to take`, `issue-number` is set to `${{ matrix.issue_number }}` and `skip-if-not-in-project` is set to `True`. ","nb_triggers":2,"triggers":["schedule","workflow_dispatch"],"nb_jobs":2,"nb_actions":3,"actions":["m7kvqbe1/github-action-move-issues/","m7kvqbe1/github-action-move-issues/","takanome-dev/assign-issue-action"],"actions_details":[{"version":"edge","name":"takanome-dev/assign-issue-action"},{"version":"add-issue-parameter","name":"m7kvqbe1/github-action-move-issues/"},{"version":"add-issue-parameter","name":"m7kvqbe1/github-action-move-issues/"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":4,"cyclomatic_complexity":1}
{"id":21121,"repository_id":18239562,"mainLanguage":"Go","file_name":"job-test-in-container.yml","file_content":"# This job runs integration tests inside a container, for all supported variants (ipv6, canary, etc)\n# Note that it is linux and nerdctl (+/- gomodjail) only.\nname: job-test-in-container\n\non:\n  workflow_call:\n    inputs:\n      timeout:\n        required: true\n        type: number\n      runner:\n        required: true\n        type: string\n      canary:\n        required: false\n        default: false\n        type: boolean\n      target:\n        required: false\n        default: ''\n        type: string\n      binary:\n        required: false\n        default: nerdctl\n        type: string\n      containerd-version:\n        required: false\n        default: ''\n        type: string\n      rootlesskit-version:\n        required: false\n        default: ''\n        type: string\n      ipv6:\n        required: false\n        default: false\n        type: boolean\n\nenv:\n  GOTOOLCHAIN: local\n\njobs:\n  test:\n    name: |\n      ${{ inputs.binary != 'nerdctl' && format('{0} < ', inputs.binary) || '' }}\n      ${{ inputs.target }}\n      ${{ contains(inputs.runner, 'arm') && '(arm)' || '' }}\n      ${{ contains(inputs.runner, '22.04') && '(old ubuntu)' || '' }}\n      ${{ inputs.ipv6 && ' (ipv6)' || '' }}\n      ${{ inputs.canary && ' (canary)' || '' }}\n      ${{ inputs.containerd-version && format(' (ctd: {0})', inputs.containerd-version) || '' }}\n      ${{ inputs.rootlesskit-version && format(' (rlk: {0})', inputs.rootlesskit-version) || '' }}\n    timeout-minutes: ${{ inputs.timeout }}\n    runs-on: ${{ inputs.runner }}\n    defaults:\n      run:\n        shell: bash\n\n    steps:\n      - name: \"Init: checkout\"\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683  # v4.2.2\n        with:\n          fetch-depth: 1\n\n      - name: \"Init: expose GitHub Runtime variables for gha\"\n        uses: crazy-max/ghaction-github-runtime@3cb05d89e1f492524af3d41a1c98c83bc3025124  # v3.1.0\n\n      - name: \"Init: register QEMU (tonistiigi/binfmt)\"\n        run: |\n          # `--install all` will only install emulation for architectures that cannot be natively executed\n          # Since some arm64 platforms do provide native fallback execution for 32 bits,\n          # armv7 emulation may or may not be installed, causing variance in the result of `uname -m`.\n          # To avoid that, we explicitly list the architectures we do want emulation for.\n          docker run --privileged --rm tonistiigi/binfmt --install linux/amd64\n          docker run --privileged --rm tonistiigi/binfmt --install linux/arm64\n          docker run --privileged --rm tonistiigi/binfmt --install linux/arm/v7\n      - if: ${{ inputs.canary }}\n        name: \"Init (canary): prepare updated test image\"\n        run: |\n          . ./hack/build-integration-canary.sh\n          canary::build::integration\n      - if: ${{ ! inputs.canary }}\n        name: \"Init: prepare test image\"\n        run: |\n          buildargs=()\n          # If the runner is old, use old ubuntu inside the container as well\n          [ \"${{ contains(inputs.runner, '22.04') }}\" != \"true\" ] || buildargs=(--build-arg UBUNTU_VERSION=22.04)\n          # Honor if we want old containerd\n          [ \"${{ inputs.containerd-version }}\" == \"\" ] || buildargs+=(--build-arg CONTAINERD_VERSION=${{ inputs.containerd-version }})\n          # Honor custom targets and if we want old rootlesskit\n          target=test-integration\n          if [ \"${{ inputs.target }}\" != \"rootful\" ]; then\n            target+=-${{ inputs.target }}\n            if [ \"${{ inputs.rootlesskit-version }}\" != \"\" ]; then\n              buildargs+=(--build-arg ROOTLESSKIT_VERSION=${{ inputs.rootlesskit-version }})\n            fi\n          fi\n          # Cache is sharded per-architecture\n          arch=${{ env.RUNNER_ARCH == 'ARM64' && 'arm64' || 'amd64' }}\n          docker buildx create --name with-gha --use\n          docker buildx build \\\n            --output=type=docker \\\n            --cache-from type=gha,scope=test-integration-dependencies-\"$arch\" \\\n            -t \"$target\" --target \"$target\" \\\n            \"${buildargs[@]}\" \\\n            .\n      # Rootful needs to disable snap\n      - if: ${{ inputs.target == 'rootful' }}\n        name: \"Init: remove snap loopback devices (conflicts with our loopback devices in TestRunDevice)\"\n        run: |\n          sudo systemctl disable --now snapd.service snapd.socket\n          sudo apt-get purge -qq snapd\n          sudo losetup -Dv\n          sudo losetup -lv\n      # Rootless on modern ubuntu wants apparmor\n      - if: ${{ inputs.target != 'rootful' && ! contains(inputs.runner, '22.04') }}\n        name: \"Init: prepare apparmor for rootless + ubuntu 24+\"\n        run: |\n          cat <<EOT | sudo tee \"/etc/apparmor.d/usr.local.bin.rootlesskit\"\n          abi <abi/4.0>,\n          include <tunables/global>\n          /usr/local/bin/rootlesskit flags=(unconfined) {\n            userns,\n            # Site-specific additions and overrides. See local/README for details.\n            include if exists <local/usr.local.bin.rootlesskit>\n          }\n          EOT\n          sudo systemctl restart apparmor.service\n      # ipv6 wants... ipv6\n      - if: ${{ inputs.ipv6 }}\n        name: \"Init: ipv6\"\n        run: |\n          # Enable ipv4 and ipv6 forwarding\n          sudo sysctl -w net.ipv6.conf.all.forwarding=1\n          sudo sysctl -w net.ipv4.ip_forward=1\n          # Enable IPv6 for Docker, and configure docker to use containerd for gha\n          sudo mkdir -p /etc/docker\n          echo '{\"ipv6\": true, \"fixed-cidr-v6\": \"2001:db8:1::/64\", \"experimental\": true, \"ip6tables\": true}' | sudo tee /etc/docker/daemon.json\n          sudo systemctl restart docker\n      # Rootless with old rootlesskit wants to disable buildkit\n      - if: ${{ inputs.target != 'rootful' && inputs.rootlesskit-version != '' }}\n        name: \"Init: disable buildkit for old rootlesskit\"\n        run: |\n          # https://github.com/containerd/nerdctl/issues/622\n          WORKAROUND_ISSUE_622=\n          if echo \"${ROOTLESSKIT_VERSION}\" | grep -q v1; then\n            WORKAROUND_ISSUE_622=1\n          fi\n          echo \"WORKAROUND_ISSUE_622=$WORKAROUND_ISSUE_622\" >> \"$GITHUB_ENV\"\n      - name: \"Run: integration tests\"\n        run: |\n          . ./hack/github/action-helpers.sh\n          github::md::h2 \"non-flaky\" >> \"$GITHUB_STEP_SUMMARY\"\n\n          # IPV6 note: nested IPv6 network inside docker and qemu is complex and needs a bunch of sysctl config.\n          # Therefore, it's hard to debug why the IPv6 tests fail in such an isolation layer.\n          # On the other side, using the host network is easier at configuration.\n          # Besides, each job is running on a different instance, which means using host network here\n          # is safe and has no side effects on others.\n          [ \"${{ inputs.target }}\" == \"rootful\" ] \\\n            && args=(test-integration ./hack/test-integration.sh) \\\n            || args=(test-integration-${{ inputs.target }} /test-integration-rootless.sh ./hack/test-integration.sh)\n          if [ \"${{ inputs.ipv6 }}\" == true ]; then\n            docker run --network host -t --rm --privileged -e GITHUB_STEP_SUMMARY=\"$GITHUB_STEP_SUMMARY\" -v \"$GITHUB_STEP_SUMMARY\":\"$GITHUB_STEP_SUMMARY\" -e WORKAROUND_ISSUE_622=${WORKAROUND_ISSUE_622:-} \"${args[@]}\" -test.only-flaky=false -test.only-ipv6 -test.target=${{ inputs.binary }}\n          else\n            docker run -t --rm --privileged -e GITHUB_STEP_SUMMARY=\"$GITHUB_STEP_SUMMARY\" -v \"$GITHUB_STEP_SUMMARY\":\"$GITHUB_STEP_SUMMARY\" -e WORKAROUND_ISSUE_622=${WORKAROUND_ISSUE_622:-} \"${args[@]}\" -test.only-flaky=false -test.target=${{ inputs.binary }}\n          fi\n      # FIXME: this NEEDS to go away\n      - name: \"Run: integration tests (flaky)\"\n        run: |\n          . ./hack/github/action-helpers.sh\n          github::md::h2 \"flaky\" >> \"$GITHUB_STEP_SUMMARY\"\n\n          [ \"${{ inputs.target }}\" == \"rootful\" ] \\\n            && args=(test-integration ./hack/test-integration.sh) \\\n            || args=(test-integration-${{ inputs.target }} /test-integration-rootless.sh ./hack/test-integration.sh)\n          if [ \"${{ inputs.ipv6 }}\" == true ]; then\n            docker run --network host -t --rm --privileged -e GITHUB_STEP_SUMMARY=\"$GITHUB_STEP_SUMMARY\" -v \"$GITHUB_STEP_SUMMARY\":\"$GITHUB_STEP_SUMMARY\" -e WORKAROUND_ISSUE_622=${WORKAROUND_ISSUE_622:-} \"${args[@]}\" -test.only-flaky=true -test.only-ipv6 -test.target=${{ inputs.binary }}\n          else\n            docker run -t --rm --privileged -e GITHUB_STEP_SUMMARY=\"$GITHUB_STEP_SUMMARY\" -v \"$GITHUB_STEP_SUMMARY\":\"$GITHUB_STEP_SUMMARY\" -e WORKAROUND_ISSUE_622=${WORKAROUND_ISSUE_622:-} \"${args[@]}\" -test.only-flaky=true -test.target=${{ inputs.binary }}\n          fi\n","repository_owner":"containerd","repository_name":"nerdctl","tokens_count":2312,"workflow":"# This job runs integration tests inside a container, for all supported variants (ipv6, canary, etc)\n# Note that it is linux and nerdctl (+/- gomodjail) only.\nname: job-test-in-container\n\non:\n  workflow_call:\n    inputs:\n      timeout:\n        required: true\n        type: number\n      runner:\n        required: true\n        type: string\n      canary:\n        required: false\n        default: false\n        type: boolean\n      target:\n        required: false\n        default: ''\n        type: string\n      binary:\n        required: false\n        default: nerdctl\n        type: string\n      containerd-version:\n        required: false\n        default: ''\n        type: string\n      rootlesskit-version:\n        required: false\n        default: ''\n        type: string\n      ipv6:\n        required: false\n        default: false\n        type: boolean\n\nenv:\n  GOTOOLCHAIN: local\n\njobs:\n  test:\n    name: |\n      ${{ inputs.binary != 'nerdctl' && format('{0} < ', inputs.binary) || '' }}\n      ${{ inputs.target }}\n      ${{ contains(inputs.runner, 'arm') && '(arm)' || '' }}\n      ${{ contains(inputs.runner, '22.04') && '(old ubuntu)' || '' }}\n      ${{ inputs.ipv6 && ' (ipv6)' || '' }}\n      ${{ inputs.canary && ' (canary)' || '' }}\n      ${{ inputs.containerd-version && format(' (ctd: {0})', inputs.containerd-version) || '' }}\n      ${{ inputs.rootlesskit-version && format(' (rlk: {0})', inputs.rootlesskit-version) || '' }}\n    timeout-minutes: ${{ inputs.timeout }}\n    runs-on: ${{ inputs.runner }}\n    defaults:\n      run:\n        shell: bash\n\n    steps:\n    - name: 'Init: checkout'\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683    # v4.2.2\n      with:\n        fetch-depth: 1\n\n    - name: 'Init: expose GitHub Runtime variables for gha'\n      uses: \n        crazy-max/ghaction-github-runtime@3cb05d89e1f492524af3d41a1c98c83bc3025124        # v3.1.0\n\n    - name: 'Init: register QEMU (tonistiigi/binfmt)'\n      run: |\n        # `--install all` will only install emulation for architectures that cannot be natively executed\n        # Since some arm64 platforms do provide native fallback execution for 32 bits,\n        # armv7 emulation may or may not be installed, causing variance in the result of `uname -m`.\n        # To avoid that, we explicitly list the architectures we do want emulation for.\n        docker run --privileged --rm tonistiigi/binfmt --install linux/amd64\n        docker run --privileged --rm tonistiigi/binfmt --install linux/arm64\n        docker run --privileged --rm tonistiigi/binfmt --install linux/arm/v7\n    - if: ${{ inputs.canary }}\n      name: 'Init (canary): prepare updated test image'\n      run: |\n        . ./hack/build-integration-canary.sh\n        canary::build::integration\n    - if: ${{ ! inputs.canary }}\n      name: 'Init: prepare test image'\n      run: |\n        buildargs=()\n        # If the runner is old, use old ubuntu inside the container as well\n        [ \"${{ contains(inputs.runner, '22.04') }}\" != \"true\" ] || buildargs=(--build-arg UBUNTU_VERSION=22.04)\n        # Honor if we want old containerd\n        [ \"${{ inputs.containerd-version }}\" == \"\" ] || buildargs+=(--build-arg CONTAINERD_VERSION=${{ inputs.containerd-version }})\n        # Honor custom targets and if we want old rootlesskit\n        target=test-integration\n        if [ \"${{ inputs.target }}\" != \"rootful\" ]; then\n          target+=-${{ inputs.target }}\n          if [ \"${{ inputs.rootlesskit-version }}\" != \"\" ]; then\n            buildargs+=(--build-arg ROOTLESSKIT_VERSION=${{ inputs.rootlesskit-version }})\n          fi\n        fi\n        # Cache is sharded per-architecture\n        arch=${{ env.RUNNER_ARCH == 'ARM64' && 'arm64' || 'amd64' }}\n        docker buildx create --name with-gha --use\n        docker buildx build \\\n          --output=type=docker \\\n          --cache-from type=gha,scope=test-integration-dependencies-\"$arch\" \\\n          -t \"$target\" --target \"$target\" \\\n          \"${buildargs[@]}\" \\\n          .\n      # Rootful needs to disable snap\n    - if: ${{ inputs.target == 'rootful' }}\n      name: 'Init: remove snap loopback devices (conflicts with our loopback devices\n        in TestRunDevice)'\n      run: |\n        sudo systemctl disable --now snapd.service snapd.socket\n        sudo apt-get purge -qq snapd\n        sudo losetup -Dv\n        sudo losetup -lv\n      # Rootless on modern ubuntu wants apparmor\n    - if: ${{ inputs.target != 'rootful' && ! contains(inputs.runner, '22.04') \n        }}\n      name: 'Init: prepare apparmor for rootless + ubuntu 24+'\n      run: |\n        cat <<EOT | sudo tee \"/etc/apparmor.d/usr.local.bin.rootlesskit\"\n        abi <abi/4.0>,\n        include <tunables/global>\n        /usr/local/bin/rootlesskit flags=(unconfined) {\n          userns,\n          # Site-specific additions and overrides. See local/README for details.\n          include if exists <local/usr.local.bin.rootlesskit>\n        }\n        EOT\n        sudo systemctl restart apparmor.service\n      # ipv6 wants... ipv6\n    - if: ${{ inputs.ipv6 }}\n      name: 'Init: ipv6'\n      run: |\n        # Enable ipv4 and ipv6 forwarding\n        sudo sysctl -w net.ipv6.conf.all.forwarding=1\n        sudo sysctl -w net.ipv4.ip_forward=1\n        # Enable IPv6 for Docker, and configure docker to use containerd for gha\n        sudo mkdir -p /etc/docker\n        echo '{\"ipv6\": true, \"fixed-cidr-v6\": \"2001:db8:1::/64\", \"experimental\": true, \"ip6tables\": true}' | sudo tee /etc/docker/daemon.json\n        sudo systemctl restart docker\n      # Rootless with old rootlesskit wants to disable buildkit\n    - if: ${{ inputs.target != 'rootful' && inputs.rootlesskit-version != '' }}\n      name: 'Init: disable buildkit for old rootlesskit'\n      run: |\n        # https://github.com/containerd/nerdctl/issues/622\n        WORKAROUND_ISSUE_622=\n        if echo \"${ROOTLESSKIT_VERSION}\" | grep -q v1; then\n          WORKAROUND_ISSUE_622=1\n        fi\n        echo \"WORKAROUND_ISSUE_622=$WORKAROUND_ISSUE_622\" >> \"$GITHUB_ENV\"\n    - name: 'Run: integration tests'\n      run: |\n        . ./hack/github/action-helpers.sh\n        github::md::h2 \"non-flaky\" >> \"$GITHUB_STEP_SUMMARY\"\n\n        # IPV6 note: nested IPv6 network inside docker and qemu is complex and needs a bunch of sysctl config.\n        # Therefore, it's hard to debug why the IPv6 tests fail in such an isolation layer.\n        # On the other side, using the host network is easier at configuration.\n        # Besides, each job is running on a different instance, which means using host network here\n        # is safe and has no side effects on others.\n        [ \"${{ inputs.target }}\" == \"rootful\" ] \\\n          && args=(test-integration ./hack/test-integration.sh) \\\n          || args=(test-integration-${{ inputs.target }} /test-integration-rootless.sh ./hack/test-integration.sh)\n        if [ \"${{ inputs.ipv6 }}\" == true ]; then\n          docker run --network host -t --rm --privileged -e GITHUB_STEP_SUMMARY=\"$GITHUB_STEP_SUMMARY\" -v \"$GITHUB_STEP_SUMMARY\":\"$GITHUB_STEP_SUMMARY\" -e WORKAROUND_ISSUE_622=${WORKAROUND_ISSUE_622:-} \"${args[@]}\" -test.only-flaky=false -test.only-ipv6 -test.target=${{ inputs.binary }}\n        else\n          docker run -t --rm --privileged -e GITHUB_STEP_SUMMARY=\"$GITHUB_STEP_SUMMARY\" -v \"$GITHUB_STEP_SUMMARY\":\"$GITHUB_STEP_SUMMARY\" -e WORKAROUND_ISSUE_622=${WORKAROUND_ISSUE_622:-} \"${args[@]}\" -test.only-flaky=false -test.target=${{ inputs.binary }}\n        fi\n      # FIXME: this NEEDS to go away\n    - name: 'Run: integration tests (flaky)'\n      run: |\n        . ./hack/github/action-helpers.sh\n        github::md::h2 \"flaky\" >> \"$GITHUB_STEP_SUMMARY\"\n\n        [ \"${{ inputs.target }}\" == \"rootful\" ] \\\n          && args=(test-integration ./hack/test-integration.sh) \\\n          || args=(test-integration-${{ inputs.target }} /test-integration-rootless.sh ./hack/test-integration.sh)\n        if [ \"${{ inputs.ipv6 }}\" == true ]; then\n          docker run --network host -t --rm --privileged -e GITHUB_STEP_SUMMARY=\"$GITHUB_STEP_SUMMARY\" -v \"$GITHUB_STEP_SUMMARY\":\"$GITHUB_STEP_SUMMARY\" -e WORKAROUND_ISSUE_622=${WORKAROUND_ISSUE_622:-} \"${args[@]}\" -test.only-flaky=true -test.only-ipv6 -test.target=${{ inputs.binary }}\n        else\n          docker run -t --rm --privileged -e GITHUB_STEP_SUMMARY=\"$GITHUB_STEP_SUMMARY\" -v \"$GITHUB_STEP_SUMMARY\":\"$GITHUB_STEP_SUMMARY\" -e WORKAROUND_ISSUE_622=${WORKAROUND_ISSUE_622:-} \"${args[@]}\" -test.only-flaky=true -test.target=${{ inputs.binary }}\n        fi\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `job-test-in-container` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 8 inputs: timeout-it must be supplied and the data type is number; runner-it must be supplied and the data type is string; canary-it is optional, its default value is False and the data type is boolean; target-it is optional, its default value is  and the data type is string; binary-it is optional, its default value is nerdctl and the data type is string; containerd-version-it is optional, its default value is  and the data type is string; rootlesskit-version-it is optional, its default value is  and the data type is string; ipv6-it is optional, its default value is False and the data type is boolean. The workflow sets an environment variable to use: `GOTOOLCHAIN` is set to `local`. The workflow has one job. The 1st job is named `${{ inputs.binary != 'nerdctl' && format('{0} < ', inputs.binary) || '' }}\n${{ inputs.target }}\n${{ contains(inputs.runner, 'arm') && '(arm)' || '' }}\n${{ contains(inputs.runner, '22.04') && '(old ubuntu)' || '' }}\n${{ inputs.ipv6 && ' (ipv6)' || '' }}\n${{ inputs.canary && ' (canary)' || '' }}\n${{ inputs.containerd-version && format(' (ctd: {0})', inputs.containerd-version) || '' }}\n${{ inputs.rootlesskit-version && format(' (rlk: {0})', inputs.rootlesskit-version) || '' }}\n` and its job id is `test`. ","prompt_level2":"Generate a GitHub Workflow named `job-test-in-container` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 8 inputs: timeout-it must be supplied and the data type is number; runner-it must be supplied and the data type is string; canary-it is optional, its default value is False and the data type is boolean; target-it is optional, its default value is  and the data type is string; binary-it is optional, its default value is nerdctl and the data type is string; containerd-version-it is optional, its default value is  and the data type is string; rootlesskit-version-it is optional, its default value is  and the data type is string; ipv6-it is optional, its default value is False and the data type is boolean. The workflow sets an environment variable to use: `GOTOOLCHAIN` is set to `local`. The workflow has one job. The 1st job is named `${{ inputs.binary != 'nerdctl' && format('{0} < ', inputs.binary) || '' }}\n${{ inputs.target }}\n${{ contains(inputs.runner, 'arm') && '(arm)' || '' }}\n${{ contains(inputs.runner, '22.04') && '(old ubuntu)' || '' }}\n${{ inputs.ipv6 && ' (ipv6)' || '' }}\n${{ inputs.canary && ' (canary)' || '' }}\n${{ inputs.containerd-version && format(' (ctd: {0})', inputs.containerd-version) || '' }}\n${{ inputs.rootlesskit-version && format(' (rlk: {0})', inputs.rootlesskit-version) || '' }}\n` and its job id is `test`. The job `test` has 11 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Init: expose GitHub Runtime variables for gha`. The 3rd step is named `Init: register QEMU (tonistiigi/binfmt)`. The 4th step is named `Init (canary): prepare updated test image`. The 5th step is named `Init: prepare test image`. The 6th step is named `Init: remove snap loopback devices (conflicts with our loopback devices in TestRunDevice)`. The 7th step is named `Init: prepare apparmor for rootless + ubuntu 24+`. The 8th step is named `Init: ipv6`. The 9th step is named `Init: disable buildkit for old rootlesskit`. The 10th step is named `Run: integration tests`. The 11th step is named `Run: integration tests (flaky)`. ","prompt_level3":"Generate a GitHub Workflow named `job-test-in-container` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 8 inputs: timeout-it must be supplied and the data type is number; runner-it must be supplied and the data type is string; canary-it is optional, its default value is False and the data type is boolean; target-it is optional, its default value is  and the data type is string; binary-it is optional, its default value is nerdctl and the data type is string; containerd-version-it is optional, its default value is  and the data type is string; rootlesskit-version-it is optional, its default value is  and the data type is string; ipv6-it is optional, its default value is False and the data type is boolean. The workflow sets an environment variable to use: `GOTOOLCHAIN` is set to `local`. The workflow has one job. The 1st job is named `${{ inputs.binary != 'nerdctl' && format('{0} < ', inputs.binary) || '' }}\n${{ inputs.target }}\n${{ contains(inputs.runner, 'arm') && '(arm)' || '' }}\n${{ contains(inputs.runner, '22.04') && '(old ubuntu)' || '' }}\n${{ inputs.ipv6 && ' (ipv6)' || '' }}\n${{ inputs.canary && ' (canary)' || '' }}\n${{ inputs.containerd-version && format(' (ctd: {0})', inputs.containerd-version) || '' }}\n${{ inputs.rootlesskit-version && format(' (rlk: {0})', inputs.rootlesskit-version) || '' }}\n` and its job id is `test`. This job will run on ${{ inputs.runner }} runner. For all run steps in the job, default shell is set to bash. The maximum number of minutes to run the job is ${{ inputs.timeout }}. The job `test` has 11 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is 11bd71901bbe5b1630ceea73d27597364c9af683. The step defines an input parameter for the action: `fetch-depth` is set to `1`. The 2nd step is named `Init: expose GitHub Runtime variables for gha`. This step runs action `crazy-max/ghaction-github-runtime` whose commit is 3cb05d89e1f492524af3d41a1c98c83bc3025124. The 3rd step is named `Init: register QEMU (tonistiigi/binfmt)`. This step runs a script: `# `--install all` will only install emulation for architectures that cannot be natively executed\n# Since some arm64 platforms do provide native fallback execution for 32 bits,\n# armv7 emulation may or may not be installed, causing variance in the result of `uname -m`.\n# To avoid that, we explicitly list the architectures we do want emulation for.\ndocker run --privileged --rm tonistiigi/binfmt --install linux/amd64\ndocker run --privileged --rm tonistiigi/binfmt --install linux/arm64\ndocker run --privileged --rm tonistiigi/binfmt --install linux/arm/v7\n`. The 4th step is named `Init (canary): prepare updated test image`. This step will run only if the condition(${{ inputs.canary }}) is met. This step runs a script: `. ./hack/build-integration-canary.sh\ncanary::build::integration\n`. The 5th step is named `Init: prepare test image`. This step will run only if the condition(${{ ! inputs.canary }}) is met. This step runs a script: `buildargs=()\n# If the runner is old, use old ubuntu inside the container as well\n[ \"${{ contains(inputs.runner, '22.04') }}\" != \"true\" ] || buildargs=(--build-arg UBUNTU_VERSION=22.04)\n# Honor if we want old containerd\n[ \"${{ inputs.containerd-version }}\" == \"\" ] || buildargs+=(--build-arg CONTAINERD_VERSION=${{ inputs.containerd-version }})\n# Honor custom targets and if we want old rootlesskit\ntarget=test-integration\nif [ \"${{ inputs.target }}\" != \"rootful\" ]; then\n  target+=-${{ inputs.target }}\n  if [ \"${{ inputs.rootlesskit-version }}\" != \"\" ]; then\n    buildargs+=(--build-arg ROOTLESSKIT_VERSION=${{ inputs.rootlesskit-version }})\n  fi\nfi\n# Cache is sharded per-architecture\narch=${{ env.RUNNER_ARCH == 'ARM64' && 'arm64' || 'amd64' }}\ndocker buildx create --name with-gha --use\ndocker buildx build \\\n  --output=type=docker \\\n  --cache-from type=gha,scope=test-integration-dependencies-\"$arch\" \\\n  -t \"$target\" --target \"$target\" \\\n  \"${buildargs[@]}\" \\\n  .\n`. The 6th step is named `Init: remove snap loopback devices (conflicts with our loopback devices in TestRunDevice)`. This step will run only if the condition(${{ inputs.target == 'rootful' }}) is met. This step runs a script: `sudo systemctl disable --now snapd.service snapd.socket\nsudo apt-get purge -qq snapd\nsudo losetup -Dv\nsudo losetup -lv\n`. The 7th step is named `Init: prepare apparmor for rootless + ubuntu 24+`. This step will run only if the condition(${{ inputs.target != 'rootful' && ! contains(inputs.runner, '22.04') }}) is met. This step runs a script: `cat <<EOT | sudo tee \"/etc/apparmor.d/usr.local.bin.rootlesskit\"\nabi <abi/4.0>,\ninclude <tunables/global>\n/usr/local/bin/rootlesskit flags=(unconfined) {\n  userns,\n  # Site-specific additions and overrides. See local/README for details.\n  include if exists <local/usr.local.bin.rootlesskit>\n}\nEOT\nsudo systemctl restart apparmor.service\n`. The 8th step is named `Init: ipv6`. This step will run only if the condition(${{ inputs.ipv6 }}) is met. This step runs a script: `# Enable ipv4 and ipv6 forwarding\nsudo sysctl -w net.ipv6.conf.all.forwarding=1\nsudo sysctl -w net.ipv4.ip_forward=1\n# Enable IPv6 for Docker, and configure docker to use containerd for gha\nsudo mkdir -p /etc/docker\necho '{\"ipv6\": true, \"fixed-cidr-v6\": \"2001:db8:1::/64\", \"experimental\": true, \"ip6tables\": true}' | sudo tee /etc/docker/daemon.json\nsudo systemctl restart docker\n`. The 9th step is named `Init: disable buildkit for old rootlesskit`. This step will run only if the condition(${{ inputs.target != 'rootful' && inputs.rootlesskit-version != '' }}) is met. This step runs a script: `# https://github.com/containerd/nerdctl/issues/622\nWORKAROUND_ISSUE_622=\nif echo \"${ROOTLESSKIT_VERSION}\" | grep -q v1; then\n  WORKAROUND_ISSUE_622=1\nfi\necho \"WORKAROUND_ISSUE_622=$WORKAROUND_ISSUE_622\" >> \"$GITHUB_ENV\"\n`. The 10th step is named `Run: integration tests`. This step runs a script: `. ./hack/github/action-helpers.sh\ngithub::md::h2 \"non-flaky\" >> \"$GITHUB_STEP_SUMMARY\"\n\n# IPV6 note: nested IPv6 network inside docker and qemu is complex and needs a bunch of sysctl config.\n# Therefore, it's hard to debug why the IPv6 tests fail in such an isolation layer.\n# On the other side, using the host network is easier at configuration.\n# Besides, each job is running on a different instance, which means using host network here\n# is safe and has no side effects on others.\n[ \"${{ inputs.target }}\" == \"rootful\" ] \\\n  && args=(test-integration ./hack/test-integration.sh) \\\n  || args=(test-integration-${{ inputs.target }} /test-integration-rootless.sh ./hack/test-integration.sh)\nif [ \"${{ inputs.ipv6 }}\" == true ]; then\n  docker run --network host -t --rm --privileged -e GITHUB_STEP_SUMMARY=\"$GITHUB_STEP_SUMMARY\" -v \"$GITHUB_STEP_SUMMARY\":\"$GITHUB_STEP_SUMMARY\" -e WORKAROUND_ISSUE_622=${WORKAROUND_ISSUE_622:-} \"${args[@]}\" -test.only-flaky=false -test.only-ipv6 -test.target=${{ inputs.binary }}\nelse\n  docker run -t --rm --privileged -e GITHUB_STEP_SUMMARY=\"$GITHUB_STEP_SUMMARY\" -v \"$GITHUB_STEP_SUMMARY\":\"$GITHUB_STEP_SUMMARY\" -e WORKAROUND_ISSUE_622=${WORKAROUND_ISSUE_622:-} \"${args[@]}\" -test.only-flaky=false -test.target=${{ inputs.binary }}\nfi\n`. The 11th step is named `Run: integration tests (flaky)`. This step runs a script: `. ./hack/github/action-helpers.sh\ngithub::md::h2 \"flaky\" >> \"$GITHUB_STEP_SUMMARY\"\n\n[ \"${{ inputs.target }}\" == \"rootful\" ] \\\n  && args=(test-integration ./hack/test-integration.sh) \\\n  || args=(test-integration-${{ inputs.target }} /test-integration-rootless.sh ./hack/test-integration.sh)\nif [ \"${{ inputs.ipv6 }}\" == true ]; then\n  docker run --network host -t --rm --privileged -e GITHUB_STEP_SUMMARY=\"$GITHUB_STEP_SUMMARY\" -v \"$GITHUB_STEP_SUMMARY\":\"$GITHUB_STEP_SUMMARY\" -e WORKAROUND_ISSUE_622=${WORKAROUND_ISSUE_622:-} \"${args[@]}\" -test.only-flaky=true -test.only-ipv6 -test.target=${{ inputs.binary }}\nelse\n  docker run -t --rm --privileged -e GITHUB_STEP_SUMMARY=\"$GITHUB_STEP_SUMMARY\" -v \"$GITHUB_STEP_SUMMARY\":\"$GITHUB_STEP_SUMMARY\" -e WORKAROUND_ISSUE_622=${WORKAROUND_ISSUE_622:-} \"${args[@]}\" -test.only-flaky=true -test.target=${{ inputs.binary }}\nfi\n`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","crazy-max/ghaction-github-runtime"],"actions_details":[{"version":"11bd71901bbe5b1630ceea73d27597364c9af683","name":"actions/checkout"},{"version":"3cb05d89e1f492524af3d41a1c98c83bc3025124","name":"crazy-max/ghaction-github-runtime"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":11,"cyclomatic_complexity":1}
{"id":9201,"repository_id":17594298,"mainLanguage":"Go","file_name":"acceptance-tests.yml","file_content":"name: Acceptance Tests\nconcurrency:\n  group: acceptance-tests\n\non:\n  workflow_dispatch:\n  push:\n    branches:\n      - 'release-please**'\njobs:\n  acceptance-tests:\n    name: Acceptance Tests\n    runs-on: ${{ github.repository == 'stainless-sdks/cloudflare-terraform' && 'depot-ubuntu-24.04' || 'lx64' }}\n    env:\n      CLOUDFLARE_ACCOUNT_ID: f037e56e89293a057740de681ac9abbe\n      CLOUDFLARE_ALT_DOMAIN: terraform2.cfapi.net\n      CLOUDFLARE_ALT_ZONE_ID: b72110c08e3382597095c29ba7e661ea\n      CLOUDFLARE_DOMAIN: terraform.cfapi.net\n      CLOUDFLARE_EMAIL: terraform-acceptance-test@cfapi.net\n      CLOUDFLARE_ZONE_ID: 0da42c8d2132a9ddaf714f9e7c920711\n      CLOUDFLARE_MUTUAL_TLS_CERTIFICATE: \"-----BEGIN CERTIFICATE-----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\\\\nd8//SuQhuJQTxJW7UzkWaao+32gW/RvuQun0XtCNoow/kMVMOeSjKL9xioM=\\\\n-----END CERTIFICATE-----\"\n      CLOUDFLARE_API_KEY: ${{ secrets.CLOUDFLARE_API_KEY }}\n      # CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}\n      # CLOUDFLARE_API_USER_SERVICE_KEY: ${{ secrets.CLOUDFLARE_API_USER_SERVICE_KEY }}\n      CLOUDFLARE_LOGPUSH_OWNERSHIP_TOKEN: ${{ secrets.CLOUDFLARE_LOGPUSH_OWNERSHIP_TOKEN }}\n      CLOUDFLARE_WORKSPACE_ONE_CLIENT_ID: d0ed71f01c884e8b94ec4e4d6639f609\n      CLOUDFLARE_WORKSPACE_ONE_CLIENT_SECRET: ${{ secrets.CLOUDFLARE_WORKSPACE_ONE_CLIENT_SECRET }}\n      CLOUDFLARE_WORKSPACE_ONE_API_URL: ${{ secrets.CLOUDFLARE_WORKSPACE_ONE_API_URL }}\n      CLOUDFLARE_WORKSPACE_ONE_AUTH_URL: ${{ secrets.CLOUDFLARE_WORKSPACE_ONE_AUTH_URL }}\n      CLOUDFLARE_PAGES_OWNER: jacobbednarz\n      CLOUDFLARE_PAGES_REPO: pages-example\n      CLOUDFLARE_R2_ACCESS_KEY_ID: ${{ secrets.CLOUDFLARE_R2_ACCESS_KEY_ID }}\n      CLOUDFLARE_R2_ACCESS_KEY_SECRET: ${{ secrets.CLOUDFLARE_R2_ACCESS_KEY_SECRET }}\n      CLOUDFLARE_HYPERDRIVE_DATABASE_NAME: neondb\n      CLOUDFLARE_HYPERDRIVE_DATABASE_PORT: 5432\n      CLOUDFLARE_HYPERDRIVE_DATABASE_USER: neondb_owner\n      CLOUDFLARE_HYPERDRIVE_DATABASE_PASSWORD: ${{ secrets.CLOUDFLARE_HYPERDRIVE_DATABASE_PASSWORD }}\n      CLOUDFLARE_HYPERDRIVE_DATABASE_HOSTNAME: ${{ secrets.CLOUDFLARE_HYPERDRIVE_DATABASE_HOSTNAME }}\n    steps:\n    - uses: actions/checkout@v4\n    - name: Setup go\n      uses: actions/setup-go@v5\n      with:\n        go-version-file: ./go.mod\n    - name: Bootstrap\n      run: ./scripts/bootstrap\n    # when all resources support sweepers, re-enable.\n    #\n    # - name: Pre-Sweeper\n    #  run: go test ./internal/services/... -v -sweep=\"1\" -timeout 60m\n    - name: Run acceptance tests\n      run: go test ./internal/services/... -run \"^TestAcc\" -count 1\n      env:\n        TF_ACC: 1\n    # when all resources support sweepers, re-enable.\n    #\n    # - name: Post-Sweeper\n    #  if: ${{ always() }}\n    #  run: go test ./internal/services/... -v -sweep=\"1\" -timeout 60m\n","repository_owner":"cloudflare","repository_name":"terraform-provider-cloudflare","tokens_count":2431,"workflow":"name: Acceptance Tests\nconcurrency:\n  group: acceptance-tests\n\non:\n  workflow_dispatch:\n  push:\n    branches:\n    - release-please**\njobs:\n  acceptance-tests:\n    name: Acceptance Tests\n    runs-on: ${{ github.repository == 'stainless-sdks/cloudflare-terraform' && \n      'depot-ubuntu-24.04' || 'lx64' }}\n    env:\n      CLOUDFLARE_ACCOUNT_ID: f037e56e89293a057740de681ac9abbe\n      CLOUDFLARE_ALT_DOMAIN: terraform2.cfapi.net\n      CLOUDFLARE_ALT_ZONE_ID: b72110c08e3382597095c29ba7e661ea\n      CLOUDFLARE_DOMAIN: terraform.cfapi.net\n      CLOUDFLARE_EMAIL: terraform-acceptance-test@cfapi.net\n      CLOUDFLARE_ZONE_ID: 0da42c8d2132a9ddaf714f9e7c920711\n      CLOUDFLARE_MUTUAL_TLS_CERTIFICATE: '-----BEGIN CERTIFICATE-----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\\nd8//SuQhuJQTxJW7UzkWaao+32gW/RvuQun0XtCNoow/kMVMOeSjKL9xioM=\\n-----END\n        CERTIFICATE-----'\n      CLOUDFLARE_API_KEY: ${{ secrets.CLOUDFLARE_API_KEY }}\n      # CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}\n      # CLOUDFLARE_API_USER_SERVICE_KEY: ${{ secrets.CLOUDFLARE_API_USER_SERVICE_KEY }}\n      CLOUDFLARE_LOGPUSH_OWNERSHIP_TOKEN: ${{ \n        secrets.CLOUDFLARE_LOGPUSH_OWNERSHIP_TOKEN }}\n      CLOUDFLARE_WORKSPACE_ONE_CLIENT_ID: d0ed71f01c884e8b94ec4e4d6639f609\n      CLOUDFLARE_WORKSPACE_ONE_CLIENT_SECRET: ${{ \n        secrets.CLOUDFLARE_WORKSPACE_ONE_CLIENT_SECRET }}\n      CLOUDFLARE_WORKSPACE_ONE_API_URL: ${{ \n        secrets.CLOUDFLARE_WORKSPACE_ONE_API_URL }}\n      CLOUDFLARE_WORKSPACE_ONE_AUTH_URL: ${{ \n        secrets.CLOUDFLARE_WORKSPACE_ONE_AUTH_URL }}\n      CLOUDFLARE_PAGES_OWNER: jacobbednarz\n      CLOUDFLARE_PAGES_REPO: pages-example\n      CLOUDFLARE_R2_ACCESS_KEY_ID: ${{ secrets.CLOUDFLARE_R2_ACCESS_KEY_ID }}\n      CLOUDFLARE_R2_ACCESS_KEY_SECRET: ${{ \n        secrets.CLOUDFLARE_R2_ACCESS_KEY_SECRET }}\n      CLOUDFLARE_HYPERDRIVE_DATABASE_NAME: neondb\n      CLOUDFLARE_HYPERDRIVE_DATABASE_PORT: 5432\n      CLOUDFLARE_HYPERDRIVE_DATABASE_USER: neondb_owner\n      CLOUDFLARE_HYPERDRIVE_DATABASE_PASSWORD: ${{ \n        secrets.CLOUDFLARE_HYPERDRIVE_DATABASE_PASSWORD }}\n      CLOUDFLARE_HYPERDRIVE_DATABASE_HOSTNAME: ${{ \n        secrets.CLOUDFLARE_HYPERDRIVE_DATABASE_HOSTNAME }}\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n    - name: Setup go\n      uses: actions/setup-go@v5\n      with:\n        go-version-file: ./go.mod\n    - name: Bootstrap\n      run: ./scripts/bootstrap\n    # when all resources support sweepers, re-enable.\n    #\n    # - name: Pre-Sweeper\n    #  run: go test ./internal/services/... -v -sweep=\"1\" -timeout 60m\n    - name: Run acceptance tests\n      run: go test ./internal/services/... -run \"^TestAcc\" -count 1\n      env:\n        TF_ACC: 1\n    # when all resources support sweepers, re-enable.\n    #\n    # - name: Post-Sweeper\n    #  if: ${{ always() }}\n    #  run: go test ./internal/services/... -v -sweep=\"1\" -timeout 60m\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Acceptance Tests` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) The workflow would run whenever there is a push event to: a branch whose name matches release-please**. Only a single workflow using the acceptance-tests concurrency group will run at a time. The workflow has one job. The 1st job is named `Acceptance Tests` and its job id is `acceptance-tests`. ","prompt_level2":"Generate a GitHub Workflow named `Acceptance Tests` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) The workflow would run whenever there is a push event to: a branch whose name matches release-please**. Only a single workflow using the acceptance-tests concurrency group will run at a time. The workflow has one job. The 1st job is named `Acceptance Tests` and its job id is `acceptance-tests`. The job `acceptance-tests` has 4 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Setup go`. The 3rd step is named `Bootstrap`. The 4th step is named `Run acceptance tests`. ","prompt_level3":"Generate a GitHub Workflow named `Acceptance Tests` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) The workflow would run whenever there is a push event to: a branch whose name matches release-please**. Only a single workflow using the acceptance-tests concurrency group will run at a time. The workflow has one job. The 1st job is named `Acceptance Tests` and its job id is `acceptance-tests`. This job will run on ${{ github.repository == 'stainless-sdks/cloudflare-terraform' && 'depot-ubuntu-24.04' || 'lx64' }} runner. The job sets 22 environment variables to use: `CLOUDFLARE_ACCOUNT_ID` is set to `f037e56e89293a057740de681ac9abbe`, `CLOUDFLARE_ALT_DOMAIN` is set to `terraform2.cfapi.net`, `CLOUDFLARE_ALT_ZONE_ID` is set to `b72110c08e3382597095c29ba7e661ea`, `CLOUDFLARE_DOMAIN` is set to `terraform.cfapi.net`, `CLOUDFLARE_EMAIL` is set to `terraform-acceptance-test@cfapi.net`, `CLOUDFLARE_ZONE_ID` is set to `0da42c8d2132a9ddaf714f9e7c920711`, `CLOUDFLARE_MUTUAL_TLS_CERTIFICATE` is set to `-----BEGIN CERTIFICATE-----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\\nd8//SuQhuJQTxJW7UzkWaao+32gW/RvuQun0XtCNoow/kMVMOeSjKL9xioM=\\n-----END CERTIFICATE-----`, `CLOUDFLARE_API_KEY` is set to `${{ secrets.CLOUDFLARE_API_KEY }}`, `CLOUDFLARE_LOGPUSH_OWNERSHIP_TOKEN` is set to `${{ secrets.CLOUDFLARE_LOGPUSH_OWNERSHIP_TOKEN }}`, `CLOUDFLARE_WORKSPACE_ONE_CLIENT_ID` is set to `d0ed71f01c884e8b94ec4e4d6639f609`, `CLOUDFLARE_WORKSPACE_ONE_CLIENT_SECRET` is set to `${{ secrets.CLOUDFLARE_WORKSPACE_ONE_CLIENT_SECRET }}`, `CLOUDFLARE_WORKSPACE_ONE_API_URL` is set to `${{ secrets.CLOUDFLARE_WORKSPACE_ONE_API_URL }}`, `CLOUDFLARE_WORKSPACE_ONE_AUTH_URL` is set to `${{ secrets.CLOUDFLARE_WORKSPACE_ONE_AUTH_URL }}`, `CLOUDFLARE_PAGES_OWNER` is set to `jacobbednarz`, `CLOUDFLARE_PAGES_REPO` is set to `pages-example`, `CLOUDFLARE_R2_ACCESS_KEY_ID` is set to `${{ secrets.CLOUDFLARE_R2_ACCESS_KEY_ID }}`, `CLOUDFLARE_R2_ACCESS_KEY_SECRET` is set to `${{ secrets.CLOUDFLARE_R2_ACCESS_KEY_SECRET }}`, `CLOUDFLARE_HYPERDRIVE_DATABASE_NAME` is set to `neondb`, `CLOUDFLARE_HYPERDRIVE_DATABASE_PORT` is set to `5432`, `CLOUDFLARE_HYPERDRIVE_DATABASE_USER` is set to `neondb_owner`, `CLOUDFLARE_HYPERDRIVE_DATABASE_PASSWORD` is set to `${{ secrets.CLOUDFLARE_HYPERDRIVE_DATABASE_PASSWORD }}` and `CLOUDFLARE_HYPERDRIVE_DATABASE_HOSTNAME` is set to `${{ secrets.CLOUDFLARE_HYPERDRIVE_DATABASE_HOSTNAME }}`. The job `acceptance-tests` has 4 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Setup go`. This step runs action `actions/setup-go` tagged as v5. The step defines an input parameter for the action: `go-version-file` is set to `./go.mod`. The 3rd step is named `Bootstrap`. This step runs a script: `./scripts/bootstrap`. The 4th step is named `Run acceptance tests`. The step sets an environment variable to use: `TF_ACC` is set to `1`. This step runs a script: `go test ./internal/services/... -run \"^TestAcc\" -count 1`. ","nb_triggers":2,"triggers":["push","workflow_dispatch"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","actions/setup-go"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v5","name":"actions/setup-go"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":4,"cyclomatic_complexity":1}
{"id":26715,"repository_id":3980051,"mainLanguage":"C++","file_name":"root-docs-632.yml","file_content":"\nname: 'ROOT Docs 6.32'\n\non:\n  schedule:\n    - cron: '0 1 * * *'\n\n  workflow_dispatch:\n    inputs:\n      incremental:\n        description: 'Do incremental build'\n        type: boolean\n        required: true\n        default: true\n      # docu_input: # opportunity: overwrite makeinput.sh with these args\n      #   description: Folders to build documentation for. All folders are built if empty.\n      #   type: string\n      #   default: \"\"\n      #   required: false\n\njobs:\n  run_nightlies:\n    uses: root-project/root/.github/workflows/root-docs-ci.yml@v6-32-00-patches\n    secrets: inherit\n","repository_owner":"root-project","repository_name":"root","tokens_count":158,"workflow":"name: ROOT Docs 6.32\n\non:\n  schedule:\n  - cron: 0 1 * * *\n\n  workflow_dispatch:\n    inputs:\n      incremental:\n        description: Do incremental build\n        type: boolean\n        required: true\n        default: true\n      # docu_input: # opportunity: overwrite makeinput.sh with these args\n      #   description: Folders to build documentation for. All folders are built if empty.\n      #   type: string\n      #   default: \"\"\n      #   required: false\n\njobs:\n  run_nightlies:\n    uses: root-project/root/.github/workflows/root-docs-ci.yml@v6-32-00-patches\n    secrets: inherit\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `ROOT Docs 6.32` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 01:00 am. 2) someone manually triggers the workflow. This workflow receives an input: incremental-this input represents do incremental build, the data type is boolean, it must be supplied and its default value is True. The workflow has one job. The job id of the 1st job is `run_nightlies`. ","prompt_level2":"Generate a GitHub Workflow named `ROOT Docs 6.32` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 01:00 am. 2) someone manually triggers the workflow. This workflow receives an input: incremental-this input represents do incremental build, the data type is boolean, it must be supplied and its default value is True. The workflow has one job. The job id of the 1st job is `run_nightlies`. ","prompt_level3":"Generate a GitHub Workflow named `ROOT Docs 6.32` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 01:00 am. 2) someone manually triggers the workflow. This workflow receives an input: incremental-this input represents do incremental build, the data type is boolean, it must be supplied and its default value is True. The workflow has one job. The job id of the 1st job is `run_nightlies`. This job will call a reusable workflow located at `root-project/root/.github/workflows/root-docs-ci.yml@v6-32-00-patches`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. ","nb_triggers":2,"triggers":["schedule","workflow_dispatch"],"nb_jobs":1,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["root-project/root/.github/workflows/root-docs-ci.yml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":59115,"repository_id":3461071,"mainLanguage":"C#","file_name":"release.yml","file_content":"name:  Release\n\non:\n  release:\n    types: [published]\n  workflow_dispatch:\n    inputs:\n      ship_run_id:\n        description: ID of the GitHub workflow run to ship\n        required: true\n\nrun-name: ${{ github.ref_name }}\n\npermissions:\n  actions: read\n  contents: write\n\njobs:\n  release:\n    runs-on: ubuntu-24.04\n    steps:\n    - uses: actions/checkout@v4\n\n    - name:  Initialization\n      shell: pwsh\n      run: |\n        if ('${{ secrets.NUGET_API_KEY }}') {\n          Write-Host \"NUGET_API_KEY secret detected. NuGet packages will be pushed.\"\n          echo \"NUGET_API_KEY_DEFINED=true\" >> $env:GITHUB_ENV\n        }\n\n        if ('${{ secrets.NPM_API_KEY }}') {\n          Write-Host \"NPM_API_KEY secret detected. NPM packages will be pushed.\"\n          echo \"NPM_API_KEY_DEFINED=true\" >> $env:GITHUB_ENV\n        }\n\n    - name:  Search for build of ${{ github.ref }}\n      shell: pwsh\n      id: findrunid\n      env:\n        GH_TOKEN: ${{ github.token }}\n      run: |\n        if ('${{ inputs.ship_run_id }}') {\n          $runid = '${{ inputs.ship_run_id }}'\n        } else {\n          $restApiRoot = '/repos/${{ github.repository }}'\n\n          # Resolve the tag reference to a commit sha\n          $resolvedRef = gh api `\n            -H \"Accept: application/vnd.github+json\" `\n            -H \"X-GitHub-Api-Version: 2022-11-28\" `\n            $restApiRoot/git/ref/tags/${{ github.ref_name }} `\n            | ConvertFrom-Json\n          $commitSha = $resolvedRef.object.sha\n\n          Write-Host \"Resolved ${{ github.ref_name }} to $commitSha\"\n\n          $releases = gh run list -R ${{ github.repository }} -c $commitSha -w .github/workflows/build.yml -s success --json databaseId,startedAt `\n            | ConvertFrom-Json | Sort-Object startedAt -Descending\n\n          if ($releases.length -eq 0) {\n            Write-Error \"No successful builds found for ${{ github.ref }}.\"\n          } elseif ($releases.length -gt 1) {\n            Write-Warning \"More than one successful run found for ${{ github.ref }}. Artifacts from the most recent successful run will ship.\"\n          }\n\n          $runid = $releases[0].databaseId\n        }\n\n        Write-Host \"Using artifacts from run-id: $runid\"\n\n        Echo \"runid=$runid\" >> $env:GITHUB_OUTPUT\n\n    - name:  Download deployables artifacts\n      uses: actions/download-artifact@v4\n      with:\n        name: deployables-Windows\n        path: ${{ runner.temp }}/deployables\n        run-id: ${{ steps.findrunid.outputs.runid }}\n        github-token: ${{ github.token }}\n\n    - name:  Code sign\n      shell: pwsh\n      run: >\n        rm global.json # avoid a need to install a particular SDK version\n\n        dotnet tool install --tool-path obj SignClient\n\n        obj/SignClient sign\n        --baseDirectory '${{ runner.temp }}/deployables'\n        --input '**/*'\n        --config '${{ github.workspace }}/.github/SignClient.json'\n        --filelist '${{ github.workspace }}/.github/signfiles.txt'\n        --user '${{ secrets.CODESIGN_USERNAME }}'\n        --secret '${{ secrets.CODESIGN_SECRET }}'\n        --name 'Nerdbank.GitVersioning'\n        --descriptionUrl 'https://github.com/dotnet/Nerdbank.GitVersioning'\n\n    - name:  Upload artifacts to release\n      shell: pwsh\n      if: ${{ github.event_name == 'release' && github.event.release.assets_url != '' }}\n      env:\n        GH_TOKEN: ${{ github.token }}\n      run: |\n        Get-ChildItem '${{ runner.temp }}/deployables' -File -Recurse |% {\n          Write-Host \"Uploading $($_.Name) to release...\"\n          gh release -R ${{ github.repository }} upload \"${{ github.ref_name }}\" $_.FullName\n        }\n\n    - name:  Push NuGet packages\n      run: dotnet nuget push ${{ runner.temp }}/deployables/*.nupkg --source https://api.nuget.org/v3/index.json -k '${{ secrets.NUGET_API_KEY }}'\n      if: ${{ env.NUGET_API_KEY_DEFINED == 'true' }}\n\n    - name:  Push NPM packages\n      shell: pwsh\n      run: |\n        npm set //registry.npmjs.org/:_authToken=${{ secrets.NPM_API_KEY }}\n        Get-ChildItem '${{ runner.temp }}/deployables/*.tgz' |% {\n          npm publish $_ --registry=https://registry.npmjs.org/\n        }\n      if: ${{ env.NPM_API_KEY_DEFINED == 'true' }}\n","repository_owner":"dotnet","repository_name":"nerdbank.gitversioning","tokens_count":1099,"workflow":"name:  Release\n\non:\n  release:\n    types: [published]\n  workflow_dispatch:\n    inputs:\n      ship_run_id:\n        description: ID of the GitHub workflow run to ship\n        required: true\n\nrun-name: ${{ github.ref_name }}\n\npermissions:\n  actions: read\n  contents: write\n\njobs:\n  release:\n    runs-on: ubuntu-24.04\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name:  Initialization\n      shell: pwsh\n      run: |\n        if ('${{ secrets.NUGET_API_KEY }}') {\n          Write-Host \"NUGET_API_KEY secret detected. NuGet packages will be pushed.\"\n          echo \"NUGET_API_KEY_DEFINED=true\" >> $env:GITHUB_ENV\n        }\n\n        if ('${{ secrets.NPM_API_KEY }}') {\n          Write-Host \"NPM_API_KEY secret detected. NPM packages will be pushed.\"\n          echo \"NPM_API_KEY_DEFINED=true\" >> $env:GITHUB_ENV\n        }\n\n    - name:  Search for build of ${{ github.ref }}\n      shell: pwsh\n      id: findrunid\n      env:\n        GH_TOKEN: ${{ github.token }}\n      run: |\n        if ('${{ inputs.ship_run_id }}') {\n          $runid = '${{ inputs.ship_run_id }}'\n        } else {\n          $restApiRoot = '/repos/${{ github.repository }}'\n\n          # Resolve the tag reference to a commit sha\n          $resolvedRef = gh api `\n            -H \"Accept: application/vnd.github+json\" `\n            -H \"X-GitHub-Api-Version: 2022-11-28\" `\n            $restApiRoot/git/ref/tags/${{ github.ref_name }} `\n            | ConvertFrom-Json\n          $commitSha = $resolvedRef.object.sha\n\n          Write-Host \"Resolved ${{ github.ref_name }} to $commitSha\"\n\n          $releases = gh run list -R ${{ github.repository }} -c $commitSha -w .github/workflows/build.yml -s success --json databaseId,startedAt `\n            | ConvertFrom-Json | Sort-Object startedAt -Descending\n\n          if ($releases.length -eq 0) {\n            Write-Error \"No successful builds found for ${{ github.ref }}.\"\n          } elseif ($releases.length -gt 1) {\n            Write-Warning \"More than one successful run found for ${{ github.ref }}. Artifacts from the most recent successful run will ship.\"\n          }\n\n          $runid = $releases[0].databaseId\n        }\n\n        Write-Host \"Using artifacts from run-id: $runid\"\n\n        Echo \"runid=$runid\" >> $env:GITHUB_OUTPUT\n\n    - name:  Download deployables artifacts\n      uses: actions/download-artifact@v4\n      with:\n        name: deployables-Windows\n        path: ${{ runner.temp }}/deployables\n        run-id: ${{ steps.findrunid.outputs.runid }}\n        github-token: ${{ github.token }}\n\n    - name:  Code sign\n      shell: pwsh\n      run: >\n        rm global.json # avoid a need to install a particular SDK version\n\n        dotnet tool install --tool-path obj SignClient\n\n        obj/SignClient sign\n        --baseDirectory '${{ runner.temp }}/deployables'\n        --input '**/*'\n        --config '${{ github.workspace }}/.github/SignClient.json'\n        --filelist '${{ github.workspace }}/.github/signfiles.txt'\n        --user '${{ secrets.CODESIGN_USERNAME }}'\n        --secret '${{ secrets.CODESIGN_SECRET }}'\n        --name 'Nerdbank.GitVersioning'\n        --descriptionUrl 'https://github.com/dotnet/Nerdbank.GitVersioning'\n\n    - name:  Upload artifacts to release\n      shell: pwsh\n      if: ${{ github.event_name == 'release' && github.event.release.assets_url \n        != '' }}\n      env:\n        GH_TOKEN: ${{ github.token }}\n      run: |\n        Get-ChildItem '${{ runner.temp }}/deployables' -File -Recurse |% {\n          Write-Host \"Uploading $($_.Name) to release...\"\n          gh release -R ${{ github.repository }} upload \"${{ github.ref_name }}\" $_.FullName\n        }\n\n    - name:  Push NuGet packages\n      run: dotnet nuget push ${{ runner.temp }}/deployables/*.nupkg --source \n        https://api.nuget.org/v3/index.json -k '${{ secrets.NUGET_API_KEY }}'\n      if: ${{ env.NUGET_API_KEY_DEFINED == 'true' }}\n\n    - name:  Push NPM packages\n      shell: pwsh\n      run: |\n        npm set //registry.npmjs.org/:_authToken=${{ secrets.NPM_API_KEY }}\n        Get-ChildItem '${{ runner.temp }}/deployables/*.tgz' |% {\n          npm publish $_ --registry=https://registry.npmjs.org/\n        }\n      if: ${{ env.NPM_API_KEY_DEFINED == 'true' }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named ` Release` for a GitHub repository whose primary programming language is C#. The name for workflow runs is set to `${{ github.ref_name }}`. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) someone manually triggers the workflow. This workflow receives an input: ship_run_id-this input represents id of the github workflow run to ship and it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `actions` scope and write access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `release`. ","prompt_level2":"Generate a GitHub Workflow named ` Release` for a GitHub repository whose primary programming language is C#. The name for workflow runs is set to `${{ github.ref_name }}`. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) someone manually triggers the workflow. This workflow receives an input: ship_run_id-this input represents id of the github workflow run to ship and it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `actions` scope and write access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `release`. The job `release` has 8 steps. The 1st step is named `Checkout repository`. The 2nd step is named ` Initialization`. The 3rd step is named ` Search for build of ${{ github.ref }}` and its id is `findrunid`. The 4th step is named ` Download deployables artifacts`. The 5th step is named ` Code sign`. The 6th step is named ` Upload artifacts to release`. The 7th step is named ` Push NuGet packages`. The 8th step is named ` Push NPM packages`. ","prompt_level3":"Generate a GitHub Workflow named ` Release` for a GitHub repository whose primary programming language is C#. The name for workflow runs is set to `${{ github.ref_name }}`. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) someone manually triggers the workflow. This workflow receives an input: ship_run_id-this input represents id of the github workflow run to ship and it must be supplied. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `actions` scope and write access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `release`. This job will run on ubuntu-24.04 runner. The job `release` has 8 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named ` Initialization`. This step uses PowerShell Core to run a script: `if ('${{ secrets.NUGET_API_KEY }}') {\n  Write-Host \"NUGET_API_KEY secret detected. NuGet packages will be pushed.\"\n  echo \"NUGET_API_KEY_DEFINED=true\" >> $env:GITHUB_ENV\n}\n\nif ('${{ secrets.NPM_API_KEY }}') {\n  Write-Host \"NPM_API_KEY secret detected. NPM packages will be pushed.\"\n  echo \"NPM_API_KEY_DEFINED=true\" >> $env:GITHUB_ENV\n}\n`. The 3rd step is named ` Search for build of ${{ github.ref }}` and its id is `findrunid`. The step sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. This step uses PowerShell Core to run a script: `if ('${{ inputs.ship_run_id }}') {\n  $runid = '${{ inputs.ship_run_id }}'\n} else {\n  $restApiRoot = '/repos/${{ github.repository }}'\n\n  # Resolve the tag reference to a commit sha\n  $resolvedRef = gh api `\n    -H \"Accept: application/vnd.github+json\" `\n    -H \"X-GitHub-Api-Version: 2022-11-28\" `\n    $restApiRoot/git/ref/tags/${{ github.ref_name }} `\n    | ConvertFrom-Json\n  $commitSha = $resolvedRef.object.sha\n\n  Write-Host \"Resolved ${{ github.ref_name }} to $commitSha\"\n\n  $releases = gh run list -R ${{ github.repository }} -c $commitSha -w .github/workflows/build.yml -s success --json databaseId,startedAt `\n    | ConvertFrom-Json | Sort-Object startedAt -Descending\n\n  if ($releases.length -eq 0) {\n    Write-Error \"No successful builds found for ${{ github.ref }}.\"\n  } elseif ($releases.length -gt 1) {\n    Write-Warning \"More than one successful run found for ${{ github.ref }}. Artifacts from the most recent successful run will ship.\"\n  }\n\n  $runid = $releases[0].databaseId\n}\n\nWrite-Host \"Using artifacts from run-id: $runid\"\n\nEcho \"runid=$runid\" >> $env:GITHUB_OUTPUT\n`. The 4th step is named ` Download deployables artifacts`. This step runs action `actions/download-artifact` tagged as v4. The step defines 4 input parameters for the action: `name` is set to `deployables-Windows`, `path` is set to `${{ runner.temp }}/deployables`, `run-id` is set to `${{ steps.findrunid.outputs.runid }}` and `github-token` is set to `${{ github.token }}`. The 5th step is named ` Code sign`. This step uses PowerShell Core to run a script: `rm global.json # avoid a need to install a particular SDK version\ndotnet tool install --tool-path obj SignClient\nobj/SignClient sign --baseDirectory '${{ runner.temp }}/deployables' --input '**/*' --config '${{ github.workspace }}/.github/SignClient.json' --filelist '${{ github.workspace }}/.github/signfiles.txt' --user '${{ secrets.CODESIGN_USERNAME }}' --secret '${{ secrets.CODESIGN_SECRET }}' --name 'Nerdbank.GitVersioning' --descriptionUrl 'https://github.com/dotnet/Nerdbank.GitVersioning'\n`. The 6th step is named ` Upload artifacts to release`. This step will run only if the condition(${{ github.event_name == 'release' && github.event.release.assets_url != '' }}) is met. The step sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. This step uses PowerShell Core to run a script: `Get-ChildItem '${{ runner.temp }}/deployables' -File -Recurse |% {\n  Write-Host \"Uploading $($_.Name) to release...\"\n  gh release -R ${{ github.repository }} upload \"${{ github.ref_name }}\" $_.FullName\n}\n`. The 7th step is named ` Push NuGet packages`. This step will run only if the condition(${{ env.NUGET_API_KEY_DEFINED == 'true' }}) is met. This step runs a script: `dotnet nuget push ${{ runner.temp }}/deployables/*.nupkg --source https://api.nuget.org/v3/index.json -k '${{ secrets.NUGET_API_KEY }}'`. The 8th step is named ` Push NPM packages`. This step will run only if the condition(${{ env.NPM_API_KEY_DEFINED == 'true' }}) is met. This step uses PowerShell Core to run a script: `npm set //registry.npmjs.org/:_authToken=${{ secrets.NPM_API_KEY }}\nGet-ChildItem '${{ runner.temp }}/deployables/*.tgz' |% {\n  npm publish $_ --registry=https://registry.npmjs.org/\n}\n`. ","nb_triggers":2,"triggers":["release","workflow_dispatch"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","actions/download-artifact"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/download-artifact"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":8,"cyclomatic_complexity":1}
{"id":4078,"repository_id":19509608,"mainLanguage":"Go","file_name":"test-failure-notification.yml","file_content":"---\nname: CI Test Failure Notification\n\non:\n  workflow_call:\n    inputs:\n      actor:\n        description: 'Triggering actor of the failed the workflow'\n        required: true\n        type: string\n      git-branch:\n        description: 'Git branch name'\n        required: true\n        type: string\n      workflow-name:\n        description: 'Name of the GitHub Action workflow'\n        required: true\n        type: string\n      workflow-run-id:\n        description: 'GitHub Action run ID that failed'\n        required: true\n        type: string\n\njobs:\n  send-notification:\n    runs-on: ${{ endsWith(github.repository, '-enterprise') && fromJSON('[\"self-hosted\", \"ondemand\", \"linux\"]') || 'ubuntu-22.04' }}\n    steps:\n      - name: Retrieve Vault-hosted Secrets\n        if: endsWith(github.repository, '-enterprise')\n        id: vault\n        uses: hashicorp/vault-action@a1b77a09293a4366e48a5067a86692ac6e94fdc0 # v3.1.0\n        with:\n          url: ${{ vars.CI_VAULT_URL }}\n          method: ${{ vars.CI_VAULT_METHOD }}\n          path: ${{ vars.CI_VAULT_PATH }}\n          jwtGithubAudience: ${{ vars.CI_VAULT_AUD }}\n          secrets: |-\n            kv/data/teams/nomad/slack-webhooks feed-nomad | SLACK_FEED_NOMAD ;\n      - name: Send Slack notification\n        uses: slackapi/slack-github-action@485a9d42d3a73031f12ec201c457e2162c45d02d # v2.0.0\n        with:\n          webhook: \"${{ env.SLACK_FEED_NOMAD || secrets.SLACK_FEED_NOMAD_CI_FAILURE }}\"\n          webhook-type: incoming-webhook\n          payload: |\n            {\n              \"text\": \":x: CI Workflow '${{ inputs.workflow-name }}' has failed\",\n              \"attachments\": [\n                {\n                  \"color\": \"#C41E3A\",\n                  \"blocks\": [\n                    {\n                      \"type\": \"section\",\n                      \"fields\": [\n                        {\n                          \"type\": \"mrkdwn\",\n                          \"text\": \"*Branch:* <${{ github.server_url }}/${{ github.repository }}/tree/${{ inputs.git-branch }}|${{ inputs.git-branch }}>\"\n                        },\n                        {\n                          \"type\": \"mrkdwn\",\n                          \"text\": \"*From:* @${{ inputs.actor }}\"\n                        },\n                        {\n                          \"type\": \"mrkdwn\",\n                          \"text\": \"*Run:* <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ inputs.workflow-run-id }}|${{ inputs.workflow-run-id }}>\"\n                        }\n                      ]\n                    }\n                  ]\n                }\n              ]\n            }\n\npermissions:\n  contents: read\n  id-token: write\n","repository_owner":"hashicorp","repository_name":"nomad","tokens_count":653,"workflow":"name: CI Test Failure Notification\n\non:\n  workflow_call:\n    inputs:\n      actor:\n        description: Triggering actor of the failed the workflow\n        required: true\n        type: string\n      git-branch:\n        description: Git branch name\n        required: true\n        type: string\n      workflow-name:\n        description: Name of the GitHub Action workflow\n        required: true\n        type: string\n      workflow-run-id:\n        description: GitHub Action run ID that failed\n        required: true\n        type: string\n\njobs:\n  send-notification:\n    runs-on: ${{ endsWith(github.repository, '-enterprise') && \n      fromJSON('[\"self-hosted\", \"ondemand\", \"linux\"]') || 'ubuntu-22.04' }}\n    steps:\n    - name: Retrieve Vault-hosted Secrets\n      if: endsWith(github.repository, '-enterprise')\n      id: vault\n      uses: hashicorp/vault-action@a1b77a09293a4366e48a5067a86692ac6e94fdc0   # v3.1.0\n      with:\n        url: ${{ vars.CI_VAULT_URL }}\n        method: ${{ vars.CI_VAULT_METHOD }}\n        path: ${{ vars.CI_VAULT_PATH }}\n        jwtGithubAudience: ${{ vars.CI_VAULT_AUD }}\n        secrets: |-\n          kv/data/teams/nomad/slack-webhooks feed-nomad | SLACK_FEED_NOMAD ;\n    - name: Send Slack notification\n      uses: \n        slackapi/slack-github-action@485a9d42d3a73031f12ec201c457e2162c45d02d       # v2.0.0\n      with:\n        webhook: ${{ env.SLACK_FEED_NOMAD || secrets.SLACK_FEED_NOMAD_CI_FAILURE\n          }}\n        webhook-type: incoming-webhook\n        payload: |\n          {\n            \"text\": \":x: CI Workflow '${{ inputs.workflow-name }}' has failed\",\n            \"attachments\": [\n              {\n                \"color\": \"#C41E3A\",\n                \"blocks\": [\n                  {\n                    \"type\": \"section\",\n                    \"fields\": [\n                      {\n                        \"type\": \"mrkdwn\",\n                        \"text\": \"*Branch:* <${{ github.server_url }}/${{ github.repository }}/tree/${{ inputs.git-branch }}|${{ inputs.git-branch }}>\"\n                      },\n                      {\n                        \"type\": \"mrkdwn\",\n                        \"text\": \"*From:* @${{ inputs.actor }}\"\n                      },\n                      {\n                        \"type\": \"mrkdwn\",\n                        \"text\": \"*Run:* <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ inputs.workflow-run-id }}|${{ inputs.workflow-run-id }}>\"\n                      }\n                    ]\n                  }\n                ]\n              }\n            ]\n          }\n\npermissions:\n  contents: read\n  id-token: write\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `CI Test Failure Notification` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 4 inputs: actor-this input represents triggering actor of the failed the workflow, it must be supplied and the data type is string; git-branch-this input represents git branch name, it must be supplied and the data type is string; workflow-name-this input represents name of the github action workflow, it must be supplied and the data type is string; workflow-run-id-this input represents github action run id that failed, it must be supplied and the data type is string. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `send-notification`. ","prompt_level2":"Generate a GitHub Workflow named `CI Test Failure Notification` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 4 inputs: actor-this input represents triggering actor of the failed the workflow, it must be supplied and the data type is string; git-branch-this input represents git branch name, it must be supplied and the data type is string; workflow-name-this input represents name of the github action workflow, it must be supplied and the data type is string; workflow-run-id-this input represents github action run id that failed, it must be supplied and the data type is string. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `send-notification`. The job `send-notification` has 2 steps. The 1st step is named `Retrieve Vault-hosted Secrets` and its id is `vault`. The 2nd step is named `Send Slack notification`. ","prompt_level3":"Generate a GitHub Workflow named `CI Test Failure Notification` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 4 inputs: actor-this input represents triggering actor of the failed the workflow, it must be supplied and the data type is string; git-branch-this input represents git branch name, it must be supplied and the data type is string; workflow-name-this input represents name of the github action workflow, it must be supplied and the data type is string; workflow-run-id-this input represents github action run id that failed, it must be supplied and the data type is string. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting applies to all jobs in the workflow. The workflow has one job. The job id of the 1st job is `send-notification`. This job will run on ${{ endsWith(github.repository, '-enterprise') && fromJSON('[\"self-hosted\", \"ondemand\", \"linux\"]') || 'ubuntu-22.04' }} runner. The job `send-notification` has 2 steps. The 1st step is named `Retrieve Vault-hosted Secrets` and its id is `vault`. This step will run only if the condition(endsWith(github.repository, '-enterprise')) is met. This step runs action `hashicorp/vault-action` whose commit is a1b77a09293a4366e48a5067a86692ac6e94fdc0. The step defines 5 input parameters for the action: `url` is set to `${{ vars.CI_VAULT_URL }}`, `method` is set to `${{ vars.CI_VAULT_METHOD }}`, `path` is set to `${{ vars.CI_VAULT_PATH }}`, `jwtGithubAudience` is set to `${{ vars.CI_VAULT_AUD }}` and `secrets` is set to `kv/data/teams/nomad/slack-webhooks feed-nomad | SLACK_FEED_NOMAD ;`. The 2nd step is named `Send Slack notification`. This step runs action `slackapi/slack-github-action` whose commit is 485a9d42d3a73031f12ec201c457e2162c45d02d. The step defines 3 input parameters for the action: `webhook` is set to `${{ env.SLACK_FEED_NOMAD || secrets.SLACK_FEED_NOMAD_CI_FAILURE }}`, `webhook-type` is set to `incoming-webhook` and `payload` is set to `{\n  \"text\": \":x: CI Workflow '${{ inputs.workflow-name }}' has failed\",\n  \"attachments\": [\n    {\n      \"color\": \"#C41E3A\",\n      \"blocks\": [\n        {\n          \"type\": \"section\",\n          \"fields\": [\n            {\n              \"type\": \"mrkdwn\",\n              \"text\": \"*Branch:* <${{ github.server_url }}/${{ github.repository }}/tree/${{ inputs.git-branch }}|${{ inputs.git-branch }}>\"\n            },\n            {\n              \"type\": \"mrkdwn\",\n              \"text\": \"*From:* @${{ inputs.actor }}\"\n            },\n            {\n              \"type\": \"mrkdwn\",\n              \"text\": \"*Run:* <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ inputs.workflow-run-id }}|${{ inputs.workflow-run-id }}>\"\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}\n`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":2,"actions":["hashicorp/vault-action","slackapi/slack-github-action"],"actions_details":[{"version":"a1b77a09293a4366e48a5067a86692ac6e94fdc0","name":"hashicorp/vault-action"},{"version":"485a9d42d3a73031f12ec201c457e2162c45d02d","name":"slackapi/slack-github-action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":2,"cyclomatic_complexity":1}
{"id":55018,"repository_id":3495343,"mainLanguage":"C","file_name":"freebsd.yml","file_content":"name: FreeBSD\n\non:\n  pull_request:\n  push:\n  schedule:\n    - cron: '00 21 * * *'\n\njobs:\n  general:\n    strategy:\n      matrix:\n        # https://github.com/marketplace/actions/freebsd-vm\n        release: [ \"15.0\", \"14.2\" ]\n        arch: [ aarch64, amd64 ]\n        build-tool: [ cmake ] # , autotools\n        compiler: [ {cpp: clang++, c: clang} ] # , {cpp: g++, c: gcc}\n        runner: [ ubuntu-24.04, ubuntu-24.04-arm ]\n        exclude:\n          - runner: ubuntu-24.04\n            arch: aarch64\n          - runner: ubuntu-24.04-arm\n            arch: amd64\n          # TODO: Though the arch of the runner and the vm is matching, it is extremly slow on aarch64\n          #       Turn it off for now. Check if it is a runner or a vm issue.\n          - runner: ubuntu-24.04-arm\n            arch: aarch64\n      fail-fast: false\n\n    runs-on: ${{ matrix.runner }}\n\n    steps:\n      - name: Checkout syslog-ng source\n        uses: actions/checkout@v4\n\n      - name: Set ENV variables\n        env:\n          CC: ${{ matrix.compiler.c }}\n          CXX: ${{ matrix.compiler.cpp }}\n          THREADS: 4\n\n        run: |\n          . .github/workflows/gh-tools.sh\n\n          #THREADS=$(sysctl -n hw.ncpu) # TODO: Check how to get it on the FreeBSD VM\n          BSDPORTS_PREFIX=/usr/local\n          SYSLOG_NG_INSTALL_DIR=\"${HOME}/install/syslog-ng\"\n          WARNING_FLAGS=\"-Wno-unused-command-line-argument\" # FIXME: -Werror must be re-added\n          CFLAGS=\"-I${BSDPORTS_PREFIX}/include/ ${WARNING_FLAGS}\"\n          CXXFLAGS=\"${CFLAGS}\"\n          LDFLAGS=\"-L${BSDPORTS_PREFIX}/lib\"\n          # -DIVYKIS_SOURCE=internal is switched to system temporally as of https://github.com/buytenh/ivykis/pulls\n          CMAKE_CONFIGURE_FLAGS=\"\n            `[ $CC = clang ] && echo '-DENABLE_FORCE_GNU99=ON' || true`\n            -DENABLE_EXTRA_WARNINGS=ON\n            -DSUMMARY_LEVEL=1\n            -DCMAKE_BUILD_TYPE=Debug\n            -DCMAKE_INSTALL_PREFIX=${SYSLOG_NG_INSTALL_DIR}\n            -DBUILD_TESTING=ON\n            -DPYTHON_VERSION=3\n            -DIVYKIS_SOURCE=internal\n            -DENABLE_JOURNALD=OFF\n            -DENABLE_JAVA=OFF\n            -DENABLE_JAVA_MODULES=OFF\n          \"\n          PKGCONF_PATH=$(pkgconf --variable pc_path pkgconf)\n          export PKG_CONFIG_PATH=\"${PKGCONF_PATH}:$PKG_CONFIG_PATH\"\n          PATH=\"${BSDPORTS_PREFIX}/bin:${BSDPORTS_PREFIX}/sbin:${PATH}\"\n\n          gh_export BSDPORTS_PREFIX SYSLOG_NG_INSTALL_DIR CC CXX PKGCONF_PATH PKG_CONFIG_PATH THREADS CONFIGURE_FLAGS CFLAGS CXXFLAGS LDFLAGS CMAKE_CONFIGURE_FLAGS PATH\n          gh_path \"${PATH}\"\n\n          env | sort\n          #cat \"${GITHUB_ENV}\" | sort\n\n      - name: Setup the environment\n        uses: vmactions/freebsd-vm@v1\n        with:\n          usesh: true\n\n          release: ${{ matrix.release }}\n          arch: ${{ matrix.arch }}\n          cpu: ${{ env.THREADS }}\n\n          sync: rsync # or sshfs or nfs\n          copyback: false\n\n          envs: |\n            BSDPORTS_PREFIX SYSLOG_NG_INSTALL_DIR CC CXX PKGCONF_PATH PKG_CONFIG_PATH THREADS CONFIGURE_FLAGS CFLAGS CXXFLAGS LDFLAGS CMAKE_CONFIGURE_FLAGS PATH\n\n          prepare: |\n            pkg install -y autoconf autoconf-archive automake bison cmake flex git gperf glib json-c libtool pcre2 pkgconf criterion gradle grpc hiredis libdbi libdbi-drivers libmaxminddb libnet libpaho-mqtt3 librdkafka libesmtp mongo-c-driver net-snmp openjdk18 rabbitmq-c riemann-c-client ivykis\n\n          run: |\n            env | sort\n            # For checking the FreeBSD port source branch\n            #cat /etc/pkg/FreeBSD.conf || true\n            # As using the default actions/checkout@v4 to get the source code, the submodules are not checked out by default\n            # Calling the git submodule update --init --recursive during the configure step would fail bacuse of the different git owners\n            # So, the safe exceptions are added to the git config (other option could be a full manual source checkout that requires a bit\n            # bigger effort, as the correct branch must be maintained as well)\n            git config --global --add safe.directory $GITHUB_WORKSPACE\n\n      - name: cmake configure\n        shell: freebsd {0}\n        run: |\n          cd $GITHUB_WORKSPACE; pwd\n\n          env | sort\n          echo \"ARCH: \" $(uname -m)\n          echo \"clang:\" $(which clang; clang --version)\n\n          cmake --install-prefix \"${SYSLOG_NG_INSTALL_DIR}\" -B build . ${CMAKE_CONFIGURE_FLAGS}\n\n      - name: cmake install\n        shell: freebsd {0}\n        run: |\n          cd $GITHUB_WORKSPACE; pwd\n\n          cmake --build ./build -j ${THREADS} --target install\n          \"${SYSLOG_NG_INSTALL_DIR}/sbin/syslog-ng\" -V\n\n      - name: cmake check\n        shell: freebsd {0}\n        run: |\n          cd $GITHUB_WORKSPACE; pwd\n\n          # TODO: Skip for now, should fix the FreeBSD tests\n          #cmake --build ./build -j ${THREADS} --target check\n","repository_owner":"syslog-ng","repository_name":"syslog-ng","tokens_count":1297,"workflow":"name: FreeBSD\n\non:\n  pull_request:\n  push:\n  schedule:\n  - cron: 00 21 * * *\n\njobs:\n  general:\n    strategy:\n      matrix:\n        # https://github.com/marketplace/actions/freebsd-vm\n        release: ['15.0', '14.2']\n        arch: [aarch64, amd64]\n        build-tool: [cmake]   # , autotools\n        compiler: [{cpp: clang++, c: clang}]   # , {cpp: g++, c: gcc}\n        runner: [ubuntu-24.04, ubuntu-24.04-arm]\n        exclude:\n        - runner: ubuntu-24.04\n          arch: aarch64\n        - runner: ubuntu-24.04-arm\n          arch: amd64\n          # TODO: Though the arch of the runner and the vm is matching, it is extremly slow on aarch64\n          #       Turn it off for now. Check if it is a runner or a vm issue.\n        - runner: ubuntu-24.04-arm\n          arch: aarch64\n      fail-fast: false\n\n    runs-on: ${{ matrix.runner }}\n\n    steps:\n    - name: Checkout syslog-ng source\n      uses: actions/checkout@v4\n\n    - name: Set ENV variables\n      env:\n        CC: ${{ matrix.compiler.c }}\n        CXX: ${{ matrix.compiler.cpp }}\n        THREADS: 4\n\n      run: |\n        . .github/workflows/gh-tools.sh\n\n        #THREADS=$(sysctl -n hw.ncpu) # TODO: Check how to get it on the FreeBSD VM\n        BSDPORTS_PREFIX=/usr/local\n        SYSLOG_NG_INSTALL_DIR=\"${HOME}/install/syslog-ng\"\n        WARNING_FLAGS=\"-Wno-unused-command-line-argument\" # FIXME: -Werror must be re-added\n        CFLAGS=\"-I${BSDPORTS_PREFIX}/include/ ${WARNING_FLAGS}\"\n        CXXFLAGS=\"${CFLAGS}\"\n        LDFLAGS=\"-L${BSDPORTS_PREFIX}/lib\"\n        # -DIVYKIS_SOURCE=internal is switched to system temporally as of https://github.com/buytenh/ivykis/pulls\n        CMAKE_CONFIGURE_FLAGS=\"\n          `[ $CC = clang ] && echo '-DENABLE_FORCE_GNU99=ON' || true`\n          -DENABLE_EXTRA_WARNINGS=ON\n          -DSUMMARY_LEVEL=1\n          -DCMAKE_BUILD_TYPE=Debug\n          -DCMAKE_INSTALL_PREFIX=${SYSLOG_NG_INSTALL_DIR}\n          -DBUILD_TESTING=ON\n          -DPYTHON_VERSION=3\n          -DIVYKIS_SOURCE=internal\n          -DENABLE_JOURNALD=OFF\n          -DENABLE_JAVA=OFF\n          -DENABLE_JAVA_MODULES=OFF\n        \"\n        PKGCONF_PATH=$(pkgconf --variable pc_path pkgconf)\n        export PKG_CONFIG_PATH=\"${PKGCONF_PATH}:$PKG_CONFIG_PATH\"\n        PATH=\"${BSDPORTS_PREFIX}/bin:${BSDPORTS_PREFIX}/sbin:${PATH}\"\n\n        gh_export BSDPORTS_PREFIX SYSLOG_NG_INSTALL_DIR CC CXX PKGCONF_PATH PKG_CONFIG_PATH THREADS CONFIGURE_FLAGS CFLAGS CXXFLAGS LDFLAGS CMAKE_CONFIGURE_FLAGS PATH\n        gh_path \"${PATH}\"\n\n        env | sort\n        #cat \"${GITHUB_ENV}\" | sort\n\n    - name: Setup the environment\n      uses: vmactions/freebsd-vm@v1\n      with:\n        usesh: true\n\n        release: ${{ matrix.release }}\n        arch: ${{ matrix.arch }}\n        cpu: ${{ env.THREADS }}\n\n        sync: rsync   # or sshfs or nfs\n        copyback: false\n\n        envs: |\n          BSDPORTS_PREFIX SYSLOG_NG_INSTALL_DIR CC CXX PKGCONF_PATH PKG_CONFIG_PATH THREADS CONFIGURE_FLAGS CFLAGS CXXFLAGS LDFLAGS CMAKE_CONFIGURE_FLAGS PATH\n\n        prepare: |\n          pkg install -y autoconf autoconf-archive automake bison cmake flex git gperf glib json-c libtool pcre2 pkgconf criterion gradle grpc hiredis libdbi libdbi-drivers libmaxminddb libnet libpaho-mqtt3 librdkafka libesmtp mongo-c-driver net-snmp openjdk18 rabbitmq-c riemann-c-client ivykis\n\n        run: |\n          env | sort\n          # For checking the FreeBSD port source branch\n          #cat /etc/pkg/FreeBSD.conf || true\n          # As using the default actions/checkout@v4 to get the source code, the submodules are not checked out by default\n          # Calling the git submodule update --init --recursive during the configure step would fail bacuse of the different git owners\n          # So, the safe exceptions are added to the git config (other option could be a full manual source checkout that requires a bit\n          # bigger effort, as the correct branch must be maintained as well)\n          git config --global --add safe.directory $GITHUB_WORKSPACE\n\n    - name: cmake configure\n      shell: freebsd {0}\n      run: |\n        cd $GITHUB_WORKSPACE; pwd\n\n        env | sort\n        echo \"ARCH: \" $(uname -m)\n        echo \"clang:\" $(which clang; clang --version)\n\n        cmake --install-prefix \"${SYSLOG_NG_INSTALL_DIR}\" -B build . ${CMAKE_CONFIGURE_FLAGS}\n\n    - name: cmake install\n      shell: freebsd {0}\n      run: |\n        cd $GITHUB_WORKSPACE; pwd\n\n        cmake --build ./build -j ${THREADS} --target install\n        \"${SYSLOG_NG_INSTALL_DIR}/sbin/syslog-ng\" -V\n\n    - name: cmake check\n      shell: freebsd {0}\n      run: |\n        cd $GITHUB_WORKSPACE; pwd\n\n        # TODO: Skip for now, should fix the FreeBSD tests\n        #cmake --build ./build -j ${THREADS} --target check\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `FreeBSD` for a GitHub repository whose primary programming language is C. This workflow will be triggered by multiple events: 1) there is activity relating to a pull request. 2) a commit or tag is pushed, or a repository is cloned. 3) the scheduled time has come: at 09:00 pm. The workflow has one job. The job id of the 1st job is `general`. ","prompt_level2":"Generate a GitHub Workflow named `FreeBSD` for a GitHub repository whose primary programming language is C. This workflow will be triggered by multiple events: 1) there is activity relating to a pull request. 2) a commit or tag is pushed, or a repository is cloned. 3) the scheduled time has come: at 09:00 pm. The workflow has one job. The job id of the 1st job is `general`. The job `general` has 6 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set ENV variables`. The 3rd step is named `Setup the environment`. The 4th step is named `cmake configure`. The 5th step is named `cmake install`. The 6th step is named `cmake check`. ","prompt_level3":"Generate a GitHub Workflow named `FreeBSD` for a GitHub repository whose primary programming language is C. This workflow will be triggered by multiple events: 1) there is activity relating to a pull request. 2) a commit or tag is pushed, or a repository is cloned. 3) the scheduled time has come: at 09:00 pm. The workflow has one job. The job id of the 1st job is `general`. This job will run on ${{ matrix.runner }} runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `release` has 2 values: 15.0 and 14.2. The variable `arch` has 2 values: aarch64 and amd64. The variable `build-tool` has one value: cmake. The variable `compiler` has one value: {'cpp': 'clang++', 'c': 'clang'}. The variable `runner` has 2 values: ubuntu-24.04 and ubuntu-24.04-arm. If combinations of variables partially match one of the objects [{'runner': 'ubuntu-24.04', 'arch': 'aarch64'}, {'runner': 'ubuntu-24.04-arm', 'arch': 'amd64'}, {'runner': 'ubuntu-24.04-arm', 'arch': 'aarch64'}], combinations should be excluded from the matrix. The job `general` has 6 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Set ENV variables`. The step sets 3 environment variables to use: `CC` is set to `${{ matrix.compiler.c }}`, `CXX` is set to `${{ matrix.compiler.cpp }}` and `THREADS` is set to `4`. This step runs a script: `. .github/workflows/gh-tools.sh\n\n#THREADS=$(sysctl -n hw.ncpu) # TODO: Check how to get it on the FreeBSD VM\nBSDPORTS_PREFIX=/usr/local\nSYSLOG_NG_INSTALL_DIR=\"${HOME}/install/syslog-ng\"\nWARNING_FLAGS=\"-Wno-unused-command-line-argument\" # FIXME: -Werror must be re-added\nCFLAGS=\"-I${BSDPORTS_PREFIX}/include/ ${WARNING_FLAGS}\"\nCXXFLAGS=\"${CFLAGS}\"\nLDFLAGS=\"-L${BSDPORTS_PREFIX}/lib\"\n# -DIVYKIS_SOURCE=internal is switched to system temporally as of https://github.com/buytenh/ivykis/pulls\nCMAKE_CONFIGURE_FLAGS=\"\n  `[ $CC = clang ] && echo '-DENABLE_FORCE_GNU99=ON' || true`\n  -DENABLE_EXTRA_WARNINGS=ON\n  -DSUMMARY_LEVEL=1\n  -DCMAKE_BUILD_TYPE=Debug\n  -DCMAKE_INSTALL_PREFIX=${SYSLOG_NG_INSTALL_DIR}\n  -DBUILD_TESTING=ON\n  -DPYTHON_VERSION=3\n  -DIVYKIS_SOURCE=internal\n  -DENABLE_JOURNALD=OFF\n  -DENABLE_JAVA=OFF\n  -DENABLE_JAVA_MODULES=OFF\n\"\nPKGCONF_PATH=$(pkgconf --variable pc_path pkgconf)\nexport PKG_CONFIG_PATH=\"${PKGCONF_PATH}:$PKG_CONFIG_PATH\"\nPATH=\"${BSDPORTS_PREFIX}/bin:${BSDPORTS_PREFIX}/sbin:${PATH}\"\n\ngh_export BSDPORTS_PREFIX SYSLOG_NG_INSTALL_DIR CC CXX PKGCONF_PATH PKG_CONFIG_PATH THREADS CONFIGURE_FLAGS CFLAGS CXXFLAGS LDFLAGS CMAKE_CONFIGURE_FLAGS PATH\ngh_path \"${PATH}\"\n\nenv | sort\n#cat \"${GITHUB_ENV}\" | sort\n`. The 3rd step is named `Setup the environment`. This step runs action `vmactions/freebsd-vm` tagged as v1. The step defines 9 input parameters for the action: `usesh` is set to `True`, `release` is set to `${{ matrix.release }}`, `arch` is set to `${{ matrix.arch }}`, `cpu` is set to `${{ env.THREADS }}`, `sync` is set to `rsync`, `copyback` is set to `False`, `envs` is set to `BSDPORTS_PREFIX SYSLOG_NG_INSTALL_DIR CC CXX PKGCONF_PATH PKG_CONFIG_PATH THREADS CONFIGURE_FLAGS CFLAGS CXXFLAGS LDFLAGS CMAKE_CONFIGURE_FLAGS PATH\n`, `prepare` is set to `pkg install -y autoconf autoconf-archive automake bison cmake flex git gperf glib json-c libtool pcre2 pkgconf criterion gradle grpc hiredis libdbi libdbi-drivers libmaxminddb libnet libpaho-mqtt3 librdkafka libesmtp mongo-c-driver net-snmp openjdk18 rabbitmq-c riemann-c-client ivykis\n` and `run` is set to `env | sort\n# For checking the FreeBSD port source branch\n#cat /etc/pkg/FreeBSD.conf || true\n# As using the default actions/checkout@v4 to get the source code, the submodules are not checked out by default\n# Calling the git submodule update --init --recursive during the configure step would fail bacuse of the different git owners\n# So, the safe exceptions are added to the git config (other option could be a full manual source checkout that requires a bit\n# bigger effort, as the correct branch must be maintained as well)\ngit config --global --add safe.directory $GITHUB_WORKSPACE\n`. The 4th step is named `cmake configure`. This step uses a custom shell freebsd {0} to run a script: `cd $GITHUB_WORKSPACE; pwd\n\nenv | sort\necho \"ARCH: \" $(uname -m)\necho \"clang:\" $(which clang; clang --version)\n\ncmake --install-prefix \"${SYSLOG_NG_INSTALL_DIR}\" -B build . ${CMAKE_CONFIGURE_FLAGS}\n`. The 5th step is named `cmake install`. This step uses a custom shell freebsd {0} to run a script: `cd $GITHUB_WORKSPACE; pwd\n\ncmake --build ./build -j ${THREADS} --target install\n\"${SYSLOG_NG_INSTALL_DIR}/sbin/syslog-ng\" -V\n`. The 6th step is named `cmake check`. This step uses a custom shell freebsd {0} to run a script: `cd $GITHUB_WORKSPACE; pwd\n\n# TODO: Skip for now, should fix the FreeBSD tests\n#cmake --build ./build -j ${THREADS} --target check\n`. ","nb_triggers":3,"triggers":["pull_request","push","schedule"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","vmactions/freebsd-vm"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v1","name":"vmactions/freebsd-vm"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":6,"cyclomatic_complexity":1}
{"id":21117,"repository_id":18239562,"mainLanguage":"Go","file_name":"job-test-unit.yml","file_content":"# Note: freebsd tests are not ran here (see integration instead)\nname: job-test-unit\n\non:\n  workflow_call:\n    inputs:\n      timeout:\n        required: true\n        type: number\n      go-version:\n        required: true\n        type: string\n      runner:\n        required: true\n        type: string\n      canary:\n        required: false\n        default: false\n        type: boolean\n      windows-cni-version:\n        required: true\n        type: string\n      linux-cni-version:\n        required: true\n        type: string\n      linux-cni-sha:\n        required: true\n        type: string\n\nenv:\n  GOTOOLCHAIN: local\n  # Windows fails without this\n  CGO_ENABLED: 0\n\njobs:\n  test-unit:\n    name: ${{ format('{0}{1}', inputs.runner, inputs.canary && ' (go canary)' || '') }}\n    timeout-minutes: ${{ inputs.timeout }}\n    runs-on: \"${{ inputs.runner }}\"\n    defaults:\n      run:\n        shell: bash\n\n    env:\n      GO_VERSION: ${{ inputs.go-version }}\n\n    steps:\n      - name: \"Init: checkout\"\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683  # v4.2.2\n        with:\n          fetch-depth: 1\n\n      # If canary is requested, check for the latest unstable release\n      - if: ${{ inputs.canary }}\n        name: \"Init (canary): retrieve GO_VERSION\"\n        run: |\n          latest_go=\"$(. ./hack/provisioning/version/fetch.sh; go::canary::for::go-setup)\"\n          printf \"GO_VERSION=%s\\n\" \"$latest_go\" >> \"$GITHUB_ENV\"\n          [ \"$latest_go\" != \"\" ] || \\\n            echo \"::warning title=No canary go::There is currently no canary go version to test. Following steps will not run.\"\n\n      - if: ${{ env.GO_VERSION != '' }}\n        name: \"Init: install go\"\n        uses: actions/setup-go@0aaccfd150d50ccaeb58ebd88d36e91967a5f35b  # v5.4.0\n        with:\n          go-version: ${{ env.GO_VERSION }}\n          check-latest: true\n\n      # Install CNI\n      - if: ${{ env.GO_VERSION != '' }}\n        name: \"Init: set up CNI\"\n        run: |\n          if [ \"$RUNNER_OS\" == \"Windows\" ]; then\n            GOPATH=$(go env GOPATH) WINCNI_VERSION=${{ inputs.windows-cni-version }} ./hack/provisioning/windows/cni.sh\n          elif [ \"$RUNNER_OS\" == \"Linux\" ]; then\n            ./hack/provisioning/linux/cni.sh install \"${{ inputs.linux-cni-version }}\" \"amd64\" \"${{ inputs.linux-cni-sha }}\"\n          fi\n\n      - if: ${{ env.GO_VERSION != '' }}\n        name: \"Run\"\n        run: |\n          make test-unit\n\n      # On linux, also run with root\n      - if: ${{ env.GO_VERSION != '' && env.RUNNER_OS == 'Linux' }}\n        name: \"Run: with root\"\n        run: |\n          sudo make test-unit\n","repository_owner":"containerd","repository_name":"nerdctl","tokens_count":735,"workflow":"# Note: freebsd tests are not ran here (see integration instead)\nname: job-test-unit\n\non:\n  workflow_call:\n    inputs:\n      timeout:\n        required: true\n        type: number\n      go-version:\n        required: true\n        type: string\n      runner:\n        required: true\n        type: string\n      canary:\n        required: false\n        default: false\n        type: boolean\n      windows-cni-version:\n        required: true\n        type: string\n      linux-cni-version:\n        required: true\n        type: string\n      linux-cni-sha:\n        required: true\n        type: string\n\nenv:\n  GOTOOLCHAIN: local\n  # Windows fails without this\n  CGO_ENABLED: 0\n\njobs:\n  test-unit:\n    name: ${{ format('{0}{1}', inputs.runner, inputs.canary && ' (go canary)' ||\n      '') }}\n    timeout-minutes: ${{ inputs.timeout }}\n    runs-on: ${{ inputs.runner }}\n    defaults:\n      run:\n        shell: bash\n\n    env:\n      GO_VERSION: ${{ inputs.go-version }}\n\n    steps:\n    - name: 'Init: checkout'\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683    # v4.2.2\n      with:\n        fetch-depth: 1\n\n      # If canary is requested, check for the latest unstable release\n    - if: ${{ inputs.canary }}\n      name: 'Init (canary): retrieve GO_VERSION'\n      run: |\n        latest_go=\"$(. ./hack/provisioning/version/fetch.sh; go::canary::for::go-setup)\"\n        printf \"GO_VERSION=%s\\n\" \"$latest_go\" >> \"$GITHUB_ENV\"\n        [ \"$latest_go\" != \"\" ] || \\\n          echo \"::warning title=No canary go::There is currently no canary go version to test. Following steps will not run.\"\n\n    - if: ${{ env.GO_VERSION != '' }}\n      name: 'Init: install go'\n      uses: actions/setup-go@0aaccfd150d50ccaeb58ebd88d36e91967a5f35b    # v5.4.0\n      with:\n        go-version: ${{ env.GO_VERSION }}\n        check-latest: true\n\n      # Install CNI\n    - if: ${{ env.GO_VERSION != '' }}\n      name: 'Init: set up CNI'\n      run: |\n        if [ \"$RUNNER_OS\" == \"Windows\" ]; then\n          GOPATH=$(go env GOPATH) WINCNI_VERSION=${{ inputs.windows-cni-version }} ./hack/provisioning/windows/cni.sh\n        elif [ \"$RUNNER_OS\" == \"Linux\" ]; then\n          ./hack/provisioning/linux/cni.sh install \"${{ inputs.linux-cni-version }}\" \"amd64\" \"${{ inputs.linux-cni-sha }}\"\n        fi\n\n    - if: ${{ env.GO_VERSION != '' }}\n      name: Run\n      run: |\n        make test-unit\n\n      # On linux, also run with root\n    - if: ${{ env.GO_VERSION != '' && env.RUNNER_OS == 'Linux' }}\n      name: 'Run: with root'\n      run: |\n        sudo make test-unit\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `job-test-unit` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 7 inputs: timeout-it must be supplied and the data type is number; go-version-it must be supplied and the data type is string; runner-it must be supplied and the data type is string; canary-it is optional, its default value is False and the data type is boolean; windows-cni-version-it must be supplied and the data type is string; linux-cni-version-it must be supplied and the data type is string; linux-cni-sha-it must be supplied and the data type is string. The workflow sets 2 environment variables to use: `GOTOOLCHAIN` is set to `local` and `CGO_ENABLED` is set to `0`. The workflow has one job. The 1st job is named `${{ format('{0}{1}', inputs.runner, inputs.canary && ' (go canary)' || '') }}` and its job id is `test-unit`. ","prompt_level2":"Generate a GitHub Workflow named `job-test-unit` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 7 inputs: timeout-it must be supplied and the data type is number; go-version-it must be supplied and the data type is string; runner-it must be supplied and the data type is string; canary-it is optional, its default value is False and the data type is boolean; windows-cni-version-it must be supplied and the data type is string; linux-cni-version-it must be supplied and the data type is string; linux-cni-sha-it must be supplied and the data type is string. The workflow sets 2 environment variables to use: `GOTOOLCHAIN` is set to `local` and `CGO_ENABLED` is set to `0`. The workflow has one job. The 1st job is named `${{ format('{0}{1}', inputs.runner, inputs.canary && ' (go canary)' || '') }}` and its job id is `test-unit`. The job `test-unit` has 6 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Init (canary): retrieve GO_VERSION`. The 3rd step is named `Init: install go`. The 4th step is named `Init: set up CNI`. The 5th step is named `Run`. The 6th step is named `Run: with root`. ","prompt_level3":"Generate a GitHub Workflow named `job-test-unit` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 7 inputs: timeout-it must be supplied and the data type is number; go-version-it must be supplied and the data type is string; runner-it must be supplied and the data type is string; canary-it is optional, its default value is False and the data type is boolean; windows-cni-version-it must be supplied and the data type is string; linux-cni-version-it must be supplied and the data type is string; linux-cni-sha-it must be supplied and the data type is string. The workflow sets 2 environment variables to use: `GOTOOLCHAIN` is set to `local` and `CGO_ENABLED` is set to `0`. The workflow has one job. The 1st job is named `${{ format('{0}{1}', inputs.runner, inputs.canary && ' (go canary)' || '') }}` and its job id is `test-unit`. This job will run on ${{ inputs.runner }} runner. The job sets an environment variable to use: `GO_VERSION` is set to `${{ inputs.go-version }}`. For all run steps in the job, default shell is set to bash. The maximum number of minutes to run the job is ${{ inputs.timeout }}. The job `test-unit` has 6 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is 11bd71901bbe5b1630ceea73d27597364c9af683. The step defines an input parameter for the action: `fetch-depth` is set to `1`. The 2nd step is named `Init (canary): retrieve GO_VERSION`. This step will run only if the condition(${{ inputs.canary }}) is met. This step runs a script: `latest_go=\"$(. ./hack/provisioning/version/fetch.sh; go::canary::for::go-setup)\"\nprintf \"GO_VERSION=%s\\n\" \"$latest_go\" >> \"$GITHUB_ENV\"\n[ \"$latest_go\" != \"\" ] || \\\n  echo \"::warning title=No canary go::There is currently no canary go version to test. Following steps will not run.\"\n`. The 3rd step is named `Init: install go`. This step will run only if the condition(${{ env.GO_VERSION != '' }}) is met. This step runs action `actions/setup-go` whose commit is 0aaccfd150d50ccaeb58ebd88d36e91967a5f35b. The step defines 2 input parameters for the action: `go-version` is set to `${{ env.GO_VERSION }}` and `check-latest` is set to `True`. The 4th step is named `Init: set up CNI`. This step will run only if the condition(${{ env.GO_VERSION != '' }}) is met. This step runs a script: `if [ \"$RUNNER_OS\" == \"Windows\" ]; then\n  GOPATH=$(go env GOPATH) WINCNI_VERSION=${{ inputs.windows-cni-version }} ./hack/provisioning/windows/cni.sh\nelif [ \"$RUNNER_OS\" == \"Linux\" ]; then\n  ./hack/provisioning/linux/cni.sh install \"${{ inputs.linux-cni-version }}\" \"amd64\" \"${{ inputs.linux-cni-sha }}\"\nfi\n`. The 5th step is named `Run`. This step will run only if the condition(${{ env.GO_VERSION != '' }}) is met. This step runs a script: `make test-unit\n`. The 6th step is named `Run: with root`. This step will run only if the condition(${{ env.GO_VERSION != '' && env.RUNNER_OS == 'Linux' }}) is met. This step runs a script: `sudo make test-unit\n`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","actions/setup-go"],"actions_details":[{"version":"11bd71901bbe5b1630ceea73d27597364c9af683","name":"actions/checkout"},{"version":"0aaccfd150d50ccaeb58ebd88d36e91967a5f35b","name":"actions/setup-go"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":6,"cyclomatic_complexity":1}
{"id":38036,"repository_id":88029133,"mainLanguage":"Shell","file_name":"build-iso-lts.yml","file_content":"name: Anaconda LTS ISO\non:\n  workflow_dispatch:\n  workflow_call:\n\njobs:\n  build-iso-lts:\n    name: Build LTS ISOs\n    uses: ./.github/workflows/reusable-build-iso.yml\n    secrets: inherit\n    with:\n      image_flavors: \"['main']\"\n      stream_name: lts\n","repository_owner":"ublue-os","repository_name":"bluefin","tokens_count":74,"workflow":"name: Anaconda LTS ISO\non:\n  workflow_dispatch:\n  workflow_call:\n\njobs:\n  build-iso-lts:\n    name: Build LTS ISOs\n    uses: ./.github/workflows/reusable-build-iso.yml\n    secrets: inherit\n    with:\n      image_flavors: \"['main']\"\n      stream_name: lts\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Anaconda LTS ISO` for a GitHub repository whose primary programming language is Shell. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) it is called from another workflow. The workflow has one job. The 1st job is named `Build LTS ISOs` and its job id is `build-iso-lts`. ","prompt_level2":"Generate a GitHub Workflow named `Anaconda LTS ISO` for a GitHub repository whose primary programming language is Shell. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) it is called from another workflow. The workflow has one job. The 1st job is named `Build LTS ISOs` and its job id is `build-iso-lts`. ","prompt_level3":"Generate a GitHub Workflow named `Anaconda LTS ISO` for a GitHub repository whose primary programming language is Shell. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) it is called from another workflow. The workflow has one job. The 1st job is named `Build LTS ISOs` and its job id is `build-iso-lts`. This job will call a reusable workflow located at `./.github/workflows/reusable-build-iso.yml`. The job will pass 2 inputs to the called workflow: the input `image_flavors` is `['main']` and the input `stream_name` is `lts`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. ","nb_triggers":2,"triggers":["workflow_call","workflow_dispatch"],"nb_jobs":1,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["./.github/workflows/reusable-build-iso.yml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":62013,"repository_id":18255702,"mainLanguage":"Go","file_name":"ci-performance-gate.yml","file_content":"# This workflow runs performance tests to ensure we do not introduce performance\n# regressions. This runs for every PR, as well as on every merge to the master\n# branch.\n#\n# The Pulumi CLI binaries used in this workflow are built without race detection\n# or coverage instrumentation to ensure that the performance tests are not\n# affected by these flags.\n\nname: Performance Gate\n\npermissions:\n  contents: read\n\non:\n  workflow_call:\n    inputs:\n      ref:\n        required: true\n        description: \"GitHub ref to use\"\n        type: string\n      version:\n        required: true\n        description: \"Version to produce\"\n        type: string\n      test-version-sets:\n        required: false\n        default: minimum current\n        description: Version sets on which to run integration tests\n        type: string\n      performance-test-platforms:\n        required: false\n        default: ubuntu-22.04\n        description: Platforms on which to run performance tests, as a space delimited list\n        type: string\n      fail-fast:\n        required: false\n        default: false\n        description: \"Fail all workflows whenever one of them fails\"\n        type: boolean\n      test-retries:\n        required: false\n        default: 0\n        description: \"Retry tests n times if there are failures\"\n        type: number\n    secrets:\n      PULUMI_PROD_ACCESS_TOKEN:\n        required: false\n        description: \"Pulumi access token, required to run tests against the service\"\n      AZURE_TENANT_ID:\n        required: false\n        description: \"Azure tenant ID, required to run tests against Azure\"\n      AZURE_CLIENT_ID:\n        required: false\n        description: \"Azure client ID, required to run tests against Azure\"\n      AZURE_CLIENT_SECRET:\n        required: false\n        description: \"Azure clients secret, needs to be rotated before 2025-12-21 (see the pulumi-test user in Azure portal)\"\n      AZURE_STORAGE_SAS_TOKEN:\n        required: false\n        description: \"Azure storage SAS token, required to run tests against Azure\"\n      GCP_SERVICE_ACCOUNT:\n        required: false\n        description: \"GCP service account, required to run tests against GCP\"\n\njobs:\n  matrix:\n    runs-on: ubuntu-22.04\n    strategy:\n      fail-fast: ${{ inputs.fail-fast }}\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.ref }}\n      - name: build matrix\n        id: matrix\n        env:\n          TEST_VERSION_SETS: ${{ inputs.test-version-sets }}\n          INPUT_PERFORMANCE_TEST_PLATFORMS: ${{ inputs.performance-test-platforms }}\n        run: |\n          echo \"::group::Test matrix variables\"\n          readarray -td' ' VERSION_SETS_TO_TEST < <(echo -n \"$TEST_VERSION_SETS\"); declare -p VERSION_SETS_TO_TEST;\n          readarray -td' ' PERFORMANCE_TEST_PLATFORMS < <(echo -n \"$INPUT_PERFORMANCE_TEST_PLATFORMS\"); declare -p PERFORMANCE_TEST_PLATFORMS;\n          BUILD_TARGETS='[\n              { \"os\": \"linux\",   \"arch\": \"amd64\", \"build-platform\": \"ubuntu-22.04\" },\n              { \"os\": \"windows\", \"arch\": \"amd64\", \"build-platform\": \"ubuntu-22.04\" },\n              { \"os\": \"darwin\",  \"arch\": \"arm64\", \"build-platform\": \"ubuntu-22.04\" }\n          ]'\n\n          PERFORMANCE_TEST_MATRIX=$(\n            ./scripts/get-job-matrix.py \\\n            -vvv \\\n            generate-matrix \\\n            --kind performance-test \\\n            --platform \"${PERFORMANCE_TEST_PLATFORMS[@]}\" \\\n            --version-set \"${VERSION_SETS_TO_TEST[@]}\"\n          )\n          echo \"::endgroup::\"\n\n          echo \"::group::Version set variable\"\n          VERSION_SET=$(./scripts/get-job-matrix.py \\\n            generate-version-set \\\n            --version-set current\n          )\n          echo \"::endgroup::\"\n\n          echo \"::group::Performance test matrix\"\n          echo \"$PERFORMANCE_TEST_MATRIX\" | yq -P '.'\n          echo \"::endgroup::\"\n          echo \"::group::Version set\"\n          echo \"$VERSION_SET\" | yq -P '.'\n          echo \"::endgroup::\"\n\n          echo \"::group::Set outputs\"\n          ./.github/scripts/set-output performance-test-matrix \"${PERFORMANCE_TEST_MATRIX}\"\n          ./.github/scripts/set-output version-set \"${VERSION_SET}\"\n          ./.github/scripts/set-output build-targets \"${BUILD_TARGETS}\"\n          echo \"::endgroup::\"\n    outputs:\n      performance-test-matrix: \"${{ fromJson(steps.matrix.outputs.performance-test-matrix) }}\"\n      version-set: \"${{ fromJson(steps.matrix.outputs.version-set) }}\"\n      build-targets: \"${{ fromJson(steps.matrix.outputs.build-targets) }}\"\n\n  build-binaries:\n    name: build binaries\n    needs: [matrix]\n    strategy:\n      fail-fast: ${{ inputs.fail-fast }}\n      matrix:\n        target: ${{ fromJson(needs.matrix.outputs.build-targets) }}\n    uses: ./.github/workflows/ci-build-binaries.yml\n    with:\n      ref: ${{ inputs.ref }}\n      version: ${{ inputs.version }}\n      os: ${{ matrix.target.os }}\n      arch: ${{ matrix.target.arch }}\n      build-platform: ${{ matrix.target.build-platform }}\n      version-set: ${{ needs.matrix.outputs.version-set }}\n      # For performance tests, we do not want coverage or race detection enabled.\n      enable-coverage: false\n      enable-race-detection: false\n      # Suffix the artifacts so they do not clash with those of the main build.\n      artifact-suffix: '-perf'\n    secrets: inherit\n\n  performance-test:\n    # By putting a variable in the name, we remove GitHub's auto-generated matrix parameters from\n    # appearing in the rendered title of the job name.\n    name: Performance Test${{ matrix.platform && '' }}\n    needs: [matrix, build-binaries]\n    strategy:\n      fail-fast: ${{ inputs.fail-fast }}\n      matrix: ${{ fromJson(needs.matrix.outputs.performance-test-matrix) }}\n    uses: ./.github/workflows/ci-run-test.yml\n    with:\n      ref: ${{ inputs.ref }}\n      version: ${{ inputs.version }}\n      platform: ${{ matrix.platform }}\n      test-name: ${{ matrix.test-suite.name || matrix.test-suite.command }} on ${{ matrix.platform }}/${{ matrix.version-set.name }}\n      test-command: ${{ matrix.test-suite.command }}\n      is-performance-test: true\n      enable-coverage: false\n      test-retries: ${{ inputs.test-retries }}\n      version-set: ${{ toJson(matrix.version-set) }}\n    secrets: inherit\n","repository_owner":"pulumi","repository_name":"pulumi","tokens_count":1429,"workflow":"# This workflow runs performance tests to ensure we do not introduce performance\n# regressions. This runs for every PR, as well as on every merge to the master\n# branch.\n#\n# The Pulumi CLI binaries used in this workflow are built without race detection\n# or coverage instrumentation to ensure that the performance tests are not\n# affected by these flags.\n\nname: Performance Gate\n\npermissions:\n  contents: read\n\non:\n  workflow_call:\n    inputs:\n      ref:\n        required: true\n        description: GitHub ref to use\n        type: string\n      version:\n        required: true\n        description: Version to produce\n        type: string\n      test-version-sets:\n        required: false\n        default: minimum current\n        description: Version sets on which to run integration tests\n        type: string\n      performance-test-platforms:\n        required: false\n        default: ubuntu-22.04\n        description: Platforms on which to run performance tests, as a space \n          delimited list\n        type: string\n      fail-fast:\n        required: false\n        default: false\n        description: Fail all workflows whenever one of them fails\n        type: boolean\n      test-retries:\n        required: false\n        default: 0\n        description: Retry tests n times if there are failures\n        type: number\n    secrets:\n      PULUMI_PROD_ACCESS_TOKEN:\n        required: false\n        description: Pulumi access token, required to run tests against the \n          service\n      AZURE_TENANT_ID:\n        required: false\n        description: Azure tenant ID, required to run tests against Azure\n      AZURE_CLIENT_ID:\n        required: false\n        description: Azure client ID, required to run tests against Azure\n      AZURE_CLIENT_SECRET:\n        required: false\n        description: Azure clients secret, needs to be rotated before 2025-12-21\n          (see the pulumi-test user in Azure portal)\n      AZURE_STORAGE_SAS_TOKEN:\n        required: false\n        description: Azure storage SAS token, required to run tests against \n          Azure\n      GCP_SERVICE_ACCOUNT:\n        required: false\n        description: GCP service account, required to run tests against GCP\n\njobs:\n  matrix:\n    runs-on: ubuntu-22.04\n    strategy:\n      fail-fast: ${{ inputs.fail-fast }}\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      with:\n        ref: ${{ inputs.ref }}\n    - name: build matrix\n      id: matrix\n      env:\n        TEST_VERSION_SETS: ${{ inputs.test-version-sets }}\n        INPUT_PERFORMANCE_TEST_PLATFORMS: ${{ inputs.performance-test-platforms \n          }}\n      run: |\n        echo \"::group::Test matrix variables\"\n        readarray -td' ' VERSION_SETS_TO_TEST < <(echo -n \"$TEST_VERSION_SETS\"); declare -p VERSION_SETS_TO_TEST;\n        readarray -td' ' PERFORMANCE_TEST_PLATFORMS < <(echo -n \"$INPUT_PERFORMANCE_TEST_PLATFORMS\"); declare -p PERFORMANCE_TEST_PLATFORMS;\n        BUILD_TARGETS='[\n            { \"os\": \"linux\",   \"arch\": \"amd64\", \"build-platform\": \"ubuntu-22.04\" },\n            { \"os\": \"windows\", \"arch\": \"amd64\", \"build-platform\": \"ubuntu-22.04\" },\n            { \"os\": \"darwin\",  \"arch\": \"arm64\", \"build-platform\": \"ubuntu-22.04\" }\n        ]'\n\n        PERFORMANCE_TEST_MATRIX=$(\n          ./scripts/get-job-matrix.py \\\n          -vvv \\\n          generate-matrix \\\n          --kind performance-test \\\n          --platform \"${PERFORMANCE_TEST_PLATFORMS[@]}\" \\\n          --version-set \"${VERSION_SETS_TO_TEST[@]}\"\n        )\n        echo \"::endgroup::\"\n\n        echo \"::group::Version set variable\"\n        VERSION_SET=$(./scripts/get-job-matrix.py \\\n          generate-version-set \\\n          --version-set current\n        )\n        echo \"::endgroup::\"\n\n        echo \"::group::Performance test matrix\"\n        echo \"$PERFORMANCE_TEST_MATRIX\" | yq -P '.'\n        echo \"::endgroup::\"\n        echo \"::group::Version set\"\n        echo \"$VERSION_SET\" | yq -P '.'\n        echo \"::endgroup::\"\n\n        echo \"::group::Set outputs\"\n        ./.github/scripts/set-output performance-test-matrix \"${PERFORMANCE_TEST_MATRIX}\"\n        ./.github/scripts/set-output version-set \"${VERSION_SET}\"\n        ./.github/scripts/set-output build-targets \"${BUILD_TARGETS}\"\n        echo \"::endgroup::\"\n    outputs:\n      performance-test-matrix: ${{ \n        fromJson(steps.matrix.outputs.performance-test-matrix) }}\n      version-set: ${{ fromJson(steps.matrix.outputs.version-set) }}\n      build-targets: ${{ fromJson(steps.matrix.outputs.build-targets) }}\n\n  build-binaries:\n    name: build binaries\n    needs: [matrix]\n    strategy:\n      fail-fast: ${{ inputs.fail-fast }}\n      matrix:\n        target: ${{ fromJson(needs.matrix.outputs.build-targets) }}\n    uses: ./.github/workflows/ci-build-binaries.yml\n    with:\n      ref: ${{ inputs.ref }}\n      version: ${{ inputs.version }}\n      os: ${{ matrix.target.os }}\n      arch: ${{ matrix.target.arch }}\n      build-platform: ${{ matrix.target.build-platform }}\n      version-set: ${{ needs.matrix.outputs.version-set }}\n      # For performance tests, we do not want coverage or race detection enabled.\n      enable-coverage: false\n      enable-race-detection: false\n      # Suffix the artifacts so they do not clash with those of the main build.\n      artifact-suffix: -perf\n    secrets: inherit\n\n  performance-test:\n    # By putting a variable in the name, we remove GitHub's auto-generated matrix parameters from\n    # appearing in the rendered title of the job name.\n    name: Performance Test${{ matrix.platform && '' }}\n    needs: [matrix, build-binaries]\n    strategy:\n      fail-fast: ${{ inputs.fail-fast }}\n      matrix: ${{ fromJson(needs.matrix.outputs.performance-test-matrix) }}\n    uses: ./.github/workflows/ci-run-test.yml\n    with:\n      ref: ${{ inputs.ref }}\n      version: ${{ inputs.version }}\n      platform: ${{ matrix.platform }}\n      test-name: ${{ matrix.test-suite.name || matrix.test-suite.command }} on \n        ${{ matrix.platform }}/${{ matrix.version-set.name }}\n      test-command: ${{ matrix.test-suite.command }}\n      is-performance-test: true\n      enable-coverage: false\n      test-retries: ${{ inputs.test-retries }}\n      version-set: ${{ toJson(matrix.version-set) }}\n    secrets: inherit\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Performance Gate` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 6 inputs: ref-it must be supplied, this input represents github ref to use and the data type is string; version-it must be supplied, this input represents version to produce and the data type is string; test-version-sets-it is optional, its default value is minimum current, this input represents version sets on which to run integration tests and the data type is string; performance-test-platforms-it is optional, its default value is ubuntu-22.04, this input represents platforms on which to run performance tests, as a space delimited list and the data type is string; fail-fast-it is optional, its default value is False, this input represents fail all workflows whenever one of them fails and the data type is boolean; test-retries-it is optional, its default value is 0, this input represents retry tests n times if there are failures and the data type is number. It receives 6 secrets: PULUMI_PROD_ACCESS_TOKEN-it is optional and it represents pulumi access token, required to run tests against the service; AZURE_TENANT_ID-it is optional and it represents azure tenant id, required to run tests against azure; AZURE_CLIENT_ID-it is optional and it represents azure client id, required to run tests against azure; AZURE_CLIENT_SECRET-it is optional and it represents azure clients secret, needs to be rotated before 2025-12-21 (see the pulumi-test user in azure portal); AZURE_STORAGE_SAS_TOKEN-it is optional and it represents azure storage sas token, required to run tests against azure; GCP_SERVICE_ACCOUNT-it is optional and it represents gcp service account, required to run tests against gcp. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 3 jobs. The job id of the 1st job is `matrix`. The 2nd job is named `build binaries` and its job id is `build-binaries`. The 3rd job is named `Performance Test${{ matrix.platform && '' }}` and its job id is `performance-test`. ","prompt_level2":"Generate a GitHub Workflow named `Performance Gate` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 6 inputs: ref-it must be supplied, this input represents github ref to use and the data type is string; version-it must be supplied, this input represents version to produce and the data type is string; test-version-sets-it is optional, its default value is minimum current, this input represents version sets on which to run integration tests and the data type is string; performance-test-platforms-it is optional, its default value is ubuntu-22.04, this input represents platforms on which to run performance tests, as a space delimited list and the data type is string; fail-fast-it is optional, its default value is False, this input represents fail all workflows whenever one of them fails and the data type is boolean; test-retries-it is optional, its default value is 0, this input represents retry tests n times if there are failures and the data type is number. It receives 6 secrets: PULUMI_PROD_ACCESS_TOKEN-it is optional and it represents pulumi access token, required to run tests against the service; AZURE_TENANT_ID-it is optional and it represents azure tenant id, required to run tests against azure; AZURE_CLIENT_ID-it is optional and it represents azure client id, required to run tests against azure; AZURE_CLIENT_SECRET-it is optional and it represents azure clients secret, needs to be rotated before 2025-12-21 (see the pulumi-test user in azure portal); AZURE_STORAGE_SAS_TOKEN-it is optional and it represents azure storage sas token, required to run tests against azure; GCP_SERVICE_ACCOUNT-it is optional and it represents gcp service account, required to run tests against gcp. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 3 jobs. The job id of the 1st job is `matrix`. The job `matrix` has 2 steps. The 1st step is named `Checkout repository`. The 2nd step is named `build matrix` and its id is `matrix`. The 2nd job is named `build binaries` and its job id is `build-binaries`. The 3rd job is named `Performance Test${{ matrix.platform && '' }}` and its job id is `performance-test`. ","prompt_level3":"Generate a GitHub Workflow named `Performance Gate` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 6 inputs: ref-it must be supplied, this input represents github ref to use and the data type is string; version-it must be supplied, this input represents version to produce and the data type is string; test-version-sets-it is optional, its default value is minimum current, this input represents version sets on which to run integration tests and the data type is string; performance-test-platforms-it is optional, its default value is ubuntu-22.04, this input represents platforms on which to run performance tests, as a space delimited list and the data type is string; fail-fast-it is optional, its default value is False, this input represents fail all workflows whenever one of them fails and the data type is boolean; test-retries-it is optional, its default value is 0, this input represents retry tests n times if there are failures and the data type is number. It receives 6 secrets: PULUMI_PROD_ACCESS_TOKEN-it is optional and it represents pulumi access token, required to run tests against the service; AZURE_TENANT_ID-it is optional and it represents azure tenant id, required to run tests against azure; AZURE_CLIENT_ID-it is optional and it represents azure client id, required to run tests against azure; AZURE_CLIENT_SECRET-it is optional and it represents azure clients secret, needs to be rotated before 2025-12-21 (see the pulumi-test user in azure portal); AZURE_STORAGE_SAS_TOKEN-it is optional and it represents azure storage sas token, required to run tests against azure; GCP_SERVICE_ACCOUNT-it is optional and it represents gcp service account, required to run tests against gcp. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 3 jobs. The job id of the 1st job is `matrix`. This job will run on ubuntu-22.04 runner. If any job run in the matrix fails, all in-progress and queued jobs in the matrix will be canceled. The job `matrix` has 2 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `ref` is set to `${{ inputs.ref }}`. The 2nd step is named `build matrix` and its id is `matrix`. The step sets 2 environment variables to use: `TEST_VERSION_SETS` is set to `${{ inputs.test-version-sets }}` and `INPUT_PERFORMANCE_TEST_PLATFORMS` is set to `${{ inputs.performance-test-platforms }}`. This step runs a script: `echo \"::group::Test matrix variables\"\nreadarray -td' ' VERSION_SETS_TO_TEST < <(echo -n \"$TEST_VERSION_SETS\"); declare -p VERSION_SETS_TO_TEST;\nreadarray -td' ' PERFORMANCE_TEST_PLATFORMS < <(echo -n \"$INPUT_PERFORMANCE_TEST_PLATFORMS\"); declare -p PERFORMANCE_TEST_PLATFORMS;\nBUILD_TARGETS='[\n    { \"os\": \"linux\",   \"arch\": \"amd64\", \"build-platform\": \"ubuntu-22.04\" },\n    { \"os\": \"windows\", \"arch\": \"amd64\", \"build-platform\": \"ubuntu-22.04\" },\n    { \"os\": \"darwin\",  \"arch\": \"arm64\", \"build-platform\": \"ubuntu-22.04\" }\n]'\n\nPERFORMANCE_TEST_MATRIX=$(\n  ./scripts/get-job-matrix.py \\\n  -vvv \\\n  generate-matrix \\\n  --kind performance-test \\\n  --platform \"${PERFORMANCE_TEST_PLATFORMS[@]}\" \\\n  --version-set \"${VERSION_SETS_TO_TEST[@]}\"\n)\necho \"::endgroup::\"\n\necho \"::group::Version set variable\"\nVERSION_SET=$(./scripts/get-job-matrix.py \\\n  generate-version-set \\\n  --version-set current\n)\necho \"::endgroup::\"\n\necho \"::group::Performance test matrix\"\necho \"$PERFORMANCE_TEST_MATRIX\" | yq -P '.'\necho \"::endgroup::\"\necho \"::group::Version set\"\necho \"$VERSION_SET\" | yq -P '.'\necho \"::endgroup::\"\n\necho \"::group::Set outputs\"\n./.github/scripts/set-output performance-test-matrix \"${PERFORMANCE_TEST_MATRIX}\"\n./.github/scripts/set-output version-set \"${VERSION_SET}\"\n./.github/scripts/set-output build-targets \"${BUILD_TARGETS}\"\necho \"::endgroup::\"\n`. This job has 3 outputs: `performance-test-matrix` is defined as ${{ fromJson(steps.matrix.outputs.performance-test-matrix) }}, `version-set` is defined as ${{ fromJson(steps.matrix.outputs.version-set) }} and `build-targets` is defined as ${{ fromJson(steps.matrix.outputs.build-targets) }}. The 2nd job is named `build binaries` and its job id is `build-binaries`. Before this job runs, `matrix` must complete successfully. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `target` has 51 values: $, {, {,  , f, r, o, m, J, s, o, n, (, n, e, e, d, s, ., m, a, t, r, i, x, ., o, u, t, p, u, t, s, ., b, u, i, l, d, -, t, a, r, g, e, t, s, ),  , } and }. If any job run in the matrix fails, all in-progress and queued jobs in the matrix will be canceled. This job will call a reusable workflow located at `./.github/workflows/ci-build-binaries.yml`. The job will pass 9 inputs to the called workflow: the input `ref` is `${{ inputs.ref }}`, the input `version` is `${{ inputs.version }}`, the input `os` is `${{ matrix.target.os }}`, the input `arch` is `${{ matrix.target.arch }}`, the input `build-platform` is `${{ matrix.target.build-platform }}`, the input `version-set` is `${{ needs.matrix.outputs.version-set }}`, the input `enable-coverage` is `False`, the input `enable-race-detection` is `False` and the input `artifact-suffix` is `-perf`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. The 3rd job is named `Performance Test${{ matrix.platform && '' }}` and its job id is `performance-test`. Before this job runs, `matrix` and `build-binaries` must complete successfully. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The matrix is ${{ fromJson(needs.matrix.outputs.performance-test-matrix) }}. If any job run in the matrix fails, all in-progress and queued jobs in the matrix will be canceled. This job will call a reusable workflow located at `./.github/workflows/ci-run-test.yml`. The job will pass 9 inputs to the called workflow: the input `ref` is `${{ inputs.ref }}`, the input `version` is `${{ inputs.version }}`, the input `platform` is `${{ matrix.platform }}`, the input `test-name` is `${{ matrix.test-suite.name || matrix.test-suite.command }} on ${{ matrix.platform }}/${{ matrix.version-set.name }}`, the input `test-command` is `${{ matrix.test-suite.command }}`, the input `is-performance-test` is `True`, the input `enable-coverage` is `False`, the input `test-retries` is `${{ inputs.test-retries }}` and the input `version-set` is `${{ toJson(matrix.version-set) }}`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":3,"nb_actions":1,"actions":["actions/checkout"],"actions_details":[{"version":"v4","name":"actions/checkout"}],"nb_reusable_workflows":2,"reusable_workflows":["./.github/workflows/ci-build-binaries.yml","./.github/workflows/ci-run-test.yml"],"nb_steps":2,"cyclomatic_complexity":2}
{"id":26720,"repository_id":3980051,"mainLanguage":"C++","file_name":"root-docs-master.yml","file_content":"\nname: 'ROOT Docs Main'\n\non:\n  schedule:\n    - cron: '0 1 * * *'\n    - cron: '0 12 * * *'\n\n  workflow_dispatch:\n    inputs:\n      incremental:\n        description: 'Do full build'\n        type: boolean\n        required: false\n        default: false\n      # docu_input: # opportunity: overwrite makeinput.sh with these args\n      #   description: Folders to build documentation for. All folders are built if empty.\n      #   type: string\n      #   default: \"\"\n      #   required: false\n\njobs:\n  run_nightlies:\n    uses: root-project/root/.github/workflows/root-docs-ci.yml@master\n    secrets: inherit\n","repository_owner":"root-project","repository_name":"root","tokens_count":158,"workflow":"name: ROOT Docs Main\n\non:\n  schedule:\n  - cron: 0 1 * * *\n  - cron: 0 12 * * *\n\n  workflow_dispatch:\n    inputs:\n      incremental:\n        description: Do full build\n        type: boolean\n        required: false\n        default: false\n      # docu_input: # opportunity: overwrite makeinput.sh with these args\n      #   description: Folders to build documentation for. All folders are built if empty.\n      #   type: string\n      #   default: \"\"\n      #   required: false\n\njobs:\n  run_nightlies:\n    uses: root-project/root/.github/workflows/root-docs-ci.yml@master\n    secrets: inherit\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `ROOT Docs Main` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 01:00 am or at 12:00 pm. 2) someone manually triggers the workflow. This workflow receives an input: incremental-this input represents do full build, the data type is boolean, it is optional and its default value is False. The workflow has one job. The job id of the 1st job is `run_nightlies`. ","prompt_level2":"Generate a GitHub Workflow named `ROOT Docs Main` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 01:00 am or at 12:00 pm. 2) someone manually triggers the workflow. This workflow receives an input: incremental-this input represents do full build, the data type is boolean, it is optional and its default value is False. The workflow has one job. The job id of the 1st job is `run_nightlies`. ","prompt_level3":"Generate a GitHub Workflow named `ROOT Docs Main` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) the scheduled time has come: at 01:00 am or at 12:00 pm. 2) someone manually triggers the workflow. This workflow receives an input: incremental-this input represents do full build, the data type is boolean, it is optional and its default value is False. The workflow has one job. The job id of the 1st job is `run_nightlies`. This job will call a reusable workflow located at `root-project/root/.github/workflows/root-docs-ci.yml@master`. The job will pass a secret to the called workflow: the secret `special_case_secrets` is `inherit`. ","nb_triggers":2,"triggers":["schedule","workflow_dispatch"],"nb_jobs":1,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":1,"reusable_workflows":["root-project/root/.github/workflows/root-docs-ci.yml"],"nb_steps":0,"cyclomatic_complexity":1}
{"id":31348,"repository_id":7793476,"mainLanguage":"TypeScript","file_name":"label-waiting-for-response.yml","file_content":"name: Auto Label Issues\n\non:\n  issue_comment:\n    types: [created]\n  workflow_dispatch:\n    inputs:\n      label-all-issues:\n        description: 'Add label to all open issues'\n        type: boolean\n        default: false\n        required: false\n\njobs:\n  add-label-single:\n    runs-on: ubuntu-latest\n    if: |\n      github.event_name == 'issue_comment' && \n      github.event.issue.user.login != github.event.comment.user.login\n    \n    steps:\n      - name: Check if commenter is maintainer\n        id: check-maintainer\n        uses: actions/github-script@v7\n        with:\n          script: |\n            const response = await github.rest.repos.getCollaboratorPermissionLevel({\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              username: context.payload.comment.user.login\n            });\n            \n            const isMaintianer = ['admin', 'write'].includes(response.data.permission);\n            return isMaintianer;\n            \n      - name: Add waiting-for-response label\n        if: steps.check-maintainer.outputs.result == 'true'\n        uses: actions/github-script@v7\n        with:\n          script: |\n            await github.rest.issues.addLabels({\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              issue_number: context.issue.number,\n              labels: ['waiting-for-response']\n            });\n\n  add-label-all:\n    runs-on: ubuntu-latest\n    if: |\n      github.event_name == 'workflow_dispatch' && \n      github.event.inputs.label-all-issues == 'true'\n    \n    steps:\n      - name: Process all open issues\n        uses: actions/github-script@v7\n        with:\n          script: |\n            async function isMaintianer(username) {\n              try {\n                const response = await github.rest.repos.getCollaboratorPermissionLevel({\n                  owner: context.repo.owner,\n                  repo: context.repo.repo,\n                  username: username\n                });\n                return ['admin', 'write'].includes(response.data.permission);\n              } catch (error) {\n                console.error(`Error checking permissions for ${username}:`, error);\n                return false;\n              }\n            }\n\n            async function getLastComment(issueNumber) {\n              try {\n                const comments = await github.paginate(github.rest.issues.listComments, {\n                  owner: context.repo.owner,\n                  repo: context.repo.repo,\n                  issue_number: issueNumber,\n                  per_page: 100\n                });\n                \n                // Return the most recent comment, or null if no comments\n                return comments.length > 0 ? comments[comments.length - 1] : null;\n              } catch (error) {\n                console.error(`Error fetching comments for issue #${issueNumber}:`, error);\n                return null;\n              }\n            }\n\n            // Get all open issues\n            const issues = await github.paginate(github.rest.issues.listForRepo, {\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              state: 'open',\n              per_page: 100\n            });\n            \n            for (const issue of issues) {\n              try {\n                console.log(`Processing issue #${issue.number}...`);\n                \n                // Get the last comment\n                const lastComment = await getLastComment(issue.number);\n                \n                // Skip if no comments\n                if (!lastComment) {\n                  console.log(`No comments found on issue #${issue.number}, skipping`);\n                  continue;\n                }\n                \n                // Check if last commenter is a maintainer\n                const lastCommenterIsMaintainer = await isMaintianer(lastComment.user.login);\n                \n                // Skip if last commenter is not a maintainer\n                if (!lastCommenterIsMaintainer) {\n                  console.log(`Last comment on issue #${issue.number} is not from a maintainer, skipping`);\n                  continue;\n                }\n                \n                // Skip if last commenter is the issue author\n                if (lastComment.user.login === issue.user.login) {\n                  console.log(`Last comment on issue #${issue.number} is from the issue author, skipping`);\n                  continue;\n                }\n\n                // Add the label\n                await github.rest.issues.addLabels({\n                  owner: context.repo.owner,\n                  repo: context.repo.repo,\n                  issue_number: issue.number,\n                  labels: ['waiting-for-response']\n                });\n                \n                console.log(`Added label to issue #${issue.number}`);\n              } catch (error) {\n                console.error(`Error processing issue #${issue.number}:`, error);\n              }\n            }","repository_owner":"wix","repository_name":"react-native-ui-lib","tokens_count":934,"workflow":"name: Auto Label Issues\n\non:\n  issue_comment:\n    types: [created]\n  workflow_dispatch:\n    inputs:\n      label-all-issues:\n        description: Add label to all open issues\n        type: boolean\n        default: false\n        required: false\n\njobs:\n  add-label-single:\n    runs-on: ubuntu-latest\n    if: |\n      github.event_name == 'issue_comment' && \n      github.event.issue.user.login != github.event.comment.user.login\n\n    steps:\n    - name: Check if commenter is maintainer\n      id: check-maintainer\n      uses: actions/github-script@v7\n      with:\n        script: |\n          const response = await github.rest.repos.getCollaboratorPermissionLevel({\n            owner: context.repo.owner,\n            repo: context.repo.repo,\n            username: context.payload.comment.user.login\n          });\n\n          const isMaintianer = ['admin', 'write'].includes(response.data.permission);\n          return isMaintianer;\n\n    - name: Add waiting-for-response label\n      if: steps.check-maintainer.outputs.result == 'true'\n      uses: actions/github-script@v7\n      with:\n        script: |\n          await github.rest.issues.addLabels({\n            owner: context.repo.owner,\n            repo: context.repo.repo,\n            issue_number: context.issue.number,\n            labels: ['waiting-for-response']\n          });\n\n  add-label-all:\n    runs-on: ubuntu-latest\n    if: |\n      github.event_name == 'workflow_dispatch' && \n      github.event.inputs.label-all-issues == 'true'\n\n    steps:\n    - name: Process all open issues\n      uses: actions/github-script@v7\n      with:\n        script: |-\n          async function isMaintianer(username) {\n            try {\n              const response = await github.rest.repos.getCollaboratorPermissionLevel({\n                owner: context.repo.owner,\n                repo: context.repo.repo,\n                username: username\n              });\n              return ['admin', 'write'].includes(response.data.permission);\n            } catch (error) {\n              console.error(`Error checking permissions for ${username}:`, error);\n              return false;\n            }\n          }\n\n          async function getLastComment(issueNumber) {\n            try {\n              const comments = await github.paginate(github.rest.issues.listComments, {\n                owner: context.repo.owner,\n                repo: context.repo.repo,\n                issue_number: issueNumber,\n                per_page: 100\n              });\n              \n              // Return the most recent comment, or null if no comments\n              return comments.length > 0 ? comments[comments.length - 1] : null;\n            } catch (error) {\n              console.error(`Error fetching comments for issue #${issueNumber}:`, error);\n              return null;\n            }\n          }\n\n          // Get all open issues\n          const issues = await github.paginate(github.rest.issues.listForRepo, {\n            owner: context.repo.owner,\n            repo: context.repo.repo,\n            state: 'open',\n            per_page: 100\n          });\n\n          for (const issue of issues) {\n            try {\n              console.log(`Processing issue #${issue.number}...`);\n              \n              // Get the last comment\n              const lastComment = await getLastComment(issue.number);\n              \n              // Skip if no comments\n              if (!lastComment) {\n                console.log(`No comments found on issue #${issue.number}, skipping`);\n                continue;\n              }\n              \n              // Check if last commenter is a maintainer\n              const lastCommenterIsMaintainer = await isMaintianer(lastComment.user.login);\n              \n              // Skip if last commenter is not a maintainer\n              if (!lastCommenterIsMaintainer) {\n                console.log(`Last comment on issue #${issue.number} is not from a maintainer, skipping`);\n                continue;\n              }\n              \n              // Skip if last commenter is the issue author\n              if (lastComment.user.login === issue.user.login) {\n                console.log(`Last comment on issue #${issue.number} is from the issue author, skipping`);\n                continue;\n              }\n\n              // Add the label\n              await github.rest.issues.addLabels({\n                owner: context.repo.owner,\n                repo: context.repo.repo,\n                issue_number: issue.number,\n                labels: ['waiting-for-response']\n              });\n              \n              console.log(`Added label to issue #${issue.number}`);\n            } catch (error) {\n              console.error(`Error processing issue #${issue.number}:`, error);\n            }\n          }\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Auto Label Issues` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) a comment on an issue or pull request is created. 2) someone manually triggers the workflow. This workflow receives an input: label-all-issues-this input represents add label to all open issues, the data type is boolean, its default value is False and it is optional. The workflow has 2 jobs. The job id of the 1st job is `add-label-single`. The job id of the 2nd job is `add-label-all`. ","prompt_level2":"Generate a GitHub Workflow named `Auto Label Issues` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) a comment on an issue or pull request is created. 2) someone manually triggers the workflow. This workflow receives an input: label-all-issues-this input represents add label to all open issues, the data type is boolean, its default value is False and it is optional. The workflow has 2 jobs. The job id of the 1st job is `add-label-single`. The job `add-label-single` has 2 steps. The 1st step is named `Check if commenter is maintainer` and its id is `check-maintainer`. The 2nd step is named `Add waiting-for-response label`. The job id of the 2nd job is `add-label-all`. The job `add-label-all` has one step. The 1st step is named `Process all open issues`. ","prompt_level3":"Generate a GitHub Workflow named `Auto Label Issues` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by multiple events: 1) a comment on an issue or pull request is created. 2) someone manually triggers the workflow. This workflow receives an input: label-all-issues-this input represents add label to all open issues, the data type is boolean, its default value is False and it is optional. The workflow has 2 jobs. The job id of the 1st job is `add-label-single`. This job will run only if the condition(github.event_name == 'issue_comment' && \ngithub.event.issue.user.login != github.event.comment.user.login\n) is met. This job will run on ubuntu-latest runner. The job `add-label-single` has 2 steps. The 1st step is named `Check if commenter is maintainer` and its id is `check-maintainer`. This step runs action `actions/github-script` tagged as v7. The step defines an input parameter for the action: `script` is set to `const response = await github.rest.repos.getCollaboratorPermissionLevel({\n  owner: context.repo.owner,\n  repo: context.repo.repo,\n  username: context.payload.comment.user.login\n});\n\nconst isMaintianer = ['admin', 'write'].includes(response.data.permission);\nreturn isMaintianer;\n`. The 2nd step is named `Add waiting-for-response label`. This step will run only if the condition(steps.check-maintainer.outputs.result == 'true') is met. This step runs action `actions/github-script` tagged as v7. The step defines an input parameter for the action: `script` is set to `await github.rest.issues.addLabels({\n  owner: context.repo.owner,\n  repo: context.repo.repo,\n  issue_number: context.issue.number,\n  labels: ['waiting-for-response']\n});\n`. The job id of the 2nd job is `add-label-all`. This job will run only if the condition(github.event_name == 'workflow_dispatch' && \ngithub.event.inputs.label-all-issues == 'true'\n) is met. This job will run on ubuntu-latest runner. The job `add-label-all` has one step. The 1st step is named `Process all open issues`. This step runs action `actions/github-script` tagged as v7. The step defines an input parameter for the action: `script` is set to `async function isMaintianer(username) {\n  try {\n    const response = await github.rest.repos.getCollaboratorPermissionLevel({\n      owner: context.repo.owner,\n      repo: context.repo.repo,\n      username: username\n    });\n    return ['admin', 'write'].includes(response.data.permission);\n  } catch (error) {\n    console.error(`Error checking permissions for ${username}:`, error);\n    return false;\n  }\n}\n\nasync function getLastComment(issueNumber) {\n  try {\n    const comments = await github.paginate(github.rest.issues.listComments, {\n      owner: context.repo.owner,\n      repo: context.repo.repo,\n      issue_number: issueNumber,\n      per_page: 100\n    });\n    \n    // Return the most recent comment, or null if no comments\n    return comments.length > 0 ? comments[comments.length - 1] : null;\n  } catch (error) {\n    console.error(`Error fetching comments for issue #${issueNumber}:`, error);\n    return null;\n  }\n}\n\n// Get all open issues\nconst issues = await github.paginate(github.rest.issues.listForRepo, {\n  owner: context.repo.owner,\n  repo: context.repo.repo,\n  state: 'open',\n  per_page: 100\n});\n\nfor (const issue of issues) {\n  try {\n    console.log(`Processing issue #${issue.number}...`);\n    \n    // Get the last comment\n    const lastComment = await getLastComment(issue.number);\n    \n    // Skip if no comments\n    if (!lastComment) {\n      console.log(`No comments found on issue #${issue.number}, skipping`);\n      continue;\n    }\n    \n    // Check if last commenter is a maintainer\n    const lastCommenterIsMaintainer = await isMaintianer(lastComment.user.login);\n    \n    // Skip if last commenter is not a maintainer\n    if (!lastCommenterIsMaintainer) {\n      console.log(`Last comment on issue #${issue.number} is not from a maintainer, skipping`);\n      continue;\n    }\n    \n    // Skip if last commenter is the issue author\n    if (lastComment.user.login === issue.user.login) {\n      console.log(`Last comment on issue #${issue.number} is from the issue author, skipping`);\n      continue;\n    }\n\n    // Add the label\n    await github.rest.issues.addLabels({\n      owner: context.repo.owner,\n      repo: context.repo.repo,\n      issue_number: issue.number,\n      labels: ['waiting-for-response']\n    });\n    \n    console.log(`Added label to issue #${issue.number}`);\n  } catch (error) {\n    console.error(`Error processing issue #${issue.number}:`, error);\n  }\n}`. ","nb_triggers":2,"triggers":["issue_comment","workflow_dispatch"],"nb_jobs":2,"nb_actions":3,"actions":["actions/github-script","actions/github-script","actions/github-script"],"actions_details":[{"version":"v7","name":"actions/github-script"},{"version":"v7","name":"actions/github-script"},{"version":"v7","name":"actions/github-script"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":3,"cyclomatic_complexity":2}
{"id":17679,"repository_id":3995171,"mainLanguage":"C","file_name":"codecov.yml","file_content":"name: \"Codecov\"\n\n# Enabling on each push is to display the coverage changes in every PR, \n# where each PR needs to be compared against the coverage of the head commit\non: [push, pull_request]\n\njobs:\n  code-coverage:\n    runs-on: ubuntu-22.04\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Install lcov and run test\n      run: |\n        sudo apt-get install lcov\n        make lcov\n\n    - name: Upload coverage reports to Codecov\n      uses: codecov/codecov-action@v4\n      with:\n        token: ${{ secrets.CODECOV_TOKEN }}\n        file: ./src/redis.info\n","repository_owner":"redis","repository_name":"redis","tokens_count":161,"workflow":"name: Codecov\n\n# Enabling on each push is to display the coverage changes in every PR, \n# where each PR needs to be compared against the coverage of the head commit\non: [push, pull_request]\n\njobs:\n  code-coverage:\n    runs-on: ubuntu-22.04\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Install lcov and run test\n      run: |\n        sudo apt-get install lcov\n        make lcov\n\n    - name: Upload coverage reports to Codecov\n      uses: codecov/codecov-action@v4\n      with:\n        token: ${{ secrets.CODECOV_TOKEN }}\n        file: ./src/redis.info\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Codecov` for a GitHub repository whose primary programming language is C. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow has one job. The job id of the 1st job is `code-coverage`. ","prompt_level2":"Generate a GitHub Workflow named `Codecov` for a GitHub repository whose primary programming language is C. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow has one job. The job id of the 1st job is `code-coverage`. The job `code-coverage` has 3 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Install lcov and run test`. The 3rd step is named `Upload coverage reports to Codecov`. ","prompt_level3":"Generate a GitHub Workflow named `Codecov` for a GitHub repository whose primary programming language is C. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow has one job. The job id of the 1st job is `code-coverage`. This job will run on ubuntu-22.04 runner. The job `code-coverage` has 3 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Install lcov and run test`. This step runs a script: `sudo apt-get install lcov\nmake lcov\n`. The 3rd step is named `Upload coverage reports to Codecov`. This step runs action `codecov/codecov-action` tagged as v4. The step defines 2 input parameters for the action: `token` is set to `${{ secrets.CODECOV_TOKEN }}` and `file` is set to `./src/redis.info`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","codecov/codecov-action"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"codecov/codecov-action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":3,"cyclomatic_complexity":1}
{"id":38046,"repository_id":78545635,"mainLanguage":"JavaScript","file_name":"build.yml","file_content":"name: Dejavu - Node.js Build and Release Workflow\n\non:\n  release:\n    types: [published]\n  repository_dispatch:\n    types: [publish_binary]\n  workflow_dispatch:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout repository with submodules\n      uses: actions/checkout@v3\n      with:\n        submodules: recursive\n        fetch-depth: 0\n\n    - name: Set up Node.js 20 LTS\n      uses: actions/setup-node@v3\n      with:\n        node-version: '20'\n        cache: 'yarn'\n\n    - name: Install dependencies\n      run: yarn\n\n    - name: Extract version from payload\n      id: get_version\n      if: ${{ github.event_name == 'repository_dispatch' }}\n      run: echo \"version=${{ github.event.client_payload.version }}\" >> $GITHUB_OUTPUT\n\n    - name: Get Version For Release\n      id: get_version_release\n      if: ${{ github.event_name != 'repository_dispatch' }}\n      uses: battila7/get-version-action@v2.2.1\n\n    - name: Determine Version\n      id: set_version\n      run: |\n        if [ -n \"${{ steps.get_version.outputs.version }}\" ]; then\n          echo \"version=${{ steps.get_version.outputs.version }}\" >> $GITHUB_OUTPUT\n        elif [ -n \"${{ steps.get_version_release.outputs.version }}\" ]; then\n          echo \"version=${{ steps.get_version_release.outputs.version }}\" >> $GITHUB_OUTPUT\n        else\n          echo \"Error: Version is not set.\"\n          exit 1\n        fi\n\n    - name: Build Dejavu App\n      run: yarn build:dejavu:app\n\n    - name: Zip the dist folder\n      run: |\n        zip -r dist-${{ steps.set_version.outputs.version }}.zip ./packages/dejavu-main/dist\n\n    # Fetch release by tag and get upload_url, stripping the placeholder\n    - name: Get upload_url for release\n      if: ${{ github.event_name == 'repository_dispatch' }}\n      id: get_release\n      run: |\n        release_data=$(curl -s \\\n          -H \"Authorization: token ${{ secrets.PAT }}\" \\\n          \"https://api.github.com/repos/${{ github.repository }}/releases/tags/${{ steps.set_version.outputs.version }}\")\n        upload_url=$(echo \"$release_data\" | jq -r '.upload_url' | sed -e \"s/{?name,label}//\")\n        if [ \"$upload_url\" == \"null\" ]; then\n          echo \"Error: Release not found for tag ${steps.set_version.outputs.version}\"\n          exit 1\n        fi\n        echo \"upload_url=$upload_url\" >> $GITHUB_OUTPUT\n\n    - name: Upload dist.zip to GitHub Release (using curl)\n      run: |\n        curl -X POST \\\n          -H \"Authorization: token ${{ secrets.PAT }}\" \\\n          -H \"Content-Type: application/zip\" \\\n          --data-binary @./dist-${{ steps.set_version.outputs.version }}.zip \\\n          \"${{ steps.get_release.outputs.upload_url }}?name=dejavu-dist-${{ steps.set_version.outputs.version }}.zip\"\n\n    # For release events, use the upload_url from the event payload\n    - name: Upload dist.zip to GitHub Release (release event)\n      if: ${{ github.event_name == 'release' }}\n      run: |\n        upload_url=\"${{ github.event.release.upload_url }}\"\n        # Strip the placeholder\n        upload_url=\"${upload_url%\\{*}\"\n        curl -X POST \\\n          -H \"Authorization: token ${{ secrets.PAT }}\" \\\n          -H \"Content-Type: application/zip\" \\\n          --data-binary @./dist-${{ steps.set_version.outputs.version }}.zip \\\n          \"${upload_url}?name=dejavu-dist-${{ steps.set_version.outputs.version }}.zip\"","repository_owner":"appbaseio","repository_name":"dejavu","tokens_count":825,"workflow":"name: Dejavu - Node.js Build and Release Workflow\n\non:\n  release:\n    types: [published]\n  repository_dispatch:\n    types: [publish_binary]\n  workflow_dispatch:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout repository with submodules\n      uses: actions/checkout@v3\n      with:\n        submodules: recursive\n        fetch-depth: 0\n\n    - name: Set up Node.js 20 LTS\n      uses: actions/setup-node@v3\n      with:\n        node-version: '20'\n        cache: yarn\n\n    - name: Install dependencies\n      run: yarn\n\n    - name: Extract version from payload\n      id: get_version\n      if: ${{ github.event_name == 'repository_dispatch' }}\n      run: echo \"version=${{ github.event.client_payload.version }}\" >> \n        $GITHUB_OUTPUT\n\n    - name: Get Version For Release\n      id: get_version_release\n      if: ${{ github.event_name != 'repository_dispatch' }}\n      uses: battila7/get-version-action@v2.2.1\n\n    - name: Determine Version\n      id: set_version\n      run: |\n        if [ -n \"${{ steps.get_version.outputs.version }}\" ]; then\n          echo \"version=${{ steps.get_version.outputs.version }}\" >> $GITHUB_OUTPUT\n        elif [ -n \"${{ steps.get_version_release.outputs.version }}\" ]; then\n          echo \"version=${{ steps.get_version_release.outputs.version }}\" >> $GITHUB_OUTPUT\n        else\n          echo \"Error: Version is not set.\"\n          exit 1\n        fi\n\n    - name: Build Dejavu App\n      run: yarn build:dejavu:app\n\n    - name: Zip the dist folder\n      run: |\n        zip -r dist-${{ steps.set_version.outputs.version }}.zip ./packages/dejavu-main/dist\n\n    # Fetch release by tag and get upload_url, stripping the placeholder\n    - name: Get upload_url for release\n      if: ${{ github.event_name == 'repository_dispatch' }}\n      id: get_release\n      run: |\n        release_data=$(curl -s \\\n          -H \"Authorization: token ${{ secrets.PAT }}\" \\\n          \"https://api.github.com/repos/${{ github.repository }}/releases/tags/${{ steps.set_version.outputs.version }}\")\n        upload_url=$(echo \"$release_data\" | jq -r '.upload_url' | sed -e \"s/{?name,label}//\")\n        if [ \"$upload_url\" == \"null\" ]; then\n          echo \"Error: Release not found for tag ${steps.set_version.outputs.version}\"\n          exit 1\n        fi\n        echo \"upload_url=$upload_url\" >> $GITHUB_OUTPUT\n\n    - name: Upload dist.zip to GitHub Release (using curl)\n      run: |\n        curl -X POST \\\n          -H \"Authorization: token ${{ secrets.PAT }}\" \\\n          -H \"Content-Type: application/zip\" \\\n          --data-binary @./dist-${{ steps.set_version.outputs.version }}.zip \\\n          \"${{ steps.get_release.outputs.upload_url }}?name=dejavu-dist-${{ steps.set_version.outputs.version }}.zip\"\n\n    # For release events, use the upload_url from the event payload\n    - name: Upload dist.zip to GitHub Release (release event)\n      if: ${{ github.event_name == 'release' }}\n      run: |-\n        upload_url=\"${{ github.event.release.upload_url }}\"\n        # Strip the placeholder\n        upload_url=\"${upload_url%\\{*}\"\n        curl -X POST \\\n          -H \"Authorization: token ${{ secrets.PAT }}\" \\\n          -H \"Content-Type: application/zip\" \\\n          --data-binary @./dist-${{ steps.set_version.outputs.version }}.zip \\\n          \"${upload_url}?name=dejavu-dist-${{ steps.set_version.outputs.version }}.zip\"\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Dejavu - Node.js Build and Release Workflow` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) a GitHub App sends a \"POST\" request to \"/repos/{owner}/{repo}/dispatches\" and its event type includes publish_binary. 3) someone manually triggers the workflow. The workflow has one job. The job id of the 1st job is `build`. ","prompt_level2":"Generate a GitHub Workflow named `Dejavu - Node.js Build and Release Workflow` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) a GitHub App sends a \"POST\" request to \"/repos/{owner}/{repo}/dispatches\" and its event type includes publish_binary. 3) someone manually triggers the workflow. The workflow has one job. The job id of the 1st job is `build`. The job `build` has 11 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up Node.js 20 LTS`. The 3rd step is named `Install dependencies`. The 4th step is named `Extract version from payload` and its id is `get_version`. The 5th step is named `Get Version For Release` and its id is `get_version_release`. The 6th step is named `Determine Version` and its id is `set_version`. The 7th step is named `Build Dejavu App`. The 8th step is named `Zip the dist folder`. The 9th step is named `Get upload_url for release` and its id is `get_release`. The 10th step is named `Upload dist.zip to GitHub Release (using curl)`. The 11th step is named `Upload dist.zip to GitHub Release (release event)`. ","prompt_level3":"Generate a GitHub Workflow named `Dejavu - Node.js Build and Release Workflow` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) a GitHub App sends a \"POST\" request to \"/repos/{owner}/{repo}/dispatches\" and its event type includes publish_binary. 3) someone manually triggers the workflow. The workflow has one job. The job id of the 1st job is `build`. This job will run on ubuntu-latest runner. The job `build` has 11 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v3. The step defines 2 input parameters for the action: `submodules` is set to `recursive` and `fetch-depth` is set to `0`. The 2nd step is named `Set up Node.js 20 LTS`. This step runs action `actions/setup-node` tagged as v3. The step defines 2 input parameters for the action: `node-version` is set to `20` and `cache` is set to `yarn`. The 3rd step is named `Install dependencies`. This step runs a script: `yarn`. The 4th step is named `Extract version from payload` and its id is `get_version`. This step will run only if the condition(${{ github.event_name == 'repository_dispatch' }}) is met. This step runs a script: `echo \"version=${{ github.event.client_payload.version }}\" >> $GITHUB_OUTPUT`. The 5th step is named `Get Version For Release` and its id is `get_version_release`. This step will run only if the condition(${{ github.event_name != 'repository_dispatch' }}) is met. This step runs action `battila7/get-version-action` tagged as v2.2.1. The 6th step is named `Determine Version` and its id is `set_version`. This step runs a script: `if [ -n \"${{ steps.get_version.outputs.version }}\" ]; then\n  echo \"version=${{ steps.get_version.outputs.version }}\" >> $GITHUB_OUTPUT\nelif [ -n \"${{ steps.get_version_release.outputs.version }}\" ]; then\n  echo \"version=${{ steps.get_version_release.outputs.version }}\" >> $GITHUB_OUTPUT\nelse\n  echo \"Error: Version is not set.\"\n  exit 1\nfi\n`. The 7th step is named `Build Dejavu App`. This step runs a script: `yarn build:dejavu:app`. The 8th step is named `Zip the dist folder`. This step runs a script: `zip -r dist-${{ steps.set_version.outputs.version }}.zip ./packages/dejavu-main/dist\n`. The 9th step is named `Get upload_url for release` and its id is `get_release`. This step will run only if the condition(${{ github.event_name == 'repository_dispatch' }}) is met. This step runs a script: `release_data=$(curl -s \\\n  -H \"Authorization: token ${{ secrets.PAT }}\" \\\n  \"https://api.github.com/repos/${{ github.repository }}/releases/tags/${{ steps.set_version.outputs.version }}\")\nupload_url=$(echo \"$release_data\" | jq -r '.upload_url' | sed -e \"s/{?name,label}//\")\nif [ \"$upload_url\" == \"null\" ]; then\n  echo \"Error: Release not found for tag ${steps.set_version.outputs.version}\"\n  exit 1\nfi\necho \"upload_url=$upload_url\" >> $GITHUB_OUTPUT\n`. The 10th step is named `Upload dist.zip to GitHub Release (using curl)`. This step runs a script: `curl -X POST \\\n  -H \"Authorization: token ${{ secrets.PAT }}\" \\\n  -H \"Content-Type: application/zip\" \\\n  --data-binary @./dist-${{ steps.set_version.outputs.version }}.zip \\\n  \"${{ steps.get_release.outputs.upload_url }}?name=dejavu-dist-${{ steps.set_version.outputs.version }}.zip\"\n`. The 11th step is named `Upload dist.zip to GitHub Release (release event)`. This step will run only if the condition(${{ github.event_name == 'release' }}) is met. This step runs a script: `upload_url=\"${{ github.event.release.upload_url }}\"\n# Strip the placeholder\nupload_url=\"${upload_url%\\{*}\"\ncurl -X POST \\\n  -H \"Authorization: token ${{ secrets.PAT }}\" \\\n  -H \"Content-Type: application/zip\" \\\n  --data-binary @./dist-${{ steps.set_version.outputs.version }}.zip \\\n  \"${upload_url}?name=dejavu-dist-${{ steps.set_version.outputs.version }}.zip\"`. ","nb_triggers":3,"triggers":["release","repository_dispatch","workflow_dispatch"],"nb_jobs":1,"nb_actions":3,"actions":["actions/checkout","actions/setup-node","battila7/get-version-action"],"actions_details":[{"version":"v3","name":"actions/checkout"},{"version":"v3","name":"actions/setup-node"},{"version":"v2.2.1","name":"battila7/get-version-action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":11,"cyclomatic_complexity":1}
{"id":22772,"repository_id":31953428,"mainLanguage":"C++","file_name":"windows-build.yml","file_content":"#\n# Copyright (c) Contributors to the Open 3D Engine Project.\n# For complete copyright and license terms please see the LICENSE at the root of this distribution.\n#\n# SPDX-License-Identifier: Apache-2.0 OR MIT\n#\n#\n\nname: Windows Build\n\n# These jobs are to be triggered by ar.yml\n\non:\n  workflow_dispatch:\n  workflow_call:\n    inputs:\n      compiler: \n        required: true\n        type: string\n      config: \n        required: true\n        type: string\n      image: \n        required: true\n        type: string\n      platform: \n        required: true\n        type: string\n      type: \n        required: true\n        type: string\n      last_artifact: \n        required: false\n        type: boolean\n\nrun-name: ${{ inputs.platform }} - ${{ inputs.type }}\n\n# Activate compiler cache\nenv:          \n  O3DE_ENABLE_COMPILER_CACHE: true\n  O3DE_COMPILER_CACHE_PATH: 'C:\\ProgramData\\Chocolatey\\bin\\ccache.exe'\n\n# Note: All 3P Github Actions use the commit hash for security reasons \n# Avoid using the tag version, which is vulnerable to supply chain attacks\n\njobs:\n  Build:\n    strategy:\n      fail-fast: false\n\n    runs-on: ${{ inputs.image }}\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n        with:\n          show-progress: false\n\n      - name: Git LFS pull\n        # Minimal pull for profile builds, otherwise pull all\n        run: |\n            git lfs install\n            if (\"${{ inputs.type }}\" -eq \"profile\") { git lfs pull --include \"*.ico,*.bmp\" } else { git lfs pull }\n          \n      - name: Setup 3p, user, and build folders\n        # Symlink the .o3de folder to the github workspace to avoid permission issues\n        run: |\n          \"3rdParty\", \"build\", \".o3de\" | % {New-Item \"${{ github.workspace }}\\$_\" -ItemType 'Directory' -Force}\n          \".o3de\" | % {New-Item -Path $env:USERPROFILE\\$_ -ItemType SymbolicLink -Target ${{ github.workspace }}\\$_ -Force}\n          \"AutomatedTesting\\Cache\", \"AutomatedTesting\\user\" | % {New-Item \"${{ github.workspace }}\\$_\" -ItemType 'Directory' -Force}\n\n      - name: Setup ccache\n        uses: Chocobo1/setup-ccache-action@f84f86840109403e0fe0ded8b0766c9633affa16 # v1.4.7\n        continue-on-error: true\n        if: always()\n        with:\n          windows_compile_environment: msvc\n          prepend_symlinks_to_path: false\n          store_cache: false\n          restore_cache: false\n          ccache_options: |\n            max_size=15G\n            cache_dir=${{ github.workspace }}\\.ccache\n      \n      - name: Get last run\n        # Get the last runid of the target branch of a PR or the current branch\n        uses: dawidd6/action-download-artifact@07ab29fd4a977ae4d2b275087cf67563dfdf0295 # v9\n        id: last-run-id\n        if: ${{ inputs.last_artifact }}\n        continue-on-error: true\n        with:\n          workflow_search: true\n          workflow_conclusion: \"\"\n          branch: ${{ github.event_name == 'pull_request' && github.event.pull_request.base.ref || github.ref_name }}\n          search_artifacts: true\n          name: O3DE-${{ inputs.platform }}-${{ inputs.config }}-build\n          dry_run: true\n    \n      - name: Set artifact run ID\n        # Set the run ID of the artifact to be used for the download step\n        id: set-artifact-run-id\n        if: steps.last-run-id.outcome == 'success' && inputs.last_artifact == true\n        run: |\n          $runId = ${{ fromJSON(steps.last-run-id.outputs.artifacts)[0].workflow_run.id }}\n          echo \"artifact_run_id=$runId\" >> $env:GITHUB_OUTPUT\n          echo \"Using artifacts from previous run: $runId\"\n    \n      - name: Restore artifact cache\n        # Restore the artifact from the \"Get last run\" step or from the current run\n        uses: actions/download-artifact@95815c38cf2ff2164869cbab79da8d1f422bc89e # v4.2.1\n        id: restore-artifact-cache\n        continue-on-error: true\n        with:\n          name: O3DE-${{ inputs.platform }}-${{ inputs.config }}-build\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          run-id: ${{ steps.set-artifact-run-id.outputs.artifact_run_id || github.run_id }}\n\n      - name: Extract artifact\n        # Extract the tar file from the artifact\n        id: extract-artifact\n        continue-on-error: true\n        if: ${{ steps.restore-artifact-cache.outcome == 'success' }}\n        run: |        \n          if (Test-Path ${{ github.workspace }}\\cache.tar) {          \n            tar -xvpf ${{ github.workspace }}\\cache.tar\n            rm ${{ github.workspace }}\\cache.tar\n          }\n      \n      - name: Setup cmake\n        # Pin the version of cmake\n        uses: lukka/get-cmake@56d043d188c3612951d8755da8f4b709ec951ad6 # v3.31.6\n        with:\n          cmakeVersion: \"~3.30.0\" \n\n      - name: Set MSBuild options\n        # Configuire VS environment variables through the developer command prompt for MSVC\n        uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n\n      - name: Configure environment\n        run: |\n          echo \"Installing dependencies\"\n          echo \"Getting python...\"\n          python\\get_python.bat\n          echo \"Installing additional python dependencies...\"\n          python\\pip.sh install tempfile2 PyGithub\n          \n      - name: Build ${{ inputs.type }}\n        # Builds with presets in ../scripts/build/Platform/Windows/build_config.json\n        env:\n          LY_3RDPARTY_PATH: ${{ github.workspace }}\\3rdParty\n        run: |\n          python\\python.cmd -u scripts\\build\\ci_build.py --platform ${{ inputs.platform }} --type ${{ inputs.type }}\n      \n      - name: Compress artifacts\n        # Compress with posix format to preserve permissions and timestamps at nanosecond precision\n        # Skip compression and upload if the type is a test to reduce dirty build artifacts from previous runs\n        id: compress-artifacts\n        if: ${{ (steps.extract-artifact.outcome == 'success' || steps.extract-artifact.outcome == 'skipped') && !cancelled() && !contains(inputs.type, 'test') }}\n        continue-on-error: true\n        run: |\n          try {\n            tar --format=posix -cvpf ${{ github.workspace }}\\cache.tar `\n              python `\n              3rdParty\\packages `\n              AutomatedTesting\\Cache `\n              AutomatedTesting\\user `\n              .ccache\n          } catch {\n            echo \"Warning: Error during tar compression\"\n          }\n  \n      - name: Save artifacts\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        if: ${{ steps.compress-artifacts.conclusion == 'success' && !cancelled() && !contains(inputs.type, 'test') }}\n        continue-on-error: true\n        with:\n          name: O3DE-${{ inputs.platform }}-${{ inputs.config }}-build\n          compression-level: 1\n          overwrite: true\n          path: |\n            ${{ github.workspace }}\\cache.tar\n","repository_owner":"o3de","repository_name":"o3de","tokens_count":1842,"workflow":"#\n# Copyright (c) Contributors to the Open 3D Engine Project.\n# For complete copyright and license terms please see the LICENSE at the root of this distribution.\n#\n# SPDX-License-Identifier: Apache-2.0 OR MIT\n#\n#\n\nname: Windows Build\n\n# These jobs are to be triggered by ar.yml\n\non:\n  workflow_dispatch:\n  workflow_call:\n    inputs:\n      compiler:\n        required: true\n        type: string\n      config:\n        required: true\n        type: string\n      image:\n        required: true\n        type: string\n      platform:\n        required: true\n        type: string\n      type:\n        required: true\n        type: string\n      last_artifact:\n        required: false\n        type: boolean\n\nrun-name: ${{ inputs.platform }} - ${{ inputs.type }}\n\n# Activate compiler cache\nenv:\n  O3DE_ENABLE_COMPILER_CACHE: true\n  O3DE_COMPILER_CACHE_PATH: C:\\ProgramData\\Chocolatey\\bin\\ccache.exe\n\n# Note: All 3P Github Actions use the commit hash for security reasons \n# Avoid using the tag version, which is vulnerable to supply chain attacks\n\njobs:\n  Build:\n    strategy:\n      fail-fast: false\n\n    runs-on: ${{ inputs.image }}\n\n    steps:\n    - name: Checkout repo\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683   # v4.2.2\n      with:\n        show-progress: false\n\n    - name: Git LFS pull\n        # Minimal pull for profile builds, otherwise pull all\n      run: |\n        git lfs install\n        if (\"${{ inputs.type }}\" -eq \"profile\") { git lfs pull --include \"*.ico,*.bmp\" } else { git lfs pull }\n\n    - name: Setup 3p, user, and build folders\n        # Symlink the .o3de folder to the github workspace to avoid permission issues\n      run: |\n        \"3rdParty\", \"build\", \".o3de\" | % {New-Item \"${{ github.workspace }}\\$_\" -ItemType 'Directory' -Force}\n        \".o3de\" | % {New-Item -Path $env:USERPROFILE\\$_ -ItemType SymbolicLink -Target ${{ github.workspace }}\\$_ -Force}\n        \"AutomatedTesting\\Cache\", \"AutomatedTesting\\user\" | % {New-Item \"${{ github.workspace }}\\$_\" -ItemType 'Directory' -Force}\n\n    - name: Setup ccache\n      uses: \n        Chocobo1/setup-ccache-action@f84f86840109403e0fe0ded8b0766c9633affa16       # v1.4.7\n      continue-on-error: true\n      if: always()\n      with:\n        windows_compile_environment: msvc\n        prepend_symlinks_to_path: false\n        store_cache: false\n        restore_cache: false\n        ccache_options: |\n          max_size=15G\n          cache_dir=${{ github.workspace }}\\.ccache\n\n    - name: Get last run\n        # Get the last runid of the target branch of a PR or the current branch\n      uses: \n        dawidd6/action-download-artifact@07ab29fd4a977ae4d2b275087cf67563dfdf0295       # v9\n      id: last-run-id\n      if: ${{ inputs.last_artifact }}\n      continue-on-error: true\n      with:\n        workflow_search: true\n        workflow_conclusion: ''\n        branch: ${{ github.event_name == 'pull_request' && \n          github.event.pull_request.base.ref || github.ref_name }}\n        search_artifacts: true\n        name: O3DE-${{ inputs.platform }}-${{ inputs.config }}-build\n        dry_run: true\n\n    - name: Set artifact run ID\n        # Set the run ID of the artifact to be used for the download step\n      id: set-artifact-run-id\n      if: steps.last-run-id.outcome == 'success' && inputs.last_artifact == true\n      run: |\n        $runId = ${{ fromJSON(steps.last-run-id.outputs.artifacts)[0].workflow_run.id }}\n        echo \"artifact_run_id=$runId\" >> $env:GITHUB_OUTPUT\n        echo \"Using artifacts from previous run: $runId\"\n\n    - name: Restore artifact cache\n        # Restore the artifact from the \"Get last run\" step or from the current run\n      uses: actions/download-artifact@95815c38cf2ff2164869cbab79da8d1f422bc89e   # v4.2.1\n      id: restore-artifact-cache\n      continue-on-error: true\n      with:\n        name: O3DE-${{ inputs.platform }}-${{ inputs.config }}-build\n        github-token: ${{ secrets.GITHUB_TOKEN }}\n        run-id: ${{ steps.set-artifact-run-id.outputs.artifact_run_id || \n          github.run_id }}\n\n    - name: Extract artifact\n        # Extract the tar file from the artifact\n      id: extract-artifact\n      continue-on-error: true\n      if: ${{ steps.restore-artifact-cache.outcome == 'success' }}\n      run: |\n        if (Test-Path ${{ github.workspace }}\\cache.tar) {          \n          tar -xvpf ${{ github.workspace }}\\cache.tar\n          rm ${{ github.workspace }}\\cache.tar\n        }\n\n    - name: Setup cmake\n        # Pin the version of cmake\n      uses: lukka/get-cmake@56d043d188c3612951d8755da8f4b709ec951ad6   # v3.31.6\n      with:\n        cmakeVersion: ~3.30.0\n\n    - name: Set MSBuild options\n        # Configuire VS environment variables through the developer command prompt for MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756   # v1.13.0\n\n    - name: Configure environment\n      run: |\n        echo \"Installing dependencies\"\n        echo \"Getting python...\"\n        python\\get_python.bat\n        echo \"Installing additional python dependencies...\"\n        python\\pip.sh install tempfile2 PyGithub\n\n    - name: Build ${{ inputs.type }}\n        # Builds with presets in ../scripts/build/Platform/Windows/build_config.json\n      env:\n        LY_3RDPARTY_PATH: ${{ github.workspace }}\\3rdParty\n      run: |\n        python\\python.cmd -u scripts\\build\\ci_build.py --platform ${{ inputs.platform }} --type ${{ inputs.type }}\n\n    - name: Compress artifacts\n        # Compress with posix format to preserve permissions and timestamps at nanosecond precision\n        # Skip compression and upload if the type is a test to reduce dirty build artifacts from previous runs\n      id: compress-artifacts\n      if: ${{ (steps.extract-artifact.outcome == 'success' || \n        steps.extract-artifact.outcome == 'skipped') && !cancelled() && \n        !contains(inputs.type, 'test') }}\n      continue-on-error: true\n      run: |\n        try {\n          tar --format=posix -cvpf ${{ github.workspace }}\\cache.tar `\n            python `\n            3rdParty\\packages `\n            AutomatedTesting\\Cache `\n            AutomatedTesting\\user `\n            .ccache\n        } catch {\n          echo \"Warning: Error during tar compression\"\n        }\n\n    - name: Save artifacts\n      uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02   # v4.6.2\n      if: ${{ steps.compress-artifacts.conclusion == 'success' && !cancelled() \n        && !contains(inputs.type, 'test') }}\n      continue-on-error: true\n      with:\n        name: O3DE-${{ inputs.platform }}-${{ inputs.config }}-build\n        compression-level: 1\n        overwrite: true\n        path: |\n          ${{ github.workspace }}\\cache.tar\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Windows Build` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `${{ inputs.platform }} - ${{ inputs.type }}`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) this workflow is called by another workflow. This workflow receives 6 inputs: compiler-it must be supplied and the data type is string; config-it must be supplied and the data type is string; image-it must be supplied and the data type is string; platform-it must be supplied and the data type is string; type-it must be supplied and the data type is string; last_artifact-it is optional and the data type is boolean. The workflow sets 2 environment variables to use: `O3DE_ENABLE_COMPILER_CACHE` is set to `True` and `O3DE_COMPILER_CACHE_PATH` is set to `C:\\ProgramData\\Chocolatey\\bin\\ccache.exe`. The workflow has one job. The job id of the 1st job is `Build`. ","prompt_level2":"Generate a GitHub Workflow named `Windows Build` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `${{ inputs.platform }} - ${{ inputs.type }}`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) this workflow is called by another workflow. This workflow receives 6 inputs: compiler-it must be supplied and the data type is string; config-it must be supplied and the data type is string; image-it must be supplied and the data type is string; platform-it must be supplied and the data type is string; type-it must be supplied and the data type is string; last_artifact-it is optional and the data type is boolean. The workflow sets 2 environment variables to use: `O3DE_ENABLE_COMPILER_CACHE` is set to `True` and `O3DE_COMPILER_CACHE_PATH` is set to `C:\\ProgramData\\Chocolatey\\bin\\ccache.exe`. The workflow has one job. The job id of the 1st job is `Build`. The job `Build` has 14 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Git LFS pull`. The 3rd step is named `Setup 3p, user, and build folders`. The 4th step is named `Setup ccache`. The 5th step is named `Get last run` and its id is `last-run-id`. The 6th step is named `Set artifact run ID` and its id is `set-artifact-run-id`. The 7th step is named `Restore artifact cache` and its id is `restore-artifact-cache`. The 8th step is named `Extract artifact` and its id is `extract-artifact`. The 9th step is named `Setup cmake`. The 10th step is named `Set MSBuild options`. The 11th step is named `Configure environment`. The 12th step is named `Build ${{ inputs.type }}`. The 13th step is named `Compress artifacts` and its id is `compress-artifacts`. The 14th step is named `Save artifacts`. ","prompt_level3":"Generate a GitHub Workflow named `Windows Build` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `${{ inputs.platform }} - ${{ inputs.type }}`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. 2) this workflow is called by another workflow. This workflow receives 6 inputs: compiler-it must be supplied and the data type is string; config-it must be supplied and the data type is string; image-it must be supplied and the data type is string; platform-it must be supplied and the data type is string; type-it must be supplied and the data type is string; last_artifact-it is optional and the data type is boolean. The workflow sets 2 environment variables to use: `O3DE_ENABLE_COMPILER_CACHE` is set to `True` and `O3DE_COMPILER_CACHE_PATH` is set to `C:\\ProgramData\\Chocolatey\\bin\\ccache.exe`. The workflow has one job. The job id of the 1st job is `Build`. This job will run on ${{ inputs.image }} runner. The job `Build` has 14 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is 11bd71901bbe5b1630ceea73d27597364c9af683. The step defines an input parameter for the action: `show-progress` is set to `False`. The 2nd step is named `Git LFS pull`. This step runs a script: `git lfs install\nif (\"${{ inputs.type }}\" -eq \"profile\") { git lfs pull --include \"*.ico,*.bmp\" } else { git lfs pull }\n`. The 3rd step is named `Setup 3p, user, and build folders`. This step runs a script: `\"3rdParty\", \"build\", \".o3de\" | % {New-Item \"${{ github.workspace }}\\$_\" -ItemType 'Directory' -Force}\n\".o3de\" | % {New-Item -Path $env:USERPROFILE\\$_ -ItemType SymbolicLink -Target ${{ github.workspace }}\\$_ -Force}\n\"AutomatedTesting\\Cache\", \"AutomatedTesting\\user\" | % {New-Item \"${{ github.workspace }}\\$_\" -ItemType 'Directory' -Force}\n`. The 4th step is named `Setup ccache`. This step will run only if the condition(always()) is met. This step runs action `Chocobo1/setup-ccache-action` whose commit is f84f86840109403e0fe0ded8b0766c9633affa16. The step defines 5 input parameters for the action: `windows_compile_environment` is set to `msvc`, `prepend_symlinks_to_path` is set to `False`, `store_cache` is set to `False`, `restore_cache` is set to `False` and `ccache_options` is set to `max_size=15G\ncache_dir=${{ github.workspace }}\\.ccache\n`. When this step fails, the job will move on to the next step. The 5th step is named `Get last run` and its id is `last-run-id`. This step will run only if the condition(${{ inputs.last_artifact }}) is met. This step runs action `dawidd6/action-download-artifact` whose commit is 07ab29fd4a977ae4d2b275087cf67563dfdf0295. The step defines 6 input parameters for the action: `workflow_search` is set to `True`, `workflow_conclusion` is set to ``, `branch` is set to `${{ github.event_name == 'pull_request' && github.event.pull_request.base.ref || github.ref_name }}`, `search_artifacts` is set to `True`, `name` is set to `O3DE-${{ inputs.platform }}-${{ inputs.config }}-build` and `dry_run` is set to `True`. When this step fails, the job will move on to the next step. The 6th step is named `Set artifact run ID` and its id is `set-artifact-run-id`. This step will run only if the condition(steps.last-run-id.outcome == 'success' && inputs.last_artifact == true) is met. This step runs a script: `$runId = ${{ fromJSON(steps.last-run-id.outputs.artifacts)[0].workflow_run.id }}\necho \"artifact_run_id=$runId\" >> $env:GITHUB_OUTPUT\necho \"Using artifacts from previous run: $runId\"\n`. The 7th step is named `Restore artifact cache` and its id is `restore-artifact-cache`. This step runs action `actions/download-artifact` whose commit is 95815c38cf2ff2164869cbab79da8d1f422bc89e. The step defines 3 input parameters for the action: `name` is set to `O3DE-${{ inputs.platform }}-${{ inputs.config }}-build`, `github-token` is set to `${{ secrets.GITHUB_TOKEN }}` and `run-id` is set to `${{ steps.set-artifact-run-id.outputs.artifact_run_id || github.run_id }}`. When this step fails, the job will move on to the next step. The 8th step is named `Extract artifact` and its id is `extract-artifact`. This step will run only if the condition(${{ steps.restore-artifact-cache.outcome == 'success' }}) is met. This step runs a script: `if (Test-Path ${{ github.workspace }}\\cache.tar) {          \n  tar -xvpf ${{ github.workspace }}\\cache.tar\n  rm ${{ github.workspace }}\\cache.tar\n}\n`. When this step fails, the job will move on to the next step. The 9th step is named `Setup cmake`. This step runs action `lukka/get-cmake` whose commit is 56d043d188c3612951d8755da8f4b709ec951ad6. The step defines an input parameter for the action: `cmakeVersion` is set to `~3.30.0`. The 10th step is named `Set MSBuild options`. This step runs action `ilammy/msvc-dev-cmd` whose commit is 0b201ec74fa43914dc39ae48a89fd1d8cb592756. The 11th step is named `Configure environment`. This step runs a script: `echo \"Installing dependencies\"\necho \"Getting python...\"\npython\\get_python.bat\necho \"Installing additional python dependencies...\"\npython\\pip.sh install tempfile2 PyGithub\n`. The 12th step is named `Build ${{ inputs.type }}`. The step sets an environment variable to use: `LY_3RDPARTY_PATH` is set to `${{ github.workspace }}\\3rdParty`. This step runs a script: `python\\python.cmd -u scripts\\build\\ci_build.py --platform ${{ inputs.platform }} --type ${{ inputs.type }}\n`. The 13th step is named `Compress artifacts` and its id is `compress-artifacts`. This step will run only if the condition(${{ (steps.extract-artifact.outcome == 'success' || steps.extract-artifact.outcome == 'skipped') && !cancelled() && !contains(inputs.type, 'test') }}) is met. This step runs a script: `try {\n  tar --format=posix -cvpf ${{ github.workspace }}\\cache.tar `\n    python `\n    3rdParty\\packages `\n    AutomatedTesting\\Cache `\n    AutomatedTesting\\user `\n    .ccache\n} catch {\n  echo \"Warning: Error during tar compression\"\n}\n`. When this step fails, the job will move on to the next step. The 14th step is named `Save artifacts`. This step will run only if the condition(${{ steps.compress-artifacts.conclusion == 'success' && !cancelled() && !contains(inputs.type, 'test') }}) is met. This step runs action `actions/upload-artifact` whose commit is ea165f8d65b6e75b540449e92b4886f43607fa02. The step defines 4 input parameters for the action: `name` is set to `O3DE-${{ inputs.platform }}-${{ inputs.config }}-build`, `compression-level` is set to `1`, `overwrite` is set to `True` and `path` is set to `${{ github.workspace }}\\cache.tar\n`. When this step fails, the job will move on to the next step. ","nb_triggers":2,"triggers":["workflow_call","workflow_dispatch"],"nb_jobs":1,"nb_actions":7,"actions":["Chocobo1/setup-ccache-action","actions/checkout","actions/download-artifact","actions/upload-artifact","dawidd6/action-download-artifact","ilammy/msvc-dev-cmd","lukka/get-cmake"],"actions_details":[{"version":"11bd71901bbe5b1630ceea73d27597364c9af683","name":"actions/checkout"},{"version":"f84f86840109403e0fe0ded8b0766c9633affa16","name":"Chocobo1/setup-ccache-action"},{"version":"07ab29fd4a977ae4d2b275087cf67563dfdf0295","name":"dawidd6/action-download-artifact"},{"version":"95815c38cf2ff2164869cbab79da8d1f422bc89e","name":"actions/download-artifact"},{"version":"56d043d188c3612951d8755da8f4b709ec951ad6","name":"lukka/get-cmake"},{"version":"0b201ec74fa43914dc39ae48a89fd1d8cb592756","name":"ilammy/msvc-dev-cmd"},{"version":"ea165f8d65b6e75b540449e92b4886f43607fa02","name":"actions/upload-artifact"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":14,"cyclomatic_complexity":1}
{"id":15307,"repository_id":3450844,"mainLanguage":"C#","file_name":"test-urp.yml","file_content":"# Required secrets\n#   UNITY_LICENSE: The contents of Unity license file\n#   UNITY_EMAIL: Unity user email to login\n#   UNITY_PASSWORD: Unity user password to login\nname:  Test URP\nrun-name:  Test URP (${{ github.event.pull_request.title || github.ref_name }})\n\nenv:\n  # MINIMUM_VERSION: The minimum version of Unity.\n  MINIMUM_VERSION: 2023.1\n  # EXCLUDE_FILTER: The excluded versions of Unity.\n  EXCLUDE_FILTER: '(2020.2.0|2021.1|2023.3)'\n\non:\n  workflow_dispatch:\n    inputs:\n      usePeriodVersions:\n        description: 'Use the period versions (.0f1, .10f1, 20f1, ...).'\n        required: false\n        default: 'true'\n  push:\n    branches:\n      - develop\n      - develop-preview\n    tags:\n      - \"!*\"\n    paths-ignore:\n      - \"**.md\"\n  pull_request_target:\n    types:\n      - opened\n      - reopened\n      - synchronize\n    paths-ignore:\n      - \"**.md\"\n\njobs:\n  setup:\n    name:  Setup\n    runs-on: ubuntu-latest\n    outputs:\n      unityVersions: ${{ steps.setup.outputs.unityVersions }}\n    steps:\n      - name:  Find target Unity versions\n        id: setup\n        run: |\n          echo \"==== Target Unity Versions ====\"\n          LATEST_VERSIONS=`npx unity-changeset list --versions --latest-patch --min ${MINIMUM_VERSION} --json --all`\n          if [ \"${{ inputs.usePeriodVersions }}\" = \"true\" ]; then\n            ADDITIONAL_VERSIONS=`npx unity-changeset list --versions --grep '0f' --min ${MINIMUM_VERSION} --json`\n          else\n            ADDITIONAL_VERSIONS=[]\n          fi\n\n          VERSIONS=`echo \"[${LATEST_VERSIONS}, ${ADDITIONAL_VERSIONS}]\" \\\n            | jq -c '[ flatten | sort | unique | .[] | select( test(\"${{ env.EXCLUDE_FILTER }}\") | not ) ]'`\n          echo \"unityVersions=${VERSIONS}\" | tee $GITHUB_OUTPUT\n\n  test:\n    name:  Run tests\n    runs-on: ubuntu-latest\n    permissions:\n      checks: write\n      contents: read\n    needs: setup\n    strategy:\n      fail-fast: false\n      max-parallel: 6\n      matrix:\n        unityVersion: ${{ fromJson(needs.setup.outputs.unityVersions) }}\n    steps:\n      - name:  Checkout ($${{ github.ref }})\n        if: github.event_name == 'push'\n        uses: actions/checkout@v4\n\n      - name:  Checkout pull request (pull_request_target)\n        if: github.event_name == 'pull_request_target'\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ github.event.pull_request.head.sha }}\n          fetch-depth: 0\n\n      - name:  Marge pull request (pull_request_target)\n        if: github.event_name == 'pull_request_target'\n        run: |\n          git config user.name \"GitHub Actions\"\n          git config user.email \"actions@github.com\"\n          git merge origin/${{ github.event.pull_request.base.ref }} --no-edit\n\n      - name:  Cache library\n        uses: actions/cache@v4\n        with:\n          path: UniversalTestProject/Library\n          key: UniversalTestProject-Library-${{ matrix.unityVersion }}-${{ github.event.pull_request.head.sha || github.sha }}\n          restore-keys: |\n            UniversalTestProject-Library-${{ matrix.unityVersion }}-\n            UniversalTestProject-Library-\n\n      - name:  Build Unity Project\n        uses: game-ci/unity-builder@v4\n        timeout-minutes: 45\n        with:\n          customImage: ghcr.io/mob-sakai/unity3d:${{ matrix.unityVersion }}\n          targetPlatform: StandaloneLinux64\n          allowDirtyBuild: true\n          customParameters: -nographics\n          projectPath: UniversalTestProject\n        env:\n          UNITY_EMAIL: ${{ secrets.UNITY_EMAIL }}\n          UNITY_PASSWORD: ${{ secrets.UNITY_PASSWORD }}\n          UNITY_LICENSE: ${{ secrets.UNITY_LICENSE }}\n\n      # - name:  Run tests\n      #   uses: game-ci/unity-test-runner@v4\n      #   timeout-minutes: 45\n      #   with:\n      #     customImage: ghcr.io/mob-sakai/unity3d:${{ matrix.unityVersion }}\n      #     # unityVersion: ${{ matrix.unityVersion }}\n      #     customParameters: -nographics\n      #     checkName: ${{ matrix.unityVersion }} Test Results\n      #     githubToken: ${{ github.token }}\n      #     coverageOptions: \"dontClear;generateHtmlReport;generateBadgeReport;pathFilters:+**/Packages/src/**;assemblyFilters:+<packages>,-*.Editor,-*.Test\"\n","repository_owner":"mob-sakai","repository_name":"softmaskforugui","tokens_count":1096,"workflow":"# Required secrets\n#   UNITY_LICENSE: The contents of Unity license file\n#   UNITY_EMAIL: Unity user email to login\n#   UNITY_PASSWORD: Unity user password to login\nname:  Test URP\nrun-name:  Test URP (${{ github.event.pull_request.title || github.ref_name }})\n\nenv:\n  # MINIMUM_VERSION: The minimum version of Unity.\n  MINIMUM_VERSION: 2023.1\n  # EXCLUDE_FILTER: The excluded versions of Unity.\n  EXCLUDE_FILTER: (2020.2.0|2021.1|2023.3)\n\non:\n  workflow_dispatch:\n    inputs:\n      usePeriodVersions:\n        description: Use the period versions (.0f1, .10f1, 20f1, ...).\n        required: false\n        default: 'true'\n  push:\n    branches:\n    - develop\n    - develop-preview\n    tags:\n    - '!*'\n    paths-ignore:\n    - '**.md'\n  pull_request_target:\n    types:\n    - opened\n    - reopened\n    - synchronize\n    paths-ignore:\n    - '**.md'\n\njobs:\n  setup:\n    name:  Setup\n    runs-on: ubuntu-latest\n    outputs:\n      unityVersions: ${{ steps.setup.outputs.unityVersions }}\n    steps:\n    - name:  Find target Unity versions\n      id: setup\n      run: |\n        echo \"==== Target Unity Versions ====\"\n        LATEST_VERSIONS=`npx unity-changeset list --versions --latest-patch --min ${MINIMUM_VERSION} --json --all`\n        if [ \"${{ inputs.usePeriodVersions }}\" = \"true\" ]; then\n          ADDITIONAL_VERSIONS=`npx unity-changeset list --versions --grep '0f' --min ${MINIMUM_VERSION} --json`\n        else\n          ADDITIONAL_VERSIONS=[]\n        fi\n\n        VERSIONS=`echo \"[${LATEST_VERSIONS}, ${ADDITIONAL_VERSIONS}]\" \\\n          | jq -c '[ flatten | sort | unique | .[] | select( test(\"${{ env.EXCLUDE_FILTER }}\") | not ) ]'`\n        echo \"unityVersions=${VERSIONS}\" | tee $GITHUB_OUTPUT\n\n  test:\n    name:  Run tests\n    runs-on: ubuntu-latest\n    permissions:\n      checks: write\n      contents: read\n    needs: setup\n    strategy:\n      fail-fast: false\n      max-parallel: 6\n      matrix:\n        unityVersion: ${{ fromJson(needs.setup.outputs.unityVersions) }}\n    steps:\n    - name:  Checkout ($${{ github.ref }})\n      if: github.event_name == 'push'\n      uses: actions/checkout@v4\n\n    - name:  Checkout pull request (pull_request_target)\n      if: github.event_name == 'pull_request_target'\n      uses: actions/checkout@v4\n      with:\n        ref: ${{ github.event.pull_request.head.sha }}\n        fetch-depth: 0\n\n    - name:  Marge pull request (pull_request_target)\n      if: github.event_name == 'pull_request_target'\n      run: |\n        git config user.name \"GitHub Actions\"\n        git config user.email \"actions@github.com\"\n        git merge origin/${{ github.event.pull_request.base.ref }} --no-edit\n\n    - name:  Cache library\n      uses: actions/cache@v4\n      with:\n        path: UniversalTestProject/Library\n        key: UniversalTestProject-Library-${{ matrix.unityVersion }}-${{ \n          github.event.pull_request.head.sha || github.sha }}\n        restore-keys: |\n          UniversalTestProject-Library-${{ matrix.unityVersion }}-\n          UniversalTestProject-Library-\n\n    - name:  Build Unity Project\n      uses: game-ci/unity-builder@v4\n      timeout-minutes: 45\n      with:\n        customImage: ghcr.io/mob-sakai/unity3d:${{ matrix.unityVersion }}\n        targetPlatform: StandaloneLinux64\n        allowDirtyBuild: true\n        customParameters: -nographics\n        projectPath: UniversalTestProject\n      env:\n        UNITY_EMAIL: ${{ secrets.UNITY_EMAIL }}\n        UNITY_PASSWORD: ${{ secrets.UNITY_PASSWORD }}\n        UNITY_LICENSE: ${{ secrets.UNITY_LICENSE }}\n\n      # - name:  Run tests\n      #   uses: game-ci/unity-test-runner@v4\n      #   timeout-minutes: 45\n      #   with:\n      #     customImage: ghcr.io/mob-sakai/unity3d:${{ matrix.unityVersion }}\n      #     # unityVersion: ${{ matrix.unityVersion }}\n      #     customParameters: -nographics\n      #     checkName: ${{ matrix.unityVersion }} Test Results\n      #     githubToken: ${{ github.token }}\n      #     coverageOptions: \"dontClear;generateHtmlReport;generateBadgeReport;pathFilters:+**/Packages/src/**;assemblyFilters:+<packages>,-*.Editor,-*.Test\"\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named ` Test URP` for a GitHub repository whose primary programming language is C#. The name for workflow runs is set to ` Test URP (${{ github.event.pull_request.title || github.ref_name }})`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives an input: usePeriodVersions-this input represents use the period versions (.0f1, .10f1, 20f1, ...)., it is optional and its default value is true. 2) The workflow would run whenever there is a push event to: a branch named develop, a branch named develop-preview or a tag whose name matches !*. When all the path names of push event match patterns in the paths-ignore filter(**.md), the workflow will not run. 3) a pull request is created, a previously closed pull request is reopened or a pull request's head branch is updated. When all the path names of pull_request_target event match patterns in the paths-ignore filter(**.md), the workflow will not run. The workflow sets 2 environment variables to use: `MINIMUM_VERSION` is set to `2023.1` and `EXCLUDE_FILTER` is set to `(2020.2.0|2021.1|2023.3)`. The workflow has 2 jobs. The 1st job is named ` Setup` and its job id is `setup`. The 2nd job is named ` Run tests` and its job id is `test`. ","prompt_level2":"Generate a GitHub Workflow named ` Test URP` for a GitHub repository whose primary programming language is C#. The name for workflow runs is set to ` Test URP (${{ github.event.pull_request.title || github.ref_name }})`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives an input: usePeriodVersions-this input represents use the period versions (.0f1, .10f1, 20f1, ...)., it is optional and its default value is true. 2) The workflow would run whenever there is a push event to: a branch named develop, a branch named develop-preview or a tag whose name matches !*. When all the path names of push event match patterns in the paths-ignore filter(**.md), the workflow will not run. 3) a pull request is created, a previously closed pull request is reopened or a pull request's head branch is updated. When all the path names of pull_request_target event match patterns in the paths-ignore filter(**.md), the workflow will not run. The workflow sets 2 environment variables to use: `MINIMUM_VERSION` is set to `2023.1` and `EXCLUDE_FILTER` is set to `(2020.2.0|2021.1|2023.3)`. The workflow has 2 jobs. The 1st job is named ` Setup` and its job id is `setup`. The job `setup` has one step. The 1st step is named ` Find target Unity versions` and its id is `setup`. The 2nd job is named ` Run tests` and its job id is `test`. The job `test` has 5 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Checkout repository`. The 3rd step is named ` Marge pull request (pull_request_target)`. The 4th step is named ` Cache library`. The 5th step is named ` Build Unity Project`. ","prompt_level3":"Generate a GitHub Workflow named ` Test URP` for a GitHub repository whose primary programming language is C#. The name for workflow runs is set to ` Test URP (${{ github.event.pull_request.title || github.ref_name }})`. This workflow will be triggered by multiple events: 1) someone manually triggers the workflow. This workflow receives an input: usePeriodVersions-this input represents use the period versions (.0f1, .10f1, 20f1, ...)., it is optional and its default value is true. 2) The workflow would run whenever there is a push event to: a branch named develop, a branch named develop-preview or a tag whose name matches !*. When all the path names of push event match patterns in the paths-ignore filter(**.md), the workflow will not run. 3) a pull request is created, a previously closed pull request is reopened or a pull request's head branch is updated. When all the path names of pull_request_target event match patterns in the paths-ignore filter(**.md), the workflow will not run. The workflow sets 2 environment variables to use: `MINIMUM_VERSION` is set to `2023.1` and `EXCLUDE_FILTER` is set to `(2020.2.0|2021.1|2023.3)`. The workflow has 2 jobs. The 1st job is named ` Setup` and its job id is `setup`. This job will run on ubuntu-latest runner. The job `setup` has one step. The 1st step is named ` Find target Unity versions` and its id is `setup`. This step runs a script: `echo \"==== Target Unity Versions ====\"\nLATEST_VERSIONS=`npx unity-changeset list --versions --latest-patch --min ${MINIMUM_VERSION} --json --all`\nif [ \"${{ inputs.usePeriodVersions }}\" = \"true\" ]; then\n  ADDITIONAL_VERSIONS=`npx unity-changeset list --versions --grep '0f' --min ${MINIMUM_VERSION} --json`\nelse\n  ADDITIONAL_VERSIONS=[]\nfi\n\nVERSIONS=`echo \"[${LATEST_VERSIONS}, ${ADDITIONAL_VERSIONS}]\" \\\n  | jq -c '[ flatten | sort | unique | .[] | select( test(\"${{ env.EXCLUDE_FILTER }}\") | not ) ]'`\necho \"unityVersions=${VERSIONS}\" | tee $GITHUB_OUTPUT\n`. This job has an output: `unityVersions` is defined as ${{ steps.setup.outputs.unityVersions }}. The 2nd job is named ` Run tests` and its job id is `test`. Before this job runs, `setup` must complete successfully. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `unityVersion` has 50 values: $, {, {,  , f, r, o, m, J, s, o, n, (, n, e, e, d, s, ., s, e, t, u, p, ., o, u, t, p, u, t, s, ., u, n, i, t, y, V, e, r, s, i, o, n, s, ),  , } and }. The maximum number of job runs in parallel is set to 6. The job `test` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `checks` scope and read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting only applies to the job `test`. The job `test` has 5 steps. The 1st step is named `Checkout repository`. This step will run only if the condition(github.event_name == 'push') is met. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Checkout repository`. This step will run only if the condition(github.event_name == 'pull_request_target') is met. This step runs action `actions/checkout` tagged as v4. The step defines 2 input parameters for the action: `ref` is set to `${{ github.event.pull_request.head.sha }}` and `fetch-depth` is set to `0`. The 3rd step is named ` Marge pull request (pull_request_target)`. This step will run only if the condition(github.event_name == 'pull_request_target') is met. This step runs a script: `git config user.name \"GitHub Actions\"\ngit config user.email \"actions@github.com\"\ngit merge origin/${{ github.event.pull_request.base.ref }} --no-edit\n`. The 4th step is named ` Cache library`. This step runs action `actions/cache` tagged as v4. The step defines 3 input parameters for the action: `path` is set to `UniversalTestProject/Library`, `key` is set to `UniversalTestProject-Library-${{ matrix.unityVersion }}-${{ github.event.pull_request.head.sha || github.sha }}` and `restore-keys` is set to `UniversalTestProject-Library-${{ matrix.unityVersion }}-\nUniversalTestProject-Library-\n`. The 5th step is named ` Build Unity Project`. The step sets 3 environment variables to use: `UNITY_EMAIL` is set to `${{ secrets.UNITY_EMAIL }}`, `UNITY_PASSWORD` is set to `${{ secrets.UNITY_PASSWORD }}` and `UNITY_LICENSE` is set to `${{ secrets.UNITY_LICENSE }}`. This step runs action `game-ci/unity-builder` tagged as v4. The step defines 5 input parameters for the action: `customImage` is set to `ghcr.io/mob-sakai/unity3d:${{ matrix.unityVersion }}`, `targetPlatform` is set to `StandaloneLinux64`, `allowDirtyBuild` is set to `True`, `customParameters` is set to `-nographics` and `projectPath` is set to `UniversalTestProject`. The maximum number of minutes to run the step is 45. ","nb_triggers":3,"triggers":["pull_request_target","push","workflow_dispatch"],"nb_jobs":2,"nb_actions":4,"actions":["actions/cache","actions/checkout","actions/checkout","game-ci/unity-builder"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/cache"},{"version":"v4","name":"game-ci/unity-builder"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":6,"cyclomatic_complexity":1}
{"id":17292,"repository_id":95259902,"mainLanguage":"TypeScript","file_name":"create-release-package.yml","file_content":"name: '[RELEASE] Create Release Package'\n\non:\n  push:\n    tags: [ 'v*.*.*' ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Install tar\n        run: sudo apt-get install tar\n\n      - name: Determine version from tag\n        id: get_version\n        run: |\n          VERSION=${GITHUB_REF#refs/tags/}\n          echo \"version=$VERSION\" >> $GITHUB_ENV\n\n      - name: Print version\n        run: |\n          echo \"Version to be used: ${{ env.version }}\"\n\n      - name: Clean up and create package\n        run: |\n          mkdir -p release_package\n          cp -r client release_package/\n          cp -r server release_package/\n          cp -r shared-lib release_package/\n          tar -czf SquirrelServersManager_${{ env.version }}.tar.gz -C release_package .\n\n      - name: Upload artifact\n        uses: actions/upload-artifact@v3\n        with:\n          name: SquirrelServersManager_${{ env.version }}\n          path: SquirrelServersManager_${{ env.version }}.tar.gz\n\n      - name: Overwrite latest version\n        run: |\n          cp SquirrelServersManager_${{ env.version }}.tar.gz SquirrelServersManager_latest.tar.gz\n\n      - name: Release\n        uses: softprops/action-gh-release@v2\n        with:\n          files: SquirrelServersManager_latest.tar.gz","repository_owner":"SquirrelCorporation","repository_name":"SquirrelServersManager","tokens_count":356,"workflow":"name: '[RELEASE] Create Release Package'\n\non:\n  push:\n    tags: [v*.*.*]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: '18'\n\n    - name: Install tar\n      run: sudo apt-get install tar\n\n    - name: Determine version from tag\n      id: get_version\n      run: |\n        VERSION=${GITHUB_REF#refs/tags/}\n        echo \"version=$VERSION\" >> $GITHUB_ENV\n\n    - name: Print version\n      run: |\n        echo \"Version to be used: ${{ env.version }}\"\n\n    - name: Clean up and create package\n      run: |\n        mkdir -p release_package\n        cp -r client release_package/\n        cp -r server release_package/\n        cp -r shared-lib release_package/\n        tar -czf SquirrelServersManager_${{ env.version }}.tar.gz -C release_package .\n\n    - name: Upload artifact\n      uses: actions/upload-artifact@v3\n      with:\n        name: SquirrelServersManager_${{ env.version }}\n        path: SquirrelServersManager_${{ env.version }}.tar.gz\n\n    - name: Overwrite latest version\n      run: |\n        cp SquirrelServersManager_${{ env.version }}.tar.gz SquirrelServersManager_latest.tar.gz\n\n    - name: Release\n      uses: softprops/action-gh-release@v2\n      with:\n        files: SquirrelServersManager_latest.tar.gz\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `[RELEASE] Create Release Package` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a tag whose name matches v*.*.*. The workflow has one job. The job id of the 1st job is `build`. ","prompt_level2":"Generate a GitHub Workflow named `[RELEASE] Create Release Package` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a tag whose name matches v*.*.*. The workflow has one job. The job id of the 1st job is `build`. The job `build` has 9 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up Node.js`. The 3rd step is named `Install tar`. The 4th step is named `Determine version from tag` and its id is `get_version`. The 5th step is named `Print version`. The 6th step is named `Clean up and create package`. The 7th step is named `Upload artifact`. The 8th step is named `Overwrite latest version`. The 9th step is named `Release`. ","prompt_level3":"Generate a GitHub Workflow named `[RELEASE] Create Release Package` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by an event: The workflow would run whenever there is a push event to: a tag whose name matches v*.*.*. The workflow has one job. The job id of the 1st job is `build`. This job will run on ubuntu-latest runner. The job `build` has 9 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v3. The 2nd step is named `Set up Node.js`. This step runs action `actions/setup-node` tagged as v3. The step defines an input parameter for the action: `node-version` is set to `18`. The 3rd step is named `Install tar`. This step runs a script: `sudo apt-get install tar`. The 4th step is named `Determine version from tag` and its id is `get_version`. This step runs a script: `VERSION=${GITHUB_REF#refs/tags/}\necho \"version=$VERSION\" >> $GITHUB_ENV\n`. The 5th step is named `Print version`. This step runs a script: `echo \"Version to be used: ${{ env.version }}\"\n`. The 6th step is named `Clean up and create package`. This step runs a script: `mkdir -p release_package\ncp -r client release_package/\ncp -r server release_package/\ncp -r shared-lib release_package/\ntar -czf SquirrelServersManager_${{ env.version }}.tar.gz -C release_package .\n`. The 7th step is named `Upload artifact`. This step runs action `actions/upload-artifact` tagged as v3. The step defines 2 input parameters for the action: `name` is set to `SquirrelServersManager_${{ env.version }}` and `path` is set to `SquirrelServersManager_${{ env.version }}.tar.gz`. The 8th step is named `Overwrite latest version`. This step runs a script: `cp SquirrelServersManager_${{ env.version }}.tar.gz SquirrelServersManager_latest.tar.gz\n`. The 9th step is named `Release`. This step runs action `softprops/action-gh-release` tagged as v2. The step defines an input parameter for the action: `files` is set to `SquirrelServersManager_latest.tar.gz`. ","nb_triggers":1,"triggers":["push"],"nb_jobs":1,"nb_actions":4,"actions":["actions/checkout","actions/setup-node","actions/upload-artifact","softprops/action-gh-release"],"actions_details":[{"version":"v3","name":"actions/checkout"},{"version":"v3","name":"actions/setup-node"},{"version":"v3","name":"actions/upload-artifact"},{"version":"v2","name":"softprops/action-gh-release"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":9,"cyclomatic_complexity":1}
{"id":24175,"repository_id":95331853,"mainLanguage":"Python","file_name":"publish-pre-release.yml","file_content":"name: Publish RF-DETR Pre-Releases to PyPI\n\non:\n  push:\n    tags:\n      - \"[0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+a[0-9]\"\n      - \"[0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+b[0-9]\"\n      - \"[0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+rc[0-9]\"\n      - \"[0-9]+.[0-9]+[0-9]+.[0-9]+a[0-9]\"\n      - \"[0-9]+.[0-9]+[0-9]+.[0-9]+b[0-9]\"\n      - \"[0-9]+.[0-9]+[0-9]+.[0-9]+rc[0-9]\"\n      - \"[0-9]+.[0-9]+.[0-9]+a[0-9]\"\n      - \"[0-9]+.[0-9]+.[0-9]+b[0-9]\"\n      - \"[0-9]+.[0-9]+.[0-9]+rc[0-9]\"\n  workflow_dispatch:\n\npermissions: {} # Explicitly remove all permissions by default\n\njobs:\n  publish-pre-release:\n    name: Publish Pre-release Package\n    runs-on: ubuntu-latest\n    environment:\n      name: test\n      url: https://pypi.org/project/rfdetr/\n    timeout-minutes: 10\n    permissions:\n      id-token: write # Required for PyPI publishing\n      contents: read # Required for checkout\n    strategy:\n      matrix:\n        python-version: [\"3.10\"]\n    steps:\n      - name:  Checkout the repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - name:  Install uv and set Python version ${{ matrix.python-version }}\n        uses: astral-sh/setup-uv@22695119d769bdb6f7032ad67b9bca0ef8c4a174 # v5.4.0\n        with:\n          python-version: ${{ matrix.python-version }}\n\n      - name:  Build source and wheel distributions\n        run: |\n          uv pip install -r pyproject.toml --extra build\n          uv build\n          uv run twine check --strict dist/*\n\n      - name:  Publish to PyPi\n        uses: pypa/gh-action-pypi-publish@76f52bc884231f62b9a034ebfe128415bbaabdfc # v1.12.4\n        with:\n          attestations: true","repository_owner":"roboflow","repository_name":"rf-detr","tokens_count":653,"workflow":"name: Publish RF-DETR Pre-Releases to PyPI\n\non:\n  push:\n    tags:\n    - '[0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+a[0-9]'\n    - '[0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+b[0-9]'\n    - '[0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+rc[0-9]'\n    - '[0-9]+.[0-9]+[0-9]+.[0-9]+a[0-9]'\n    - '[0-9]+.[0-9]+[0-9]+.[0-9]+b[0-9]'\n    - '[0-9]+.[0-9]+[0-9]+.[0-9]+rc[0-9]'\n    - '[0-9]+.[0-9]+.[0-9]+a[0-9]'\n    - '[0-9]+.[0-9]+.[0-9]+b[0-9]'\n    - '[0-9]+.[0-9]+.[0-9]+rc[0-9]'\n  workflow_dispatch:\n\npermissions: {} # Explicitly remove all permissions by default\n\njobs:\n  publish-pre-release:\n    name: Publish Pre-release Package\n    runs-on: ubuntu-latest\n    environment:\n      name: test\n      url: https://pypi.org/project/rfdetr/\n    timeout-minutes: 10\n    permissions:\n      id-token: write # Required for PyPI publishing\n      contents: read # Required for checkout\n    strategy:\n      matrix:\n        python-version: ['3.10']\n    steps:\n    - name:  Checkout the repository\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683   # v4.2.2\n\n    - name:  Install uv and set Python version ${{ matrix.python-version }}\n      uses: astral-sh/setup-uv@22695119d769bdb6f7032ad67b9bca0ef8c4a174   # v5.4.0\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name:  Build source and wheel distributions\n      run: |\n        uv pip install -r pyproject.toml --extra build\n        uv build\n        uv run twine check --strict dist/*\n\n    - name:  Publish to PyPi\n      uses: pypa/gh-action-pypi-publish@76f52bc884231f62b9a034ebfe128415bbaabdfc   # v1.12.4\n      with:\n        attestations: true\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Publish RF-DETR Pre-Releases to PyPI` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+a[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+b[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+rc[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+a[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+b[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+rc[0-9], a tag whose name matches [0-9]+.[0-9]+.[0-9]+a[0-9], a tag whose name matches [0-9]+.[0-9]+.[0-9]+b[0-9] or a tag whose name matches [0-9]+.[0-9]+.[0-9]+rc[0-9]. 2) someone manually triggers the workflow. The workflow modifies the default permissions for the GITHUB_TOKEN: the workflow disables permissions for the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Publish Pre-release Package` and its job id is `publish-pre-release`. ","prompt_level2":"Generate a GitHub Workflow named `Publish RF-DETR Pre-Releases to PyPI` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+a[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+b[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+rc[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+a[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+b[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+rc[0-9], a tag whose name matches [0-9]+.[0-9]+.[0-9]+a[0-9], a tag whose name matches [0-9]+.[0-9]+.[0-9]+b[0-9] or a tag whose name matches [0-9]+.[0-9]+.[0-9]+rc[0-9]. 2) someone manually triggers the workflow. The workflow modifies the default permissions for the GITHUB_TOKEN: the workflow disables permissions for the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Publish Pre-release Package` and its job id is `publish-pre-release`. The job `publish-pre-release` has 4 steps. The 1st step is named `Checkout repository`. The 2nd step is named ` Install uv and set Python version ${{ matrix.python-version }}`. The 3rd step is named ` Build source and wheel distributions`. The 4th step is named ` Publish to PyPi`. ","prompt_level3":"Generate a GitHub Workflow named `Publish RF-DETR Pre-Releases to PyPI` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+a[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+b[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+[0-9]+rc[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+a[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+b[0-9], a tag whose name matches [0-9]+.[0-9]+[0-9]+.[0-9]+rc[0-9], a tag whose name matches [0-9]+.[0-9]+.[0-9]+a[0-9], a tag whose name matches [0-9]+.[0-9]+.[0-9]+b[0-9] or a tag whose name matches [0-9]+.[0-9]+.[0-9]+rc[0-9]. 2) someone manually triggers the workflow. The workflow modifies the default permissions for the GITHUB_TOKEN: the workflow disables permissions for the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow has one job. The 1st job is named `Publish Pre-release Package` and its job id is `publish-pre-release`. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `python-version` has one value: 3.10. The job `publish-pre-release` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `id-token` scope and read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting only applies to the job `publish-pre-release`. This job references test environment whose url is https://pypi.org/project/rfdetr/. The maximum number of minutes to run the job is 10. The job `publish-pre-release` has 4 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is 11bd71901bbe5b1630ceea73d27597364c9af683. The 2nd step is named ` Install uv and set Python version ${{ matrix.python-version }}`. This step runs action `astral-sh/setup-uv` whose commit is 22695119d769bdb6f7032ad67b9bca0ef8c4a174. The step defines an input parameter for the action: `python-version` is set to `${{ matrix.python-version }}`. The 3rd step is named ` Build source and wheel distributions`. This step runs a script: `uv pip install -r pyproject.toml --extra build\nuv build\nuv run twine check --strict dist/*\n`. The 4th step is named ` Publish to PyPi`. This step runs action `pypa/gh-action-pypi-publish` whose commit is 76f52bc884231f62b9a034ebfe128415bbaabdfc. The step defines an input parameter for the action: `attestations` is set to `True`. ","nb_triggers":2,"triggers":["push","workflow_dispatch"],"nb_jobs":1,"nb_actions":3,"actions":["actions/checkout","astral-sh/setup-uv","pypa/gh-action-pypi-publish"],"actions_details":[{"version":"11bd71901bbe5b1630ceea73d27597364c9af683","name":"actions/checkout"},{"version":"22695119d769bdb6f7032ad67b9bca0ef8c4a174","name":"astral-sh/setup-uv"},{"version":"76f52bc884231f62b9a034ebfe128415bbaabdfc","name":"pypa/gh-action-pypi-publish"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":4,"cyclomatic_complexity":1}
{"id":252,"repository_id":91567220,"mainLanguage":"Python","file_name":"classic-forge-ci.yml","file_content":"name: Classic - Forge CI\n\non:\n  push:\n    branches: [ master, dev, ci-test* ]\n    paths:\n      - '.github/workflows/classic-forge-ci.yml'\n      - 'classic/forge/**'\n      - '!classic/forge/tests/vcr_cassettes'\n  pull_request:\n    branches: [ master, dev, release-* ]\n    paths:\n      - '.github/workflows/classic-forge-ci.yml'\n      - 'classic/forge/**'\n      - '!classic/forge/tests/vcr_cassettes'\n\nconcurrency:\n  group: ${{ format('forge-ci-{0}', github.head_ref && format('{0}-{1}', github.event_name, github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ startsWith(github.event_name, 'pull_request') }}\n\ndefaults:\n  run:\n    shell: bash\n    working-directory: classic/forge\n\njobs:\n  test:\n    permissions:\n      contents: read\n    timeout-minutes: 30\n    strategy:\n      fail-fast: false\n      matrix:\n        python-version: [\"3.10\"]\n        platform-os: [ubuntu, macos, macos-arm64, windows]\n    runs-on: ${{ matrix.platform-os != 'macos-arm64' && format('{0}-latest', matrix.platform-os) || 'macos-14' }}\n\n    steps:\n      # Quite slow on macOS (2~4 minutes to set up Docker)\n      # - name: Set up Docker (macOS)\n      #   if: runner.os == 'macOS'\n      #   uses: crazy-max/ghaction-setup-docker@v3\n\n      - name: Start MinIO service (Linux)\n        if: runner.os == 'Linux'\n        working-directory: '.'\n        run: |\n          docker pull minio/minio:edge-cicd\n          docker run -d -p 9000:9000 minio/minio:edge-cicd\n\n      - name: Start MinIO service (macOS)\n        if: runner.os == 'macOS'\n        working-directory: ${{ runner.temp }}\n        run: |\n          brew install minio/stable/minio\n          mkdir data\n          minio server ./data &\n\n      # No MinIO on Windows:\n      # - Windows doesn't support running Linux Docker containers\n      # - It doesn't seem possible to start background processes on Windows. They are\n      #   killed after the step returns.\n      #   See: https://github.com/actions/runner/issues/598#issuecomment-2011890429\n\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n          submodules: true\n\n      - name: Checkout cassettes\n        if: ${{ startsWith(github.event_name, 'pull_request') }}\n        env:\n          PR_BASE: ${{ github.event.pull_request.base.ref }}\n          PR_BRANCH: ${{ github.event.pull_request.head.ref }}\n          PR_AUTHOR: ${{ github.event.pull_request.user.login }}\n        run: |\n          cassette_branch=\"${PR_AUTHOR}-${PR_BRANCH}\"\n          cassette_base_branch=\"${PR_BASE}\"\n          cd tests/vcr_cassettes\n\n          if ! git ls-remote --exit-code --heads origin $cassette_base_branch ; then\n            cassette_base_branch=\"master\"\n          fi\n\n          if git ls-remote --exit-code --heads origin $cassette_branch ; then\n            git fetch origin $cassette_branch\n            git fetch origin $cassette_base_branch\n\n            git checkout $cassette_branch\n\n            # Pick non-conflicting cassette updates from the base branch\n            git merge --no-commit --strategy-option=ours origin/$cassette_base_branch\n            echo \"Using cassettes from mirror branch '$cassette_branch',\" \\\n              \"synced to upstream branch '$cassette_base_branch'.\"\n          else\n            git checkout -b $cassette_branch\n            echo \"Branch '$cassette_branch' does not exist in cassette submodule.\" \\\n              \"Using cassettes from '$cassette_base_branch'.\"\n          fi\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n\n      - name: Set up Python dependency cache\n        # On Windows, unpacking cached dependencies takes longer than just installing them\n        if: runner.os != 'Windows'\n        uses: actions/cache@v4\n        with:\n          path: ${{ runner.os == 'macOS' && '~/Library/Caches/pypoetry' || '~/.cache/pypoetry' }}\n          key: poetry-${{ runner.os }}-${{ hashFiles('classic/forge/poetry.lock') }}\n\n      - name: Install Poetry (Unix)\n        if: runner.os != 'Windows'\n        run: |\n          curl -sSL https://install.python-poetry.org | python3 -\n\n          if [ \"${{ runner.os }}\" = \"macOS\" ]; then\n            PATH=\"$HOME/.local/bin:$PATH\"\n            echo \"$HOME/.local/bin\" >> $GITHUB_PATH\n          fi\n\n      - name: Install Poetry (Windows)\n        if: runner.os == 'Windows'\n        shell: pwsh\n        run: |\n          (Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | python -\n\n          $env:PATH += \";$env:APPDATA\\Python\\Scripts\"\n          echo \"$env:APPDATA\\Python\\Scripts\" >> $env:GITHUB_PATH\n\n      - name: Install Python dependencies\n        run: poetry install\n\n      - name: Run pytest with coverage\n        run: |\n          poetry run pytest -vv \\\n            --cov=forge --cov-branch --cov-report term-missing --cov-report xml \\\n            --durations=10 \\\n            --junitxml=junit.xml -o junit_family=legacy \\\n            forge\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n          S3_ENDPOINT_URL: ${{ runner.os != 'Windows' && 'http://127.0.0.1:9000' || '' }}\n          AWS_ACCESS_KEY_ID: minioadmin\n          AWS_SECRET_ACCESS_KEY: minioadmin\n\n      - name: Upload test results to Codecov\n        if: ${{ !cancelled() }}  # Run even if tests fail\n        uses: codecov/test-results-action@v1\n        with:\n          token: ${{ secrets.CODECOV_TOKEN }}\n\n      - name: Upload coverage reports to Codecov\n        uses: codecov/codecov-action@v5\n        with:\n          token: ${{ secrets.CODECOV_TOKEN }}\n          flags: forge,${{ runner.os }}\n\n      - id: setup_git_auth\n        name: Set up git token authentication\n        # Cassettes may be pushed even when tests fail\n        if: success() || failure()\n        run: |\n          config_key=\"http.${{ github.server_url }}/.extraheader\"\n          if [ \"${{ runner.os }}\" = 'macOS' ]; then\n            base64_pat=$(echo -n \"pat:${{ secrets.PAT_REVIEW }}\" | base64)\n          else\n            base64_pat=$(echo -n \"pat:${{ secrets.PAT_REVIEW }}\" | base64 -w0)\n          fi\n\n          git config \"$config_key\" \\\n            \"Authorization: Basic $base64_pat\"\n\n          cd tests/vcr_cassettes\n          git config \"$config_key\" \\\n            \"Authorization: Basic $base64_pat\"\n\n          echo \"config_key=$config_key\" >> $GITHUB_OUTPUT\n\n      - id: push_cassettes\n        name: Push updated cassettes\n        # For pull requests, push updated cassettes even when tests fail\n        if: github.event_name == 'push' || (! github.event.pull_request.head.repo.fork && (success() || failure()))\n        env:\n          PR_BRANCH: ${{ github.event.pull_request.head.ref }}\n          PR_AUTHOR: ${{ github.event.pull_request.user.login }}\n        run: |\n          if [ \"${{ startsWith(github.event_name, 'pull_request') }}\" = \"true\" ]; then\n            is_pull_request=true\n            cassette_branch=\"${PR_AUTHOR}-${PR_BRANCH}\"\n          else\n            cassette_branch=\"${{ github.ref_name }}\"\n          fi\n\n          cd tests/vcr_cassettes\n          # Commit & push changes to cassettes if any\n          if ! git diff --quiet; then\n            git add .\n            git commit -m \"Auto-update cassettes\"\n            git push origin HEAD:$cassette_branch\n            if [ ! $is_pull_request ]; then\n              cd ../..\n              git add tests/vcr_cassettes\n              git commit -m \"Update cassette submodule\"\n              git push origin HEAD:$cassette_branch\n            fi\n            echo \"updated=true\" >> $GITHUB_OUTPUT\n          else\n            echo \"updated=false\" >> $GITHUB_OUTPUT\n            echo \"No cassette changes to commit\"\n          fi\n\n      - name: Post Set up git token auth\n        if: steps.setup_git_auth.outcome == 'success'\n        run: |\n          git config --unset-all '${{ steps.setup_git_auth.outputs.config_key }}'\n          git submodule foreach git config --unset-all '${{ steps.setup_git_auth.outputs.config_key }}'\n\n      - name: Apply \"behaviour change\" label and comment on PR\n        if: ${{ startsWith(github.event_name, 'pull_request') }}\n        run: |\n          PR_NUMBER=\"${{ github.event.pull_request.number }}\"\n          TOKEN=\"${{ secrets.PAT_REVIEW }}\"\n          REPO=\"${{ github.repository }}\"\n\n          if [[ \"${{ steps.push_cassettes.outputs.updated }}\" == \"true\" ]]; then\n            echo \"Adding label and comment...\"\n            echo $TOKEN | gh auth login --with-token\n            gh issue edit $PR_NUMBER --add-label \"behaviour change\"\n            gh issue comment $PR_NUMBER --body \"You changed AutoGPT's behaviour on ${{ runner.os }}. The cassettes have been updated and will be merged to the submodule when this Pull Request gets merged.\"\n          fi\n\n      - name: Upload logs to artifact\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: test-logs\n          path: classic/forge/logs/\n","repository_owner":"kaqijiang","repository_name":"auto-gpt-zh","tokens_count":2221,"workflow":"name: Classic - Forge CI\n\non:\n  push:\n    branches: [master, dev, ci-test*]\n    paths:\n    - .github/workflows/classic-forge-ci.yml\n    - classic/forge/**\n    - '!classic/forge/tests/vcr_cassettes'\n  pull_request:\n    branches: [master, dev, release-*]\n    paths:\n    - .github/workflows/classic-forge-ci.yml\n    - classic/forge/**\n    - '!classic/forge/tests/vcr_cassettes'\n\nconcurrency:\n  group: ${{ format('forge-ci-{0}', github.head_ref && format('{0}-{1}', \n    github.event_name, github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ startsWith(github.event_name, 'pull_request') }}\n\ndefaults:\n  run:\n    shell: bash\n    working-directory: classic/forge\n\njobs:\n  test:\n    permissions:\n      contents: read\n    timeout-minutes: 30\n    strategy:\n      fail-fast: false\n      matrix:\n        python-version: ['3.10']\n        platform-os: [ubuntu, macos, macos-arm64, windows]\n    runs-on: ${{ matrix.platform-os != 'macos-arm64' && format('{0}-latest', \n      matrix.platform-os) || 'macos-14' }}\n\n    steps:\n      # Quite slow on macOS (2~4 minutes to set up Docker)\n      # - name: Set up Docker (macOS)\n      #   if: runner.os == 'macOS'\n      #   uses: crazy-max/ghaction-setup-docker@v3\n\n    - name: Start MinIO service (Linux)\n      if: runner.os == 'Linux'\n      working-directory: .\n      run: |\n        docker pull minio/minio:edge-cicd\n        docker run -d -p 9000:9000 minio/minio:edge-cicd\n\n    - name: Start MinIO service (macOS)\n      if: runner.os == 'macOS'\n      working-directory: ${{ runner.temp }}\n      run: |\n        brew install minio/stable/minio\n        mkdir data\n        minio server ./data &\n\n      # No MinIO on Windows:\n      # - Windows doesn't support running Linux Docker containers\n      # - It doesn't seem possible to start background processes on Windows. They are\n      #   killed after the step returns.\n      #   See: https://github.com/actions/runner/issues/598#issuecomment-2011890429\n\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      with:\n        fetch-depth: 0\n        submodules: true\n\n    - name: Checkout cassettes\n      if: ${{ startsWith(github.event_name, 'pull_request') }}\n      env:\n        PR_BASE: ${{ github.event.pull_request.base.ref }}\n        PR_BRANCH: ${{ github.event.pull_request.head.ref }}\n        PR_AUTHOR: ${{ github.event.pull_request.user.login }}\n      run: |\n        cassette_branch=\"${PR_AUTHOR}-${PR_BRANCH}\"\n        cassette_base_branch=\"${PR_BASE}\"\n        cd tests/vcr_cassettes\n\n        if ! git ls-remote --exit-code --heads origin $cassette_base_branch ; then\n          cassette_base_branch=\"master\"\n        fi\n\n        if git ls-remote --exit-code --heads origin $cassette_branch ; then\n          git fetch origin $cassette_branch\n          git fetch origin $cassette_base_branch\n\n          git checkout $cassette_branch\n\n          # Pick non-conflicting cassette updates from the base branch\n          git merge --no-commit --strategy-option=ours origin/$cassette_base_branch\n          echo \"Using cassettes from mirror branch '$cassette_branch',\" \\\n            \"synced to upstream branch '$cassette_base_branch'.\"\n        else\n          git checkout -b $cassette_branch\n          echo \"Branch '$cassette_branch' does not exist in cassette submodule.\" \\\n            \"Using cassettes from '$cassette_base_branch'.\"\n        fi\n\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v5\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Set up Python dependency cache\n        # On Windows, unpacking cached dependencies takes longer than just installing them\n      if: runner.os != 'Windows'\n      uses: actions/cache@v4\n      with:\n        path: ${{ runner.os == 'macOS' && '~/Library/Caches/pypoetry' || \n          '~/.cache/pypoetry' }}\n        key: poetry-${{ runner.os }}-${{ hashFiles('classic/forge/poetry.lock') \n          }}\n\n    - name: Install Poetry (Unix)\n      if: runner.os != 'Windows'\n      run: |\n        curl -sSL https://install.python-poetry.org | python3 -\n\n        if [ \"${{ runner.os }}\" = \"macOS\" ]; then\n          PATH=\"$HOME/.local/bin:$PATH\"\n          echo \"$HOME/.local/bin\" >> $GITHUB_PATH\n        fi\n\n    - name: Install Poetry (Windows)\n      if: runner.os == 'Windows'\n      shell: pwsh\n      run: |\n        (Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | python -\n\n        $env:PATH += \";$env:APPDATA\\Python\\Scripts\"\n        echo \"$env:APPDATA\\Python\\Scripts\" >> $env:GITHUB_PATH\n\n    - name: Install Python dependencies\n      run: poetry install\n\n    - name: Run pytest with coverage\n      run: |\n        poetry run pytest -vv \\\n          --cov=forge --cov-branch --cov-report term-missing --cov-report xml \\\n          --durations=10 \\\n          --junitxml=junit.xml -o junit_family=legacy \\\n          forge\n      env:\n        CI: true\n        PLAIN_OUTPUT: true\n        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        S3_ENDPOINT_URL: ${{ runner.os != 'Windows' && 'http://127.0.0.1:9000' \n          || '' }}\n        AWS_ACCESS_KEY_ID: minioadmin\n        AWS_SECRET_ACCESS_KEY: minioadmin\n\n    - name: Upload test results to Codecov\n      if: ${{ !cancelled() }}    # Run even if tests fail\n      uses: codecov/test-results-action@v1\n      with:\n        token: ${{ secrets.CODECOV_TOKEN }}\n\n    - name: Upload coverage reports to Codecov\n      uses: codecov/codecov-action@v5\n      with:\n        token: ${{ secrets.CODECOV_TOKEN }}\n        flags: forge,${{ runner.os }}\n\n    - id: setup_git_auth\n      name: Set up git token authentication\n        # Cassettes may be pushed even when tests fail\n      if: success() || failure()\n      run: |\n        config_key=\"http.${{ github.server_url }}/.extraheader\"\n        if [ \"${{ runner.os }}\" = 'macOS' ]; then\n          base64_pat=$(echo -n \"pat:${{ secrets.PAT_REVIEW }}\" | base64)\n        else\n          base64_pat=$(echo -n \"pat:${{ secrets.PAT_REVIEW }}\" | base64 -w0)\n        fi\n\n        git config \"$config_key\" \\\n          \"Authorization: Basic $base64_pat\"\n\n        cd tests/vcr_cassettes\n        git config \"$config_key\" \\\n          \"Authorization: Basic $base64_pat\"\n\n        echo \"config_key=$config_key\" >> $GITHUB_OUTPUT\n\n    - id: push_cassettes\n      name: Push updated cassettes\n        # For pull requests, push updated cassettes even when tests fail\n      if: github.event_name == 'push' || (! \n        github.event.pull_request.head.repo.fork && (success() || failure()))\n      env:\n        PR_BRANCH: ${{ github.event.pull_request.head.ref }}\n        PR_AUTHOR: ${{ github.event.pull_request.user.login }}\n      run: |\n        if [ \"${{ startsWith(github.event_name, 'pull_request') }}\" = \"true\" ]; then\n          is_pull_request=true\n          cassette_branch=\"${PR_AUTHOR}-${PR_BRANCH}\"\n        else\n          cassette_branch=\"${{ github.ref_name }}\"\n        fi\n\n        cd tests/vcr_cassettes\n        # Commit & push changes to cassettes if any\n        if ! git diff --quiet; then\n          git add .\n          git commit -m \"Auto-update cassettes\"\n          git push origin HEAD:$cassette_branch\n          if [ ! $is_pull_request ]; then\n            cd ../..\n            git add tests/vcr_cassettes\n            git commit -m \"Update cassette submodule\"\n            git push origin HEAD:$cassette_branch\n          fi\n          echo \"updated=true\" >> $GITHUB_OUTPUT\n        else\n          echo \"updated=false\" >> $GITHUB_OUTPUT\n          echo \"No cassette changes to commit\"\n        fi\n\n    - name: Post Set up git token auth\n      if: steps.setup_git_auth.outcome == 'success'\n      run: |\n        git config --unset-all '${{ steps.setup_git_auth.outputs.config_key }}'\n        git submodule foreach git config --unset-all '${{ steps.setup_git_auth.outputs.config_key }}'\n\n    - name: Apply \"behaviour change\" label and comment on PR\n      if: ${{ startsWith(github.event_name, 'pull_request') }}\n      run: |\n        PR_NUMBER=\"${{ github.event.pull_request.number }}\"\n        TOKEN=\"${{ secrets.PAT_REVIEW }}\"\n        REPO=\"${{ github.repository }}\"\n\n        if [[ \"${{ steps.push_cassettes.outputs.updated }}\" == \"true\" ]]; then\n          echo \"Adding label and comment...\"\n          echo $TOKEN | gh auth login --with-token\n          gh issue edit $PR_NUMBER --add-label \"behaviour change\"\n          gh issue comment $PR_NUMBER --body \"You changed AutoGPT's behaviour on ${{ runner.os }}. The cassettes have been updated and will be merged to the submodule when this Pull Request gets merged.\"\n        fi\n\n    - name: Upload logs to artifact\n      if: always()\n      uses: actions/upload-artifact@v4\n      with:\n        name: test-logs\n        path: classic/forge/logs/\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Classic - Forge CI` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master, a branch named dev or a branch whose name matches ci-test*. Only if at least one path of push event matches a pattern in the paths filter(.github/workflows/classic-forge-ci.yml, classic/forge/** or !classic/forge/tests/vcr_cassettes), the workflow runs. 2) The workflow would run whenever there is a pull_request event targeting: a branch named master, a branch named dev or a branch whose name matches release-*. Only if at least one path of pull_request event matches a pattern in the paths filter(.github/workflows/classic-forge-ci.yml, classic/forge/** or !classic/forge/tests/vcr_cassettes), the workflow runs. For all run steps in the workflow, default shell is set to bash and default working directory is set to classic/forge. Only a single workflow using the ${{ format('forge-ci-{0}', github.head_ref && format('{0}-{1}', github.event_name, github.event.pull_request.number) || github.sha) }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `test`. ","prompt_level2":"Generate a GitHub Workflow named `Classic - Forge CI` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master, a branch named dev or a branch whose name matches ci-test*. Only if at least one path of push event matches a pattern in the paths filter(.github/workflows/classic-forge-ci.yml, classic/forge/** or !classic/forge/tests/vcr_cassettes), the workflow runs. 2) The workflow would run whenever there is a pull_request event targeting: a branch named master, a branch named dev or a branch whose name matches release-*. Only if at least one path of pull_request event matches a pattern in the paths filter(.github/workflows/classic-forge-ci.yml, classic/forge/** or !classic/forge/tests/vcr_cassettes), the workflow runs. For all run steps in the workflow, default shell is set to bash and default working directory is set to classic/forge. Only a single workflow using the ${{ format('forge-ci-{0}', github.head_ref && format('{0}-{1}', github.event_name, github.event.pull_request.number) || github.sha) }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `test`. The job `test` has 17 steps. The 1st step is named `Start MinIO service (Linux)`. The 2nd step is named `Start MinIO service (macOS)`. The 3rd step is named `Checkout repository`. The 4th step is named `Checkout cassettes`. The 5th step is named `Set up Python ${{ matrix.python-version }}`. The 6th step is named `Set up Python dependency cache`. The 7th step is named `Install Poetry (Unix)`. The 8th step is named `Install Poetry (Windows)`. The 9th step is named `Install Python dependencies`. The 10th step is named `Run pytest with coverage`. The 11th step is named `Upload test results to Codecov`. The 12th step is named `Upload coverage reports to Codecov`. The 13th step is named `Set up git token authentication` and its id is `setup_git_auth`. The 14th step is named `Push updated cassettes` and its id is `push_cassettes`. The 15th step is named `Post Set up git token auth`. The 16th step is named `Apply \"behaviour change\" label and comment on PR`. The 17th step is named `Upload logs to artifact`. ","prompt_level3":"Generate a GitHub Workflow named `Classic - Forge CI` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named master, a branch named dev or a branch whose name matches ci-test*. Only if at least one path of push event matches a pattern in the paths filter(.github/workflows/classic-forge-ci.yml, classic/forge/** or !classic/forge/tests/vcr_cassettes), the workflow runs. 2) The workflow would run whenever there is a pull_request event targeting: a branch named master, a branch named dev or a branch whose name matches release-*. Only if at least one path of pull_request event matches a pattern in the paths filter(.github/workflows/classic-forge-ci.yml, classic/forge/** or !classic/forge/tests/vcr_cassettes), the workflow runs. For all run steps in the workflow, default shell is set to bash and default working directory is set to classic/forge. Only a single workflow using the ${{ format('forge-ci-{0}', github.head_ref && format('{0}-{1}', github.event_name, github.event.pull_request.number) || github.sha) }} concurrency group will run at a time. When this workflow is queued, any currently running workflow in the same concurrency group will be canceled. The workflow has one job. The job id of the 1st job is `test`. This job will run on ${{ matrix.platform-os != 'macos-arm64' && format('{0}-latest', matrix.platform-os) || 'macos-14' }} runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `python-version` has one value: 3.10. The variable `platform-os` has 4 values: ubuntu, macos, macos-arm64 and windows. The job `test` modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting only applies to the job `test`. The maximum number of minutes to run the job is 30. The job `test` has 17 steps. The 1st step is named `Start MinIO service (Linux)`. This step will run only if the condition(runner.os == 'Linux') is met. This step runs a script: `docker pull minio/minio:edge-cicd\ndocker run -d -p 9000:9000 minio/minio:edge-cicd\n`. The 2nd step is named `Start MinIO service (macOS)`. This step will run only if the condition(runner.os == 'macOS') is met. This step runs a script: `brew install minio/stable/minio\nmkdir data\nminio server ./data &\n`. The 3rd step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines 2 input parameters for the action: `fetch-depth` is set to `0` and `submodules` is set to `True`. The 4th step is named `Checkout cassettes`. This step will run only if the condition(${{ startsWith(github.event_name, 'pull_request') }}) is met. The step sets 3 environment variables to use: `PR_BASE` is set to `${{ github.event.pull_request.base.ref }}`, `PR_BRANCH` is set to `${{ github.event.pull_request.head.ref }}` and `PR_AUTHOR` is set to `${{ github.event.pull_request.user.login }}`. This step runs a script: `cassette_branch=\"${PR_AUTHOR}-${PR_BRANCH}\"\ncassette_base_branch=\"${PR_BASE}\"\ncd tests/vcr_cassettes\n\nif ! git ls-remote --exit-code --heads origin $cassette_base_branch ; then\n  cassette_base_branch=\"master\"\nfi\n\nif git ls-remote --exit-code --heads origin $cassette_branch ; then\n  git fetch origin $cassette_branch\n  git fetch origin $cassette_base_branch\n\n  git checkout $cassette_branch\n\n  # Pick non-conflicting cassette updates from the base branch\n  git merge --no-commit --strategy-option=ours origin/$cassette_base_branch\n  echo \"Using cassettes from mirror branch '$cassette_branch',\" \\\n    \"synced to upstream branch '$cassette_base_branch'.\"\nelse\n  git checkout -b $cassette_branch\n  echo \"Branch '$cassette_branch' does not exist in cassette submodule.\" \\\n    \"Using cassettes from '$cassette_base_branch'.\"\nfi\n`. The 5th step is named `Set up Python ${{ matrix.python-version }}`. This step runs action `actions/setup-python` tagged as v5. The step defines an input parameter for the action: `python-version` is set to `${{ matrix.python-version }}`. The 6th step is named `Set up Python dependency cache`. This step will run only if the condition(runner.os != 'Windows') is met. This step runs action `actions/cache` tagged as v4. The step defines 2 input parameters for the action: `path` is set to `${{ runner.os == 'macOS' && '~/Library/Caches/pypoetry' || '~/.cache/pypoetry' }}` and `key` is set to `poetry-${{ runner.os }}-${{ hashFiles('classic/forge/poetry.lock') }}`. The 7th step is named `Install Poetry (Unix)`. This step will run only if the condition(runner.os != 'Windows') is met. This step runs a script: `curl -sSL https://install.python-poetry.org | python3 -\n\nif [ \"${{ runner.os }}\" = \"macOS\" ]; then\n  PATH=\"$HOME/.local/bin:$PATH\"\n  echo \"$HOME/.local/bin\" >> $GITHUB_PATH\nfi\n`. The 8th step is named `Install Poetry (Windows)`. This step will run only if the condition(runner.os == 'Windows') is met. This step uses PowerShell Core to run a script: `(Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | python -\n\n$env:PATH += \";$env:APPDATA\\Python\\Scripts\"\necho \"$env:APPDATA\\Python\\Scripts\" >> $env:GITHUB_PATH\n`. The 9th step is named `Install Python dependencies`. This step runs a script: `poetry install`. The 10th step is named `Run pytest with coverage`. The step sets 6 environment variables to use: `CI` is set to `True`, `PLAIN_OUTPUT` is set to `True`, `OPENAI_API_KEY` is set to `${{ secrets.OPENAI_API_KEY }}`, `S3_ENDPOINT_URL` is set to `${{ runner.os != 'Windows' && 'http://127.0.0.1:9000' || '' }}`, `AWS_ACCESS_KEY_ID` is set to `minioadmin` and `AWS_SECRET_ACCESS_KEY` is set to `minioadmin`. This step runs a script: `poetry run pytest -vv \\\n  --cov=forge --cov-branch --cov-report term-missing --cov-report xml \\\n  --durations=10 \\\n  --junitxml=junit.xml -o junit_family=legacy \\\n  forge\n`. The 11th step is named `Upload test results to Codecov`. This step will run only if the condition(${{ !cancelled() }}) is met. This step runs action `codecov/test-results-action` tagged as v1. The step defines an input parameter for the action: `token` is set to `${{ secrets.CODECOV_TOKEN }}`. The 12th step is named `Upload coverage reports to Codecov`. This step runs action `codecov/codecov-action` tagged as v5. The step defines 2 input parameters for the action: `token` is set to `${{ secrets.CODECOV_TOKEN }}` and `flags` is set to `forge,${{ runner.os }}`. The 13th step is named `Set up git token authentication` and its id is `setup_git_auth`. This step will run only if the condition(success() || failure()) is met. This step runs a script: `config_key=\"http.${{ github.server_url }}/.extraheader\"\nif [ \"${{ runner.os }}\" = 'macOS' ]; then\n  base64_pat=$(echo -n \"pat:${{ secrets.PAT_REVIEW }}\" | base64)\nelse\n  base64_pat=$(echo -n \"pat:${{ secrets.PAT_REVIEW }}\" | base64 -w0)\nfi\n\ngit config \"$config_key\" \\\n  \"Authorization: Basic $base64_pat\"\n\ncd tests/vcr_cassettes\ngit config \"$config_key\" \\\n  \"Authorization: Basic $base64_pat\"\n\necho \"config_key=$config_key\" >> $GITHUB_OUTPUT\n`. The 14th step is named `Push updated cassettes` and its id is `push_cassettes`. This step will run only if the condition(github.event_name == 'push' || (! github.event.pull_request.head.repo.fork && (success() || failure()))) is met. The step sets 2 environment variables to use: `PR_BRANCH` is set to `${{ github.event.pull_request.head.ref }}` and `PR_AUTHOR` is set to `${{ github.event.pull_request.user.login }}`. This step runs a script: `if [ \"${{ startsWith(github.event_name, 'pull_request') }}\" = \"true\" ]; then\n  is_pull_request=true\n  cassette_branch=\"${PR_AUTHOR}-${PR_BRANCH}\"\nelse\n  cassette_branch=\"${{ github.ref_name }}\"\nfi\n\ncd tests/vcr_cassettes\n# Commit & push changes to cassettes if any\nif ! git diff --quiet; then\n  git add .\n  git commit -m \"Auto-update cassettes\"\n  git push origin HEAD:$cassette_branch\n  if [ ! $is_pull_request ]; then\n    cd ../..\n    git add tests/vcr_cassettes\n    git commit -m \"Update cassette submodule\"\n    git push origin HEAD:$cassette_branch\n  fi\n  echo \"updated=true\" >> $GITHUB_OUTPUT\nelse\n  echo \"updated=false\" >> $GITHUB_OUTPUT\n  echo \"No cassette changes to commit\"\nfi\n`. The 15th step is named `Post Set up git token auth`. This step will run only if the condition(steps.setup_git_auth.outcome == 'success') is met. This step runs a script: `git config --unset-all '${{ steps.setup_git_auth.outputs.config_key }}'\ngit submodule foreach git config --unset-all '${{ steps.setup_git_auth.outputs.config_key }}'\n`. The 16th step is named `Apply \"behaviour change\" label and comment on PR`. This step will run only if the condition(${{ startsWith(github.event_name, 'pull_request') }}) is met. This step runs a script: `PR_NUMBER=\"${{ github.event.pull_request.number }}\"\nTOKEN=\"${{ secrets.PAT_REVIEW }}\"\nREPO=\"${{ github.repository }}\"\n\nif [[ \"${{ steps.push_cassettes.outputs.updated }}\" == \"true\" ]]; then\n  echo \"Adding label and comment...\"\n  echo $TOKEN | gh auth login --with-token\n  gh issue edit $PR_NUMBER --add-label \"behaviour change\"\n  gh issue comment $PR_NUMBER --body \"You changed AutoGPT's behaviour on ${{ runner.os }}. The cassettes have been updated and will be merged to the submodule when this Pull Request gets merged.\"\nfi\n`. The 17th step is named `Upload logs to artifact`. This step will run only if the condition(always()) is met. This step runs action `actions/upload-artifact` tagged as v4. The step defines 2 input parameters for the action: `name` is set to `test-logs` and `path` is set to `classic/forge/logs/`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":1,"nb_actions":6,"actions":["actions/cache","actions/checkout","actions/setup-python","actions/upload-artifact","codecov/codecov-action","codecov/test-results-action"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v5","name":"actions/setup-python"},{"version":"v4","name":"actions/cache"},{"version":"v1","name":"codecov/test-results-action"},{"version":"v5","name":"codecov/codecov-action"},{"version":"v4","name":"actions/upload-artifact"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":17,"cyclomatic_complexity":1}
{"id":59835,"repository_id":94700741,"mainLanguage":"Python","file_name":"diff.yml","file_content":"name: Diff\non:\n  workflow_call:\n    inputs:\n      config:\n        type: string\n        required: true\n        description: 'YAML file containing modules to track'\n    outputs:\n      diff:\n        description: \"diff\"\n        value: \"${{ jobs.diff.outputs.diff }}\"\n      tags:\n        description: \"tags\"\n        value: \"${{ jobs.diff.outputs.tags }}\"\n      modules:\n        description: \"modules\"\n        value: \"${{ jobs.diff.outputs.modules }}\"\n      changed:\n        description: \"changed\"\n        value: \"${{ jobs.diff.outputs.changed }}\"\n\njobs:\n  diff:\n    name: Compare\n    runs-on: ubuntu-latest\n    outputs:\n      diff: ${{ steps.run.outputs.diff }}\n      tags: ${{ steps.run.outputs.tags }}\n      modules: ${{ steps.run.outputs.modules }}\n      changed: ${{ steps.run.outputs.changed }}\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v4\n\n    - id: run\n      name: Diff action\n      uses: aurelio-labs/diff-action@0.2.0\n      with:\n        token: ${{ secrets.GITHUB_TOKEN }}\n        config: ${{ inputs.config }}\n\n    - name: Print output\n      run: echo '${{ toJSON(steps.run.outputs) }}' | jq .\n","repository_owner":"aurelio-labs","repository_name":"semantic-router","tokens_count":271,"workflow":"name: Diff\non:\n  workflow_call:\n    inputs:\n      config:\n        type: string\n        required: true\n        description: YAML file containing modules to track\n    outputs:\n      diff:\n        description: diff\n        value: ${{ jobs.diff.outputs.diff }}\n      tags:\n        description: tags\n        value: ${{ jobs.diff.outputs.tags }}\n      modules:\n        description: modules\n        value: ${{ jobs.diff.outputs.modules }}\n      changed:\n        description: changed\n        value: ${{ jobs.diff.outputs.changed }}\n\njobs:\n  diff:\n    name: Compare\n    runs-on: ubuntu-latest\n    outputs:\n      diff: ${{ steps.run.outputs.diff }}\n      tags: ${{ steps.run.outputs.tags }}\n      modules: ${{ steps.run.outputs.modules }}\n      changed: ${{ steps.run.outputs.changed }}\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v4\n\n    - id: run\n      name: Diff action\n      uses: aurelio-labs/diff-action@0.2.0\n      with:\n        token: ${{ secrets.GITHUB_TOKEN }}\n        config: ${{ inputs.config }}\n\n    - name: Print output\n      run: echo '${{ toJSON(steps.run.outputs) }}' | jq .\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Diff` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives an input: config-the data type is string, it must be supplied and this input represents yaml file containing modules to track. This workflow has 4 outputs: diff-it represents diff and its value is ${{ jobs.diff.outputs.diff }}; tags-it represents tags and its value is ${{ jobs.diff.outputs.tags }}; modules-it represents modules and its value is ${{ jobs.diff.outputs.modules }}; changed-it represents changed and its value is ${{ jobs.diff.outputs.changed }}. The workflow has one job. The 1st job is named `Compare` and its job id is `diff`. ","prompt_level2":"Generate a GitHub Workflow named `Diff` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives an input: config-the data type is string, it must be supplied and this input represents yaml file containing modules to track. This workflow has 4 outputs: diff-it represents diff and its value is ${{ jobs.diff.outputs.diff }}; tags-it represents tags and its value is ${{ jobs.diff.outputs.tags }}; modules-it represents modules and its value is ${{ jobs.diff.outputs.modules }}; changed-it represents changed and its value is ${{ jobs.diff.outputs.changed }}. The workflow has one job. The 1st job is named `Compare` and its job id is `diff`. The job `diff` has 3 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Diff action` and its id is `run`. The 3rd step is named `Print output`. ","prompt_level3":"Generate a GitHub Workflow named `Diff` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives an input: config-the data type is string, it must be supplied and this input represents yaml file containing modules to track. This workflow has 4 outputs: diff-it represents diff and its value is ${{ jobs.diff.outputs.diff }}; tags-it represents tags and its value is ${{ jobs.diff.outputs.tags }}; modules-it represents modules and its value is ${{ jobs.diff.outputs.modules }}; changed-it represents changed and its value is ${{ jobs.diff.outputs.changed }}. The workflow has one job. The 1st job is named `Compare` and its job id is `diff`. This job will run on ubuntu-latest runner. The job `diff` has 3 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Diff action` and its id is `run`. This step runs action `aurelio-labs/diff-action` tagged as 0.2.0. The step defines 2 input parameters for the action: `token` is set to `${{ secrets.GITHUB_TOKEN }}` and `config` is set to `${{ inputs.config }}`. The 3rd step is named `Print output`. This step runs a script: `echo '${{ toJSON(steps.run.outputs) }}' | jq .`. This job has 4 outputs: `diff` is defined as ${{ steps.run.outputs.diff }}, `tags` is defined as ${{ steps.run.outputs.tags }}, `modules` is defined as ${{ steps.run.outputs.modules }} and `changed` is defined as ${{ steps.run.outputs.changed }}. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":2,"actions":["actions/checkout","aurelio-labs/diff-action"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"0.2.0","name":"aurelio-labs/diff-action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":3,"cyclomatic_complexity":1}
{"id":20354,"repository_id":17302469,"mainLanguage":"Go","file_name":"markdown-fail-fast.yml","file_content":"name: Markdown (Fail Fast)\n\non:\n  push:\n  pull_request:\n\n# Declare default permissions as read only.\npermissions: read-all\n\njobs:\n  changedfiles:\n    name: changed files\n    runs-on: ubuntu-latest\n    outputs:\n      md: ${{ steps.changes.outputs.md }}\n    steps:\n      - name: Checkout Repo\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4\n        with:\n          fetch-depth: 0\n      - name: Get changed files\n        id: changes\n        run: |\n          echo \"md=$(git diff --name-only --diff-filter=ACMRTUXB origin/${{ github.event.pull_request.base.ref }} ${{ github.event.pull_request.head.sha }} | grep .md$ | xargs)\" >> $GITHUB_OUTPUT\n\n  lint:\n    name: lint markdown files\n    runs-on: ubuntu-latest\n    needs: changedfiles\n    if: ${{needs.changedfiles.outputs.md}}\n    steps:\n    - name: Checkout Repo\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4\n    - name: Lint Markdown\n      uses: docker://avtodev/markdown-lint:v1@sha256:6aeedc2f49138ce7a1cd0adffc1b1c0321b841dc2102408967d9301c031949ee\n      with:\n        args: ${{needs.changedfiles.outputs.md}}\n","repository_owner":"open-telemetry","repository_name":"opentelemetry-go-contrib","tokens_count":387,"workflow":"name: Markdown (Fail Fast)\n\non:\n  push:\n  pull_request:\n\n# Declare default permissions as read only.\npermissions: read-all\n\njobs:\n  changedfiles:\n    name: changed files\n    runs-on: ubuntu-latest\n    outputs:\n      md: ${{ steps.changes.outputs.md }}\n    steps:\n    - name: Checkout Repo\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683   # v4\n      with:\n        fetch-depth: 0\n    - name: Get changed files\n      id: changes\n      run: |\n        echo \"md=$(git diff --name-only --diff-filter=ACMRTUXB origin/${{ github.event.pull_request.base.ref }} ${{ github.event.pull_request.head.sha }} | grep .md$ | xargs)\" >> $GITHUB_OUTPUT\n\n  lint:\n    name: lint markdown files\n    runs-on: ubuntu-latest\n    needs: changedfiles\n    if: ${{needs.changedfiles.outputs.md}}\n    steps:\n    - name: Checkout Repo\n      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4\n    - name: Lint Markdown\n      uses: \n        docker://avtodev/markdown-lint:v1@sha256:6aeedc2f49138ce7a1cd0adffc1b1c0321b841dc2102408967d9301c031949ee\n      with:\n        args: ${{needs.changedfiles.outputs.md}}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Markdown (Fail Fast)` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow has 2 jobs. The 1st job is named `changed files` and its job id is `changedfiles`. The 2nd job is named `lint markdown files` and its job id is `lint`. ","prompt_level2":"Generate a GitHub Workflow named `Markdown (Fail Fast)` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow has 2 jobs. The 1st job is named `changed files` and its job id is `changedfiles`. The job `changedfiles` has 2 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Get changed files` and its id is `changes`. The 2nd job is named `lint markdown files` and its job id is `lint`. The job `lint` has 2 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Lint Markdown`. ","prompt_level3":"Generate a GitHub Workflow named `Markdown (Fail Fast)` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by multiple events: 1) a commit or tag is pushed, or a repository is cloned. 2) there is activity relating to a pull request. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN across all scopes. This permission setting applies to all jobs in the workflow. The workflow has 2 jobs. The 1st job is named `changed files` and its job id is `changedfiles`. This job will run on ubuntu-latest runner. The job `changedfiles` has 2 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is 11bd71901bbe5b1630ceea73d27597364c9af683. The step defines an input parameter for the action: `fetch-depth` is set to `0`. The 2nd step is named `Get changed files` and its id is `changes`. This step runs a script: `echo \"md=$(git diff --name-only --diff-filter=ACMRTUXB origin/${{ github.event.pull_request.base.ref }} ${{ github.event.pull_request.head.sha }} | grep .md$ | xargs)\" >> $GITHUB_OUTPUT\n`. This job has an output: `md` is defined as ${{ steps.changes.outputs.md }}. The 2nd job is named `lint markdown files` and its job id is `lint`. Before this job runs, `changedfiles` must complete successfully. This job will run only if the condition(${{needs.changedfiles.outputs.md}}) is met. This job will run on ubuntu-latest runner. The job `lint` has 2 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is 11bd71901bbe5b1630ceea73d27597364c9af683. The 2nd step is named `Lint Markdown`. This step runs action `docker://avtodev/markdown-lint:v1` from the sha256:6aeedc2f49138ce7a1cd0adffc1b1c0321b841dc2102408967d9301c031949ee branch. The step defines an input parameter for the action: `args` is set to `${{needs.changedfiles.outputs.md}}`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":2,"nb_actions":3,"actions":["actions/checkout","actions/checkout","docker://avtodev/markdown-lint:v1"],"actions_details":[{"version":"11bd71901bbe5b1630ceea73d27597364c9af683","name":"actions/checkout"},{"version":"11bd71901bbe5b1630ceea73d27597364c9af683","name":"actions/checkout"},{"version":"sha256:6aeedc2f49138ce7a1cd0adffc1b1c0321b841dc2102408967d9301c031949ee","name":"docker://avtodev/markdown-lint:v1"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":4,"cyclomatic_complexity":1}
{"id":51579,"repository_id":95266545,"mainLanguage":"Rust","file_name":"release-publish.yml","file_content":"name: \"Release: (03) Publish\"\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: \"The version to release, e.g. \\\"0.1.2\\\"\"\n        type: string\n        required: true\n      next-version:\n        description: \"The next revision to set. Will have \\\"-dev\\\" appended\"\n        type: string\n        required: true\n\nenv:\n  RELEASE_VERSION: ${{ inputs.version }}\n  NEXT_VERSION: \"${{ inputs.next-version }}-dev\"\n  BRANCH_NAME: \"pending-releases/${{ inputs.version }}\"\n  DOCKER_RC_TAG: \"yshavit/mdq:${{ inputs.version }}-rc\"\n  DOCKER_PUBLISH_TAG: \"yshavit/mdq:${{ inputs.version }}\"\n\njobs:\n  verify:\n    runs-on: ubuntu-latest\n    env:\n      GH_TOKEN: ${{ github.token }}\n    outputs:\n      pr-json: ${{ steps.pr-info.outputs.json }}\n    steps:\n      - name: Get PR Info\n        id: pr-info\n        run: |\n          set -euo pipefail\n          pr_json=\"$(gh pr view -R \"$REPO_NAME\" \"$BRANCH_NAME\" --json mergeStateStatus,body,baseRefName)\"\n          <<<\"$pr_json\" | jq .\n          echo \"json=$pr_json\" >> \"$GITHUB_OUTPUT\"\n        env:\n          REPO_NAME: ${{ github.repository }}\n\n      - name: Validate PR status\n        run: |\n          set -euo pipefail\n          merge_status=\"$(<<<\"$PR_JSON\" jq -r .mergeStateStatus)\"\n          if [[ \"$merge_status\" != CLEAN ]]; then\n            echo \"::error title=invalid branch state::require CLEAN, saw $merge_status\"\n            exit 1\n          fi\n        env:\n          PR_JSON: ${{ steps.pr-info.outputs.json }}\n\n      - name: Docker pull\n        run: docker pull \"$DOCKER_RC_TAG\"\n\n      - name: Look for unfinished checkbox items\n        run: |\n          exit_status=0\n          while read -r line ; do\n            echo \"::error title=unfinished task::$line\"\n            exit_status=1\n          done < <(echo \"$PR_JSON\" | jq -r .body | docker run --rm -i \"$DOCKER_RC_TAG\" -o plain '- [ ]')\n          exit \"$exit_status\"\n        env:\n          PR_JSON: ${{ steps.pr-info.outputs.json }}\n\n  docker:\n    environment: Docker Hub\n    needs: verify\n    runs-on: ubuntu-latest\n    steps:\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ vars.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_PAT }}\n\n      - name: Pull\n        run: docker pull \"$DOCKER_RC_TAG\"\n\n      - name: Retag\n        run: docker tag \"$DOCKER_RC_TAG\" \"$DOCKER_PUBLISH_TAG\"\n\n      - name: Push\n        run: docker push \"$DOCKER_PUBLISH_TAG\"\n\n  github:\n\n    needs: [ verify, docker ]\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n      pull-requests: write\n\n    steps:\n\n      - name: Get PR base ref\n        id: base-ref\n        run: echo \"name=$(echo \"$PR_JSON\" | jq -r .baseRefName)\" >> \"$GITHUB_OUTPUT\"\n        env:\n          PR_JSON: ${{ needs.verify.outputs.pr-json }}\n\n      - uses: actions/checkout@v4\n        with:\n          ref: ${{ steps.base-ref.outputs.name }}\n\n      - name: Fetch release branch\n        run: git fetch origin \"$BRANCH_NAME\"\n\n      - name: Git FF main\n        run: git merge --ff-only \"origin/$BRANCH_NAME\"\n\n      - name: Git push\n        run: git push origin \"$TARGET_REF\"\n        env:\n          TARGET_REF: ${{ steps.base-ref.outputs.name }}\n\n      - name: Publish Release\n        run: gh release edit \"v$RELEASE_VERSION\" --draft=false\n        env:\n          GH_TOKEN: ${{ github.token }}\n\n      - name: Update Cargo.toml\n        run: |\n          set -euo pipefail\n          sed -i 's/^version = \".*\"/version = \"${{ env.NEXT_VERSION }}\"/' Cargo.toml\n          cargo metadata >/dev/null\n\n      - name: Configure git\n        run: |\n          set -euo pipefail\n          git config --global user.name 'github-actions[bot]'\n          git config --global user.email 'github-actions[bot]@users.noreply.github.com'\n\n      - name: Commit change\n        run: git commit -am \"bump version to $NEXT_VERSION\"\n\n      - name: Push to branch\n        run: |\n          set -euo pipefail\n          git checkout -b \"prepare-$NEXT_VERSION\"\n          git push --set-upstream origin \"prepare-$NEXT_VERSION\"\n\n      - name: Open PR\n        run: |\n          set -euo pipefail\n          gh pr create --title \"Bump version to $NEXT_VERSION\" --body \"Created by release-publish.yml\" --base \"$TARGET_REF\"\n        env:\n          TARGET_REF: ${{ steps.base-ref.outputs.name }}\n          GH_TOKEN: ${{ github.token }}\n\n      - name: Push to target ref\n        run: |\n          git checkout -B \"$TARGET_REF\" \"origin/$TARGET_REF\"\n          git merge --ff-only \"prepare-$NEXT_VERSION\"\n          git push\n        env:\n          TARGET_REF: ${{ steps.base-ref.outputs.name }}\n\n  crates-io:\n    needs: github\n    environment: \"crates.io\"\n    runs-on: ubuntu-latest\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          ref: \"v${{ env.RELEASE_VERSION }}\"\n\n      - name: cargo login\n        run: cargo login <<<\"$CRATESIO_API_TOKEN\"\n        env:\n          CRATESIO_API_TOKEN: ${{ secrets.CRATESIO_API_TOKEN }}\n\n      - name: Publish\n        run: cargo publish\n\n","repository_owner":"yshavit","repository_name":"mdq","tokens_count":1279,"workflow":"name: 'Release: (03) Publish'\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: The version to release, e.g. \"0.1.2\"\n        type: string\n        required: true\n      next-version:\n        description: The next revision to set. Will have \"-dev\" appended\n        type: string\n        required: true\n\nenv:\n  RELEASE_VERSION: ${{ inputs.version }}\n  NEXT_VERSION: ${{ inputs.next-version }}-dev\n  BRANCH_NAME: pending-releases/${{ inputs.version }}\n  DOCKER_RC_TAG: yshavit/mdq:${{ inputs.version }}-rc\n  DOCKER_PUBLISH_TAG: yshavit/mdq:${{ inputs.version }}\n\njobs:\n  verify:\n    runs-on: ubuntu-latest\n    env:\n      GH_TOKEN: ${{ github.token }}\n    outputs:\n      pr-json: ${{ steps.pr-info.outputs.json }}\n    steps:\n    - name: Get PR Info\n      id: pr-info\n      run: |\n        set -euo pipefail\n        pr_json=\"$(gh pr view -R \"$REPO_NAME\" \"$BRANCH_NAME\" --json mergeStateStatus,body,baseRefName)\"\n        <<<\"$pr_json\" | jq .\n        echo \"json=$pr_json\" >> \"$GITHUB_OUTPUT\"\n      env:\n        REPO_NAME: ${{ github.repository }}\n\n    - name: Validate PR status\n      run: |\n        set -euo pipefail\n        merge_status=\"$(<<<\"$PR_JSON\" jq -r .mergeStateStatus)\"\n        if [[ \"$merge_status\" != CLEAN ]]; then\n          echo \"::error title=invalid branch state::require CLEAN, saw $merge_status\"\n          exit 1\n        fi\n      env:\n        PR_JSON: ${{ steps.pr-info.outputs.json }}\n\n    - name: Docker pull\n      run: docker pull \"$DOCKER_RC_TAG\"\n\n    - name: Look for unfinished checkbox items\n      run: |\n        exit_status=0\n        while read -r line ; do\n          echo \"::error title=unfinished task::$line\"\n          exit_status=1\n        done < <(echo \"$PR_JSON\" | jq -r .body | docker run --rm -i \"$DOCKER_RC_TAG\" -o plain '- [ ]')\n        exit \"$exit_status\"\n      env:\n        PR_JSON: ${{ steps.pr-info.outputs.json }}\n\n  docker:\n    environment: Docker Hub\n    needs: verify\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Log in to Docker Hub\n      uses: docker/login-action@v3\n      with:\n        username: ${{ vars.DOCKERHUB_USERNAME }}\n        password: ${{ secrets.DOCKERHUB_PAT }}\n\n    - name: Pull\n      run: docker pull \"$DOCKER_RC_TAG\"\n\n    - name: Retag\n      run: docker tag \"$DOCKER_RC_TAG\" \"$DOCKER_PUBLISH_TAG\"\n\n    - name: Push\n      run: docker push \"$DOCKER_PUBLISH_TAG\"\n\n  github:\n\n    needs: [verify, docker]\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n      pull-requests: write\n\n    steps:\n\n    - name: Get PR base ref\n      id: base-ref\n      run: echo \"name=$(echo \"$PR_JSON\" | jq -r .baseRefName)\" >> \n        \"$GITHUB_OUTPUT\"\n      env:\n        PR_JSON: ${{ needs.verify.outputs.pr-json }}\n\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      with:\n        ref: ${{ steps.base-ref.outputs.name }}\n\n    - name: Fetch release branch\n      run: git fetch origin \"$BRANCH_NAME\"\n\n    - name: Git FF main\n      run: git merge --ff-only \"origin/$BRANCH_NAME\"\n\n    - name: Git push\n      run: git push origin \"$TARGET_REF\"\n      env:\n        TARGET_REF: ${{ steps.base-ref.outputs.name }}\n\n    - name: Publish Release\n      run: gh release edit \"v$RELEASE_VERSION\" --draft=false\n      env:\n        GH_TOKEN: ${{ github.token }}\n\n    - name: Update Cargo.toml\n      run: |\n        set -euo pipefail\n        sed -i 's/^version = \".*\"/version = \"${{ env.NEXT_VERSION }}\"/' Cargo.toml\n        cargo metadata >/dev/null\n\n    - name: Configure git\n      run: |\n        set -euo pipefail\n        git config --global user.name 'github-actions[bot]'\n        git config --global user.email 'github-actions[bot]@users.noreply.github.com'\n\n    - name: Commit change\n      run: git commit -am \"bump version to $NEXT_VERSION\"\n\n    - name: Push to branch\n      run: |\n        set -euo pipefail\n        git checkout -b \"prepare-$NEXT_VERSION\"\n        git push --set-upstream origin \"prepare-$NEXT_VERSION\"\n\n    - name: Open PR\n      run: |\n        set -euo pipefail\n        gh pr create --title \"Bump version to $NEXT_VERSION\" --body \"Created by release-publish.yml\" --base \"$TARGET_REF\"\n      env:\n        TARGET_REF: ${{ steps.base-ref.outputs.name }}\n        GH_TOKEN: ${{ github.token }}\n\n    - name: Push to target ref\n      run: |\n        git checkout -B \"$TARGET_REF\" \"origin/$TARGET_REF\"\n        git merge --ff-only \"prepare-$NEXT_VERSION\"\n        git push\n      env:\n        TARGET_REF: ${{ steps.base-ref.outputs.name }}\n\n  crates-io:\n    needs: github\n    environment: crates.io\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      with:\n        ref: v${{ env.RELEASE_VERSION }}\n\n    - name: cargo login\n      run: cargo login <<<\"$CRATESIO_API_TOKEN\"\n      env:\n        CRATESIO_API_TOKEN: ${{ secrets.CRATESIO_API_TOKEN }}\n\n    - name: Publish\n      run: cargo publish\n\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Release: (03) Publish` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 2 inputs: version-this input represents the version to release, e.g. \"0.1.2\", the data type is string and it must be supplied; next-version-this input represents the next revision to set. will have \"-dev\" appended, the data type is string and it must be supplied. The workflow sets 5 environment variables to use: `RELEASE_VERSION` is set to `${{ inputs.version }}`, `NEXT_VERSION` is set to `${{ inputs.next-version }}-dev`, `BRANCH_NAME` is set to `pending-releases/${{ inputs.version }}`, `DOCKER_RC_TAG` is set to `yshavit/mdq:${{ inputs.version }}-rc` and `DOCKER_PUBLISH_TAG` is set to `yshavit/mdq:${{ inputs.version }}`. The workflow has 4 jobs. The job id of the 1st job is `verify`. The job id of the 2nd job is `docker`. The job id of the 3rd job is `github`. The job id of the 4th job is `crates-io`. ","prompt_level2":"Generate a GitHub Workflow named `Release: (03) Publish` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 2 inputs: version-this input represents the version to release, e.g. \"0.1.2\", the data type is string and it must be supplied; next-version-this input represents the next revision to set. will have \"-dev\" appended, the data type is string and it must be supplied. The workflow sets 5 environment variables to use: `RELEASE_VERSION` is set to `${{ inputs.version }}`, `NEXT_VERSION` is set to `${{ inputs.next-version }}-dev`, `BRANCH_NAME` is set to `pending-releases/${{ inputs.version }}`, `DOCKER_RC_TAG` is set to `yshavit/mdq:${{ inputs.version }}-rc` and `DOCKER_PUBLISH_TAG` is set to `yshavit/mdq:${{ inputs.version }}`. The workflow has 4 jobs. The job id of the 1st job is `verify`. The job `verify` has 4 steps. The 1st step is named `Get PR Info` and its id is `pr-info`. The 2nd step is named `Validate PR status`. The 3rd step is named `Docker pull`. The 4th step is named `Look for unfinished checkbox items`. The job id of the 2nd job is `docker`. The job `docker` has 4 steps. The 1st step is named `Log in to Docker Hub`. The 2nd step is named `Pull`. The 3rd step is named `Retag`. The 4th step is named `Push`. The job id of the 3rd job is `github`. The job `github` has 12 steps. The 1st step is named `Get PR base ref` and its id is `base-ref`. The 2nd step is named `Checkout repository`. The 3rd step is named `Fetch release branch`. The 4th step is named `Git FF main`. The 5th step is named `Git push`. The 6th step is named `Publish Release`. The 7th step is named `Update Cargo.toml`. The 8th step is named `Configure git`. The 9th step is named `Commit change`. The 10th step is named `Push to branch`. The 11th step is named `Open PR`. The 12th step is named `Push to target ref`. The job id of the 4th job is `crates-io`. The job `crates-io` has 3 steps. The 1st step is named `Checkout repository`. The 2nd step is named `cargo login`. The 3rd step is named `Publish`. ","prompt_level3":"Generate a GitHub Workflow named `Release: (03) Publish` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 2 inputs: version-this input represents the version to release, e.g. \"0.1.2\", the data type is string and it must be supplied; next-version-this input represents the next revision to set. will have \"-dev\" appended, the data type is string and it must be supplied. The workflow sets 5 environment variables to use: `RELEASE_VERSION` is set to `${{ inputs.version }}`, `NEXT_VERSION` is set to `${{ inputs.next-version }}-dev`, `BRANCH_NAME` is set to `pending-releases/${{ inputs.version }}`, `DOCKER_RC_TAG` is set to `yshavit/mdq:${{ inputs.version }}-rc` and `DOCKER_PUBLISH_TAG` is set to `yshavit/mdq:${{ inputs.version }}`. The workflow has 4 jobs. The job id of the 1st job is `verify`. This job will run on ubuntu-latest runner. The job sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. The job `verify` has 4 steps. The 1st step is named `Get PR Info` and its id is `pr-info`. The step sets an environment variable to use: `REPO_NAME` is set to `${{ github.repository }}`. This step runs a script: `set -euo pipefail\npr_json=\"$(gh pr view -R \"$REPO_NAME\" \"$BRANCH_NAME\" --json mergeStateStatus,body,baseRefName)\"\n<<<\"$pr_json\" | jq .\necho \"json=$pr_json\" >> \"$GITHUB_OUTPUT\"\n`. The 2nd step is named `Validate PR status`. The step sets an environment variable to use: `PR_JSON` is set to `${{ steps.pr-info.outputs.json }}`. This step runs a script: `set -euo pipefail\nmerge_status=\"$(<<<\"$PR_JSON\" jq -r .mergeStateStatus)\"\nif [[ \"$merge_status\" != CLEAN ]]; then\n  echo \"::error title=invalid branch state::require CLEAN, saw $merge_status\"\n  exit 1\nfi\n`. The 3rd step is named `Docker pull`. This step runs a script: `docker pull \"$DOCKER_RC_TAG\"`. The 4th step is named `Look for unfinished checkbox items`. The step sets an environment variable to use: `PR_JSON` is set to `${{ steps.pr-info.outputs.json }}`. This step runs a script: `exit_status=0\nwhile read -r line ; do\n  echo \"::error title=unfinished task::$line\"\n  exit_status=1\ndone < <(echo \"$PR_JSON\" | jq -r .body | docker run --rm -i \"$DOCKER_RC_TAG\" -o plain '- [ ]')\nexit \"$exit_status\"\n`. This job has an output: `pr-json` is defined as ${{ steps.pr-info.outputs.json }}. The job id of the 2nd job is `docker`. Before this job runs, `verify` must complete successfully. This job will run on ubuntu-latest runner. This job references Docker Hub environment. The job `docker` has 4 steps. The 1st step is named `Log in to Docker Hub`. This step runs action `docker/login-action` tagged as v3. The step defines 2 input parameters for the action: `username` is set to `${{ vars.DOCKERHUB_USERNAME }}` and `password` is set to `${{ secrets.DOCKERHUB_PAT }}`. The 2nd step is named `Pull`. This step runs a script: `docker pull \"$DOCKER_RC_TAG\"`. The 3rd step is named `Retag`. This step runs a script: `docker tag \"$DOCKER_RC_TAG\" \"$DOCKER_PUBLISH_TAG\"`. The 4th step is named `Push`. This step runs a script: `docker push \"$DOCKER_PUBLISH_TAG\"`. The job id of the 3rd job is `github`. Before this job runs, `verify` and `docker` must complete successfully. This job will run on ubuntu-latest runner. The job `github` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `pull-requests` scope. This permission setting only applies to the job `github`. The job `github` has 12 steps. The 1st step is named `Get PR base ref` and its id is `base-ref`. The step sets an environment variable to use: `PR_JSON` is set to `${{ needs.verify.outputs.pr-json }}`. This step runs a script: `echo \"name=$(echo \"$PR_JSON\" | jq -r .baseRefName)\" >> \"$GITHUB_OUTPUT\"`. The 2nd step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `ref` is set to `${{ steps.base-ref.outputs.name }}`. The 3rd step is named `Fetch release branch`. This step runs a script: `git fetch origin \"$BRANCH_NAME\"`. The 4th step is named `Git FF main`. This step runs a script: `git merge --ff-only \"origin/$BRANCH_NAME\"`. The 5th step is named `Git push`. The step sets an environment variable to use: `TARGET_REF` is set to `${{ steps.base-ref.outputs.name }}`. This step runs a script: `git push origin \"$TARGET_REF\"`. The 6th step is named `Publish Release`. The step sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. This step runs a script: `gh release edit \"v$RELEASE_VERSION\" --draft=false`. The 7th step is named `Update Cargo.toml`. This step runs a script: `set -euo pipefail\nsed -i 's/^version = \".*\"/version = \"${{ env.NEXT_VERSION }}\"/' Cargo.toml\ncargo metadata >/dev/null\n`. The 8th step is named `Configure git`. This step runs a script: `set -euo pipefail\ngit config --global user.name 'github-actions[bot]'\ngit config --global user.email 'github-actions[bot]@users.noreply.github.com'\n`. The 9th step is named `Commit change`. This step runs a script: `git commit -am \"bump version to $NEXT_VERSION\"`. The 10th step is named `Push to branch`. This step runs a script: `set -euo pipefail\ngit checkout -b \"prepare-$NEXT_VERSION\"\ngit push --set-upstream origin \"prepare-$NEXT_VERSION\"\n`. The 11th step is named `Open PR`. The step sets 2 environment variables to use: `TARGET_REF` is set to `${{ steps.base-ref.outputs.name }}` and `GH_TOKEN` is set to `${{ github.token }}`. This step runs a script: `set -euo pipefail\ngh pr create --title \"Bump version to $NEXT_VERSION\" --body \"Created by release-publish.yml\" --base \"$TARGET_REF\"\n`. The 12th step is named `Push to target ref`. The step sets an environment variable to use: `TARGET_REF` is set to `${{ steps.base-ref.outputs.name }}`. This step runs a script: `git checkout -B \"$TARGET_REF\" \"origin/$TARGET_REF\"\ngit merge --ff-only \"prepare-$NEXT_VERSION\"\ngit push\n`. The job id of the 4th job is `crates-io`. Before this job runs, `github` must complete successfully. This job will run on ubuntu-latest runner. This job references crates.io environment. The job `crates-io` has 3 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `ref` is set to `v${{ env.RELEASE_VERSION }}`. The 2nd step is named `cargo login`. The step sets an environment variable to use: `CRATESIO_API_TOKEN` is set to `${{ secrets.CRATESIO_API_TOKEN }}`. This step runs a script: `cargo login <<<\"$CRATESIO_API_TOKEN\"`. The 3rd step is named `Publish`. This step runs a script: `cargo publish`. ","nb_triggers":1,"triggers":["workflow_dispatch"],"nb_jobs":4,"nb_actions":3,"actions":["actions/checkout","actions/checkout","docker/login-action"],"actions_details":[{"version":"v3","name":"docker/login-action"},{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/checkout"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":23,"cyclomatic_complexity":2}
{"id":19904,"repository_id":70442652,"mainLanguage":"Rust","file_name":"cherry-pick-since-release-branch.yml","file_content":"name: PR for release branches\non:\n  pull_request:\n    branches:\n      - main\n    types: [\"closed\", \"labeled\"]\n  workflow_dispatch:\n    inputs:\n      pr_number:\n        description: \"PR number to cherry-pick\"\n        required: true\n        type: number\n      base_version:\n        description: \"Base version to cherry-pick since\"\n        default: \"2.1\"\n        required: true\n        type: string\n\nenv:\n  GH_TOKEN: ${{ github.token }}\n\njobs:\n  get-target-release-branches:\n    if: |\n      (github.event_name == 'pull_request' &&\n       github.event.pull_request.merged &&\n       ((github.event.action == 'labeled' && startsWith(github.event.label.name, 'need-cherry-pick-since')) ||\n       (github.event.action == 'closed' && contains(toJson(github.event.pull_request.labels), 'need-cherry-pick-since')))) ||\n      github.event_name == 'workflow_dispatch'\n    runs-on: ubuntu-latest\n    outputs:\n      branches: ${{ steps.filter-release-branches.outputs.branches }}\n      pr_number: ${{ steps.filter-release-branches.outputs.pr_number }}\n      pr_sha: ${{ steps.filter-release-branches.outputs.pr_sha }}\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0 # Ensures all branches are fetched\n\n      - name: Get all release branches including label version and higher\n        id: filter-release-branches\n        run: |\n          if [[ \"${{ github.event_name }}\" == \"workflow_dispatch\" ]]; then\n            # For manual workflow dispatch\n            base_version=\"${{ github.event.inputs.base_version }}\"\n            pr_number=\"${{ github.event.inputs.pr_number }}\"\n            echo \"Using manually provided base version: $base_version for PR #$pr_number\"\n            # Get the PR merge commit SHA\n            pr_sha=$(gh pr view $pr_number --repo ${{ github.repository }} --json mergeCommit --jq .mergeCommit.oid)\n            echo \"PR merge commit SHA: $pr_sha\"\n            echo \"pr_sha=$pr_sha\" >> \"$GITHUB_OUTPUT\"\n          else\n            # For automatic trigger from PR events\n            if [[ \"${{ github.event.action }}\" == 'labeled' ]]; then\n              label=\"${{ github.event.label.name }}\"\n            else\n              labels='${{ toJson(github.event.pull_request.labels) }}'\n              label=$(echo \"$labels\" | jq -r '.[] | select(.name | contains(\"need-cherry-pick-since\")).name' | sort -V | head -n 1)\n            fi\n            base_version=$(echo \"$label\" | sed 's/need-cherry-pick-since-release-//')\n            pr_number=\"${{ github.event.number }}\"\n          fi\n\n          # Output the PR number for use in downstream jobs\n          echo \"PR number: $pr_number\"\n          echo \"pr_number=$pr_number\" >> \"$GITHUB_OUTPUT\"\n\n          echo \"Base version from label: $base_version\"\n\n          branches=$(git branch -r | grep \"origin/release-\" | sed 's|origin/release-||' | sort -V)\n\n          echo \"Branches: $branches\"\n\n          target_branches=()\n\n          while IFS= read -r version; do\n            version=$(echo \"$version\" | xargs)\n\n            if [[ ! \"$version\" =~ ^[0-9]+(\\.[0-9]+)*$ ]]; then\n              echo \"Skipping non-numeric branch: release-$version\"\n              continue\n            fi\n\n            if [[ -n \"$version\" ]] && [[ \"$version\" == \"$(printf \"%s\\n%s\" \"$base_version\" \"$version\" | sort -V | tail -n1)\" ]]; then\n              target_branches+=(\"release-$version\")\n            fi\n          done <<< \"$branches\"\n\n          if [ ${#target_branches[@]} -eq 0 ]; then\n            echo \"No matching release branches found.\"\n            echo \"branches=[]\" >> \"$GITHUB_OUTPUT\"\n          else\n            echo \"Matching release branches found:\"\n            for branch in \"${target_branches[@]}\"; do\n              echo \"$branch\"\n            done\n            echo \"branches=$(printf '%s\\n' \"${target_branches[@]}\" | jq -R . | jq -s -c .)\" >> \"$GITHUB_OUTPUT\"\n          fi\n\n  release_pull_request:\n    needs: get-target-release-branches\n    if: needs.get-target-release-branches.outputs.branches != '[]'\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        branch: ${{ fromJson(needs.get-target-release-branches.outputs.branches) }}\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n\n      - name: Create PR to branch\n        uses: risingwavelabs/github-action-cherry-pick@master\n        with:\n          # For automatic trigger from PR events, `pr_sha` is unset,\n          # and it will use the triggering SHA (GITHUB_SHA) instead.\n          commit_sha: ${{ needs.get-target-release-branches.outputs.pr_sha || '' }}\n          pr_branch: ${{ matrix.branch }}\n          pr_labels: \"cherry-pick\"\n          pr_body: \"Cherry picking #${{ needs.get-target-release-branches.outputs.pr_number }} onto branch ${{ matrix.branch }}\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n  # This job runs after all cherry-pick attempts and reports the final status\n  report_status:\n    needs: [get-target-release-branches, release_pull_request]\n    if: needs.get-target-release-branches.outputs.branches != '[]'\n    runs-on: ubuntu-latest\n    steps:\n      - name: Report final status\n        uses: actions/github-script@v7\n        with:\n          script: |\n            const jobStatus = '${{ needs.release_pull_request.result }}';\n            const prNumber = ${{ needs.get-target-release-branches.outputs.pr_number }};\n\n            if (jobStatus === 'success') {\n              await github.rest.issues.createComment({\n                owner: context.repo.owner,\n                repo: context.repo.repo,\n                issue_number: prNumber,\n                body: ' Cherry-pick PRs (or issues if encountered conflicts) have been created successfully to all target branches.'\n              });\n            } else if (jobStatus === 'failure') {\n              const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${process.env.GITHUB_RUN_ID}`;\n              await github.rest.issues.createComment({\n                owner: context.repo.owner,\n                repo: context.repo.repo,\n                issue_number: prNumber,\n                body: ` Cherry-pick failed for one or more branches. Please check the [workflow run logs](${runUrl}) and consider retrying or manually cherry-picking.`\n              });\n            }\n\npermissions:\n  issues: write\n  pull-requests: write\n  contents: write\n  actions: write\n","repository_owner":"risingwavelabs","repository_name":"risingwave","tokens_count":1466,"workflow":"name: PR for release branches\non:\n  pull_request:\n    branches:\n    - main\n    types: [closed, labeled]\n  workflow_dispatch:\n    inputs:\n      pr_number:\n        description: PR number to cherry-pick\n        required: true\n        type: number\n      base_version:\n        description: Base version to cherry-pick since\n        default: '2.1'\n        required: true\n        type: string\n\nenv:\n  GH_TOKEN: ${{ github.token }}\n\njobs:\n  get-target-release-branches:\n    if: |\n      (github.event_name == 'pull_request' &&\n       github.event.pull_request.merged &&\n       ((github.event.action == 'labeled' && startsWith(github.event.label.name, 'need-cherry-pick-since')) ||\n       (github.event.action == 'closed' && contains(toJson(github.event.pull_request.labels), 'need-cherry-pick-since')))) ||\n      github.event_name == 'workflow_dispatch'\n    runs-on: ubuntu-latest\n    outputs:\n      branches: ${{ steps.filter-release-branches.outputs.branches }}\n      pr_number: ${{ steps.filter-release-branches.outputs.pr_number }}\n      pr_sha: ${{ steps.filter-release-branches.outputs.pr_sha }}\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      with:\n        fetch-depth: 0   # Ensures all branches are fetched\n\n    - name: Get all release branches including label version and higher\n      id: filter-release-branches\n      run: |\n        if [[ \"${{ github.event_name }}\" == \"workflow_dispatch\" ]]; then\n          # For manual workflow dispatch\n          base_version=\"${{ github.event.inputs.base_version }}\"\n          pr_number=\"${{ github.event.inputs.pr_number }}\"\n          echo \"Using manually provided base version: $base_version for PR #$pr_number\"\n          # Get the PR merge commit SHA\n          pr_sha=$(gh pr view $pr_number --repo ${{ github.repository }} --json mergeCommit --jq .mergeCommit.oid)\n          echo \"PR merge commit SHA: $pr_sha\"\n          echo \"pr_sha=$pr_sha\" >> \"$GITHUB_OUTPUT\"\n        else\n          # For automatic trigger from PR events\n          if [[ \"${{ github.event.action }}\" == 'labeled' ]]; then\n            label=\"${{ github.event.label.name }}\"\n          else\n            labels='${{ toJson(github.event.pull_request.labels) }}'\n            label=$(echo \"$labels\" | jq -r '.[] | select(.name | contains(\"need-cherry-pick-since\")).name' | sort -V | head -n 1)\n          fi\n          base_version=$(echo \"$label\" | sed 's/need-cherry-pick-since-release-//')\n          pr_number=\"${{ github.event.number }}\"\n        fi\n\n        # Output the PR number for use in downstream jobs\n        echo \"PR number: $pr_number\"\n        echo \"pr_number=$pr_number\" >> \"$GITHUB_OUTPUT\"\n\n        echo \"Base version from label: $base_version\"\n\n        branches=$(git branch -r | grep \"origin/release-\" | sed 's|origin/release-||' | sort -V)\n\n        echo \"Branches: $branches\"\n\n        target_branches=()\n\n        while IFS= read -r version; do\n          version=$(echo \"$version\" | xargs)\n\n          if [[ ! \"$version\" =~ ^[0-9]+(\\.[0-9]+)*$ ]]; then\n            echo \"Skipping non-numeric branch: release-$version\"\n            continue\n          fi\n\n          if [[ -n \"$version\" ]] && [[ \"$version\" == \"$(printf \"%s\\n%s\" \"$base_version\" \"$version\" | sort -V | tail -n1)\" ]]; then\n            target_branches+=(\"release-$version\")\n          fi\n        done <<< \"$branches\"\n\n        if [ ${#target_branches[@]} -eq 0 ]; then\n          echo \"No matching release branches found.\"\n          echo \"branches=[]\" >> \"$GITHUB_OUTPUT\"\n        else\n          echo \"Matching release branches found:\"\n          for branch in \"${target_branches[@]}\"; do\n            echo \"$branch\"\n          done\n          echo \"branches=$(printf '%s\\n' \"${target_branches[@]}\" | jq -R . | jq -s -c .)\" >> \"$GITHUB_OUTPUT\"\n        fi\n\n  release_pull_request:\n    needs: get-target-release-branches\n    if: needs.get-target-release-branches.outputs.branches != '[]'\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        branch: ${{ fromJson(needs.get-target-release-branches.outputs.branches)\n          }}\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Create PR to branch\n      uses: risingwavelabs/github-action-cherry-pick@master\n      with:\n          # For automatic trigger from PR events, `pr_sha` is unset,\n          # and it will use the triggering SHA (GITHUB_SHA) instead.\n        commit_sha: ${{ needs.get-target-release-branches.outputs.pr_sha || '' \n          }}\n        pr_branch: ${{ matrix.branch }}\n        pr_labels: cherry-pick\n        pr_body: 'Cherry picking #${{ needs.get-target-release-branches.outputs.pr_number\n          }} onto branch ${{ matrix.branch }}'\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n  # This job runs after all cherry-pick attempts and reports the final status\n  report_status:\n    needs: [get-target-release-branches, release_pull_request]\n    if: needs.get-target-release-branches.outputs.branches != '[]'\n    runs-on: ubuntu-latest\n    steps:\n    - name: Report final status\n      uses: actions/github-script@v7\n      with:\n        script: |\n          const jobStatus = '${{ needs.release_pull_request.result }}';\n          const prNumber = ${{ needs.get-target-release-branches.outputs.pr_number }};\n\n          if (jobStatus === 'success') {\n            await github.rest.issues.createComment({\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              issue_number: prNumber,\n              body: ' Cherry-pick PRs (or issues if encountered conflicts) have been created successfully to all target branches.'\n            });\n          } else if (jobStatus === 'failure') {\n            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${process.env.GITHUB_RUN_ID}`;\n            await github.rest.issues.createComment({\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              issue_number: prNumber,\n              body: ` Cherry-pick failed for one or more branches. Please check the [workflow run logs](${runUrl}) and consider retrying or manually cherry-picking.`\n            });\n          }\n\npermissions:\n  issues: write\n  pull-requests: write\n  contents: write\n  actions: write\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `PR for release branches` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by multiple events: 1) a pull request is closed or a label is added to a pull request. The workflow would run whenever there is a pull_request event targeting: a branch named main. 2) someone manually triggers the workflow. This workflow receives 2 inputs: pr_number-this input represents pr number to cherry-pick, it must be supplied and the data type is number; base_version-this input represents base version to cherry-pick since, its default value is 2.1, it must be supplied and the data type is string. The workflow modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `issues` scope, write access is granted to the GITHUB_TOKEN in the `pull-requests` scope, write access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `actions` scope. This permission setting applies to all jobs in the workflow. The workflow sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. The workflow has 3 jobs. The job id of the 1st job is `get-target-release-branches`. The job id of the 2nd job is `release_pull_request`. The job id of the 3rd job is `report_status`. ","prompt_level2":"Generate a GitHub Workflow named `PR for release branches` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by multiple events: 1) a pull request is closed or a label is added to a pull request. The workflow would run whenever there is a pull_request event targeting: a branch named main. 2) someone manually triggers the workflow. This workflow receives 2 inputs: pr_number-this input represents pr number to cherry-pick, it must be supplied and the data type is number; base_version-this input represents base version to cherry-pick since, its default value is 2.1, it must be supplied and the data type is string. The workflow modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `issues` scope, write access is granted to the GITHUB_TOKEN in the `pull-requests` scope, write access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `actions` scope. This permission setting applies to all jobs in the workflow. The workflow sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. The workflow has 3 jobs. The job id of the 1st job is `get-target-release-branches`. The job `get-target-release-branches` has 2 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Get all release branches including label version and higher` and its id is `filter-release-branches`. The job id of the 2nd job is `release_pull_request`. The job `release_pull_request` has 2 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Create PR to branch`. The job id of the 3rd job is `report_status`. The job `report_status` has one step. The 1st step is named `Report final status`. ","prompt_level3":"Generate a GitHub Workflow named `PR for release branches` for a GitHub repository whose primary programming language is Rust. This workflow will be triggered by multiple events: 1) a pull request is closed or a label is added to a pull request. The workflow would run whenever there is a pull_request event targeting: a branch named main. 2) someone manually triggers the workflow. This workflow receives 2 inputs: pr_number-this input represents pr number to cherry-pick, it must be supplied and the data type is number; base_version-this input represents base version to cherry-pick since, its default value is 2.1, it must be supplied and the data type is string. The workflow modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `issues` scope, write access is granted to the GITHUB_TOKEN in the `pull-requests` scope, write access is granted to the GITHUB_TOKEN in the `contents` scope and write access is granted to the GITHUB_TOKEN in the `actions` scope. This permission setting applies to all jobs in the workflow. The workflow sets an environment variable to use: `GH_TOKEN` is set to `${{ github.token }}`. The workflow has 3 jobs. The job id of the 1st job is `get-target-release-branches`. This job will run only if the condition((github.event_name == 'pull_request' &&\n github.event.pull_request.merged &&\n ((github.event.action == 'labeled' && startsWith(github.event.label.name, 'need-cherry-pick-since')) ||\n (github.event.action == 'closed' && contains(toJson(github.event.pull_request.labels), 'need-cherry-pick-since')))) ||\ngithub.event_name == 'workflow_dispatch'\n) is met. This job will run on ubuntu-latest runner. The job `get-target-release-branches` has 2 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The step defines an input parameter for the action: `fetch-depth` is set to `0`. The 2nd step is named `Get all release branches including label version and higher` and its id is `filter-release-branches`. This step runs a script: `if [[ \"${{ github.event_name }}\" == \"workflow_dispatch\" ]]; then\n  # For manual workflow dispatch\n  base_version=\"${{ github.event.inputs.base_version }}\"\n  pr_number=\"${{ github.event.inputs.pr_number }}\"\n  echo \"Using manually provided base version: $base_version for PR #$pr_number\"\n  # Get the PR merge commit SHA\n  pr_sha=$(gh pr view $pr_number --repo ${{ github.repository }} --json mergeCommit --jq .mergeCommit.oid)\n  echo \"PR merge commit SHA: $pr_sha\"\n  echo \"pr_sha=$pr_sha\" >> \"$GITHUB_OUTPUT\"\nelse\n  # For automatic trigger from PR events\n  if [[ \"${{ github.event.action }}\" == 'labeled' ]]; then\n    label=\"${{ github.event.label.name }}\"\n  else\n    labels='${{ toJson(github.event.pull_request.labels) }}'\n    label=$(echo \"$labels\" | jq -r '.[] | select(.name | contains(\"need-cherry-pick-since\")).name' | sort -V | head -n 1)\n  fi\n  base_version=$(echo \"$label\" | sed 's/need-cherry-pick-since-release-//')\n  pr_number=\"${{ github.event.number }}\"\nfi\n\n# Output the PR number for use in downstream jobs\necho \"PR number: $pr_number\"\necho \"pr_number=$pr_number\" >> \"$GITHUB_OUTPUT\"\n\necho \"Base version from label: $base_version\"\n\nbranches=$(git branch -r | grep \"origin/release-\" | sed 's|origin/release-||' | sort -V)\n\necho \"Branches: $branches\"\n\ntarget_branches=()\n\nwhile IFS= read -r version; do\n  version=$(echo \"$version\" | xargs)\n\n  if [[ ! \"$version\" =~ ^[0-9]+(\\.[0-9]+)*$ ]]; then\n    echo \"Skipping non-numeric branch: release-$version\"\n    continue\n  fi\n\n  if [[ -n \"$version\" ]] && [[ \"$version\" == \"$(printf \"%s\\n%s\" \"$base_version\" \"$version\" | sort -V | tail -n1)\" ]]; then\n    target_branches+=(\"release-$version\")\n  fi\ndone <<< \"$branches\"\n\nif [ ${#target_branches[@]} -eq 0 ]; then\n  echo \"No matching release branches found.\"\n  echo \"branches=[]\" >> \"$GITHUB_OUTPUT\"\nelse\n  echo \"Matching release branches found:\"\n  for branch in \"${target_branches[@]}\"; do\n    echo \"$branch\"\n  done\n  echo \"branches=$(printf '%s\\n' \"${target_branches[@]}\" | jq -R . | jq -s -c .)\" >> \"$GITHUB_OUTPUT\"\nfi\n`. This job has 3 outputs: `branches` is defined as ${{ steps.filter-release-branches.outputs.branches }}, `pr_number` is defined as ${{ steps.filter-release-branches.outputs.pr_number }} and `pr_sha` is defined as ${{ steps.filter-release-branches.outputs.pr_sha }}. The job id of the 2nd job is `release_pull_request`. Before this job runs, `get-target-release-branches` must complete successfully. This job will run only if the condition(needs.get-target-release-branches.outputs.branches != '[]') is met. This job will run on ubuntu-latest runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `branch` has 67 values: $, {, {,  , f, r, o, m, J, s, o, n, (, n, e, e, d, s, ., g, e, t, -, t, a, r, g, e, t, -, r, e, l, e, a, s, e, -, b, r, a, n, c, h, e, s, ., o, u, t, p, u, t, s, ., b, r, a, n, c, h, e, s, ),  , } and }. The job `release_pull_request` has 2 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Create PR to branch`. The step sets an environment variable to use: `GITHUB_TOKEN` is set to `${{ secrets.GITHUB_TOKEN }}`. This step runs action `risingwavelabs/github-action-cherry-pick` from the master branch. The step defines 4 input parameters for the action: `commit_sha` is set to `${{ needs.get-target-release-branches.outputs.pr_sha || '' }}`, `pr_branch` is set to `${{ matrix.branch }}`, `pr_labels` is set to `cherry-pick` and `pr_body` is set to `Cherry picking #${{ needs.get-target-release-branches.outputs.pr_number }} onto branch ${{ matrix.branch }}`. The job id of the 3rd job is `report_status`. Before this job runs, `get-target-release-branches` and `release_pull_request` must complete successfully. This job will run only if the condition(needs.get-target-release-branches.outputs.branches != '[]') is met. This job will run on ubuntu-latest runner. The job `report_status` has one step. The 1st step is named `Report final status`. This step runs action `actions/github-script` tagged as v7. The step defines an input parameter for the action: `script` is set to `const jobStatus = '${{ needs.release_pull_request.result }}';\nconst prNumber = ${{ needs.get-target-release-branches.outputs.pr_number }};\n\nif (jobStatus === 'success') {\n  await github.rest.issues.createComment({\n    owner: context.repo.owner,\n    repo: context.repo.repo,\n    issue_number: prNumber,\n    body: ' Cherry-pick PRs (or issues if encountered conflicts) have been created successfully to all target branches.'\n  });\n} else if (jobStatus === 'failure') {\n  const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${process.env.GITHUB_RUN_ID}`;\n  await github.rest.issues.createComment({\n    owner: context.repo.owner,\n    repo: context.repo.repo,\n    issue_number: prNumber,\n    body: ` Cherry-pick failed for one or more branches. Please check the [workflow run logs](${runUrl}) and consider retrying or manually cherry-picking.`\n  });\n}\n`. ","nb_triggers":2,"triggers":["pull_request","workflow_dispatch"],"nb_jobs":3,"nb_actions":4,"actions":["actions/checkout","actions/checkout","actions/github-script","risingwavelabs/github-action-cherry-pick"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v4","name":"actions/checkout"},{"version":"master","name":"risingwavelabs/github-action-cherry-pick"},{"version":"v7","name":"actions/github-script"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":5,"cyclomatic_complexity":2}
{"id":15113,"repository_id":3981483,"mainLanguage":"C#","file_name":"labeler-predict-issues.yml","file_content":"# Predict labels for Issues using a trained model\nname: \"Labeler: Predict (Issues)\"\n\non:\n  # Only automatically predict area labels when issues are first opened\n  issues:\n    types: opened\n\n  # Allow dispatching the workflow via the Actions UI, specifying ranges of numbers\n  workflow_dispatch:\n    inputs:\n      issues:\n        description: \"Issue Numbers (comma-separated list of ranges).\"\n        required: true\n      cache_key:\n        description: \"The cache key suffix to use for restoring the model. Defaults to 'ACTIVE'.\"\n        required: true\n        default: \"ACTIVE\"\n\nenv:\n  # Do not allow failure for jobs triggered automatically (as this causes red noise on the workflows list)\n  ALLOW_FAILURE: ${{ github.event_name == 'workflow_dispatch' }}\n\n  LABEL_PREFIX: \"area-\"\n  THRESHOLD: 0.40\n  DEFAULT_LABEL: \"needs-area-label\"\n\njobs:\n  predict-issue-label:\n    # Do not automatically run the workflow on forks outside the 'dotnet' org\n    if: ${{ github.event_name == 'workflow_dispatch' || github.repository_owner == 'dotnet' }}\n    runs-on: ubuntu-latest\n    permissions:\n      issues: write\n    steps:\n      - name: \"Restore issues model from cache\"\n        id: restore-model\n        uses: dotnet/issue-labeler/restore@46125e85e6a568dc712f358c39f35317366f5eed # v2.0.0\n        with:\n          type: issues\n          fail-on-cache-miss: ${{ env.ALLOW_FAILURE }}\n          quiet: true\n\n      - name: \"Predict issue labels\"\n        id: prediction\n        if: ${{ steps.restore-model.outputs.cache-hit == 'true' }}\n        uses: dotnet/issue-labeler/predict@46125e85e6a568dc712f358c39f35317366f5eed # v2.0.0\n        with:\n          issues: ${{ inputs.issues || github.event.issue.number }}\n          label_prefix: ${{ env.LABEL_PREFIX }}\n          threshold: ${{ env.THRESHOLD }}\n          default_label: ${{ env.DEFAULT_LABEL }}\n        env:\n          GITHUB_TOKEN: ${{ github.token }}\n        continue-on-error: ${{ !env.ALLOW_FAILURE }}\n","repository_owner":"dotnet","repository_name":"extensions","tokens_count":520,"workflow":"# Predict labels for Issues using a trained model\nname: 'Labeler: Predict (Issues)'\n\non:\n  # Only automatically predict area labels when issues are first opened\n  issues:\n    types: opened\n\n  # Allow dispatching the workflow via the Actions UI, specifying ranges of numbers\n  workflow_dispatch:\n    inputs:\n      issues:\n        description: Issue Numbers (comma-separated list of ranges).\n        required: true\n      cache_key:\n        description: The cache key suffix to use for restoring the model. \n          Defaults to 'ACTIVE'.\n        required: true\n        default: ACTIVE\n\nenv:\n  # Do not allow failure for jobs triggered automatically (as this causes red noise on the workflows list)\n  ALLOW_FAILURE: ${{ github.event_name == 'workflow_dispatch' }}\n\n  LABEL_PREFIX: area-\n  THRESHOLD: 0.40\n  DEFAULT_LABEL: needs-area-label\n\njobs:\n  predict-issue-label:\n    # Do not automatically run the workflow on forks outside the 'dotnet' org\n    if: ${{ github.event_name == 'workflow_dispatch' || github.repository_owner \n      == 'dotnet' }}\n    runs-on: ubuntu-latest\n    permissions:\n      issues: write\n    steps:\n    - name: Restore issues model from cache\n      id: restore-model\n      uses: \n        dotnet/issue-labeler/restore@46125e85e6a568dc712f358c39f35317366f5eed       # v2.0.0\n      with:\n        type: issues\n        fail-on-cache-miss: ${{ env.ALLOW_FAILURE }}\n        quiet: true\n\n    - name: Predict issue labels\n      id: prediction\n      if: ${{ steps.restore-model.outputs.cache-hit == 'true' }}\n      uses: \n        dotnet/issue-labeler/predict@46125e85e6a568dc712f358c39f35317366f5eed       # v2.0.0\n      with:\n        issues: ${{ inputs.issues || github.event.issue.number }}\n        label_prefix: ${{ env.LABEL_PREFIX }}\n        threshold: ${{ env.THRESHOLD }}\n        default_label: ${{ env.DEFAULT_LABEL }}\n      env:\n        GITHUB_TOKEN: ${{ github.token }}\n      continue-on-error: ${{ !env.ALLOW_FAILURE }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Labeler: Predict (Issues)` for a GitHub repository whose primary programming language is C#. This workflow will be triggered by multiple events: 1) an issue is opened. 2) someone manually triggers the workflow. This workflow receives 2 inputs: issues-this input represents issue numbers (comma-separated list of ranges). and it must be supplied; cache_key-this input represents the cache key suffix to use for restoring the model. defaults to 'active'., it must be supplied and its default value is ACTIVE. The workflow sets 4 environment variables to use: `ALLOW_FAILURE` is set to `${{ github.event_name == 'workflow_dispatch' }}`, `LABEL_PREFIX` is set to `area-`, `THRESHOLD` is set to `0.4` and `DEFAULT_LABEL` is set to `needs-area-label`. The workflow has one job. The job id of the 1st job is `predict-issue-label`. ","prompt_level2":"Generate a GitHub Workflow named `Labeler: Predict (Issues)` for a GitHub repository whose primary programming language is C#. This workflow will be triggered by multiple events: 1) an issue is opened. 2) someone manually triggers the workflow. This workflow receives 2 inputs: issues-this input represents issue numbers (comma-separated list of ranges). and it must be supplied; cache_key-this input represents the cache key suffix to use for restoring the model. defaults to 'active'., it must be supplied and its default value is ACTIVE. The workflow sets 4 environment variables to use: `ALLOW_FAILURE` is set to `${{ github.event_name == 'workflow_dispatch' }}`, `LABEL_PREFIX` is set to `area-`, `THRESHOLD` is set to `0.4` and `DEFAULT_LABEL` is set to `needs-area-label`. The workflow has one job. The job id of the 1st job is `predict-issue-label`. The job `predict-issue-label` has 2 steps. The 1st step is named `Restore issues model from cache` and its id is `restore-model`. The 2nd step is named `Predict issue labels` and its id is `prediction`. ","prompt_level3":"Generate a GitHub Workflow named `Labeler: Predict (Issues)` for a GitHub repository whose primary programming language is C#. This workflow will be triggered by multiple events: 1) an issue is opened. 2) someone manually triggers the workflow. This workflow receives 2 inputs: issues-this input represents issue numbers (comma-separated list of ranges). and it must be supplied; cache_key-this input represents the cache key suffix to use for restoring the model. defaults to 'active'., it must be supplied and its default value is ACTIVE. The workflow sets 4 environment variables to use: `ALLOW_FAILURE` is set to `${{ github.event_name == 'workflow_dispatch' }}`, `LABEL_PREFIX` is set to `area-`, `THRESHOLD` is set to `0.4` and `DEFAULT_LABEL` is set to `needs-area-label`. The workflow has one job. The job id of the 1st job is `predict-issue-label`. This job will run only if the condition(${{ github.event_name == 'workflow_dispatch' || github.repository_owner == 'dotnet' }}) is met. This job will run on ubuntu-latest runner. The job `predict-issue-label` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `issues` scope. This permission setting only applies to the job `predict-issue-label`. The job `predict-issue-label` has 2 steps. The 1st step is named `Restore issues model from cache` and its id is `restore-model`. This step runs action `dotnet/issue-labeler/restore` whose commit is 46125e85e6a568dc712f358c39f35317366f5eed. The step defines 3 input parameters for the action: `type` is set to `issues`, `fail-on-cache-miss` is set to `${{ env.ALLOW_FAILURE }}` and `quiet` is set to `True`. The 2nd step is named `Predict issue labels` and its id is `prediction`. This step will run only if the condition(${{ steps.restore-model.outputs.cache-hit == 'true' }}) is met. The step sets an environment variable to use: `GITHUB_TOKEN` is set to `${{ github.token }}`. This step runs action `dotnet/issue-labeler/predict` whose commit is 46125e85e6a568dc712f358c39f35317366f5eed. The step defines 4 input parameters for the action: `issues` is set to `${{ inputs.issues || github.event.issue.number }}`, `label_prefix` is set to `${{ env.LABEL_PREFIX }}`, `threshold` is set to `${{ env.THRESHOLD }}` and `default_label` is set to `${{ env.DEFAULT_LABEL }}`. When this step fails, the job will move on to the next step. ","nb_triggers":2,"triggers":["issues","workflow_dispatch"],"nb_jobs":1,"nb_actions":2,"actions":["dotnet/issue-labeler/predict","dotnet/issue-labeler/restore"],"actions_details":[{"version":"46125e85e6a568dc712f358c39f35317366f5eed","name":"dotnet/issue-labeler/restore"},{"version":"46125e85e6a568dc712f358c39f35317366f5eed","name":"dotnet/issue-labeler/predict"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":2,"cyclomatic_complexity":1}
{"id":53887,"repository_id":3895691,"mainLanguage":"C++","file_name":"yamllint.yml","file_content":"---\nname: run yamllint on files\n\n\"on\":\n  push:\n    branches:\n      - main\n      - devel\n  pull_request:\n\n\njobs:\n  build:\n    name: Runs the yamllint on files\n    runs-on: ubuntu-24.04\n\n    steps:\n      - name: checkout\n        uses: actions/checkout@v4\n      - name: install packages\n        run: sudo apt install python3\n      - name: install yamllint\n        run: python3 -m venv .venv && .venv/bin/python3 -m pip install yamllint\n      - name: run yamllint\n        run: ./do_yamllint.sh\n","repository_owner":"pauldreik","repository_name":"rdfind","tokens_count":155,"workflow":"name: run yamllint on files\n\non:\n  push:\n    branches:\n    - main\n    - devel\n  pull_request:\n\n\njobs:\n  build:\n    name: Runs the yamllint on files\n    runs-on: ubuntu-24.04\n\n    steps:\n    - name: checkout\n      uses: actions/checkout@v4\n    - name: install packages\n      run: sudo apt install python3\n    - name: install yamllint\n      run: python3 -m venv .venv && .venv/bin/python3 -m pip install yamllint\n    - name: run yamllint\n      run: ./do_yamllint.sh\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `run yamllint on files` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main or a branch named devel. 2) there is activity relating to a pull request. The workflow has one job. The 1st job is named `Runs the yamllint on files` and its job id is `build`. ","prompt_level2":"Generate a GitHub Workflow named `run yamllint on files` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main or a branch named devel. 2) there is activity relating to a pull request. The workflow has one job. The 1st job is named `Runs the yamllint on files` and its job id is `build`. The job `build` has 4 steps. The 1st step is named `Checkout repository`. The 2nd step is named `install packages`. The 3rd step is named `install yamllint`. The 4th step is named `run yamllint`. ","prompt_level3":"Generate a GitHub Workflow named `run yamllint on files` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main or a branch named devel. 2) there is activity relating to a pull request. The workflow has one job. The 1st job is named `Runs the yamllint on files` and its job id is `build`. This job will run on ubuntu-24.04 runner. The job `build` has 4 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `install packages`. This step runs a script: `sudo apt install python3`. The 3rd step is named `install yamllint`. This step runs a script: `python3 -m venv .venv && .venv/bin/python3 -m pip install yamllint`. The 4th step is named `run yamllint`. This step runs a script: `./do_yamllint.sh`. ","nb_triggers":2,"triggers":["pull_request","push"],"nb_jobs":1,"nb_actions":1,"actions":["actions/checkout"],"actions_details":[{"version":"v4","name":"actions/checkout"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":4,"cyclomatic_complexity":1}
{"id":45839,"repository_id":18236569,"mainLanguage":"Go","file_name":"coverage-report.yml","file_content":"name: \"coverage-report\"\n\non:\n  push:\n    branches:\n      - main\n      - release**\n    paths:\n      - '**/coverage-report.yml'\n  pull_request:\n    branches:\n      - main\n      - release**\n    paths:\n      - '**/coverage-report.yml'\n\n  workflow_dispatch:\n    inputs:\n      debug:\n        type: boolean\n        description: \"Run the build with tmate debugging enabled\"\n        required: false\n        default: false\n      last_date:\n        type: string\n        description: \"last date of coverage data\"\n        required: false\n        default: \"\"\n  schedule:\n    - cron:  '0 23 * * *'\n    \njobs:\n  coverage-report:\n    strategy:\n      fail-fast: false\n      matrix:\n        branch: ['main']\n        test: ['ut', 'it', 'all']\n          \n    timeout-minutes: 60\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout\n        timeout-minutes: 1\n        uses: actions/checkout@v3\n        with:\n          fetch-depth: 1\n\n      - name: mount coverage dir for cleanup\n        if: ${{ matrix.test == 'all' }}\n        timeout-minutes: 5\n        uses: ./.github/actions/mount-coverage-dir\n        with:\n          mount_point: /ci-coverage\n          subdir: juicefs/\n          access_key: ${{ secrets.CI_COVERAGE_AWS_AK }}\n          secret_key: ${{ secrets.CI_COVERAGE_AWS_SK }}\n          token: ${{ secrets.CI_COVERAGE_AWS_TOKEN }}\n\n      - name: clean up old coverage data\n        if: ${{ matrix.test == 'all' }}\n        continue-on-error: true\n        timeout-minutes: 10\n        run: |\n          sudo find /ci-coverage -type f \\( -name 'covcounters*' -o -name 'covmeta*' \\) -mtime +2 -print -exec rm -f {} +\n          umount /jfs-coverage\n\n      - name: mount coverage dir\n        timeout-minutes: 5\n        uses: ./.github/actions/mount-coverage-dir\n        with:\n          mount_point: schedule\n          subdir: juicefs/schedule\n          access_key: ${{ secrets.CI_COVERAGE_AWS_AK }}\n          secret_key: ${{ secrets.CI_COVERAGE_AWS_SK }}\n          token: ${{ secrets.CI_COVERAGE_AWS_TOKEN }}\n      \n      - name: Determine lastdate dir\n        timeout-minutes: 120\n        run: |\n          if [[ -n \"${{github.event.inputs.last_date}}\" ]]; then\n            last_date=${{github.event.inputs.last_date}}\n          else\n            last_date=$(ls -t schedule | head -n 1)\n            [[ -z \"$last_date\" ]] && echo \"no data found in schedule\" && exit 1\n          fi\n          [[ ! -d \"schedule/$last_date\" ]] && echo \"schedule/$last_date not found\" && exit 1\n          echo \"last_date=$last_date\" >> $GITHUB_ENV\n\n      - name: Generate today's coverage report\n        timeout-minutes: 30\n        working-directory: schedule/${{env.last_date}}\n        run: |\n          echo \"current dir is $(pwd)\"\n          coverdirs=\"\"\n          for dir in $(find . -mindepth 1 -maxdepth 1 -type d -exec basename {} \\;); do\n              if [[ ${{matrix.test}} == \"ut\" ]]; then\n                if [[ \"$dir\" == \"unittests\" ]]; then\n                  coverdirs+=\"$dir,\"\n                fi\n              elif [[ ${{matrix.test}} == \"it\" ]]; then\n                if [[ \"$dir\" != \"unittests\" ]]; then\n                  coverdirs+=\"$dir,\"\n                fi\n              elif [[ ${{matrix.test}} == \"all\" ]]; then\n                coverdirs+=\"$dir,\"\n              fi\n          done\n          coverdirs=${coverdirs%,}\n          echo coverdirs is $coverdirs\n          [[ -z \"$coverdirs\" ]] && echo \"no coverage dir found\" && exit 0\n          name=cover_${{matrix.test}}\n          sudo go tool covdata percent -i=$coverdirs | sudo tee ${name}.percent\n          echo \"generated coverage percent report:\" $(realpath ${name}.percent)\n          sudo go tool covdata textfmt -i=$coverdirs -o ${name}.txt \n          echo \"generated coverage report in text format:\" $(realpath ${name}.txt)\n          sudo go tool cover -html=${name}.txt -o ${name}.html\n          echo \"generated coverage report in html format:\" $(realpath ${name}.html)\n          ls -l cover_*\n          \n      - name: upload coverage report\n        working-directory: schedule/${{env.last_date}}\n        timeout-minutes: 10\n        run: |\n          echo \"current dir is $(pwd)\"\n          [[ ! -f \"cover_${{matrix.test}}.html\" ]] && echo \"no coverage report found\" && exit 0\n          UPLOAD_PATH=${{github.workflow}}_${{github.run_id}}_${{matrix.test}}.html\n          response=$(curl -w '%{http_code}' -s -o /dev/null --form 'file=@cover_${{matrix.test}}.html' https://juicefs.com/upload-file-u80sdvuke/${UPLOAD_PATH}?token=${{secrets.CI_COVERAGE_FILE_UPLOAD_AUTH_TOKEN}})\n          if [ \"$response\" -eq 200 ]; then\n            echo Coverage Report for ${{matrix.test}}: https://i.juicefs.io/ci-coverage/${UPLOAD_PATH}\n          else\n            echo \"Upload failed with status code $response\"\n            exit 1\n          fi\n  \n      - name: Setup upterm session\n        if: failure() && (github.event.inputs.debug == 'true' || github.run_attempt != 1)\n        # if: failure()\n        timeout-minutes: 30\n        uses: lhotari/action-upterm@v1\n","repository_owner":"juicedata","repository_name":"juicefs","tokens_count":1293,"workflow":"name: coverage-report\n\non:\n  push:\n    branches:\n    - main\n    - release**\n    paths:\n    - '**/coverage-report.yml'\n  pull_request:\n    branches:\n    - main\n    - release**\n    paths:\n    - '**/coverage-report.yml'\n\n  workflow_dispatch:\n    inputs:\n      debug:\n        type: boolean\n        description: Run the build with tmate debugging enabled\n        required: false\n        default: false\n      last_date:\n        type: string\n        description: last date of coverage data\n        required: false\n        default: ''\n  schedule:\n  - cron: 0 23 * * *\njobs:\n  coverage-report:\n    strategy:\n      fail-fast: false\n      matrix:\n        branch: [main]\n        test: [ut, it, all]\n    timeout-minutes: 60\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Checkout\n      timeout-minutes: 1\n      uses: actions/checkout@v3\n      with:\n        fetch-depth: 1\n\n    - name: mount coverage dir for cleanup\n      if: ${{ matrix.test == 'all' }}\n      timeout-minutes: 5\n      uses: ./.github/actions/mount-coverage-dir\n      with:\n        mount_point: /ci-coverage\n        subdir: juicefs/\n        access_key: ${{ secrets.CI_COVERAGE_AWS_AK }}\n        secret_key: ${{ secrets.CI_COVERAGE_AWS_SK }}\n        token: ${{ secrets.CI_COVERAGE_AWS_TOKEN }}\n\n    - name: clean up old coverage data\n      if: ${{ matrix.test == 'all' }}\n      continue-on-error: true\n      timeout-minutes: 10\n      run: |\n        sudo find /ci-coverage -type f \\( -name 'covcounters*' -o -name 'covmeta*' \\) -mtime +2 -print -exec rm -f {} +\n        umount /jfs-coverage\n\n    - name: mount coverage dir\n      timeout-minutes: 5\n      uses: ./.github/actions/mount-coverage-dir\n      with:\n        mount_point: schedule\n        subdir: juicefs/schedule\n        access_key: ${{ secrets.CI_COVERAGE_AWS_AK }}\n        secret_key: ${{ secrets.CI_COVERAGE_AWS_SK }}\n        token: ${{ secrets.CI_COVERAGE_AWS_TOKEN }}\n\n    - name: Determine lastdate dir\n      timeout-minutes: 120\n      run: |\n        if [[ -n \"${{github.event.inputs.last_date}}\" ]]; then\n          last_date=${{github.event.inputs.last_date}}\n        else\n          last_date=$(ls -t schedule | head -n 1)\n          [[ -z \"$last_date\" ]] && echo \"no data found in schedule\" && exit 1\n        fi\n        [[ ! -d \"schedule/$last_date\" ]] && echo \"schedule/$last_date not found\" && exit 1\n        echo \"last_date=$last_date\" >> $GITHUB_ENV\n\n    - name: Generate today's coverage report\n      timeout-minutes: 30\n      working-directory: schedule/${{env.last_date}}\n      run: |\n        echo \"current dir is $(pwd)\"\n        coverdirs=\"\"\n        for dir in $(find . -mindepth 1 -maxdepth 1 -type d -exec basename {} \\;); do\n            if [[ ${{matrix.test}} == \"ut\" ]]; then\n              if [[ \"$dir\" == \"unittests\" ]]; then\n                coverdirs+=\"$dir,\"\n              fi\n            elif [[ ${{matrix.test}} == \"it\" ]]; then\n              if [[ \"$dir\" != \"unittests\" ]]; then\n                coverdirs+=\"$dir,\"\n              fi\n            elif [[ ${{matrix.test}} == \"all\" ]]; then\n              coverdirs+=\"$dir,\"\n            fi\n        done\n        coverdirs=${coverdirs%,}\n        echo coverdirs is $coverdirs\n        [[ -z \"$coverdirs\" ]] && echo \"no coverage dir found\" && exit 0\n        name=cover_${{matrix.test}}\n        sudo go tool covdata percent -i=$coverdirs | sudo tee ${name}.percent\n        echo \"generated coverage percent report:\" $(realpath ${name}.percent)\n        sudo go tool covdata textfmt -i=$coverdirs -o ${name}.txt \n        echo \"generated coverage report in text format:\" $(realpath ${name}.txt)\n        sudo go tool cover -html=${name}.txt -o ${name}.html\n        echo \"generated coverage report in html format:\" $(realpath ${name}.html)\n        ls -l cover_*\n\n    - name: upload coverage report\n      working-directory: schedule/${{env.last_date}}\n      timeout-minutes: 10\n      run: |\n        echo \"current dir is $(pwd)\"\n        [[ ! -f \"cover_${{matrix.test}}.html\" ]] && echo \"no coverage report found\" && exit 0\n        UPLOAD_PATH=${{github.workflow}}_${{github.run_id}}_${{matrix.test}}.html\n        response=$(curl -w '%{http_code}' -s -o /dev/null --form 'file=@cover_${{matrix.test}}.html' https://juicefs.com/upload-file-u80sdvuke/${UPLOAD_PATH}?token=${{secrets.CI_COVERAGE_FILE_UPLOAD_AUTH_TOKEN}})\n        if [ \"$response\" -eq 200 ]; then\n          echo Coverage Report for ${{matrix.test}}: https://i.juicefs.io/ci-coverage/${UPLOAD_PATH}\n        else\n          echo \"Upload failed with status code $response\"\n          exit 1\n        fi\n\n    - name: Setup upterm session\n      if: failure() && (github.event.inputs.debug == 'true' || \n        github.run_attempt != 1)\n        # if: failure()\n      timeout-minutes: 30\n      uses: lhotari/action-upterm@v1\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `coverage-report` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main or a branch whose name matches release**. Only if at least one path of push event matches a pattern in the paths filter(**/coverage-report.yml), the workflow runs. 2) The workflow would run whenever there is a pull_request event targeting: a branch named main or a branch whose name matches release**. Only if at least one path of pull_request event matches a pattern in the paths filter(**/coverage-report.yml), the workflow runs. 3) someone manually triggers the workflow. This workflow receives 2 inputs: debug-the data type is boolean, this input represents run the build with tmate debugging enabled, it is optional and its default value is False; last_date-the data type is string, this input represents last date of coverage data, it is optional and its default value is. 4) the scheduled time has come: at 11:00 pm. The workflow has one job. The job id of the 1st job is `coverage-report`. ","prompt_level2":"Generate a GitHub Workflow named `coverage-report` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main or a branch whose name matches release**. Only if at least one path of push event matches a pattern in the paths filter(**/coverage-report.yml), the workflow runs. 2) The workflow would run whenever there is a pull_request event targeting: a branch named main or a branch whose name matches release**. Only if at least one path of pull_request event matches a pattern in the paths filter(**/coverage-report.yml), the workflow runs. 3) someone manually triggers the workflow. This workflow receives 2 inputs: debug-the data type is boolean, this input represents run the build with tmate debugging enabled, it is optional and its default value is False; last_date-the data type is string, this input represents last date of coverage data, it is optional and its default value is. 4) the scheduled time has come: at 11:00 pm. The workflow has one job. The job id of the 1st job is `coverage-report`. The job `coverage-report` has 8 steps. The 1st step is named `Checkout repository`. The 2nd step is named `mount coverage dir for cleanup`. The 3rd step is named `clean up old coverage data`. The 4th step is named `mount coverage dir`. The 5th step is named `Determine lastdate dir`. The 6th step is named `Generate today's coverage report`. The 7th step is named `upload coverage report`. The 8th step is named `Setup upterm session`. ","prompt_level3":"Generate a GitHub Workflow named `coverage-report` for a GitHub repository whose primary programming language is Go. This workflow will be triggered by multiple events: 1) The workflow would run whenever there is a push event to: a branch named main or a branch whose name matches release**. Only if at least one path of push event matches a pattern in the paths filter(**/coverage-report.yml), the workflow runs. 2) The workflow would run whenever there is a pull_request event targeting: a branch named main or a branch whose name matches release**. Only if at least one path of pull_request event matches a pattern in the paths filter(**/coverage-report.yml), the workflow runs. 3) someone manually triggers the workflow. This workflow receives 2 inputs: debug-the data type is boolean, this input represents run the build with tmate debugging enabled, it is optional and its default value is False; last_date-the data type is string, this input represents last date of coverage data, it is optional and its default value is. 4) the scheduled time has come: at 11:00 pm. The workflow has one job. The job id of the 1st job is `coverage-report`. This job will run on ubuntu-22.04 runner. The job uses a matrix strategy to automatically create multiple job runs that are based on the combinations of the variables. The variable `branch` has one value: main. The variable `test` has 3 values: ut, it and all. The maximum number of minutes to run the job is 60. The job `coverage-report` has 8 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v3. The step defines an input parameter for the action: `fetch-depth` is set to `1`. The maximum number of minutes to run the step is 1. The 2nd step is named `mount coverage dir for cleanup`. This step will run only if the condition(${{ matrix.test == 'all' }}) is met. This step runs action `./.github/actions/mount-coverage-dir`.The step defines 5 input parameters for the action: `mount_point` is set to `/ci-coverage`, `subdir` is set to `juicefs/`, `access_key` is set to `${{ secrets.CI_COVERAGE_AWS_AK }}`, `secret_key` is set to `${{ secrets.CI_COVERAGE_AWS_SK }}` and `token` is set to `${{ secrets.CI_COVERAGE_AWS_TOKEN }}`. The maximum number of minutes to run the step is 5. The 3rd step is named `clean up old coverage data`. This step will run only if the condition(${{ matrix.test == 'all' }}) is met. This step runs a script: `sudo find /ci-coverage -type f \\( -name 'covcounters*' -o -name 'covmeta*' \\) -mtime +2 -print -exec rm -f {} +\numount /jfs-coverage\n`. When this step fails, the job will move on to the next step. The maximum number of minutes to run the step is 10. The 4th step is named `mount coverage dir`. This step runs action `./.github/actions/mount-coverage-dir`.The step defines 5 input parameters for the action: `mount_point` is set to `schedule`, `subdir` is set to `juicefs/schedule`, `access_key` is set to `${{ secrets.CI_COVERAGE_AWS_AK }}`, `secret_key` is set to `${{ secrets.CI_COVERAGE_AWS_SK }}` and `token` is set to `${{ secrets.CI_COVERAGE_AWS_TOKEN }}`. The maximum number of minutes to run the step is 5. The 5th step is named `Determine lastdate dir`. This step runs a script: `if [[ -n \"${{github.event.inputs.last_date}}\" ]]; then\n  last_date=${{github.event.inputs.last_date}}\nelse\n  last_date=$(ls -t schedule | head -n 1)\n  [[ -z \"$last_date\" ]] && echo \"no data found in schedule\" && exit 1\nfi\n[[ ! -d \"schedule/$last_date\" ]] && echo \"schedule/$last_date not found\" && exit 1\necho \"last_date=$last_date\" >> $GITHUB_ENV\n`. The maximum number of minutes to run the step is 120. The 6th step is named `Generate today's coverage report`. This step runs a script: `echo \"current dir is $(pwd)\"\ncoverdirs=\"\"\nfor dir in $(find . -mindepth 1 -maxdepth 1 -type d -exec basename {} \\;); do\n    if [[ ${{matrix.test}} == \"ut\" ]]; then\n      if [[ \"$dir\" == \"unittests\" ]]; then\n        coverdirs+=\"$dir,\"\n      fi\n    elif [[ ${{matrix.test}} == \"it\" ]]; then\n      if [[ \"$dir\" != \"unittests\" ]]; then\n        coverdirs+=\"$dir,\"\n      fi\n    elif [[ ${{matrix.test}} == \"all\" ]]; then\n      coverdirs+=\"$dir,\"\n    fi\ndone\ncoverdirs=${coverdirs%,}\necho coverdirs is $coverdirs\n[[ -z \"$coverdirs\" ]] && echo \"no coverage dir found\" && exit 0\nname=cover_${{matrix.test}}\nsudo go tool covdata percent -i=$coverdirs | sudo tee ${name}.percent\necho \"generated coverage percent report:\" $(realpath ${name}.percent)\nsudo go tool covdata textfmt -i=$coverdirs -o ${name}.txt \necho \"generated coverage report in text format:\" $(realpath ${name}.txt)\nsudo go tool cover -html=${name}.txt -o ${name}.html\necho \"generated coverage report in html format:\" $(realpath ${name}.html)\nls -l cover_*\n`. The maximum number of minutes to run the step is 30. The 7th step is named `upload coverage report`. This step runs a script: `echo \"current dir is $(pwd)\"\n[[ ! -f \"cover_${{matrix.test}}.html\" ]] && echo \"no coverage report found\" && exit 0\nUPLOAD_PATH=${{github.workflow}}_${{github.run_id}}_${{matrix.test}}.html\nresponse=$(curl -w '%{http_code}' -s -o /dev/null --form 'file=@cover_${{matrix.test}}.html' https://juicefs.com/upload-file-u80sdvuke/${UPLOAD_PATH}?token=${{secrets.CI_COVERAGE_FILE_UPLOAD_AUTH_TOKEN}})\nif [ \"$response\" -eq 200 ]; then\n  echo Coverage Report for ${{matrix.test}}: https://i.juicefs.io/ci-coverage/${UPLOAD_PATH}\nelse\n  echo \"Upload failed with status code $response\"\n  exit 1\nfi\n`. The maximum number of minutes to run the step is 10. The 8th step is named `Setup upterm session`. This step will run only if the condition(failure() && (github.event.inputs.debug == 'true' || github.run_attempt != 1)) is met. This step runs action `lhotari/action-upterm` tagged as v1. The maximum number of minutes to run the step is 30. ","nb_triggers":4,"triggers":["pull_request","push","schedule","workflow_dispatch"],"nb_jobs":1,"nb_actions":4,"actions":["./.github/actions/mount-coverage-dir","./.github/actions/mount-coverage-dir","actions/checkout","lhotari/action-upterm"],"actions_details":[{"version":"v3","name":"actions/checkout"},{"version":null,"name":"./.github/actions/mount-coverage-dir"},{"version":null,"name":"./.github/actions/mount-coverage-dir"},{"version":"v1","name":"lhotari/action-upterm"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":8,"cyclomatic_complexity":1}
{"id":19669,"repository_id":3976043,"mainLanguage":"C++","file_name":"4_builderprecompiled_docker-images-upload-manager.yml","file_content":"run-name: Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}\nname: Package - Upload manager images amd64\n\non:\n  workflow_dispatch:\n    inputs:\n      docker_image_tag:\n        description: |\n          Tag name of the Docker image to be uploaded.\n          Use 'developer' to set branch name as tag.\n          Use 'auto' to set branch version as tag.\n          If using a custom tag, use only '-', '_', '.' and alphanumeric characters.\n          Default is 'auto'.\n        required: false\n        default: auto\n      system:\n        type: choice\n        description: |\n          System image to upload [deb, rpm].\n        options:\n          - deb\n          - rpm\n      source_reference:\n        description: |\n          Branch from wazuh/wazuh repository to use.\n        required: true\n\njobs:\n  Upload-package-building-images:\n    runs-on: ubuntu-latest\n    timeout-minutes: 140\n    name: Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}\n\n    steps:\n      - name: Checkout wazuh/wazuh repository\n        uses: actions/checkout@v4\n        with:\n          repository: wazuh/wazuh\n          ref: ${{ inputs.source_reference }}\n\n      - name: Set TAG\n        run: |\n          VERSION=\"$(grep '\"version\"' VERSION.json | sed -E 's/.*\"version\": *\"([^\"]+)\".*/\\1/')\"\n          if [ \"${{ inputs.docker_image_tag }}\" == \"auto\" ]; then\n            echo \"TAG=$VERSION\" >> $GITHUB_ENV;\n          elif [ \"${{ inputs.docker_image_tag }}\" == \"developer\" ]; then\n            echo \"TAG=$(sed 's|[/\\]|--|g' <<< ${{ inputs.source_reference }})\" >> $GITHUB_ENV;\n          else\n            echo \"TAG=${{ inputs.docker_image_tag }}\" >> $GITHUB_ENV;\n          fi\n\n      - name: Copy build.sh and utils to Dockerfile path\n        run: |\n          dockerfile_path=\"packages/${{ inputs.system }}s/amd64/manager\"\n          echo \"DOCKERFILE_PATH=$dockerfile_path\" >> $GITHUB_ENV\n          cp packages/build.sh $dockerfile_path\n          cp packages/${{ inputs.system }}s/utils/* $dockerfile_path\n\n      - name: Build and push image pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ env.TAG }} to Github Container Registry\n        run:\n          bash .github/actions/ghcr-pull-and-push/build_and_push_image_to_ghcr.sh ${{ secrets.GITHUB_TOKEN }} ${{ github.actor}} pkg_${{ inputs.system }}_manager_builder_amd64 ${{ env.DOCKERFILE_PATH }} ${{ env.TAG }}\n","repository_owner":"wazuh","repository_name":"wazuh","tokens_count":602,"workflow":"run-name: Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with \n  tag ${{ inputs.docker_image_tag }}\nname: Package - Upload manager images amd64\n\non:\n  workflow_dispatch:\n    inputs:\n      docker_image_tag:\n        description: |\n          Tag name of the Docker image to be uploaded.\n          Use 'developer' to set branch name as tag.\n          Use 'auto' to set branch version as tag.\n          If using a custom tag, use only '-', '_', '.' and alphanumeric characters.\n          Default is 'auto'.\n        required: false\n        default: auto\n      system:\n        type: choice\n        description: |\n          System image to upload [deb, rpm].\n        options:\n        - deb\n        - rpm\n      source_reference:\n        description: |\n          Branch from wazuh/wazuh repository to use.\n        required: true\n\njobs:\n  Upload-package-building-images:\n    runs-on: ubuntu-latest\n    timeout-minutes: 140\n    name: Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with \n      tag ${{ inputs.docker_image_tag }}\n\n    steps:\n    - name: Checkout wazuh/wazuh repository\n      uses: actions/checkout@v4\n      with:\n        repository: wazuh/wazuh\n        ref: ${{ inputs.source_reference }}\n\n    - name: Set TAG\n      run: |\n        VERSION=\"$(grep '\"version\"' VERSION.json | sed -E 's/.*\"version\": *\"([^\"]+)\".*/\\1/')\"\n        if [ \"${{ inputs.docker_image_tag }}\" == \"auto\" ]; then\n          echo \"TAG=$VERSION\" >> $GITHUB_ENV;\n        elif [ \"${{ inputs.docker_image_tag }}\" == \"developer\" ]; then\n          echo \"TAG=$(sed 's|[/\\]|--|g' <<< ${{ inputs.source_reference }})\" >> $GITHUB_ENV;\n        else\n          echo \"TAG=${{ inputs.docker_image_tag }}\" >> $GITHUB_ENV;\n        fi\n\n    - name: Copy build.sh and utils to Dockerfile path\n      run: |\n        dockerfile_path=\"packages/${{ inputs.system }}s/amd64/manager\"\n        echo \"DOCKERFILE_PATH=$dockerfile_path\" >> $GITHUB_ENV\n        cp packages/build.sh $dockerfile_path\n        cp packages/${{ inputs.system }}s/utils/* $dockerfile_path\n\n    - name: Build and push image pkg_${{ inputs.system }}_manager_builder_amd64 \n        with tag ${{ env.TAG }} to Github Container Registry\n      run: bash \n        .github/actions/ghcr-pull-and-push/build_and_push_image_to_ghcr.sh ${{ \n        secrets.GITHUB_TOKEN }} ${{ github.actor}} pkg_${{ inputs.system \n        }}_manager_builder_amd64 ${{ env.DOCKERFILE_PATH }} ${{ env.TAG }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Package - Upload manager images amd64` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}`. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 3 inputs: docker_image_tag-this input represents tag name of the docker image to be uploaded.\nuse 'developer' to set branch name as tag.\nuse 'auto' to set branch version as tag.\nif using a custom tag, use only '-', '_', '.' and alphanumeric characters.\ndefault is 'auto'.\n, it is optional and its default value is auto; system-the data type is choice, this input represents system image to upload [deb, rpm].\n and it has options including deb and rpm; source_reference-this input represents branch from wazuh/wazuh repository to use.\n and it must be supplied. The workflow has one job. The 1st job is named `Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}` and its job id is `Upload-package-building-images`. ","prompt_level2":"Generate a GitHub Workflow named `Package - Upload manager images amd64` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}`. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 3 inputs: docker_image_tag-this input represents tag name of the docker image to be uploaded.\nuse 'developer' to set branch name as tag.\nuse 'auto' to set branch version as tag.\nif using a custom tag, use only '-', '_', '.' and alphanumeric characters.\ndefault is 'auto'.\n, it is optional and its default value is auto; system-the data type is choice, this input represents system image to upload [deb, rpm].\n and it has options including deb and rpm; source_reference-this input represents branch from wazuh/wazuh repository to use.\n and it must be supplied. The workflow has one job. The 1st job is named `Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}` and its job id is `Upload-package-building-images`. The job `Upload-package-building-images` has 4 steps. The 1st step is named `Checkout wazuh/wazuh`. The 2nd step is named `Set TAG`. The 3rd step is named `Copy build.sh and utils to Dockerfile path`. The 4th step is named `Build and push image pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ env.TAG }} to Github Container Registry`. ","prompt_level3":"Generate a GitHub Workflow named `Package - Upload manager images amd64` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}`. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 3 inputs: docker_image_tag-this input represents tag name of the docker image to be uploaded.\nuse 'developer' to set branch name as tag.\nuse 'auto' to set branch version as tag.\nif using a custom tag, use only '-', '_', '.' and alphanumeric characters.\ndefault is 'auto'.\n, it is optional and its default value is auto; system-the data type is choice, this input represents system image to upload [deb, rpm].\n and it has options including deb and rpm; source_reference-this input represents branch from wazuh/wazuh repository to use.\n and it must be supplied. The workflow has one job. The 1st job is named `Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}` and its job id is `Upload-package-building-images`. This job will run on ubuntu-latest runner. The maximum number of minutes to run the job is 140. The job `Upload-package-building-images` has 4 steps. The 1st step is named `Checkout wazuh/wazuh`. This step runs action `actions/checkout` tagged as v4. The step defines 2 input parameters for the action: `repository` is set to `wazuh/wazuh` and `ref` is set to `${{ inputs.source_reference }}`. The 2nd step is named `Set TAG`. This step runs a script: `VERSION=\"$(grep '\"version\"' VERSION.json | sed -E 's/.*\"version\": *\"([^\"]+)\".*/\\1/')\"\nif [ \"${{ inputs.docker_image_tag }}\" == \"auto\" ]; then\n  echo \"TAG=$VERSION\" >> $GITHUB_ENV;\nelif [ \"${{ inputs.docker_image_tag }}\" == \"developer\" ]; then\n  echo \"TAG=$(sed 's|[/\\]|--|g' <<< ${{ inputs.source_reference }})\" >> $GITHUB_ENV;\nelse\n  echo \"TAG=${{ inputs.docker_image_tag }}\" >> $GITHUB_ENV;\nfi\n`. The 3rd step is named `Copy build.sh and utils to Dockerfile path`. This step runs a script: `dockerfile_path=\"packages/${{ inputs.system }}s/amd64/manager\"\necho \"DOCKERFILE_PATH=$dockerfile_path\" >> $GITHUB_ENV\ncp packages/build.sh $dockerfile_path\ncp packages/${{ inputs.system }}s/utils/* $dockerfile_path\n`. The 4th step is named `Build and push image pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ env.TAG }} to Github Container Registry`. This step runs a script: `bash .github/actions/ghcr-pull-and-push/build_and_push_image_to_ghcr.sh ${{ secrets.GITHUB_TOKEN }} ${{ github.actor}} pkg_${{ inputs.system }}_manager_builder_amd64 ${{ env.DOCKERFILE_PATH }} ${{ env.TAG }}`. ","nb_triggers":1,"triggers":["workflow_dispatch"],"nb_jobs":1,"nb_actions":1,"actions":["actions/checkout"],"actions_details":[{"version":"v4","name":"actions/checkout"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":4,"cyclomatic_complexity":1}
{"id":27677,"repository_id":3993770,"mainLanguage":"C++","file_name":"docker.yml","file_content":"on:\n  workflow_call:\n    outputs:\n      docker_cpu_image:\n        description: \"Generate images for all CI usage\"\n        value: ${{ jobs.build-docker-images.outputs.docker_cpu_image }}\n\n      docker_inference_image:\n        description: \"Generate images for all CI usage\"\n        value: ${{ jobs.build-docker-images.outputs.docker_inference_image }}\n\n      docker_coverage_image:\n        description: \"Generate images for all CI usage\"\n        value: ${{ jobs.build-docker-images.outputs.docker_coverage_image }}\n\n      docker_build_image:\n        description: \"Generate images for all CI usage\"\n        value: ${{ jobs.build-docker-images.outputs.docker_build_image }}\n\n      docker_distribute_file:\n        description: \"Generate images for all CI usage\"\n        value: ${{ jobs.build-docker-images.outputs.docker_distribute_image }}\n\njobs:\n  build-docker-images:\n    name: build docker\n    runs-on:\n      group: Docker-build\n    outputs:\n      docker_cpu_image: ${{ steps.build-docker-images.outputs.docker_cpu_image }}\n      docker_inference_image: ${{ steps.build-docker-images.outputs.docker_inference_image }}\n      docker_coverage_image: ${{ steps.build-docker-images.outputs.docker_coverage_image }}\n      docker_build_image: ${{ steps.build-docker-images.outputs.docker_build_image }}\n      docker_distribute_image: ${{ steps.build-docker-images.outputs.docker_distribute_image }}\n    steps:\n      - id: build-docker-images\n        name: build docker images\n        env:\n          PR_ID: ${{ github.event.pull_request.number }}\n          COMMIT_ID: ${{ github.event.pull_request.head.sha }}\n          docker_cpu_file: Dockerfile.cuda9_cudnn7_gcc48_py35_centos6\n          docker_inference_file: Dockerfile.cuda11.2_cudnn8.1_trt8.4_gcc8.2_ubuntu18\n          docker_coverage_file: Dockerfile.cuda117_cudnn8_gcc82_ubuntu18_coverage\n          docker_build_file: Dockerfile.cuda11.2_cudnn8_gcc82_trt8\n          docker_distribute_file: Dockerfile.cuda123_cudnn9_gcc122_ubuntu20\n        run: |\n          set -x\n          wget -q --no-proxy https://paddle-github-action.bj.bcebos.com/PR/Paddle/${PR_ID}/${COMMIT_ID}/Paddle.tar.gz --no-check-certificate\n          tar xf Paddle.tar.gz --strip-components=1\n          rm Paddle.tar.gz\n          cd tools/dockerfile\n          bash ci_dockerfile.sh\n          cd ../..\n\n          # docker build images\n          declare -A docker_files=([\"docker_cpu\"]=\"$docker_cpu_file\" [\"docker_inference\"]=\"$docker_inference_file\" [\"docker_coverage\"]=\"$docker_coverage_file\" [\"docker_build\"]=\"$docker_build_file\" [\"docker_distribute\"]=\"$docker_distribute_file\")\n          for name in \"${!docker_files[@]}\"\n          do\n            md5_value=`md5sum tools/dockerfile/${docker_files[$name]} | awk '{print $1}'`\n            docker_image=\"ccr-2vdh3abv-pub.cnc.bj.baidubce.com/ci/paddle:${md5_value}\"\n            declare \"${name}_image=${docker_image}\"\n            echo \"${name}_image=${docker_image}\" >> $GITHUB_OUTPUT\n            set +e\n            docker pull $docker_image\n            if [ $? -eq 0 ];then\n              echo use docker cache\n            else\n              docker build -t $docker_image -f tools/dockerfile/${docker_files[$name]} .\n              docker push $docker_image\n              echo end docker build\n            fi\n            set -e\n          done\n\n          # clean workspace\n          cd ${{ github.workspace }}\n          rm -rf ./*\n","repository_owner":"paddlepaddle","repository_name":"paddle","tokens_count":806,"workflow":"on:\n  workflow_call:\n    outputs:\n      docker_cpu_image:\n        description: Generate images for all CI usage\n        value: ${{ jobs.build-docker-images.outputs.docker_cpu_image }}\n\n      docker_inference_image:\n        description: Generate images for all CI usage\n        value: ${{ jobs.build-docker-images.outputs.docker_inference_image }}\n\n      docker_coverage_image:\n        description: Generate images for all CI usage\n        value: ${{ jobs.build-docker-images.outputs.docker_coverage_image }}\n\n      docker_build_image:\n        description: Generate images for all CI usage\n        value: ${{ jobs.build-docker-images.outputs.docker_build_image }}\n\n      docker_distribute_file:\n        description: Generate images for all CI usage\n        value: ${{ jobs.build-docker-images.outputs.docker_distribute_image }}\n\njobs:\n  build-docker-images:\n    name: build docker\n    runs-on:\n      group: Docker-build\n    outputs:\n      docker_cpu_image: ${{ steps.build-docker-images.outputs.docker_cpu_image \n        }}\n      docker_inference_image: ${{ \n        steps.build-docker-images.outputs.docker_inference_image }}\n      docker_coverage_image: ${{ \n        steps.build-docker-images.outputs.docker_coverage_image }}\n      docker_build_image: ${{ \n        steps.build-docker-images.outputs.docker_build_image }}\n      docker_distribute_image: ${{ \n        steps.build-docker-images.outputs.docker_distribute_image }}\n    steps:\n    - id: build-docker-images\n      name: build docker images\n      env:\n        PR_ID: ${{ github.event.pull_request.number }}\n        COMMIT_ID: ${{ github.event.pull_request.head.sha }}\n        docker_cpu_file: Dockerfile.cuda9_cudnn7_gcc48_py35_centos6\n        docker_inference_file: \n          Dockerfile.cuda11.2_cudnn8.1_trt8.4_gcc8.2_ubuntu18\n        docker_coverage_file: Dockerfile.cuda117_cudnn8_gcc82_ubuntu18_coverage\n        docker_build_file: Dockerfile.cuda11.2_cudnn8_gcc82_trt8\n        docker_distribute_file: Dockerfile.cuda123_cudnn9_gcc122_ubuntu20\n      run: |\n        set -x\n        wget -q --no-proxy https://paddle-github-action.bj.bcebos.com/PR/Paddle/${PR_ID}/${COMMIT_ID}/Paddle.tar.gz --no-check-certificate\n        tar xf Paddle.tar.gz --strip-components=1\n        rm Paddle.tar.gz\n        cd tools/dockerfile\n        bash ci_dockerfile.sh\n        cd ../..\n\n        # docker build images\n        declare -A docker_files=([\"docker_cpu\"]=\"$docker_cpu_file\" [\"docker_inference\"]=\"$docker_inference_file\" [\"docker_coverage\"]=\"$docker_coverage_file\" [\"docker_build\"]=\"$docker_build_file\" [\"docker_distribute\"]=\"$docker_distribute_file\")\n        for name in \"${!docker_files[@]}\"\n        do\n          md5_value=`md5sum tools/dockerfile/${docker_files[$name]} | awk '{print $1}'`\n          docker_image=\"ccr-2vdh3abv-pub.cnc.bj.baidubce.com/ci/paddle:${md5_value}\"\n          declare \"${name}_image=${docker_image}\"\n          echo \"${name}_image=${docker_image}\" >> $GITHUB_OUTPUT\n          set +e\n          docker pull $docker_image\n          if [ $? -eq 0 ];then\n            echo use docker cache\n          else\n            docker build -t $docker_image -f tools/dockerfile/${docker_files[$name]} .\n            docker push $docker_image\n            echo end docker build\n          fi\n          set -e\n        done\n\n        # clean workspace\n        cd ${{ github.workspace }}\n        rm -rf ./*\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow has 5 outputs: docker_cpu_image-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_cpu_image }}; docker_inference_image-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_inference_image }}; docker_coverage_image-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_coverage_image }}; docker_build_image-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_build_image }}; docker_distribute_file-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_distribute_image }}. The workflow has one job. The 1st job is named `build docker` and its job id is `build-docker-images`. ","prompt_level2":"Generate a GitHub Workflow named `` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow has 5 outputs: docker_cpu_image-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_cpu_image }}; docker_inference_image-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_inference_image }}; docker_coverage_image-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_coverage_image }}; docker_build_image-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_build_image }}; docker_distribute_file-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_distribute_image }}. The workflow has one job. The 1st job is named `build docker` and its job id is `build-docker-images`. The job `build-docker-images` has one step. The 1st step is named `build docker images` and its id is `build-docker-images`. ","prompt_level3":"Generate a GitHub Workflow named `` for a GitHub repository whose primary programming language is C++. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow has 5 outputs: docker_cpu_image-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_cpu_image }}; docker_inference_image-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_inference_image }}; docker_coverage_image-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_coverage_image }}; docker_build_image-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_build_image }}; docker_distribute_file-it represents generate images for all ci usage and its value is ${{ jobs.build-docker-images.outputs.docker_distribute_image }}. The workflow has one job. The 1st job is named `build docker` and its job id is `build-docker-images`. This job will execute on any runner that is a member of Docker-build. The job `build-docker-images` has one step. The 1st step is named `build docker images` and its id is `build-docker-images`. The step sets 7 environment variables to use: `PR_ID` is set to `${{ github.event.pull_request.number }}`, `COMMIT_ID` is set to `${{ github.event.pull_request.head.sha }}`, `docker_cpu_file` is set to `Dockerfile.cuda9_cudnn7_gcc48_py35_centos6`, `docker_inference_file` is set to `Dockerfile.cuda11.2_cudnn8.1_trt8.4_gcc8.2_ubuntu18`, `docker_coverage_file` is set to `Dockerfile.cuda117_cudnn8_gcc82_ubuntu18_coverage`, `docker_build_file` is set to `Dockerfile.cuda11.2_cudnn8_gcc82_trt8` and `docker_distribute_file` is set to `Dockerfile.cuda123_cudnn9_gcc122_ubuntu20`. This step runs a script: `set -x\nwget -q --no-proxy https://paddle-github-action.bj.bcebos.com/PR/Paddle/${PR_ID}/${COMMIT_ID}/Paddle.tar.gz --no-check-certificate\ntar xf Paddle.tar.gz --strip-components=1\nrm Paddle.tar.gz\ncd tools/dockerfile\nbash ci_dockerfile.sh\ncd ../..\n\n# docker build images\ndeclare -A docker_files=([\"docker_cpu\"]=\"$docker_cpu_file\" [\"docker_inference\"]=\"$docker_inference_file\" [\"docker_coverage\"]=\"$docker_coverage_file\" [\"docker_build\"]=\"$docker_build_file\" [\"docker_distribute\"]=\"$docker_distribute_file\")\nfor name in \"${!docker_files[@]}\"\ndo\n  md5_value=`md5sum tools/dockerfile/${docker_files[$name]} | awk '{print $1}'`\n  docker_image=\"ccr-2vdh3abv-pub.cnc.bj.baidubce.com/ci/paddle:${md5_value}\"\n  declare \"${name}_image=${docker_image}\"\n  echo \"${name}_image=${docker_image}\" >> $GITHUB_OUTPUT\n  set +e\n  docker pull $docker_image\n  if [ $? -eq 0 ];then\n    echo use docker cache\n  else\n    docker build -t $docker_image -f tools/dockerfile/${docker_files[$name]} .\n    docker push $docker_image\n    echo end docker build\n  fi\n  set -e\ndone\n\n# clean workspace\ncd ${{ github.workspace }}\nrm -rf ./*\n`. This job has 5 outputs: `docker_cpu_image` is defined as ${{ steps.build-docker-images.outputs.docker_cpu_image }}, `docker_inference_image` is defined as ${{ steps.build-docker-images.outputs.docker_inference_image }}, `docker_coverage_image` is defined as ${{ steps.build-docker-images.outputs.docker_coverage_image }}, `docker_build_image` is defined as ${{ steps.build-docker-images.outputs.docker_build_image }} and `docker_distribute_image` is defined as ${{ steps.build-docker-images.outputs.docker_distribute_image }}. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":0,"actions":[],"actions_details":[],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":1,"cyclomatic_complexity":1}
{"id":17489,"repository_id":95285757,"mainLanguage":"JavaScript","file_name":"docker-build.yml","file_content":"name: Build and Push Docker Image\n\non:\n  release:\n    types: [ published ]\n  workflow_dispatch:\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - name: Login to Docker Hub\n        uses: docker/login-action@v2\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      # Extract metadata for Docker\n      - name: Extract Docker metadata\n        id: meta\n        uses: docker/metadata-action@v4\n        with:\n          images: cooldockerizer93/spotizerr\n          # Set latest tag to follow semantic versioning\n          flavor: |\n            latest=auto\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            # Set 'latest' tag for the most recent semver tag (following proper semver ordering)\n            type=semver,pattern=latest,priority=1000\n            # Keep dev tag for main/master branch\n            type=raw,value=dev,enable=${{ github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' }}\n\n      # Build and push Docker image with multiarch support\n      - name: Build and push\n        uses: docker/build-push-action@v4\n        with:\n          context: .\n          # Specify the multiarch platforms\n          platforms: linux/amd64,linux/arm64\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          no-cache: true\n","repository_owner":"Xoconoch","repository_name":"spotizerr","tokens_count":419,"workflow":"name: Build and Push Docker Image\n\non:\n  release:\n    types: [published]\n  workflow_dispatch:\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - name: Login to Docker Hub\n      uses: docker/login-action@v2\n      with:\n        username: ${{ secrets.DOCKERHUB_USERNAME }}\n        password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      # Extract metadata for Docker\n    - name: Extract Docker metadata\n      id: meta\n      uses: docker/metadata-action@v4\n      with:\n        images: cooldockerizer93/spotizerr\n          # Set latest tag to follow semantic versioning\n        flavor: |\n          latest=auto\n        tags: |\n          type=ref,event=branch\n          type=ref,event=pr\n          type=semver,pattern={{version}}\n          type=semver,pattern={{major}}.{{minor}}\n          # Set 'latest' tag for the most recent semver tag (following proper semver ordering)\n          type=semver,pattern=latest,priority=1000\n          # Keep dev tag for main/master branch\n          type=raw,value=dev,enable=${{ github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' }}\n\n      # Build and push Docker image with multiarch support\n    - name: Build and push\n      uses: docker/build-push-action@v4\n      with:\n        context: .\n          # Specify the multiarch platforms\n        platforms: linux/amd64,linux/arm64\n        push: ${{ github.event_name != 'pull_request' }}\n        tags: ${{ steps.meta.outputs.tags }}\n        labels: ${{ steps.meta.outputs.labels }}\n        no-cache: true\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Build and Push Docker Image` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) someone manually triggers the workflow. The workflow has one job. The job id of the 1st job is `build-and-push`. ","prompt_level2":"Generate a GitHub Workflow named `Build and Push Docker Image` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) someone manually triggers the workflow. The workflow has one job. The job id of the 1st job is `build-and-push`. The job `build-and-push` has 5 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Set up Docker Buildx`. The 3rd step is named `Login to Docker Hub`. The 4th step is named `Extract Docker metadata` and its id is `meta`. The 5th step is named `Build and push`. ","prompt_level3":"Generate a GitHub Workflow named `Build and Push Docker Image` for a GitHub repository whose primary programming language is JavaScript. This workflow will be triggered by multiple events: 1) a release, pre-release, or draft of a release is published. 2) someone manually triggers the workflow. The workflow has one job. The job id of the 1st job is `build-and-push`. This job will run on ubuntu-latest runner. The job `build-and-push` has 5 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v3. The 2nd step is named `Set up Docker Buildx`. This step runs action `docker/setup-buildx-action` tagged as v2. The 3rd step is named `Login to Docker Hub`. This step runs action `docker/login-action` tagged as v2. The step defines 2 input parameters for the action: `username` is set to `${{ secrets.DOCKERHUB_USERNAME }}` and `password` is set to `${{ secrets.DOCKERHUB_TOKEN }}`. The 4th step is named `Extract Docker metadata` and its id is `meta`. This step runs action `docker/metadata-action` tagged as v4. The step defines 3 input parameters for the action: `images` is set to `cooldockerizer93/spotizerr`, `flavor` is set to `latest=auto\n` and `tags` is set to `type=ref,event=branch\ntype=ref,event=pr\ntype=semver,pattern={{version}}\ntype=semver,pattern={{major}}.{{minor}}\n# Set 'latest' tag for the most recent semver tag (following proper semver ordering)\ntype=semver,pattern=latest,priority=1000\n# Keep dev tag for main/master branch\ntype=raw,value=dev,enable=${{ github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' }}\n`. The 5th step is named `Build and push`. This step runs action `docker/build-push-action` tagged as v4. The step defines 6 input parameters for the action: `context` is set to `.`, `platforms` is set to `linux/amd64,linux/arm64`, `push` is set to `${{ github.event_name != 'pull_request' }}`, `tags` is set to `${{ steps.meta.outputs.tags }}`, `labels` is set to `${{ steps.meta.outputs.labels }}` and `no-cache` is set to `True`. ","nb_triggers":2,"triggers":["release","workflow_dispatch"],"nb_jobs":1,"nb_actions":5,"actions":["actions/checkout","docker/build-push-action","docker/login-action","docker/metadata-action","docker/setup-buildx-action"],"actions_details":[{"version":"v3","name":"actions/checkout"},{"version":"v2","name":"docker/setup-buildx-action"},{"version":"v2","name":"docker/login-action"},{"version":"v4","name":"docker/metadata-action"},{"version":"v4","name":"docker/build-push-action"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":5,"cyclomatic_complexity":1}
{"id":66017,"repository_id":94700812,"mainLanguage":"Python","file_name":"release.yml","file_content":"name: Upload Python Package\n\non:\n  release:\n    types: [published]\n\npermissions:\n  contents: read\n\njobs:\n  release-build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1\n      - uses: actions/setup-python@65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236 # v4.7.1\n        with:\n          python-version: '3.10'\n\n      - name: Build release distributions\n        run: ./scripts/build_pip.sh\n\n      - name: Upload distributions\n        uses: actions/upload-artifact@65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08 # v4.6.0\n        with:\n          name: release-dists\n          path: dist/\n\n  pypi-publish:\n    runs-on: ubuntu-latest\n\n    needs:\n      - release-build\n\n    permissions:\n      # IMPORTANT: this permission is mandatory for trusted publishing\n      id-token: write\n\n    # Dedicated environments with protections for publishing are strongly recommended.\n    environment:\n      name: pypi\n      url: https://pypi.org/p/mesop\n\n    steps:\n      - name: Retrieve release distributions\n        uses: actions/download-artifact@cc203385981b70ca67e1cc392babf9cc229d5806 # v4.1.9\n        with:\n          name: release-dists\n          path: dist/\n\n      - name: Publish release distributions to PyPI\n        uses: pypa/gh-action-pypi-publish@76f52bc884231f62b9a034ebfe128415bbaabdfc # v1.12.4\n","repository_owner":"google","repository_name":"mesop","tokens_count":466,"workflow":"name: Upload Python Package\n\non:\n  release:\n    types: [published]\n\npermissions:\n  contents: read\n\njobs:\n  release-build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11   # v4.1.1\n    - name: Setup Python 3.10\n      uses: actions/setup-python@65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236   # v4.7.1\n      with:\n        python-version: '3.10'\n\n    - name: Build release distributions\n      run: ./scripts/build_pip.sh\n\n    - name: Upload distributions\n      uses: actions/upload-artifact@65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08   # v4.6.0\n      with:\n        name: release-dists\n        path: dist/\n\n  pypi-publish:\n    runs-on: ubuntu-latest\n\n    needs:\n    - release-build\n\n    permissions:\n      # IMPORTANT: this permission is mandatory for trusted publishing\n      id-token: write\n\n    # Dedicated environments with protections for publishing are strongly recommended.\n    environment:\n      name: pypi\n      url: https://pypi.org/p/mesop\n\n    steps:\n    - name: Retrieve release distributions\n      uses: actions/download-artifact@cc203385981b70ca67e1cc392babf9cc229d5806   # v4.1.9\n      with:\n        name: release-dists\n        path: dist/\n\n    - name: Publish release distributions to PyPI\n      uses: pypa/gh-action-pypi-publish@76f52bc884231f62b9a034ebfe128415bbaabdfc   # v1.12.4\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Upload Python Package` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: a release, pre-release, or draft of a release is published. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 2 jobs. The job id of the 1st job is `release-build`. The job id of the 2nd job is `pypi-publish`. ","prompt_level2":"Generate a GitHub Workflow named `Upload Python Package` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: a release, pre-release, or draft of a release is published. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 2 jobs. The job id of the 1st job is `release-build`. The job `release-build` has 4 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Setup Python 3.10`. The 3rd step is named `Build release distributions`. The 4th step is named `Upload distributions`. The job id of the 2nd job is `pypi-publish`. The job `pypi-publish` has 2 steps. The 1st step is named `Retrieve release distributions`. The 2nd step is named `Publish release distributions to PyPI`. ","prompt_level3":"Generate a GitHub Workflow named `Upload Python Package` for a GitHub repository whose primary programming language is Python. This workflow will be triggered by an event: a release, pre-release, or draft of a release is published. The workflow modifies the default permissions for the GITHUB_TOKEN: read access is granted to the GITHUB_TOKEN in the `contents` scope. This permission setting applies to all jobs in the workflow. The workflow has 2 jobs. The job id of the 1st job is `release-build`. This job will run on ubuntu-latest runner. The job `release-build` has 4 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` whose commit is b4ffde65f46336ab88eb53be808477a3936bae11. The 2nd step is named `Setup Python 3.10`. This step runs action `actions/setup-python` whose commit is 65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236. The step defines an input parameter for the action: `python-version` is set to `3.10`. The 3rd step is named `Build release distributions`. This step runs a script: `./scripts/build_pip.sh`. The 4th step is named `Upload distributions`. This step runs action `actions/upload-artifact` whose commit is 65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08. The step defines 2 input parameters for the action: `name` is set to `release-dists` and `path` is set to `dist/`. The job id of the 2nd job is `pypi-publish`. Before this job runs, `release-build` must complete successfully. This job will run on ubuntu-latest runner. The job `pypi-publish` modifies the default permissions for the GITHUB_TOKEN: write access is granted to the GITHUB_TOKEN in the `id-token` scope. This permission setting only applies to the job `pypi-publish`. This job references pypi environment whose url is https://pypi.org/p/mesop. The job `pypi-publish` has 2 steps. The 1st step is named `Retrieve release distributions`. This step runs action `actions/download-artifact` whose commit is cc203385981b70ca67e1cc392babf9cc229d5806. The step defines 2 input parameters for the action: `name` is set to `release-dists` and `path` is set to `dist/`. The 2nd step is named `Publish release distributions to PyPI`. This step runs action `pypa/gh-action-pypi-publish` whose commit is 76f52bc884231f62b9a034ebfe128415bbaabdfc. ","nb_triggers":1,"triggers":["release"],"nb_jobs":2,"nb_actions":5,"actions":["actions/checkout","actions/download-artifact","actions/setup-python","actions/upload-artifact","pypa/gh-action-pypi-publish"],"actions_details":[{"version":"b4ffde65f46336ab88eb53be808477a3936bae11","name":"actions/checkout"},{"version":"65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236","name":"actions/setup-python"},{"version":"65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08","name":"actions/upload-artifact"},{"version":"cc203385981b70ca67e1cc392babf9cc229d5806","name":"actions/download-artifact"},{"version":"76f52bc884231f62b9a034ebfe128415bbaabdfc","name":"pypa/gh-action-pypi-publish"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":6,"cyclomatic_complexity":1}
{"id":19669,"repository_id":3976043,"mainLanguage":"C++","file_name":"4_builderprecompiled_docker-images-upload-manager.yml","file_content":"run-name: Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}\nname: Package - Upload manager images amd64\n\non:\n  workflow_dispatch:\n    inputs:\n      docker_image_tag:\n        description: |\n          Tag name of the Docker image to be uploaded.\n          Use 'developer' to set branch name as tag.\n          Use 'auto' to set branch version as tag.\n          If using a custom tag, use only '-', '_', '.' and alphanumeric characters.\n          Default is 'auto'.\n        required: false\n        default: auto\n      system:\n        type: choice\n        description: |\n          System image to upload [deb, rpm].\n        options:\n          - deb\n          - rpm\n      source_reference:\n        description: |\n          Branch from wazuh/wazuh repository to use.\n        required: true\n\njobs:\n  Upload-package-building-images:\n    runs-on: ubuntu-latest\n    timeout-minutes: 140\n    name: Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}\n\n    steps:\n      - name: Checkout wazuh/wazuh repository\n        uses: actions/checkout@v4\n        with:\n          repository: wazuh/wazuh\n          ref: ${{ inputs.source_reference }}\n\n      - name: Set TAG\n        run: |\n          VERSION=\"$(grep '\"version\"' VERSION.json | sed -E 's/.*\"version\": *\"([^\"]+)\".*/\\1/')\"\n          if [ \"${{ inputs.docker_image_tag }}\" == \"auto\" ]; then\n            echo \"TAG=$VERSION\" >> $GITHUB_ENV;\n          elif [ \"${{ inputs.docker_image_tag }}\" == \"developer\" ]; then\n            echo \"TAG=$(sed 's|[/\\]|--|g' <<< ${{ inputs.source_reference }})\" >> $GITHUB_ENV;\n          else\n            echo \"TAG=${{ inputs.docker_image_tag }}\" >> $GITHUB_ENV;\n          fi\n\n      - name: Copy build.sh and utils to Dockerfile path\n        run: |\n          dockerfile_path=\"packages/${{ inputs.system }}s/amd64/manager\"\n          echo \"DOCKERFILE_PATH=$dockerfile_path\" >> $GITHUB_ENV\n          cp packages/build.sh $dockerfile_path\n          cp packages/${{ inputs.system }}s/utils/* $dockerfile_path\n\n      - name: Build and push image pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ env.TAG }} to Github Container Registry\n        run:\n          bash .github/actions/ghcr-pull-and-push/build_and_push_image_to_ghcr.sh ${{ secrets.GITHUB_TOKEN }} ${{ github.actor}} pkg_${{ inputs.system }}_manager_builder_amd64 ${{ env.DOCKERFILE_PATH }} ${{ env.TAG }}\n","repository_owner":"wazuh","repository_name":"wazuh","tokens_count":602,"workflow":"run-name: Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with \n  tag ${{ inputs.docker_image_tag }}\nname: Package - Upload manager images amd64\n\non:\n  workflow_dispatch:\n    inputs:\n      docker_image_tag:\n        description: |\n          Tag name of the Docker image to be uploaded.\n          Use 'developer' to set branch name as tag.\n          Use 'auto' to set branch version as tag.\n          If using a custom tag, use only '-', '_', '.' and alphanumeric characters.\n          Default is 'auto'.\n        required: false\n        default: auto\n      system:\n        type: choice\n        description: |\n          System image to upload [deb, rpm].\n        options:\n        - deb\n        - rpm\n      source_reference:\n        description: |\n          Branch from wazuh/wazuh repository to use.\n        required: true\n\njobs:\n  Upload-package-building-images:\n    runs-on: ubuntu-latest\n    timeout-minutes: 140\n    name: Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with \n      tag ${{ inputs.docker_image_tag }}\n\n    steps:\n    - name: Checkout wazuh/wazuh repository\n      uses: actions/checkout@v4\n      with:\n        repository: wazuh/wazuh\n        ref: ${{ inputs.source_reference }}\n\n    - name: Set TAG\n      run: |\n        VERSION=\"$(grep '\"version\"' VERSION.json | sed -E 's/.*\"version\": *\"([^\"]+)\".*/\\1/')\"\n        if [ \"${{ inputs.docker_image_tag }}\" == \"auto\" ]; then\n          echo \"TAG=$VERSION\" >> $GITHUB_ENV;\n        elif [ \"${{ inputs.docker_image_tag }}\" == \"developer\" ]; then\n          echo \"TAG=$(sed 's|[/\\]|--|g' <<< ${{ inputs.source_reference }})\" >> $GITHUB_ENV;\n        else\n          echo \"TAG=${{ inputs.docker_image_tag }}\" >> $GITHUB_ENV;\n        fi\n\n    - name: Copy build.sh and utils to Dockerfile path\n      run: |\n        dockerfile_path=\"packages/${{ inputs.system }}s/amd64/manager\"\n        echo \"DOCKERFILE_PATH=$dockerfile_path\" >> $GITHUB_ENV\n        cp packages/build.sh $dockerfile_path\n        cp packages/${{ inputs.system }}s/utils/* $dockerfile_path\n\n    - name: Build and push image pkg_${{ inputs.system }}_manager_builder_amd64 \n        with tag ${{ env.TAG }} to Github Container Registry\n      run: bash \n        .github/actions/ghcr-pull-and-push/build_and_push_image_to_ghcr.sh ${{ \n        secrets.GITHUB_TOKEN }} ${{ github.actor}} pkg_${{ inputs.system \n        }}_manager_builder_amd64 ${{ env.DOCKERFILE_PATH }} ${{ env.TAG }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Package - Upload manager images amd64` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}`. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 3 inputs: docker_image_tag-this input represents tag name of the docker image to be uploaded.\nuse 'developer' to set branch name as tag.\nuse 'auto' to set branch version as tag.\nif using a custom tag, use only '-', '_', '.' and alphanumeric characters.\ndefault is 'auto'.\n, it is optional and its default value is auto; system-the data type is choice, this input represents system image to upload [deb, rpm].\n and it has options including deb and rpm; source_reference-this input represents branch from wazuh/wazuh repository to use.\n and it must be supplied. The workflow has one job. The 1st job is named `Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}` and its job id is `Upload-package-building-images`. ","prompt_level2":"Generate a GitHub Workflow named `Package - Upload manager images amd64` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}`. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 3 inputs: docker_image_tag-this input represents tag name of the docker image to be uploaded.\nuse 'developer' to set branch name as tag.\nuse 'auto' to set branch version as tag.\nif using a custom tag, use only '-', '_', '.' and alphanumeric characters.\ndefault is 'auto'.\n, it is optional and its default value is auto; system-the data type is choice, this input represents system image to upload [deb, rpm].\n and it has options including deb and rpm; source_reference-this input represents branch from wazuh/wazuh repository to use.\n and it must be supplied. The workflow has one job. The 1st job is named `Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}` and its job id is `Upload-package-building-images`. The job `Upload-package-building-images` has 4 steps. The 1st step is named `Checkout wazuh/wazuh`. The 2nd step is named `Set TAG`. The 3rd step is named `Copy build.sh and utils to Dockerfile path`. The 4th step is named `Build and push image pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ env.TAG }} to Github Container Registry`. ","prompt_level3":"Generate a GitHub Workflow named `Package - Upload manager images amd64` for a GitHub repository whose primary programming language is C++. The name for workflow runs is set to `Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}`. This workflow will be triggered by an event: someone manually triggers the workflow. This workflow receives 3 inputs: docker_image_tag-this input represents tag name of the docker image to be uploaded.\nuse 'developer' to set branch name as tag.\nuse 'auto' to set branch version as tag.\nif using a custom tag, use only '-', '_', '.' and alphanumeric characters.\ndefault is 'auto'.\n, it is optional and its default value is auto; system-the data type is choice, this input represents system image to upload [deb, rpm].\n and it has options including deb and rpm; source_reference-this input represents branch from wazuh/wazuh repository to use.\n and it must be supplied. The workflow has one job. The 1st job is named `Package - Upload pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ inputs.docker_image_tag }}` and its job id is `Upload-package-building-images`. This job will run on ubuntu-latest runner. The maximum number of minutes to run the job is 140. The job `Upload-package-building-images` has 4 steps. The 1st step is named `Checkout wazuh/wazuh`. This step runs action `actions/checkout` tagged as v4. The step defines 2 input parameters for the action: `repository` is set to `wazuh/wazuh` and `ref` is set to `${{ inputs.source_reference }}`. The 2nd step is named `Set TAG`. This step runs a script: `VERSION=\"$(grep '\"version\"' VERSION.json | sed -E 's/.*\"version\": *\"([^\"]+)\".*/\\1/')\"\nif [ \"${{ inputs.docker_image_tag }}\" == \"auto\" ]; then\n  echo \"TAG=$VERSION\" >> $GITHUB_ENV;\nelif [ \"${{ inputs.docker_image_tag }}\" == \"developer\" ]; then\n  echo \"TAG=$(sed 's|[/\\]|--|g' <<< ${{ inputs.source_reference }})\" >> $GITHUB_ENV;\nelse\n  echo \"TAG=${{ inputs.docker_image_tag }}\" >> $GITHUB_ENV;\nfi\n`. The 3rd step is named `Copy build.sh and utils to Dockerfile path`. This step runs a script: `dockerfile_path=\"packages/${{ inputs.system }}s/amd64/manager\"\necho \"DOCKERFILE_PATH=$dockerfile_path\" >> $GITHUB_ENV\ncp packages/build.sh $dockerfile_path\ncp packages/${{ inputs.system }}s/utils/* $dockerfile_path\n`. The 4th step is named `Build and push image pkg_${{ inputs.system }}_manager_builder_amd64 with tag ${{ env.TAG }} to Github Container Registry`. This step runs a script: `bash .github/actions/ghcr-pull-and-push/build_and_push_image_to_ghcr.sh ${{ secrets.GITHUB_TOKEN }} ${{ github.actor}} pkg_${{ inputs.system }}_manager_builder_amd64 ${{ env.DOCKERFILE_PATH }} ${{ env.TAG }}`. ","nb_triggers":1,"triggers":["workflow_dispatch"],"nb_jobs":1,"nb_actions":1,"actions":["actions/checkout"],"actions_details":[{"version":"v4","name":"actions/checkout"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":4,"cyclomatic_complexity":1}
{"id":39834,"repository_id":56894538,"mainLanguage":"TypeScript","file_name":"pipeline-build-docker.yml","file_content":"name: Build docker pipeline\non:\n  workflow_call:\n    inputs:\n      environment:\n        description: Environment for build\n        default: 'staging'\n        type: string\n\n      for_e2e_tests:\n        description: Build for e2e docker tests\n        default: false\n        type: boolean\n\n      debug:\n        description: SSH Debug\n        default: false\n        type: boolean\n\n      enterprise:\n        description: Enterprise build\n        type: boolean\n\njobs:\n  build:\n    name: Build docker\n    runs-on: ubuntu-24.04\n    environment: ${{ inputs.environment }}\n    steps:\n      - uses: actions/checkout@v4\n\n      # SSH Debug\n      - name: Enable SSH\n        uses: mxschmitt/action-tmate@v3\n        if: inputs.debug\n        with:\n          detached: true\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      - name: Install all libs and dependencies\n        uses: ./.github/actions/install-all-build-libs\n        with:\n          keytar-host-mirror: ${{ secrets.NPM_CONFIG_KEYTAR_BINARY_HOST_MIRROR }}\n          sqlite3-host-mirror: ${{ secrets.NPM_CONFIG_NODE_SQLITE3_BINARY_HOST_MIRROR }}\n\n      - name: Build sources\n        run: ./.github/build/build.sh\n\n        # todo: matrix\n      - name: Build web archives for e2e tests\n        if: inputs.for_e2e_tests\n        run: |\n          unset npm_config_keytar_binary_host_mirror\n          unset npm_config_node_sqlite3_binary_host_mirror\n          # Docker sources\n          PLATFORM=linux ARCH=x64 LIBC=musl .github/build/build_modules.sh\n\n      - name: Build web archives\n        if: ${{ !inputs.for_e2e_tests }}\n        run: |\n          unset npm_config_keytar_binary_host_mirror\n          unset npm_config_node_sqlite3_binary_host_mirror\n          # Docker sources\n          PLATFORM=linux ARCH=x64 LIBC=musl .github/build/build_modules.sh\n          PLATFORM=linux ARCH=arm64 LIBC=musl .github/build/build_modules.sh\n          # Redis Stack + VSC Linux\n          PLATFORM=linux ARCH=x64 .github/build/build_modules.sh\n          PLATFORM=linux ARCH=arm64 .github/build/build_modules.sh\n          # VSC Darwin\n          PLATFORM=darwin ARCH=x64 .github/build/build_modules.sh\n          PLATFORM=darwin ARCH=arm64 .github/build/build_modules.sh\n          # VSC Windows\n          PLATFORM=win32 ARCH=x64 .github/build/build_modules.sh\n\n      - name: Build Docker (x64)\n        run: |\n          # Build alpine x64 image\n          docker buildx build \\\n          -f .github/build/build.Dockerfile \\\n          --platform linux/amd64 \\\n          --build-arg DIST=release/web/Redis-Insight-web-linux-musl.x64.tar.gz \\\n          --build-arg NODE_ENV=\"$ENV\" \\\n          --build-arg RI_SEGMENT_WRITE_KEY=\"$RI_SEGMENT_WRITE_KEY\" \\\n          -t redisinsight:amd64 \\\n          .\n\n          mkdir -p release/docker\n          docker image save -o release/docker/docker-linux-alpine.amd64.tar redisinsight:amd64\n\n      - name: Build Docker (arm64)\n        if: ${{ !inputs.for_e2e_tests }}\n        run: |\n          # Build alpine arm64 image\n          docker buildx build \\\n          -f .github/build/build.Dockerfile \\\n          --platform linux/arm64 \\\n          --build-arg DIST=release/web/Redis-Insight-web-linux-musl.arm64.tar.gz \\\n          --build-arg NODE_ENV=\"$ENV\" \\\n          --build-arg RI_SEGMENT_WRITE_KEY=\"$RI_SEGMENT_WRITE_KEY\" \\\n          -t redisinsight:arm64 \\\n          .\n\n          mkdir -p release/docker\n          docker image save -o release/docker/docker-linux-alpine.arm64.tar redisinsight:arm64\n\n      - uses: actions/upload-artifact@v4\n        name: Upload docker builds\n        with:\n          if-no-files-found: warn\n          name: docker-builds\n          path: |\n            ./release/docker\n            ./release/web\n            ./release/web-mini\n\n    env:\n      ENV: ${{ vars.ENV }}\n      RI_AI_CONVAI_TOKEN: ${{ secrets.RI_AI_CONVAI_TOKEN }}\n      RI_AI_QUERY_PASS: ${{ secrets.RI_AI_QUERY_PASS }}\n      RI_AI_QUERY_USER: ${{ secrets.RI_AI_QUERY_USER }}\n      RI_CLOUD_API_URL: ${{ secrets.RI_CLOUD_API_URL }}\n      RI_CLOUD_CAPI_URL: ${{ secrets.RI_CLOUD_CAPI_URL }}\n      RI_CLOUD_IDP_AUTHORIZE_URL: ${{ secrets.RI_CLOUD_IDP_AUTHORIZE_URL }}\n      RI_CLOUD_IDP_CLIENT_ID: ${{ secrets.RI_CLOUD_IDP_CLIENT_ID }}\n      RI_CLOUD_IDP_GH_ID: ${{ secrets.RI_CLOUD_IDP_GH_ID }}\n      RI_CLOUD_IDP_GOOGLE_ID: ${{ secrets.RI_CLOUD_IDP_GOOGLE_ID }}\n      RI_CLOUD_IDP_ISSUER: ${{ secrets.RI_CLOUD_IDP_ISSUER }}\n      RI_CLOUD_IDP_REDIRECT_URI: ${{ secrets.RI_CLOUD_IDP_REDIRECT_URI }}\n      RI_CLOUD_IDP_TOKEN_URL: ${{ secrets.RI_CLOUD_IDP_TOKEN_URL }}\n      RI_SEGMENT_WRITE_KEY: ${{ secrets.RI_SEGMENT_WRITE_KEY }}\n      RI_SERVER_TLS_CERT: ${{ secrets.RI_SERVER_TLS_CERT }}\n      RI_SERVER_TLS_KEY: ${{ secrets.RI_SERVER_TLS_KEY }}\n      RI_FEATURES_CONFIG_URL: ${{ secrets.RI_FEATURES_CONFIG_URL }}\n      RI_UPGRADES_LINK: ${{ secrets.RI_UPGRADES_LINK }}\n      RI_FEATURES_CLOUD_ADS_DEFAULT_FLAG: ${{ inputs.enterprise == false }}\n      RI_DISABLE_AUTO_UPGRADE: ${{ inputs.enterprise }}\n","repository_owner":"redisinsight","repository_name":"redisinsight","tokens_count":1289,"workflow":"name: Build docker pipeline\non:\n  workflow_call:\n    inputs:\n      environment:\n        description: Environment for build\n        default: staging\n        type: string\n\n      for_e2e_tests:\n        description: Build for e2e docker tests\n        default: false\n        type: boolean\n\n      debug:\n        description: SSH Debug\n        default: false\n        type: boolean\n\n      enterprise:\n        description: Enterprise build\n        type: boolean\n\njobs:\n  build:\n    name: Build docker\n    runs-on: ubuntu-24.04\n    environment: ${{ inputs.environment }}\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n      # SSH Debug\n    - name: Enable SSH\n      uses: mxschmitt/action-tmate@v3\n      if: inputs.debug\n      with:\n        detached: true\n\n    - name: Set up QEMU\n      uses: docker/setup-qemu-action@v3\n\n    - name: Install all libs and dependencies\n      uses: ./.github/actions/install-all-build-libs\n      with:\n        keytar-host-mirror: ${{ secrets.NPM_CONFIG_KEYTAR_BINARY_HOST_MIRROR }}\n        sqlite3-host-mirror: ${{ \n          secrets.NPM_CONFIG_NODE_SQLITE3_BINARY_HOST_MIRROR }}\n\n    - name: Build sources\n      run: ./.github/build/build.sh\n\n        # todo: matrix\n    - name: Build web archives for e2e tests\n      if: inputs.for_e2e_tests\n      run: |\n        unset npm_config_keytar_binary_host_mirror\n        unset npm_config_node_sqlite3_binary_host_mirror\n        # Docker sources\n        PLATFORM=linux ARCH=x64 LIBC=musl .github/build/build_modules.sh\n\n    - name: Build web archives\n      if: ${{ !inputs.for_e2e_tests }}\n      run: |\n        unset npm_config_keytar_binary_host_mirror\n        unset npm_config_node_sqlite3_binary_host_mirror\n        # Docker sources\n        PLATFORM=linux ARCH=x64 LIBC=musl .github/build/build_modules.sh\n        PLATFORM=linux ARCH=arm64 LIBC=musl .github/build/build_modules.sh\n        # Redis Stack + VSC Linux\n        PLATFORM=linux ARCH=x64 .github/build/build_modules.sh\n        PLATFORM=linux ARCH=arm64 .github/build/build_modules.sh\n        # VSC Darwin\n        PLATFORM=darwin ARCH=x64 .github/build/build_modules.sh\n        PLATFORM=darwin ARCH=arm64 .github/build/build_modules.sh\n        # VSC Windows\n        PLATFORM=win32 ARCH=x64 .github/build/build_modules.sh\n\n    - name: Build Docker (x64)\n      run: |\n        # Build alpine x64 image\n        docker buildx build \\\n        -f .github/build/build.Dockerfile \\\n        --platform linux/amd64 \\\n        --build-arg DIST=release/web/Redis-Insight-web-linux-musl.x64.tar.gz \\\n        --build-arg NODE_ENV=\"$ENV\" \\\n        --build-arg RI_SEGMENT_WRITE_KEY=\"$RI_SEGMENT_WRITE_KEY\" \\\n        -t redisinsight:amd64 \\\n        .\n\n        mkdir -p release/docker\n        docker image save -o release/docker/docker-linux-alpine.amd64.tar redisinsight:amd64\n\n    - name: Build Docker (arm64)\n      if: ${{ !inputs.for_e2e_tests }}\n      run: |\n        # Build alpine arm64 image\n        docker buildx build \\\n        -f .github/build/build.Dockerfile \\\n        --platform linux/arm64 \\\n        --build-arg DIST=release/web/Redis-Insight-web-linux-musl.arm64.tar.gz \\\n        --build-arg NODE_ENV=\"$ENV\" \\\n        --build-arg RI_SEGMENT_WRITE_KEY=\"$RI_SEGMENT_WRITE_KEY\" \\\n        -t redisinsight:arm64 \\\n        .\n\n        mkdir -p release/docker\n        docker image save -o release/docker/docker-linux-alpine.arm64.tar redisinsight:arm64\n\n    - uses: actions/upload-artifact@v4\n      name: Upload docker builds\n      with:\n        if-no-files-found: warn\n        name: docker-builds\n        path: |\n          ./release/docker\n          ./release/web\n          ./release/web-mini\n\n    env:\n      ENV: ${{ vars.ENV }}\n      RI_AI_CONVAI_TOKEN: ${{ secrets.RI_AI_CONVAI_TOKEN }}\n      RI_AI_QUERY_PASS: ${{ secrets.RI_AI_QUERY_PASS }}\n      RI_AI_QUERY_USER: ${{ secrets.RI_AI_QUERY_USER }}\n      RI_CLOUD_API_URL: ${{ secrets.RI_CLOUD_API_URL }}\n      RI_CLOUD_CAPI_URL: ${{ secrets.RI_CLOUD_CAPI_URL }}\n      RI_CLOUD_IDP_AUTHORIZE_URL: ${{ secrets.RI_CLOUD_IDP_AUTHORIZE_URL }}\n      RI_CLOUD_IDP_CLIENT_ID: ${{ secrets.RI_CLOUD_IDP_CLIENT_ID }}\n      RI_CLOUD_IDP_GH_ID: ${{ secrets.RI_CLOUD_IDP_GH_ID }}\n      RI_CLOUD_IDP_GOOGLE_ID: ${{ secrets.RI_CLOUD_IDP_GOOGLE_ID }}\n      RI_CLOUD_IDP_ISSUER: ${{ secrets.RI_CLOUD_IDP_ISSUER }}\n      RI_CLOUD_IDP_REDIRECT_URI: ${{ secrets.RI_CLOUD_IDP_REDIRECT_URI }}\n      RI_CLOUD_IDP_TOKEN_URL: ${{ secrets.RI_CLOUD_IDP_TOKEN_URL }}\n      RI_SEGMENT_WRITE_KEY: ${{ secrets.RI_SEGMENT_WRITE_KEY }}\n      RI_SERVER_TLS_CERT: ${{ secrets.RI_SERVER_TLS_CERT }}\n      RI_SERVER_TLS_KEY: ${{ secrets.RI_SERVER_TLS_KEY }}\n      RI_FEATURES_CONFIG_URL: ${{ secrets.RI_FEATURES_CONFIG_URL }}\n      RI_UPGRADES_LINK: ${{ secrets.RI_UPGRADES_LINK }}\n      RI_FEATURES_CLOUD_ADS_DEFAULT_FLAG: ${{ inputs.enterprise == false }}\n      RI_DISABLE_AUTO_UPGRADE: ${{ inputs.enterprise }}\n","augmented_workflow":"","prompt_level1":"Generate a GitHub Workflow named `Build docker pipeline` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 4 inputs: environment-this input represents environment for build, its default value is staging and the data type is string; for_e2e_tests-this input represents build for e2e docker tests, its default value is False and the data type is boolean; debug-this input represents ssh debug, its default value is False and the data type is boolean; enterprise-this input represents enterprise build and the data type is boolean. The workflow has one job. The 1st job is named `Build docker` and its job id is `build`. ","prompt_level2":"Generate a GitHub Workflow named `Build docker pipeline` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 4 inputs: environment-this input represents environment for build, its default value is staging and the data type is string; for_e2e_tests-this input represents build for e2e docker tests, its default value is False and the data type is boolean; debug-this input represents ssh debug, its default value is False and the data type is boolean; enterprise-this input represents enterprise build and the data type is boolean. The workflow has one job. The 1st job is named `Build docker` and its job id is `build`. The job `build` has 10 steps. The 1st step is named `Checkout repository`. The 2nd step is named `Enable SSH`. The 3rd step is named `Set up QEMU`. The 4th step is named `Install all libs and dependencies`. The 5th step is named `Build sources`. The 6th step is named `Build web archives for e2e tests`. The 7th step is named `Build web archives`. The 8th step is named `Build Docker (x64)`. The 9th step is named `Build Docker (arm64)`. The 10th step is named `Upload docker builds`. ","prompt_level3":"Generate a GitHub Workflow named `Build docker pipeline` for a GitHub repository whose primary programming language is TypeScript. This workflow will be triggered by an event: this workflow is called by another workflow. This workflow receives 4 inputs: environment-this input represents environment for build, its default value is staging and the data type is string; for_e2e_tests-this input represents build for e2e docker tests, its default value is False and the data type is boolean; debug-this input represents ssh debug, its default value is False and the data type is boolean; enterprise-this input represents enterprise build and the data type is boolean. The workflow has one job. The 1st job is named `Build docker` and its job id is `build`. This job will run on ubuntu-24.04 runner. The job sets 20 environment variables to use: `ENV` is set to `${{ vars.ENV }}`, `RI_AI_CONVAI_TOKEN` is set to `${{ secrets.RI_AI_CONVAI_TOKEN }}`, `RI_AI_QUERY_PASS` is set to `${{ secrets.RI_AI_QUERY_PASS }}`, `RI_AI_QUERY_USER` is set to `${{ secrets.RI_AI_QUERY_USER }}`, `RI_CLOUD_API_URL` is set to `${{ secrets.RI_CLOUD_API_URL }}`, `RI_CLOUD_CAPI_URL` is set to `${{ secrets.RI_CLOUD_CAPI_URL }}`, `RI_CLOUD_IDP_AUTHORIZE_URL` is set to `${{ secrets.RI_CLOUD_IDP_AUTHORIZE_URL }}`, `RI_CLOUD_IDP_CLIENT_ID` is set to `${{ secrets.RI_CLOUD_IDP_CLIENT_ID }}`, `RI_CLOUD_IDP_GH_ID` is set to `${{ secrets.RI_CLOUD_IDP_GH_ID }}`, `RI_CLOUD_IDP_GOOGLE_ID` is set to `${{ secrets.RI_CLOUD_IDP_GOOGLE_ID }}`, `RI_CLOUD_IDP_ISSUER` is set to `${{ secrets.RI_CLOUD_IDP_ISSUER }}`, `RI_CLOUD_IDP_REDIRECT_URI` is set to `${{ secrets.RI_CLOUD_IDP_REDIRECT_URI }}`, `RI_CLOUD_IDP_TOKEN_URL` is set to `${{ secrets.RI_CLOUD_IDP_TOKEN_URL }}`, `RI_SEGMENT_WRITE_KEY` is set to `${{ secrets.RI_SEGMENT_WRITE_KEY }}`, `RI_SERVER_TLS_CERT` is set to `${{ secrets.RI_SERVER_TLS_CERT }}`, `RI_SERVER_TLS_KEY` is set to `${{ secrets.RI_SERVER_TLS_KEY }}`, `RI_FEATURES_CONFIG_URL` is set to `${{ secrets.RI_FEATURES_CONFIG_URL }}`, `RI_UPGRADES_LINK` is set to `${{ secrets.RI_UPGRADES_LINK }}`, `RI_FEATURES_CLOUD_ADS_DEFAULT_FLAG` is set to `${{ inputs.enterprise == false }}` and `RI_DISABLE_AUTO_UPGRADE` is set to `${{ inputs.enterprise }}`. This job references ${{ inputs.environment }} environment. The job `build` has 10 steps. The 1st step is named `Checkout repository`. This step runs action `actions/checkout` tagged as v4. The 2nd step is named `Enable SSH`. This step will run only if the condition(inputs.debug) is met. This step runs action `mxschmitt/action-tmate` tagged as v3. The step defines an input parameter for the action: `detached` is set to `True`. The 3rd step is named `Set up QEMU`. This step runs action `docker/setup-qemu-action` tagged as v3. The 4th step is named `Install all libs and dependencies`. This step runs action `./.github/actions/install-all-build-libs`.The step defines 2 input parameters for the action: `keytar-host-mirror` is set to `${{ secrets.NPM_CONFIG_KEYTAR_BINARY_HOST_MIRROR }}` and `sqlite3-host-mirror` is set to `${{ secrets.NPM_CONFIG_NODE_SQLITE3_BINARY_HOST_MIRROR }}`. The 5th step is named `Build sources`. This step runs a script: `./.github/build/build.sh`. The 6th step is named `Build web archives for e2e tests`. This step will run only if the condition(inputs.for_e2e_tests) is met. This step runs a script: `unset npm_config_keytar_binary_host_mirror\nunset npm_config_node_sqlite3_binary_host_mirror\n# Docker sources\nPLATFORM=linux ARCH=x64 LIBC=musl .github/build/build_modules.sh\n`. The 7th step is named `Build web archives`. This step will run only if the condition(${{ !inputs.for_e2e_tests }}) is met. This step runs a script: `unset npm_config_keytar_binary_host_mirror\nunset npm_config_node_sqlite3_binary_host_mirror\n# Docker sources\nPLATFORM=linux ARCH=x64 LIBC=musl .github/build/build_modules.sh\nPLATFORM=linux ARCH=arm64 LIBC=musl .github/build/build_modules.sh\n# Redis Stack + VSC Linux\nPLATFORM=linux ARCH=x64 .github/build/build_modules.sh\nPLATFORM=linux ARCH=arm64 .github/build/build_modules.sh\n# VSC Darwin\nPLATFORM=darwin ARCH=x64 .github/build/build_modules.sh\nPLATFORM=darwin ARCH=arm64 .github/build/build_modules.sh\n# VSC Windows\nPLATFORM=win32 ARCH=x64 .github/build/build_modules.sh\n`. The 8th step is named `Build Docker (x64)`. This step runs a script: `# Build alpine x64 image\ndocker buildx build \\\n-f .github/build/build.Dockerfile \\\n--platform linux/amd64 \\\n--build-arg DIST=release/web/Redis-Insight-web-linux-musl.x64.tar.gz \\\n--build-arg NODE_ENV=\"$ENV\" \\\n--build-arg RI_SEGMENT_WRITE_KEY=\"$RI_SEGMENT_WRITE_KEY\" \\\n-t redisinsight:amd64 \\\n.\n\nmkdir -p release/docker\ndocker image save -o release/docker/docker-linux-alpine.amd64.tar redisinsight:amd64\n`. The 9th step is named `Build Docker (arm64)`. This step will run only if the condition(${{ !inputs.for_e2e_tests }}) is met. This step runs a script: `# Build alpine arm64 image\ndocker buildx build \\\n-f .github/build/build.Dockerfile \\\n--platform linux/arm64 \\\n--build-arg DIST=release/web/Redis-Insight-web-linux-musl.arm64.tar.gz \\\n--build-arg NODE_ENV=\"$ENV\" \\\n--build-arg RI_SEGMENT_WRITE_KEY=\"$RI_SEGMENT_WRITE_KEY\" \\\n-t redisinsight:arm64 \\\n.\n\nmkdir -p release/docker\ndocker image save -o release/docker/docker-linux-alpine.arm64.tar redisinsight:arm64\n`. The 10th step is named `Upload docker builds`. This step runs action `actions/upload-artifact` tagged as v4. The step defines 3 input parameters for the action: `if-no-files-found` is set to `warn`, `name` is set to `docker-builds` and `path` is set to `./release/docker\n./release/web\n./release/web-mini\n`. ","nb_triggers":1,"triggers":["workflow_call"],"nb_jobs":1,"nb_actions":5,"actions":["./.github/actions/install-all-build-libs","actions/checkout","actions/upload-artifact","docker/setup-qemu-action","mxschmitt/action-tmate"],"actions_details":[{"version":"v4","name":"actions/checkout"},{"version":"v3","name":"mxschmitt/action-tmate"},{"version":"v3","name":"docker/setup-qemu-action"},{"version":null,"name":"./.github/actions/install-all-build-libs"},{"version":"v4","name":"actions/upload-artifact"}],"nb_reusable_workflows":0,"reusable_workflows":[],"nb_steps":10,"cyclomatic_complexity":1}
